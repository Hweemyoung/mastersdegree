{"twitter": {"1089050625755750401": {"author": "@Rosenchild", "datetime": "2019-01-26 06:41:17", "content_summary": "RT @Rosenchild: Large-Batch Training for #LSTM and Beyond \ud83d\udda5\ufe0fhttps://t.co/DG3wpLHSTj @HubBucket @HubDataScience @HubAnalytics1 @HubAnalysi\u2026", "followers": "11,919"}, "1089137186555875328": {"author": "@63556poiuytrewq", "datetime": "2019-01-26 12:25:15", "content_summary": "RT @mosko_mule: Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual w\u2026", "followers": "417"}, "1089196673534910467": {"author": "@morioka", "datetime": "2019-01-26 16:21:37", "content_summary": "RT @mosko_mule: Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual w\u2026", "followers": "823"}, "1089160892384591873": {"author": "@8kazu3", "datetime": "2019-01-26 13:59:27", "content_summary": "RT @mosko_mule: Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual w\u2026", "followers": "464"}, "1088929805469392899": {"author": "@diegovogeid", "datetime": "2019-01-25 22:41:11", "content_summary": "RT @Miles_Brundage: \"Large-Batch Training for LSTM and Beyond,\" You et al.: https://t.co/EPNFibo3HQ", "followers": "68"}, "1088629602711416832": {"author": "@BrundageBot", "datetime": "2019-01-25 02:48:17", "content_summary": "Large-Batch Training for LSTM and Beyond. Yang You, Jonathan Hseu, Chris Ying, James Demmel, Kurt Keutzer, and Cho-Jui Hsieh https://t.co/vC6AaUenO8", "followers": "3,858"}, "1088615850695970816": {"author": "@StatMLPapers", "datetime": "2019-01-25 01:53:38", "content_summary": "Large-Batch Training for LSTM and Beyond. (arXiv:1901.08256v1 [cs.LG]) https://t.co/ni6QR66aEj", "followers": "9,664"}, "1088684154999447555": {"author": "@TheCuriousLuke", "datetime": "2019-01-25 06:25:03", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Large-Batch Training for LSTM and Beyond. (arXiv:1901.08256v1 [cs.LG]) https://t.co/cCazXZcq\u2026", "followers": "4,547"}, "1089160097874362370": {"author": "@CharaBentoPapa", "datetime": "2019-01-26 13:56:17", "content_summary": "RT @mosko_mule: Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual w\u2026", "followers": "44"}, "1088955961442676736": {"author": "@arxiv_org", "datetime": "2019-01-26 00:25:07", "content_summary": "Large-Batch Training for LSTM and Beyond. https://t.co/UahuaODapm https://t.co/YvrwjyPOnP", "followers": "12,713"}, "1089103390775431169": {"author": "@HubBucketIOT", "datetime": "2019-01-26 10:10:57", "content_summary": "RT @HubBucket: Large-Batch Training for #LSTM and Beyond \ud83d\udda5\ufe0fhttps://t.co/w1AACRPg48 @HubBucket @HubDataScience @HubAnalytics1 @HubAnalysis\u2026", "followers": "135"}, "1088728638739177472": {"author": "@arxivml", "datetime": "2019-01-25 09:21:49", "content_summary": "\"Large-Batch Training for LSTM and Beyond\", Yang You, Jonathan Hseu, Chris Ying, James Demmel, Kurt Keutzer, Cho-Ju\u2026 https://t.co/rPoqN4B72v", "followers": "767"}, "1089040916038541312": {"author": "@Rosenchild", "datetime": "2019-01-26 06:02:42", "content_summary": "Large-Batch Training for #LSTM and Beyond \ud83d\udda5\ufe0fhttps://t.co/DG3wpLHSTj @HubBucket @HubDataScience @HubAnalytics1 @HubAnalysis1 @HubGraph @HubDispatch @HubBucketEP @HubClouds @HubStackOS @HubSparks @HubXStream @HubHarbor @HubBucketIOT #DataScience #DeepLear", "followers": "11,919"}, "1088924180177870848": {"author": "@Miles_Brundage", "datetime": "2019-01-25 22:18:50", "content_summary": "\"Large-Batch Training for LSTM and Beyond,\" You et al.: https://t.co/EPNFibo3HQ", "followers": "25,578"}, "1089695854263332864": {"author": "@__A_WADA__", "datetime": "2019-01-28 01:25:11", "content_summary": "RT @mosko_mule: Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual w\u2026", "followers": "50"}, "1088632569384632320": {"author": "@arxiv_cs_LG", "datetime": "2019-01-25 03:00:05", "content_summary": "Large-Batch Training for LSTM and Beyond. Yang You, Jonathan Hseu, Chris Ying, James Demmel, Kurt Keutzer, and Cho-Jui Hsieh https://t.co/0nghZl52uw", "followers": "308"}, "1088625154899525632": {"author": "@deep_rl", "datetime": "2019-01-25 02:30:37", "content_summary": "Large-Batch Training for LSTM and Beyond - Yang You https://t.co/dDtXSmDfCm", "followers": "857"}, "1089055367454212096": {"author": "@HubBucket", "datetime": "2019-01-26 07:00:07", "content_summary": "Large-Batch Training for #LSTM and Beyond \ud83d\udda5\ufe0fhttps://t.co/w1AACRPg48 @HubBucket @HubDataScience @HubAnalytics1 @HubAnalysis1 @HubGraph @HubDispatch @HubBucketEP @HubClouds @HubStackOS @HubSparks @HubXStream @HubHarbor @HubBucketIOT #DataScience #DeepLear", "followers": "5,310"}, "1089136674557161472": {"author": "@imenurok", "datetime": "2019-01-26 12:23:13", "content_summary": "RT @mosko_mule: Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual w\u2026", "followers": "2,042"}, "1089126065589678080": {"author": "@Rosenchild", "datetime": "2019-01-26 11:41:03", "content_summary": "RT @HubBucket: Large-Batch Training for #LSTM and Beyond \ud83d\udda5\ufe0fhttps://t.co/w1AACRPg48 @HubBucket @HubDataScience @HubAnalytics1 @HubAnalysis\u2026", "followers": "11,919"}, "1089157736863014912": {"author": "@udmrzn", "datetime": "2019-01-26 13:46:54", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Large-Batch Training for LSTM and Beyond. (arXiv:1901.08256v1 [cs.LG]) https://t.co/cCazXZcq\u2026", "followers": "1,348"}, "1088673143697350657": {"author": "@arXiv__ml", "datetime": "2019-01-25 05:41:18", "content_summary": "#arXiv #machinelearning [cs.LG] Large-Batch Training for LSTM and Beyond. (arXiv:1901.08256v1 [cs.LG]) https://t.co/cCazXZcqfs Large-batch training approaches have enabled researchers to utilize large-scale distributed processing and greatly accelerate de", "followers": "1,700"}, "1089147190562324480": {"author": "@_moto86", "datetime": "2019-01-26 13:05:00", "content_summary": "RT @mosko_mule: Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual w\u2026", "followers": "113"}, "1090260732627771393": {"author": "@HubBucket", "datetime": "2019-01-29 14:49:49", "content_summary": "RT @HubBucket: Large-Batch Training for #LSTM and Beyond \ud83d\udda5\ufe0fhttps://t.co/w1AACRPg48 @HubBucket @HubDataScience @HubAnalytics1 @HubAnalysis\u2026", "followers": "5,310"}, "1089136455560060928": {"author": "@mosko_mule", "datetime": "2019-01-26 12:22:20", "content_summary": "Large-Batch Training for LSTM and Beyond https://t.co/YxJ9EQy8x0 \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c8k\u3092\u8d85\u3048\u308b\u3068BS\u3068\u5b66\u7fd2\u7387\u306e\u6bd4\u4f8b\u95a2\u4fc2\u304c\u5d29\u308c\u8abf\u6574\u304c\u5927\u5909\u3060\u304c\u3001linear-epoch gradual warmup\u3092\u7528\u3044\u308b\u3068\u5b66\u7fd2\u7387\u304c\u221aBS\u306b\u6bd4\u4f8b\u3059\u308b\u306e\u3067\u7c21\u5358\u306b\uff08\u4e88\u7b97\u304c\u3042\u308c\u3070\uff09\u3002\u5f93\u6765\u306eCNN\u3060\u3051\u3067\u306a\u304fLSTM\u3067\u3082\u8d85\u5de8\u5927\u30d0\u30c3\u30c1\u306e\u30b9\u30b1\u30fc\u30eb\u3092\u78ba\u8a8d\u3002 https://t.co/pzn7Tp3MeH", "followers": "2,653"}, "1088638206264918016": {"author": "@mlmemoirs", "datetime": "2019-01-25 03:22:28", "content_summary": "#arXiv #machinelearning [cs.LG] Large-Batch Training for LSTM and Beyond. (arXiv:1901.08256v1 [cs.LG]) https://t.co/TovhpggP7p Large-batch training approaches have enabled researchers to utilize large-scale distributed processing and greatly accelerate de", "followers": "1,247"}, "1089681915949518849": {"author": "@Rosenchild", "datetime": "2019-01-28 00:29:48", "content_summary": "RT @HubBucket: Large-Batch Training for #LSTM and Beyond \ud83d\udda5\ufe0fhttps://t.co/w1AACRPg48 @HubBucket @HubDataScience @HubAnalytics1 @HubAnalysis\u2026", "followers": "11,919"}, "1088961480316280834": {"author": "@AssistedEvolve", "datetime": "2019-01-26 00:47:03", "content_summary": "RT @Miles_Brundage: \"Large-Batch Training for LSTM and Beyond,\" You et al.: https://t.co/EPNFibo3HQ", "followers": "215"}, "1090773546979053569": {"author": "@arxiv_pop", "datetime": "2019-01-31 00:47:33", "content_summary": "2019/01/24 \u6295\u7a3f 5\u4f4d LG(Machine Learning) Large-Batch Training for LSTM and Beyond https://t.co/PKPUnIsjyq 11 Tweets 12 Retweets 59 Favorites", "followers": "691"}, "1092483543018758144": {"author": "@erogol", "datetime": "2019-02-04 18:02:28", "content_summary": "If you scale up the batch size k times, scale the initial learning rate by sqrt(k) and increase the warmup iterations k times to keep the performance the same... https://t.co/zuI5gPioGx", "followers": "506"}}, "queriedAt": "2020-05-21 20:00:17", "completed": "1", "citation_id": "54455979", "tab": "twitter"}