{"citation_id": "56155694", "tab": "twitter", "twitter": {"1100997106653908993": {"author": "@muktabh", "followers": "794", "datetime": "2019-02-28 05:52:20", "content_summary": "RT @Miles_Brundage: \"Provable Guarantees for Gradient-Based Meta-Learning,\" Khodak et al.: https://t.co/qKEvXDzrDy"}, "1100960394078834689": {"author": "@arxiv_cs_LG", "followers": "320", "datetime": "2019-02-28 03:26:27", "content_summary": "Provable Guarantees for Gradient-Based Meta-Learning. Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar https://t.co/kOsuR7Dthz"}, "1100938028284104704": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-28 01:57:35", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/Rj4hQdECtM Provable Guarantees for Gradient-Based Meta-Learning. (arXiv:1902.10644v1 [cs.LG])"}, "1100968387511869441": {"author": "@muktabh", "followers": "794", "datetime": "2019-02-28 03:58:13", "content_summary": "RT @arxiv_cs_LG: Provable Guarantees for Gradient-Based Meta-Learning. Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar https://t.\u2026"}, "1100956415693389824": {"author": "@deep_rl", "followers": "862", "datetime": "2019-02-28 03:10:38", "content_summary": "Provable Guarantees for Gradient-Based Meta-Learning - Mikhail Khodak https://t.co/BNTegbPz76"}, "1139925865033281536": {"author": "@DeterminedAI", "followers": "487", "datetime": "2019-06-15 16:01:19", "content_summary": "We look forward to the talk by our co-founder @atalwalkar at the #ICML2019 AMTL workshop (https://t.co/c2eeITO3vR) today at 1:45 pm. If you're interested, you can read the corresponding research paper \"Provable Guarantees for Gradient-Based Meta-Learning\""}, "1101272160482590720": {"author": "@jvmancuso", "followers": "648", "datetime": "2019-03-01 00:05:18", "content_summary": "RT @Miles_Brundage: \"Provable Guarantees for Gradient-Based Meta-Learning,\" Khodak et al.: https://t.co/qKEvXDzrDy"}, "1129186163162583040": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-05-17 00:45:35", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/KUE8KgEM0y Provable Guarantees for Gradient-Based Meta-Learning. (arXiv:1902.10644v2 [cs.LG] UPDATED)"}, "1129186647269150721": {"author": "@helioRocha_", "followers": "631", "datetime": "2019-05-17 00:47:30", "content_summary": "\"Provable Guarantees for Gradient-Based Meta-Learning. (arXiv:1902.10644v2 [cs.LG] UPDATED)\" #arXiv https://t.co/GRydJGzcTZ"}, "1101268972173811714": {"author": "@AssistedEvolve", "followers": "219", "datetime": "2019-02-28 23:52:38", "content_summary": "RT @Miles_Brundage: \"Provable Guarantees for Gradient-Based Meta-Learning,\" Khodak et al.: https://t.co/qKEvXDzrDy"}, "1100958231684435969": {"author": "@BrundageBot", "followers": "3,906", "datetime": "2019-02-28 03:17:51", "content_summary": "Provable Guarantees for Gradient-Based Meta-Learning. Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar https://t.co/q0bIvGIO8p"}, "1100974201798905857": {"author": "@arxivml", "followers": "782", "datetime": "2019-02-28 04:21:19", "content_summary": "\"Provable Guarantees for Gradient-Based Meta-Learning\", Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar https://t.co/z6QB3C8NAa"}, "1100994671931645952": {"author": "@Miles_Brundage", "followers": "25,873", "datetime": "2019-02-28 05:42:39", "content_summary": "\"Provable Guarantees for Gradient-Based Meta-Learning,\" Khodak et al.: https://t.co/qKEvXDzrDy"}, "1109293402309324800": {"author": "@ArxivSanityHype", "followers": "7", "datetime": "2019-03-23 03:18:51", "content_summary": "Provable Guarantees for Gradient-Based Meta-Learning https://t.co/u9ZpDejoNf https://t.co/DbUstTC53u"}, "1101031373220007936": {"author": "@gastronomy", "followers": "1,388", "datetime": "2019-02-28 08:08:30", "content_summary": "[arXiv] Provable Guarantees for Gradient-Based Meta-Learning. (arXiv:1902.10644v1 [cs.LG]) --> We study the problem of meta-learning through the lens of online convex optimization, developing a meta-algorithm bridging the gap between popular gradient-b"}, "1129281439495839744": {"author": "@pm_girl", "followers": "2,172", "datetime": "2019-05-17 07:04:10", "content_summary": "#Provable Guarantees for Gradient-Based Meta-Learning. (arXiv:1902.10644v2 [cs.LG] UPDATED) https://t.co/9wqODiO1T4 #artificialintelligence #ai"}, "1101131017656696832": {"author": "@EricSchles", "followers": "2,078", "datetime": "2019-02-28 14:44:27", "content_summary": "RT @Miles_Brundage: \"Provable Guarantees for Gradient-Based Meta-Learning,\" Khodak et al.: https://t.co/qKEvXDzrDy"}, "1101272824621105152": {"author": "@PerthMLGroup", "followers": "456", "datetime": "2019-03-01 00:07:56", "content_summary": "RT @Miles_Brundage: \"Provable Guarantees for Gradient-Based Meta-Learning,\" Khodak et al.: https://t.co/qKEvXDzrDy"}, "1100937460073275393": {"author": "@helioRocha_", "followers": "631", "datetime": "2019-02-28 01:55:19", "content_summary": "\"Provable Guarantees for Gradient-Based Meta-Learning. (arXiv:1902.10644v1 [cs.LG])\" #arXiv https://t.co/GRydJGzcTZ"}}, "completed": "1", "queriedAt": "2020-06-03 01:42:29"}