{"tab": "twitter", "completed": "1", "twitter": {"1097681491616825344": {"author": "@helioRocha_", "followers": "624", "datetime": "2019-02-19 02:17:16", "content_summary": "\"Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks. (arXiv:1902.06292v1 [https://t.co/jqZ5dwubSV])\" #arXiv https://t.co/e5hEyH4rmd"}, "1098253059975634944": {"author": "@sercanarik", "followers": "176", "datetime": "2019-02-20 16:08:28", "content_summary": "The preprint of our recent research on attention-based prototypical learning: https://t.co/erAGoZs8vV. Our method enables interpretability by outputting the samples most relevant to decision making, and yields well-calibrated confidence scores."}, "1099072085157122049": {"author": "@ZizhaoZhang", "followers": "139", "datetime": "2019-02-22 22:22:59", "content_summary": "RT @sercanarik: The preprint of our recent research on attention-based prototypical learning: https://t.co/erAGoZs8vV. Our method enables i\u2026"}, "1097843570621538306": {"author": "@arxivml", "followers": "768", "datetime": "2019-02-19 13:01:18", "content_summary": "\"Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks\", Sercan O\uff0e\u2026 https://t.co/qj0CErRQw3"}, "1097701906653368320": {"author": "@MLandDL_papers", "followers": "378", "datetime": "2019-02-19 03:38:23", "content_summary": "Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks. (arXiv:1902.06292v1 [cs.LG]) https://t.co/fPlhgzQkEF"}, "1097687354284879872": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-02-19 02:40:33", "content_summary": "Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks https://t.co/T4uJbJJsat"}, "1099079130719625216": {"author": "@ulasbagci", "followers": "403", "datetime": "2019-02-22 22:50:59", "content_summary": "Seems interesting! Congrats! This maybe useful for image based diagnosis applications (like last example you showed), do you have source code available public by any chance ? (So that we can try in radilogy images)"}, "1177443123040940032": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-27 04:41:31", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbK1321"}, "1132808882760421378": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-05-27 00:40:58", "content_summary": "Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1098360326951747584": {"author": "@arxiv_in_review", "followers": "1,298", "datetime": "2019-02-20 23:14:43", "content_summary": "#ICML2019 Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks. (arXiv:1902.06292v1 [cs\\.LG]) https://t.co/14yBIRIzh3"}, "1132929585467789312": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-05-27 08:40:36", "content_summary": "Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1098850647330512896": {"author": "@Eschersand", "followers": "748", "datetime": "2019-02-22 07:43:04", "content_summary": "We propose a framework for prototypical learning that bases decision-making on few relevant examples that we call prototypes. Our framework utilizes an attention mechanism that relates the encoded representations to determine the prototypes."}, "1177790393213169664": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-28 03:41:26", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1177619796621266944": {"author": "@keylinker", "followers": "153", "datetime": "2019-09-27 16:23:33", "content_summary": "RT @arxiv_cscv: ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1158175912418074624": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-08-05 00:40:30", "content_summary": "Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1097681284032274432": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-19 02:16:26", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/vr50YG4bC2 Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks. (arXiv:1902.06292v1 [https://t.co/8kHVi9UcuF])"}, "1158357137258627072": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-08-05 12:40:37", "content_summary": "Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1097692884709437442": {"author": "@MelroLeandro", "followers": "56", "datetime": "2019-02-19 03:02:32", "content_summary": "Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks. (arXiv:1902.06292v1 [https://t.co/fKvYpy1qtq]) https://t.co/FnSDtxLkhW"}, "1097868660826431488": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-02-19 14:41:00", "content_summary": "Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks https://t.co/T4uJbJJsat"}, "1177594014226440192": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-27 14:41:06", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1133126001997828098": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-05-27 21:41:05", "content_summary": "Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1177986475272687617": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-28 16:40:36", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1097693339086999552": {"author": "@BrundageBot", "followers": "3,858", "datetime": "2019-02-19 03:04:20", "content_summary": "Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks. Sercan O. Arik and Tomas Pfister https://t.co/Vrk2Q1ZAM9"}, "1178258309733916672": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-29 10:40:46", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1177397731637256192": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-27 01:41:08", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1099470749436235776": {"author": "@arxiv_pop", "followers": "691", "datetime": "2019-02-24 00:47:08", "content_summary": "2019/02/17 \u6295\u7a3f 3\u4f4d LG(Machine Learning) Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks https://t.co/SRG69IAwcy 10 Tweets 2 Retweets 14 Favorites"}, "1178243128634966018": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-29 09:40:27", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbK1321"}, "1178062177393094657": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-28 21:41:25", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}, "1098659073157939200": {"author": "@udmrzn", "followers": "1,348", "datetime": "2019-02-21 19:01:49", "content_summary": "RT @arxiv_in_review: #ICML2019 Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks. (arX\u2026"}, "1178454768093716480": {"author": "@arxiv_cscv", "followers": "4,082", "datetime": "2019-09-29 23:41:26", "content_summary": "ProtoAttend: Attention-Based Prototypical Learning https://t.co/T4uJbJJsat"}}, "citation_id": "55701902", "queriedAt": "2020-06-03 23:40:02"}