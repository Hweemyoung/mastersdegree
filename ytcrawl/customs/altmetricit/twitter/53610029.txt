{"citation_id": "53610029", "tab": "twitter", "twitter": {"1082796124145111041": {"author": "@HeulwenCz", "followers": "247", "datetime": "2019-01-09 00:28:08", "content_summary": "RT @romanyam: Personal Universes: A Solution to the Multi-Agent Value Alignment Problem https://t.co/q12f4RqQcy https://t.co/KnVHo3aDzZ"}, "1088102428162048001": {"author": "@ai_hub", "followers": "38", "datetime": "2019-01-23 15:53:29", "content_summary": "Question: How would a friendly Superintelligent #AI take actions that align with human values, when human values are so divergent? Answer: You get your own \"Personal Universe\" \ud83e\udd28. Check out the research paper here: https://t.co/dDaWdHUXqd https://t.co/8R5ZT"}, "1082861383753125888": {"author": "@estes_rickey", "followers": "803", "datetime": "2019-01-09 04:47:27", "content_summary": "RT @romanyam: Personal Universes: A Solution to the Multi-Agent Value Alignment Problem https://t.co/q12f4RqQcy https://t.co/KnVHo3aDzZ"}, "1082767191173447682": {"author": "@peterbpg", "followers": "89", "datetime": "2019-01-08 22:33:09", "content_summary": "Great exploratory paper by @romanyam \u201dPerhaps we should stop trying to make \u201cone size fits all\u201d approach to the optimization of the universe work and instead look at potential for delivering an experience customized to individual users.\u201d"}, "1082795715502452741": {"author": "@romanyam", "followers": "29,335", "datetime": "2019-01-09 00:26:30", "content_summary": "RT @peterbpg: Great exploratory paper by @romanyam \u201dPerhaps we should stop trying to make \u201cone size fits all\u201d approach to the optimization\u2026"}, "1082783991030198272": {"author": "@SzymonBDA", "followers": "285", "datetime": "2019-01-08 23:39:55", "content_summary": "RT @romanyam: Personal Universes: A Solution to the Multi-Agent Value Alignment Problem https://t.co/q12f4RqQcy https://t.co/KnVHo3aDzZ"}, "1082457934792142848": {"author": "@helioRocha_", "followers": "619", "datetime": "2019-01-08 02:04:17", "content_summary": "\"Personal Universes: A Solution to the Multi-Agent Value Alignment Problem. (arXiv:1901.01851v1 [https://t.co/jqZ5dwubSV])\" #arXiv https://t.co/N3u3yFA0zM"}, "1082623556570238976": {"author": "@arxivml", "followers": "765", "datetime": "2019-01-08 13:02:24", "content_summary": "\"Personal Universes: A Solution to the Multi-Agent Value Alignment Problem\", Roman V\uff0e Yampolskiy https://t.co/sHjPSmpsXB"}, "1082458095966666753": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-01-08 02:04:55", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/KLmmONmKBb Personal Universes: A Solution to the Multi-Agent Value Alignment Problem. (arXiv:1901.01851v1 [https://t.co/8kHVi9UcuF])"}, "1082664589295316992": {"author": "@romanyam", "followers": "29,335", "datetime": "2019-01-08 15:45:27", "content_summary": "Personal Universes: A Solution to the Multi-Agent Value Alignment Problem https://t.co/q12f4RqQcy https://t.co/KnVHo3aDzZ"}, "1082855086076891136": {"author": "@estes_rickey", "followers": "803", "datetime": "2019-01-09 04:22:25", "content_summary": "RT @peterbpg: Great exploratory paper by @romanyam \u201dPerhaps we should stop trying to make \u201cone size fits all\u201d approach to the optimization\u2026"}, "1082944756399919104": {"author": "@vbehzadan", "followers": "273", "datetime": "2019-01-09 10:18:44", "content_summary": "RT @romanyam: Personal Universes: A Solution to the Multi-Agent Value Alignment Problem https://t.co/q12f4RqQcy https://t.co/KnVHo3aDzZ"}}, "completed": "1", "queriedAt": "2020-06-02 23:58:35"}