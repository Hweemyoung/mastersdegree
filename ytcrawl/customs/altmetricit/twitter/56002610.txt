{"tab": "twitter", "completed": "1", "twitter": {"1099881298921807874": {"author": "@yapp1e", "followers": "48", "datetime": "2019-02-25 03:58:31", "content_summary": "Overcoming Multi-Model Forgetting. (arXiv:1902.08232v1 [cs.LG]) https://t.co/8dLpMXS6vO We identify a phenomenon, which we refer to as multi-model forgetting, that occurs when sequentially training multiple deep networks with partially-shared parameters;"}, "1100030225268817920": {"author": "@udmrzn", "followers": "1,348", "datetime": "2019-02-25 13:50:17", "content_summary": "RT @StatMLPapers: Overcoming Multi-Model Forgetting. (arXiv:1902.08232v1 [cs.LG]) https://t.co/7dKwfOy2uY"}, "1100031157708701696": {"author": "@Wronskia12", "followers": "54", "datetime": "2019-02-25 13:54:00", "content_summary": "RT @StatMLPapers: Overcoming Multi-Model Forgetting. (arXiv:1902.08232v1 [cs.LG]) https://t.co/7dKwfOy2uY"}, "1099934084493598721": {"author": "@arxiv_org", "followers": "12,715", "datetime": "2019-02-25 07:28:16", "content_summary": "Overcoming Multi-Model Forgetting. https://t.co/uE7TKdfw9I https://t.co/XukjwJGGNh"}, "1099878376536297474": {"author": "@StatsPapers", "followers": "5,454", "datetime": "2019-02-25 03:46:54", "content_summary": "Overcoming Multi-Model Forgetting. https://t.co/dyD0gNv293"}, "1099972354543927296": {"author": "@_Claudiu_Musat", "followers": "113", "datetime": "2019-02-25 10:00:20", "content_summary": "Looking for a culprit? Weight sharing is probably it, as described both in https://t.co/ZtRWQDqeFd and https://t.co/PYtGpZX607 ."}, "1100096776189734912": {"author": "@arxiv_in_review", "followers": "1,300", "datetime": "2019-02-25 18:14:44", "content_summary": "#ICML2019 Overcoming Multi-Model Forgetting. (arXiv:1902.08232v1 [cs\\.LG]) https://t.co/Wp48sNci16"}, "1099982849892143104": {"author": "@HubBucket", "followers": "5,309", "datetime": "2019-02-25 10:42:02", "content_summary": "RT @arxiv_org: Overcoming Multi-Model Forgetting. https://t.co/uE7TKdfw9I https://t.co/XukjwJGGNh"}, "1099948047285526528": {"author": "@Wronskia12", "followers": "54", "datetime": "2019-02-25 08:23:45", "content_summary": "@L_badikho @jeremyphoward That\u2019s what we discovered in our paper, https://t.co/ZvjBMq52Zx We studied the concept of weight-sharing used by ENAS and showed that it negatively affects architectures, which causes the process to be closer to random."}, "1099856321413873664": {"author": "@StatMLPapers", "followers": "9,664", "datetime": "2019-02-25 02:19:16", "content_summary": "Overcoming Multi-Model Forgetting. (arXiv:1902.08232v1 [cs.LG]) https://t.co/7dKwfOy2uY"}, "1099863391139704832": {"author": "@BrundageBot", "followers": "3,858", "datetime": "2019-02-25 02:47:21", "content_summary": "Overcoming Multi-Model Forgetting. Yassine Benyahia, Kaicheng Yu, Kamil Bennani-Smires, Martin Jaggi, Anthony Davison, Mathieu Salzmann, and Claudiu Musat https://t.co/sNklDbDgou"}, "1099864652111069184": {"author": "@deep_rl", "followers": "857", "datetime": "2019-02-25 02:52:22", "content_summary": "Overcoming Multi-Model Forgetting - Yassine Benyahia https://t.co/WqxTQi35MO"}, "1099924792554242048": {"author": "@arxivml", "followers": "767", "datetime": "2019-02-25 06:51:20", "content_summary": "\"Overcoming Multi-Model Forgetting\", Yassine Benyahia, Kaicheng Yu, Kamil Bennani-Smires, Martin Jaggi, Anthony Dav\u2026 https://t.co/hwzUDdsJPS"}}, "citation_id": "56002610", "queriedAt": "2020-06-04 00:08:58"}