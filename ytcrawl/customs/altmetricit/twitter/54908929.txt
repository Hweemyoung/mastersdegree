{"queriedAt": "2020-06-03 14:40:54", "completed": "1", "citation_id": "54908929", "tab": "twitter", "twitter": {"1121519616579309568": {"author": "@comcomodel", "datetime": "2019-04-25 21:01:28", "content_summary": "great podcast \ud83d\ude03\ud83d\udce3 experiments with humans #preference #performance #randomexamples training models from skratch, reduction processes and meaningful selections, consistent results #neuralmodels @ihsgnef #NLPHighlights", "followers": "192"}, "1092676772712173568": {"author": "@anshulkundaje", "datetime": "2019-02-05 06:50:18", "content_summary": "RT @FeiziSoheil: If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpre\u2026", "followers": "7,218"}, "1092253457933914117": {"author": "@BrundageBot", "datetime": "2019-02-04 02:48:12", "content_summary": "Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation. Sahil Singla, Eric Wallace, Shi Feng, and Soheil Feizi https://t.co/vKuRhU6yyO", "followers": "3,903"}, "1120293270704349184": {"author": "@sahilsingla47", "datetime": "2019-04-22 11:48:24", "content_summary": "RT @FeiziSoheil: I am glad our paper on \"Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretati\u2026", "followers": "295"}, "1092571756315893760": {"author": "@TheGradient", "datetime": "2019-02-04 23:53:00", "content_summary": "RT @FeiziSoheil: If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpre\u2026", "followers": "1,729"}, "1092565757374926849": {"author": "@umdcs", "datetime": "2019-02-04 23:29:10", "content_summary": "RT @FeiziSoheil: If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpre\u2026", "followers": "3,336"}, "1093166098718044160": {"author": "@arxiv_in_review", "datetime": "2019-02-06 15:14:42", "content_summary": "#ICML2019 Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation. (arXiv:1902.00407v1 [cs\\.LG]) https://t.co/OEM6dpk8JE", "followers": "1,318"}, "1092287170415681536": {"author": "@arxivml", "datetime": "2019-02-04 05:02:09", "content_summary": "\"Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation\", Sahil Singl\u2026 https://t.co/J38xjU9bIS", "followers": "783"}, "1121604419965968385": {"author": "@Epsilon_Lee", "datetime": "2019-04-26 02:38:26", "content_summary": "#interpretability and how to detect pathology, great work", "followers": "88"}, "1092263120754626560": {"author": "@arxiv_cs_LG", "datetime": "2019-02-04 03:26:35", "content_summary": "Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation. Sahil Singla, Eric Wallace, Shi Feng, and Soheil Feizi https://t.co/tj4EYd8XR8", "followers": "320"}, "1121507109772775424": {"author": "@vivwylai", "datetime": "2019-04-25 20:11:46", "content_summary": "RT @ihsgnef: Thanks for having me! It was a lot of fun. plug: check out our #icml2019 paper on relaxing the first-order assumption that in\u2026", "followers": "228"}, "1092678320079044608": {"author": "@dperrin", "datetime": "2019-02-05 06:56:27", "content_summary": "RT @FeiziSoheil: If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpre\u2026", "followers": "450"}, "1120499719598428161": {"author": "@umdcs", "datetime": "2019-04-23 01:28:45", "content_summary": "RT @FeiziSoheil: I am glad our paper on \"Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretati\u2026", "followers": "3,336"}, "1120290064473391105": {"author": "@FeiziSoheil", "datetime": "2019-04-22 11:35:40", "content_summary": "I am glad our paper on \"Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation\" has been accepted to #ICML 2019. Congrats to #umdcs students @sahilsingla47 @Eric_Wallace_ @ihsgnef. See the draft here: https://t", "followers": "767"}, "1092564297878851589": {"author": "@FeiziSoheil", "datetime": "2019-02-04 23:23:22", "content_summary": "If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpretation or adversarial examples), you may find our recent paper of interest: https://t.co/FatoiRHNXx https://t.co/yAgrR3nqrw", "followers": "767"}, "1092604100330500097": {"author": "@sahilsingla47", "datetime": "2019-02-05 02:01:31", "content_summary": "RT @FeiziSoheil: If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpre\u2026", "followers": "295"}, "1092249427308351488": {"author": "@deep_rl", "datetime": "2019-02-04 02:32:11", "content_summary": "Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation - Sahil Singla https://t.co/UhzoOEQt1e", "followers": "863"}, "1092564406620307459": {"author": "@umiacs", "datetime": "2019-02-04 23:23:48", "content_summary": "RT @FeiziSoheil: If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpre\u2026", "followers": "1,266"}, "1121505373624647689": {"author": "@ihsgnef", "datetime": "2019-04-25 20:04:52", "content_summary": "Thanks for having me! It was a lot of fun. plug: check out our #icml2019 paper on relaxing the first-order assumption that interpretations make which leads to issues discussed in the podcast https://t.co/AEKeaDYy08 it's on images, for now :)", "followers": "319"}, "1092680573552943105": {"author": "@gauravjain49", "datetime": "2019-02-05 07:05:24", "content_summary": "RT @FeiziSoheil: If you plan to include higher-order loss approximations (e.g. the Hessian term) in your deep learning method (for interpre\u2026", "followers": "393"}}}