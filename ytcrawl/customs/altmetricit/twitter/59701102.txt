{"citation_id": "59701102", "tab": "twitter", "completed": "1", "queriedAt": "2020-05-14 14:31:32", "twitter": {"1123338782906945536": {"followers": "292", "datetime": "2019-04-30 21:30:11", "author": "@Shujian_Liu", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123314374515548163": {"followers": "171", "datetime": "2019-04-30 19:53:11", "author": "@SerialDev", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123103046437941248": {"followers": "92", "datetime": "2019-04-30 05:53:27", "author": "@_ghnn_", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1150344450297737216": {"followers": "221", "datetime": "2019-07-14 10:01:03", "author": "@PapersTrending", "content_summary": "[2/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 264 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxjBsu - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1123193530166411264": {"followers": "517", "datetime": "2019-04-30 11:53:00", "author": "@engsoares_gyn", "content_summary": "Um avan\u00e7o importante."}, "1123097992884641794": {"followers": "1,084", "datetime": "2019-04-30 05:33:22", "author": "@Atabey_Kaygun", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123109518525771776": {"followers": "6", "datetime": "2019-04-30 06:19:10", "author": "@nahidcse05", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1187264487046316034": {"followers": "2,031", "datetime": "2019-10-24 07:08:06", "author": "@jayeshmthakur", "content_summary": "RT @BioDecoded: Inference of clonal selection in cancer populations using single-cell sequencing data | Bioinformatics https://t.co/hbXrtDZ\u2026"}, "1247242193489645568": {"followers": "40,478", "datetime": "2020-04-06 19:18:06", "author": "@pabbeel", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1177985721539317761": {"followers": "784", "datetime": "2019-09-28 16:37:36", "author": "@muktabh", "content_summary": "RT @arxiv_cscv: Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123198063068184576": {"followers": "740", "datetime": "2019-04-30 12:11:00", "author": "@JoaoVictor_AC", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126319628873945089": {"followers": "825", "datetime": "2019-05-09 02:55:00", "author": "@morioka", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126320341951737856": {"followers": "203", "datetime": "2019-05-09 02:57:50", "author": "@wayama_ryousuke", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123225977708879872": {"followers": "2,663", "datetime": "2019-04-30 14:01:56", "author": "@sigitpurnomo", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123247683043389440": {"followers": "2,050", "datetime": "2019-04-30 15:28:11", "author": "@shunk031", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1152250312834654208": {"followers": "818", "datetime": "2019-07-19 16:14:17", "author": "@ErmiaBivatan", "content_summary": "RT @PapersTrending: [9/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 402 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxjBsu - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1243261069306613762": {"followers": "61", "datetime": "2020-03-26 19:38:32", "author": "@axershov", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1242919854304198657": {"followers": "18,260", "datetime": "2020-03-25 21:02:40", "author": "@quocleix", "content_summary": "This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34ztIFttUQ FixMatch: https://t.co/3qTUVbPO0N Noisy Student: https://t.co/ZYDaef6sdp etc. Joint work with @hieupham789 @QizheXie @Zihan"}, "1123216676462395392": {"followers": "709", "datetime": "2019-04-30 13:24:58", "author": "@arthurostapenko", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123177101664768000": {"followers": "217", "datetime": "2019-04-30 10:47:43", "author": "@AssistedEvolve", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125706020913799168": {"followers": "1,667", "datetime": "2019-05-07 10:16:44", "author": "@Scaled_Wurm", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1123045916271894528": {"followers": "3,881", "datetime": "2019-04-30 02:06:26", "author": "@BrundageBot", "content_summary": "Unsupervised Data Augmentation. Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V. Le https://t.co/LGDZpGp9xc"}, "1126645498171912192": {"followers": "17", "datetime": "2019-05-10 00:29:53", "author": "@watek334", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1151069349190483969": {"followers": "221", "datetime": "2019-07-16 10:01:33", "author": "@PapersTrending", "content_summary": "[6/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 329 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxjBsu - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1235362675183497221": {"followers": "11,927", "datetime": "2020-03-05 00:33:08", "author": "@Rosenchild", "content_summary": "RT @lmthang: Our UDA work (https://t.co/Uoj2RbpfS7) proposes the use of strong augmentation (RandAugment) which subsequent works (FixMatch,\u2026"}, "1125693108136464386": {"followers": "825", "datetime": "2019-05-07 09:25:26", "author": "@morioka", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1125688103136423937": {"followers": "435", "datetime": "2019-05-07 09:05:32", "author": "@kawauso_kun", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1126967904069533696": {"followers": "1,461", "datetime": "2019-05-10 21:51:01", "author": "@rfrsarmiento", "content_summary": "RT @arjunmanrai: Wow: \"on IMDb, UDA with 20 labeled examples outperforms the state-of-the-art model trained on 1250x more labeled data\" htt\u2026"}, "1123219644809084928": {"followers": "34", "datetime": "2019-04-30 13:36:46", "author": "@therealaseifert", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123316446149402626": {"followers": "323", "datetime": "2019-04-30 20:01:25", "author": "@ksopyla", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126334084634988546": {"followers": "1,322", "datetime": "2019-05-09 03:52:26", "author": "@ararabo", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1151794231373176832": {"followers": "221", "datetime": "2019-07-18 10:01:58", "author": "@PapersTrending", "content_summary": "[10/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 374 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1123209727876399104": {"followers": "179,061", "datetime": "2019-04-30 12:57:22", "author": "@Montreal_AI", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1235416822268096514": {"followers": "132", "datetime": "2020-03-05 04:08:18", "author": "@GiseopK", "content_summary": "RT @lmthang: Our UDA work (https://t.co/Uoj2RbpfS7) proposes the use of strong augmentation (RandAugment) which subsequent works (FixMatch,\u2026"}, "1149117886281199618": {"followers": "61", "datetime": "2019-07-11 00:47:08", "author": "@SoEngineering", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/LTiimePmBY Unsupervised Data Augmentation for Consistency Training. (arXiv:1904.12848v2 [cs.LG] UPDATED)"}, "1130078357511725056": {"followers": "395", "datetime": "2019-05-19 11:50:50", "author": "@qiming82", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1130203789858709505": {"followers": "12", "datetime": "2019-05-19 20:09:16", "author": "@2000Qiu", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123417929368793088": {"followers": "70", "datetime": "2019-05-01 02:44:41", "author": "@mnrmja007", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1138505974980009984": {"followers": "65", "datetime": "2019-06-11 17:59:11", "author": "@phirabu", "content_summary": "Unsupervised Data Augmentation: Google gets its AI systems to generate their own synthetic data #ArtificialIntelligence https://t.co/eGkV9LkeDS"}, "1123732134877966336": {"followers": "181", "datetime": "2019-05-01 23:33:13", "author": "@lpadukana", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123296610291609602": {"followers": "201", "datetime": "2019-04-30 18:42:36", "author": "@sebcossin", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123267392426131457": {"followers": "802", "datetime": "2019-04-30 16:46:30", "author": "@drscotthawley", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1243195678257487874": {"followers": "1,287", "datetime": "2020-03-26 15:18:41", "author": "@heghbalz", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1130249346903969792": {"followers": "18,260", "datetime": "2019-05-19 23:10:17", "author": "@quocleix", "content_summary": "To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. The method works well on top of transfer learning (e.g., BERT). You can find these results in Unsupervised Data Augmentation pap"}, "1123562181008793602": {"followers": "21", "datetime": "2019-05-01 12:17:53", "author": "@GersonVizcarra", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1247325783582015489": {"followers": "818", "datetime": "2020-04-07 00:50:15", "author": "@deepgradient", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1126332016775942145": {"followers": "12,763", "datetime": "2019-05-09 03:44:13", "author": "@jaguring1", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1130199334883155973": {"followers": "53", "datetime": "2019-05-19 19:51:34", "author": "@Surreabral", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1125405876385243140": {"followers": "871", "datetime": "2019-05-06 14:24:04", "author": "@mihail_eric", "content_summary": "Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various language and vision tasks: https://t.co/7zq0ypVTGl"}, "1242986339592617985": {"followers": "65", "datetime": "2020-03-26 01:26:51", "author": "@kli_nlpr", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1126191330047270912": {"followers": "218", "datetime": "2019-05-08 18:25:11", "author": "@david_macedo", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123325567636361217": {"followers": "12", "datetime": "2019-04-30 20:37:40", "author": "@2000Qiu", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123221861502873600": {"followers": "764", "datetime": "2019-04-30 13:45:34", "author": "@RandallJEllis", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126363415167979521": {"followers": "657", "datetime": "2019-05-09 05:48:59", "author": "@komakusaryama", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1243900772384899074": {"followers": "211", "datetime": "2020-03-28 14:00:29", "author": "@aleksei_tiulpin", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123518346958446597": {"followers": "150", "datetime": "2019-05-01 09:23:42", "author": "@rodgzilla", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243308916181594112": {"followers": "21", "datetime": "2020-03-26 22:48:39", "author": "@sbmaruf", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1242995003460325380": {"followers": "289", "datetime": "2020-03-26 02:01:17", "author": "@dannyehb", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1125511765691789312": {"followers": "18,260", "datetime": "2019-05-06 21:24:50", "author": "@quocleix", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1126527670185889793": {"followers": "417", "datetime": "2019-05-09 16:41:41", "author": "@DAUDAUDA", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1126338597462990848": {"followers": "2,744", "datetime": "2019-05-09 04:10:22", "author": "@KagiyamaNobu", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123673898116055040": {"followers": "47", "datetime": "2019-05-01 19:41:48", "author": "@abstract_datum", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123127191934578689": {"followers": "4,327", "datetime": "2019-04-30 07:29:23", "author": "@jekbradbury", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1243076134738239491": {"followers": "274", "datetime": "2020-03-26 07:23:40", "author": "@playittodeath", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123205695380250624": {"followers": "377", "datetime": "2019-04-30 12:41:20", "author": "@dotnetcorechris", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1149619710490599426": {"followers": "221", "datetime": "2019-07-12 10:01:12", "author": "@PapersTrending", "content_summary": "[3/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 191 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfETfmH - \ud83d\udd17 https://t.co/PL92FzPFTq"}, "1150706819666501632": {"followers": "221", "datetime": "2019-07-15 10:00:59", "author": "@PapersTrending", "content_summary": "[3/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 303 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxjBsu - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1243000072465350657": {"followers": "27", "datetime": "2020-03-26 02:21:25", "author": "@mahesh21aug", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1123265355298820096": {"followers": "45", "datetime": "2019-04-30 16:38:24", "author": "@SteinfeldtJakob", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126476926804086785": {"followers": "4,825", "datetime": "2019-05-09 13:20:02", "author": "@prototechno", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1219839075118538755": {"followers": "331", "datetime": "2020-01-22 04:27:53", "author": "@sai_prasanna", "content_summary": "@D_Berthelot_ML @chunliang_tw @ZizhaoZhang @ekindogus @Han_Zhang_ @colinraffel @alexey2004 Is this a variant of UDA? https://t.co/nY70VfUGef"}, "1126309828953903104": {"followers": "1,597", "datetime": "2019-05-09 02:16:03", "author": "@matsui_kota", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123265867540836353": {"followers": "470", "datetime": "2019-04-30 16:40:26", "author": "@cyrta", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123180823157641217": {"followers": "6", "datetime": "2019-04-30 11:02:30", "author": "@dmalaescu", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123255999081660416": {"followers": "81", "datetime": "2019-04-30 16:01:13", "author": "@JL_Samper", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123043426520444928": {"followers": "98", "datetime": "2019-04-30 01:56:32", "author": "@shpotes", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123667464196218880": {"followers": "223", "datetime": "2019-05-01 19:16:14", "author": "@johntigue", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123043544032145409": {"followers": "70", "datetime": "2019-04-30 01:57:00", "author": "@sumitsethy", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123143144340586497": {"followers": "1,402", "datetime": "2019-04-30 08:32:47", "author": "@RTFMCelia", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126319377702215680": {"followers": "825", "datetime": "2019-05-09 02:54:00", "author": "@morioka", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123229598135676928": {"followers": "57", "datetime": "2019-04-30 14:16:19", "author": "@tuxnguyen", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1242998125939372032": {"followers": "22", "datetime": "2020-03-26 02:13:41", "author": "@Tsingggg", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123718736601600000": {"followers": "0", "datetime": "2019-05-01 22:39:59", "author": "@ZengZenith", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1129984327939284992": {"followers": "4", "datetime": "2019-05-19 05:37:12", "author": "@tomaxent", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123590999077457920": {"followers": "135", "datetime": "2019-05-01 14:12:24", "author": "@joyenergynews", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1248254889643462656": {"followers": "593", "datetime": "2020-04-09 14:22:11", "author": "@soumen_eclectic", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123028716433494016": {"followers": "15,224", "datetime": "2019-04-30 00:58:05", "author": "@lmthang", "content_summary": "Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Dai, Eduard Hovy, & @quocleix. SOTA results on IMDB (with just 20 labeled examples!), SSL Cifar10 & SVHN (30% error reductio"}, "1125637473562808320": {"followers": "2,517", "datetime": "2019-05-07 05:44:21", "author": "@tosshin321", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1123100532971835392": {"followers": "885", "datetime": "2019-04-30 05:43:27", "author": "@RichmanRonald", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126316350660472832": {"followers": "475", "datetime": "2019-05-09 02:41:58", "author": "@censored__", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1236646771109040134": {"followers": "513", "datetime": "2020-03-08 13:35:40", "author": "@PasqualeDeMar", "content_summary": "RT @Deep_In_Depth: Unsupervised Data Augmentation for Consistency Training https://t.co/BZOt43yPaX #DeepLearning #NeuralNetworks #Artifici\u2026"}, "1247543921439367169": {"followers": "23", "datetime": "2020-04-07 15:17:03", "author": "@lirong11", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1128921530123997184": {"followers": "228", "datetime": "2019-05-16 07:14:01", "author": "@m3yrin", "content_summary": "\u9006\u7ffb\u8a33\u3060\u3051\u3067UDA\u8a66\u3057\u3066\u3044\u308b\u3002TSA\u306eeta\u3092\u3069\u308c\u304f\u3089\u3044\u65e9\u304f1\u306b\u6301\u3063\u3066\u3044\u304f\u304b\u304c\u6c7a\u3081\u3089\u308c\u306a\u3044\u3002https://t.co/2d7kf9vZW5"}, "1123086888926101504": {"followers": "291", "datetime": "2019-04-30 04:49:14", "author": "@QizheXie", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126389311362879493": {"followers": "2,993", "datetime": "2019-05-09 07:31:53", "author": "@dante2160", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123110051256791046": {"followers": "5,454", "datetime": "2019-04-30 06:21:17", "author": "@StatsPapers", "content_summary": "Unsupervised Data Augmentation. https://t.co/Nfd6wMI5Ow"}, "1123194918162374656": {"followers": "67", "datetime": "2019-04-30 11:58:31", "author": "@__maikros__", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123376251723325440": {"followers": "66", "datetime": "2019-04-30 23:59:04", "author": "@khuongav", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125599539430170626": {"followers": "474", "datetime": "2019-05-07 03:13:37", "author": "@yasuokajihei", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1123185513647759361": {"followers": "16", "datetime": "2019-04-30 11:21:08", "author": "@p_kot1", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123379934552965120": {"followers": "60", "datetime": "2019-05-01 00:13:42", "author": "@foxhu007", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123102737066020865": {"followers": "145", "datetime": "2019-04-30 05:52:13", "author": "@esvhd", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1153724859312197632": {"followers": "11,927", "datetime": "2019-07-23 17:53:36", "author": "@Rosenchild", "content_summary": "RT @BioDecoded: Advancing Semi-supervised Learning with Unsupervised Data Augmentation | Google AI Blog https://t.co/hbXrtDZk7S https://t.c\u2026"}, "1187534550462816256": {"followers": "290", "datetime": "2019-10-25 01:01:14", "author": "@VESTEDTECH", "content_summary": "RT @BioDecoded: Inference of clonal selection in cancer populations using single-cell sequencing data | Bioinformatics https://t.co/hbXrtDZ\u2026"}, "1123204511743586304": {"followers": "378", "datetime": "2019-04-30 12:36:38", "author": "@RyanAEMetz", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123100001284976640": {"followers": "19,073", "datetime": "2019-04-30 05:41:21", "author": "@xamat", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126311342820904960": {"followers": "1,055", "datetime": "2019-05-09 02:22:04", "author": "@stealthinu", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1247467512284844033": {"followers": "13", "datetime": "2020-04-07 10:13:26", "author": "@FerdousBinAli1", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1125944987735285760": {"followers": "1,253", "datetime": "2019-05-08 02:06:18", "author": "@NatashaReid95", "content_summary": "RT @DS_insights: #UDA or unsupervised data augmentations new technique from @google to generate synthetic data for #neuralnetworks #AI #mac\u2026"}, "1123220318930083840": {"followers": "71", "datetime": "2019-04-30 13:39:27", "author": "@eigenVishal", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1243121729716846592": {"followers": "299", "datetime": "2020-03-26 10:24:51", "author": "@westis96", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123589938161827841": {"followers": "934", "datetime": "2019-05-01 14:08:11", "author": "@AI_Kho_", "content_summary": "Training SOTA model just from 20 labeled examples. Impressive! Would like to reproduce this. Hope authors will release the code. #NLP #NLProc #ML #AI #DS #DataScience #MachineLearning"}, "1123165683104174083": {"followers": "13", "datetime": "2019-04-30 10:02:20", "author": "@michaelgteo", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123257204008792065": {"followers": "179,061", "datetime": "2019-04-30 16:06:01", "author": "@Montreal_AI", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123226003554295808": {"followers": "99,904", "datetime": "2019-04-30 14:02:02", "author": "@jeremyphoward", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1161612310823231488": {"followers": "52", "datetime": "2019-08-14 12:15:31", "author": "@sergeypod", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/DCQa3YFlcF"}, "1123247506534481922": {"followers": "2,176", "datetime": "2019-04-30 15:27:29", "author": "@udoooom", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126372908421398528": {"followers": "174", "datetime": "2019-05-09 06:26:43", "author": "@SquirrelYellow", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123402720457699328": {"followers": "3,374", "datetime": "2019-05-01 01:44:15", "author": "@renato_umeton", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1235395721714495489": {"followers": "27", "datetime": "2020-03-05 02:44:27", "author": "@mahesh21aug", "content_summary": "RT @lmthang: Our UDA work (https://t.co/Uoj2RbpfS7) proposes the use of strong augmentation (RandAugment) which subsequent works (FixMatch,\u2026"}, "1235467103978864640": {"followers": "202", "datetime": "2020-03-05 07:28:06", "author": "@zein_shahine", "content_summary": "RT @lmthang: Our UDA work (https://t.co/Uoj2RbpfS7) proposes the use of strong augmentation (RandAugment) which subsequent works (FixMatch,\u2026"}, "1123223169483960320": {"followers": "15", "datetime": "2019-04-30 13:50:46", "author": "@The_UBD", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123298238902091776": {"followers": "439", "datetime": "2019-04-30 18:49:04", "author": "@0xleonerd", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126316884419158016": {"followers": "115", "datetime": "2019-05-09 02:44:05", "author": "@million_color", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123227980380168192": {"followers": "113", "datetime": "2019-04-30 14:09:53", "author": "@JoanGibert4", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123122799214596096": {"followers": "56", "datetime": "2019-04-30 07:11:56", "author": "@BrambleXu", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123123926123601920": {"followers": "171", "datetime": "2019-04-30 07:16:25", "author": "@SerialDev", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123352605030273025": {"followers": "23", "datetime": "2019-04-30 22:25:06", "author": "@ASh0T5", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123102947452309504": {"followers": "1,287", "datetime": "2019-04-30 05:53:03", "author": "@heghbalz", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123240053675659265": {"followers": "322", "datetime": "2019-04-30 14:57:52", "author": "@CalcCon", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126338070414905345": {"followers": "158", "datetime": "2019-05-09 04:08:16", "author": "@Charon_poker", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123068522777546752": {"followers": "19", "datetime": "2019-04-30 03:36:16", "author": "@iamShashwatA", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1149334925172064257": {"followers": "94", "datetime": "2019-07-11 15:09:34", "author": "@kuroneko32794", "content_summary": "RT @imenurok: \u8a71\u984c\u306eUnsupervised Data Augmentation (UDA)\u3002 https://t.co/IW3AgZWjdO Ablation study\u306eCropping & flipping\u306eError\u7387\u304c16.17%\u306a\u3053\u3068\u304c\u8003\u3048\u3055\u305b\u3089\u308c\u308b\u2026"}, "1242932916583370753": {"followers": "105", "datetime": "2020-03-25 21:54:34", "author": "@ShuiwangJi", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1242977889198288896": {"followers": "29", "datetime": "2020-03-26 00:53:16", "author": "@chenlailin", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1243259419434971136": {"followers": "0", "datetime": "2020-03-26 19:31:58", "author": "@JiayuanDing", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1126624265690726400": {"followers": "631", "datetime": "2019-05-09 23:05:31", "author": "@BambooMura", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123110628309102597": {"followers": "767", "datetime": "2019-04-30 06:23:34", "author": "@_smileyball", "content_summary": "I've always been a big fan of the self-consistency for semi-sup. Finding the right notion of neighborhood is important. I'm glad someone took the effort of trying various augmentation strategies c: I also hope we find more interesting/insightful neighborho"}, "1130251993669259264": {"followers": "174", "datetime": "2019-05-19 23:20:49", "author": "@SquirrelYellow", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1247499955779932161": {"followers": "257", "datetime": "2020-04-07 12:22:21", "author": "@shashankpr16", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123222178298830853": {"followers": "3,885", "datetime": "2019-04-30 13:46:50", "author": "@LTIatCMU", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123238610717691904": {"followers": "2,672", "datetime": "2019-04-30 14:52:08", "author": "@ayirpelle", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130118131681234944": {"followers": "164,080", "datetime": "2019-05-19 14:28:53", "author": "@ceobillionaire", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123039386369765376": {"followers": "870", "datetime": "2019-04-30 01:40:29", "author": "@mrdrozdov", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123163751576940549": {"followers": "753", "datetime": "2019-04-30 09:54:40", "author": "@suneelmarthi", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1169332871976357888": {"followers": "634", "datetime": "2019-09-04 19:34:16", "author": "@ahalterman", "content_summary": "This is very heartening to hear as @amilliff and I start labeling some text. source: https://t.co/sbJJiQLxJ5 Xie et al: https://t.co/bO234maQvz https://t.co/2NYDuHhUGg"}, "1126732589249601536": {"followers": "228", "datetime": "2019-05-10 06:15:57", "author": "@m3yrin", "content_summary": "Unsupervised Data Augmentation ( https://t.co/dWUIO4yua9 ) \u3001\u3060\u308c\u304bKaggle\u306eIMDB data\u4f7f\u3063\u3066Kernel\u3067\u518d\u73fe\u3057\u3066\u304f\u308c\u306a\u3044\u304b\u306a (\u81ea\u5206\u3067\u3084\u308c)"}, "1242982482787446784": {"followers": "424", "datetime": "2020-03-26 01:11:32", "author": "@iamknighton", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1177443129005240321": {"followers": "4,096", "datetime": "2019-09-27 04:41:32", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABShJFez"}, "1126383138593234945": {"followers": "417", "datetime": "2019-05-09 07:07:22", "author": "@63556poiuytrewq", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1149188273601822722": {"followers": "2,043", "datetime": "2019-07-11 05:26:49", "author": "@imenurok", "content_summary": "\u8a71\u984c\u306eUnsupervised Data Augmentation (UDA)\u3002 https://t.co/IW3AgZWjdO Ablation study\u306eCropping & flipping\u306eError\u7387\u304c16.17%\u306a\u3053\u3068\u304c\u8003\u3048\u3055\u305b\u3089\u308c\u308b\u30026.42%\u306ecutout\u307b\u3069\u306e\u6b20\u640d\u304c\u306a\u3044\u3068\u3044\u3046\u3053\u3068\u306a\u3093\u3060\u308d\u3046\u3051\u3069\u2026\u3002"}, "1125549877696401409": {"followers": "180", "datetime": "2019-05-06 23:56:17", "author": "@sriharshams", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1149362293072752640": {"followers": "196", "datetime": "2019-07-11 16:58:19", "author": "@gatheluck", "content_summary": "RT @imenurok: \u8a71\u984c\u306eUnsupervised Data Augmentation (UDA)\u3002 https://t.co/IW3AgZWjdO Ablation study\u306eCropping & flipping\u306eError\u7387\u304c16.17%\u306a\u3053\u3068\u304c\u8003\u3048\u3055\u305b\u3089\u308c\u308b\u2026"}, "1123323996521496577": {"followers": "898", "datetime": "2019-04-30 20:31:25", "author": "@AISC_TO", "content_summary": "Unsupervised Data Augmentation https://t.co/gxI6DvzcLp"}, "1123502488139603968": {"followers": "1,603", "datetime": "2019-05-01 08:20:41", "author": "@Emil_Hvitfeldt", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123148472691990529": {"followers": "457", "datetime": "2019-04-30 08:53:57", "author": "@SingingData", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123222034924941318": {"followers": "136", "datetime": "2019-04-30 13:46:16", "author": "@FaisalMaqbool94", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123174234098847745": {"followers": "5,606", "datetime": "2019-04-30 10:36:19", "author": "@__MLT__", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1125554070788292610": {"followers": "232", "datetime": "2019-05-07 00:12:56", "author": "@bamboo4031", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1125820663405654016": {"followers": "92", "datetime": "2019-05-07 17:52:17", "author": "@Sphere_OI", "content_summary": "Unsupervised Data Augmentation (UDA) method outperforms all previous approaches and reduces more than 30% of the error rates of state-of-the-art [data augmentation] methods. https://t.co/ByuTk0dIWa #computerscience #ML #AI #patternrecognition #computervi"}, "1149131510039162880": {"followers": "4,096", "datetime": "2019-07-11 01:41:16", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123631497641177090": {"followers": "37", "datetime": "2019-05-01 16:53:19", "author": "@manuelschmidt90", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123184524593119235": {"followers": "242", "datetime": "2019-04-30 11:17:13", "author": "@Steinhafenn", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126194990533603328": {"followers": "52", "datetime": "2019-05-08 18:39:44", "author": "@gvessere", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126308797654261760": {"followers": "11,462", "datetime": "2019-05-09 02:11:57", "author": "@icoxfog417", "content_summary": "Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u51fa\u306a\u3044\u3088\u3046\u306b\u5b66\u7fd2\u3092\u884c\u3046\u3002\u753b\u50cf/\u30c6\u30ad\u30b9\u30c8\u5171\u306b\u52b9\u679c\u3092\u78ba\u8a8d\u3002"}, "1243290352087228416": {"followers": "66", "datetime": "2020-03-26 21:34:53", "author": "@khuongav", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1126438932630032385": {"followers": "512", "datetime": "2019-05-09 10:49:04", "author": "@yamasaKit_", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1126089589041418240": {"followers": "1,557", "datetime": "2019-05-08 11:40:54", "author": "@A6Singularity", "content_summary": "Create as much data as you need! Read \"UDA can synthesize unlabeled data\" https://t.co/vyDQGCau2V For more, get the app at https://t.co/0ic5yan9qn #AI #data https://t.co/Tu0P5sipOz"}, "1123170215305420800": {"followers": "217", "datetime": "2019-04-30 10:20:21", "author": "@AssistedEvolve", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1152249244536864768": {"followers": "6,658", "datetime": "2019-07-19 16:10:02", "author": "@prdeepakbabu", "content_summary": "unsupervised data augmentation (UDA) is an interesting paper. 4K labelled data instead of 25K labelled samples and still matching accuracy. great to see works for both text & images #datascience #unsupervised Autoaugment too seems interesting https://t"}, "1247441027910242305": {"followers": "20", "datetime": "2020-04-07 08:28:12", "author": "@Boristream", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123103387522932741": {"followers": "1,020", "datetime": "2019-04-30 05:54:48", "author": "@serrjoa", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1255768873703559169": {"followers": "2,332", "datetime": "2020-04-30 08:00:05", "author": "@kyuzelif", "content_summary": "RT @mtugrull: Benim kulland\u0131\u011f\u0131m ve i\u00e7eri\u011fini sevdi\u011fim #MachineLearning Bilinmesi Gereken Ara\u015ft\u0131rma Makaleleri 1)https://t.co/QAofv0DBGm 2)h\u2026"}, "1123557935269810176": {"followers": "2,663", "datetime": "2019-05-01 12:01:01", "author": "@sigitpurnomo", "content_summary": "RT @bgoncalves: Unsupervised Data Augmentation https://t.co/FqrG4068tS"}, "1123341362630316032": {"followers": "174", "datetime": "2019-04-30 21:40:26", "author": "@SquirrelYellow", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1178847299465891841": {"followers": "3,498", "datetime": "2019-10-01 01:41:12", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1123033178292117508": {"followers": "38", "datetime": "2019-04-30 01:15:49", "author": "@experiencor", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123297217152864257": {"followers": "41", "datetime": "2019-04-30 18:45:01", "author": "@008karanp", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1152156591870894080": {"followers": "221", "datetime": "2019-07-19 10:01:52", "author": "@PapersTrending", "content_summary": "[9/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 402 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxjBsu - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1123223151180038144": {"followers": "15", "datetime": "2019-04-30 13:50:42", "author": "@The_UBD", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123804482763153408": {"followers": "11", "datetime": "2019-05-02 04:20:42", "author": "@leduy3890", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123110088867061760": {"followers": "13", "datetime": "2019-04-30 06:21:26", "author": "@BenLI_Phys_AI", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126398648793722880": {"followers": "224", "datetime": "2019-05-09 08:09:00", "author": "@ElectronNest", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1130270565766275072": {"followers": "29", "datetime": "2019-05-20 00:34:36", "author": "@chenlailin", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1123099198570651649": {"followers": "25,578", "datetime": "2019-04-30 05:38:09", "author": "@Miles_Brundage", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123126523060469765": {"followers": "299", "datetime": "2019-04-30 07:26:44", "author": "@westis96", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1236923591536467969": {"followers": "13", "datetime": "2020-03-09 07:55:39", "author": "@EricKuy", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123039470624886785": {"followers": "4,096", "datetime": "2019-04-30 01:40:49", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation https://t.co/ppABSi1gD9"}, "1129576092887597058": {"followers": "121", "datetime": "2019-05-18 02:35:01", "author": "@blaine_bateman", "content_summary": "Unsupervised Data Augmentation. Google Brain/Carnegie Mellon: a NN is trained on small amounts of labeled data & lots of unlabeled data by minimizing the KL divergence between the predicted distribution of unlabeled and augmented unlabeled data https:"}, "1126348241132326912": {"followers": "113", "datetime": "2019-05-09 04:48:41", "author": "@_moto86", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123138232193970177": {"followers": "309", "datetime": "2019-04-30 08:13:16", "author": "@wiraindrak", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130602530784681984": {"followers": "375", "datetime": "2019-05-20 22:33:43", "author": "@surfnm", "content_summary": "Unsupervised Data Augmentation Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, Quoc V. Le arXiv:1904.12848 https://t.co/gl1A0xbp2J"}, "1123099235455385601": {"followers": "1,119", "datetime": "2019-04-30 05:38:18", "author": "@jsteward2930", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123129869141991424": {"followers": "544", "datetime": "2019-04-30 07:40:02", "author": "@altamborrino", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1132239928417501184": {"followers": "1", "datetime": "2019-05-25 11:00:09", "author": "@chelovekkorzhik", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125688733959745537": {"followers": "2,061", "datetime": "2019-05-07 09:08:03", "author": "@yo_ehara", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123094947517743104": {"followers": "99", "datetime": "2019-04-30 05:21:16", "author": "@treasured_write", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126312292931461120": {"followers": "560", "datetime": "2019-05-09 02:25:51", "author": "@pudding_info", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123049602834255873": {"followers": "99", "datetime": "2019-04-30 02:21:05", "author": "@treasured_write", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1125635300598996992": {"followers": "1,287", "datetime": "2019-05-07 05:35:43", "author": "@heghbalz", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123189130362359809": {"followers": "35", "datetime": "2019-04-30 11:35:31", "author": "@Kevin_Duu", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123233515225661445": {"followers": "159,742", "datetime": "2019-04-30 14:31:53", "author": "@Montreal_IA", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1149477908747960320": {"followers": "65", "datetime": "2019-07-12 00:37:44", "author": "@kli_nlpr", "content_summary": "RT @lmthang: These plots (also included in the updated version of our UDA paper https://t.co/Uoj2Rb7Etx with a lot more results & details)\u2026"}, "1243147874310844416": {"followers": "327", "datetime": "2020-03-26 12:08:44", "author": "@aditya_soni2k17", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1125544024167706624": {"followers": "18,231", "datetime": "2019-05-06 23:33:01", "author": "@hillbig", "content_summary": "In semi-supervised learning, VAT adds adversarial noise to unsupervised data and makes its prediction distribution matches the original distribution. UDA instead applies data augmentation methods and gradually increases the signal from the supervised data"}, "1123303145218740228": {"followers": "647", "datetime": "2019-04-30 19:08:34", "author": "@zzprosper", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123128143483744256": {"followers": "154", "datetime": "2019-04-30 07:33:10", "author": "@DCasBol", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1124021676973412353": {"followers": "89", "datetime": "2019-05-02 18:43:45", "author": "@mgrankin", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123053902038032384": {"followers": "2,675", "datetime": "2019-04-30 02:38:10", "author": "@MohitIyyer", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126481391925915649": {"followers": "126", "datetime": "2019-05-09 13:37:47", "author": "@nakaet", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1154647094541594624": {"followers": "2,078", "datetime": "2019-07-26 06:58:14", "author": "@julianharris", "content_summary": "Unsupervised data augmentation details: Paper (10 July'19): https://t.co/5zWaCwTTWa Source for images and text. Includes comparison vs BERT and vs current SOTA for neural sentiment (IMDb dataset) https://t.co/2cJVpZbYSu Ping me if you get a Colab version"}, "1123571132316114945": {"followers": "69", "datetime": "2019-05-01 12:53:27", "author": "@ku21fan", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123103991603372032": {"followers": "19", "datetime": "2019-04-30 05:57:12", "author": "@MassBassLol", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123191637247553538": {"followers": "614", "datetime": "2019-04-30 11:45:28", "author": "@KouroshMeshgi", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243083663719321600": {"followers": "37", "datetime": "2020-03-26 07:53:35", "author": "@sajid_tee", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1149349449220542464": {"followers": "15,224", "datetime": "2019-07-11 16:07:17", "author": "@lmthang", "content_summary": "These plots (also included in the updated version of our UDA paper https://t.co/Uoj2Rb7Etx with a lot more results & details) illustrate very well Vincent's article on the quiet revolution of semi-supervised learning! https://t.co/ryuAeJFdZx"}, "1244008572024848384": {"followers": "2,672", "datetime": "2020-03-28 21:08:50", "author": "@ayirpelle", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1150344427749150721": {"followers": "221", "datetime": "2019-07-14 10:00:58", "author": "@PapersTrending", "content_summary": "[1/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 264 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1126312983359975424": {"followers": "24", "datetime": "2019-05-09 02:28:35", "author": "@nasu_0407", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123362173797847041": {"followers": "25", "datetime": "2019-04-30 23:03:07", "author": "@DeepHindsight", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126460017987674112": {"followers": "13", "datetime": "2019-05-09 12:12:51", "author": "@nononono713", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130512472274800640": {"followers": "442", "datetime": "2019-05-20 16:35:51", "author": "@AdrianB82", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1126350702626742272": {"followers": "153", "datetime": "2019-05-09 04:58:28", "author": "@zakki", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1177594078348877825": {"followers": "3,498", "datetime": "2019-09-27 14:41:21", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1178167811560132608": {"followers": "3,498", "datetime": "2019-09-29 04:41:10", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1123337949251276800": {"followers": "920", "datetime": "2019-04-30 21:26:52", "author": "@KloudStrife", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123146335501242368": {"followers": "62", "datetime": "2019-04-30 08:45:28", "author": "@ju_chieh", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123104415232200704": {"followers": "77", "datetime": "2019-04-30 05:58:53", "author": "@rajivpoc", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125555837777403904": {"followers": "184", "datetime": "2019-05-07 00:19:58", "author": "@johnnyprothero", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1128706869881475073": {"followers": "122", "datetime": "2019-05-15 17:01:02", "author": "@hasansaikatt", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1250976361944154113": {"followers": "117", "datetime": "2020-04-17 02:36:21", "author": "@moss_dalvi", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123801309998735363": {"followers": "54", "datetime": "2019-05-02 04:08:06", "author": "@drorhilman", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123092371065978881": {"followers": "19,900", "datetime": "2019-04-30 05:11:01", "author": "@dawnieando", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1177397784959496192": {"followers": "3,498", "datetime": "2019-09-27 01:41:21", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1125544272990617603": {"followers": "825", "datetime": "2019-05-06 23:34:00", "author": "@morioka", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1197701563185131520": {"followers": "130", "datetime": "2019-11-22 02:21:19", "author": "@jkronand", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1123095917140140033": {"followers": "99", "datetime": "2019-04-30 05:25:07", "author": "@treasured_write", "content_summary": "RT @arxiv_cs_LG: Unsupervised Data Augmentation. Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V. Le https://t.co/fvWfIwvX\u2026"}, "1123112921264005121": {"followers": "60", "datetime": "2019-04-30 06:32:41", "author": "@__isaac_s__", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123297325496111106": {"followers": "211", "datetime": "2019-04-30 18:45:26", "author": "@tiulpin", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1242985940869668872": {"followers": "2,067", "datetime": "2020-03-26 01:25:16", "author": "@EricSchles", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1177397734770393089": {"followers": "4,096", "datetime": "2019-09-27 01:41:09", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123112934782251009": {"followers": "20", "datetime": "2019-04-30 06:32:44", "author": "@Boristream", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123227559221530624": {"followers": "1,413", "datetime": "2019-04-30 14:08:13", "author": "@RexDouglass", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123040332659085312": {"followers": "4,350", "datetime": "2019-04-30 01:44:15", "author": "@aerinykim", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1247468835810054144": {"followers": "415", "datetime": "2020-04-07 10:18:41", "author": "@__nggih", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123041376013148162": {"followers": "3,104", "datetime": "2019-04-30 01:48:23", "author": "@eturner303", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123042547461267457": {"followers": "12,511", "datetime": "2019-04-30 01:53:03", "author": "@suzatweet", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123091705069047811": {"followers": "18,260", "datetime": "2019-04-30 05:08:23", "author": "@quocleix", "content_summary": "Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It combines well with transfer learning (e.g. BERT) and improves everything when datasets have a small number of labeled examples. Link:"}, "1123279647637164038": {"followers": "23", "datetime": "2019-04-30 17:35:12", "author": "@ycaedes", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123307863039008769": {"followers": "11,927", "datetime": "2019-04-30 19:27:19", "author": "@Rosenchild", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1125563325318778880": {"followers": "14", "datetime": "2019-05-07 00:49:43", "author": "@TsuguoMogami", "content_summary": "https://t.co/lnVhNyZJcf augmentation\u3067\u30e9\u30d9\u30eb\u304c\u5909\u308f\u3089\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u3060\u3051\u3067\u3001semi-supervised learning\u306b\u306a\u308b\u3068\u3002\u7d20\u6674\u3089\u3057\u304fsimple\u3002\u3053\u306e\u767a\u60f3\u306f\u306a\u304b\u3063\u305f\u3002"}, "1178137685212487681": {"followers": "4,096", "datetime": "2019-09-29 02:41:27", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123140716354514944": {"followers": "596", "datetime": "2019-04-30 08:23:08", "author": "@khanhxuannguyen", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123237596786610178": {"followers": "2,202", "datetime": "2019-04-30 14:48:06", "author": "@dansitu", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130077417568182272": {"followers": "1,456", "datetime": "2019-05-19 11:47:06", "author": "@Gabriel_Oguna", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1126402950312497159": {"followers": "620", "datetime": "2019-05-09 08:26:05", "author": "@Eseshinpu", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123094224100921344": {"followers": "88", "datetime": "2019-04-30 05:18:23", "author": "@Epsilon_Lee", "content_summary": "#dataaugmentation"}, "1123557824452288512": {"followers": "4,071", "datetime": "2019-05-01 12:00:34", "author": "@bgoncalves", "content_summary": "Unsupervised Data Augmentation https://t.co/FqrG4068tS"}, "1126711132964569088": {"followers": "252", "datetime": "2019-05-10 04:50:42", "author": "@bgangk", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1177956221313269760": {"followers": "4,096", "datetime": "2019-09-28 14:40:23", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1149327631814397954": {"followers": "3,498", "datetime": "2019-07-11 14:40:35", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1123452742574456833": {"followers": "614", "datetime": "2019-05-01 05:03:01", "author": "@KouroshMeshgi", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1243153668200960005": {"followers": "237", "datetime": "2020-03-26 12:31:45", "author": "@b2sam", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1247306333595942912": {"followers": "1,151", "datetime": "2020-04-06 23:32:58", "author": "@jd_mashiro", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123097661911945217": {"followers": "91", "datetime": "2019-04-30 05:32:03", "author": "@0xhexhex", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123833228098449410": {"followers": "28,418", "datetime": "2019-05-02 06:14:56", "author": "@ogrisel", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123885236029407232": {"followers": "29", "datetime": "2019-05-02 09:41:35", "author": "@ouali_yas", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123196674472534016": {"followers": "446", "datetime": "2019-04-30 12:05:29", "author": "@fikri2992", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123235005428162561": {"followers": "44", "datetime": "2019-04-30 14:37:48", "author": "@howardmeng", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126360254978019328": {"followers": "128", "datetime": "2019-05-09 05:36:26", "author": "@kodai_nakashima", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1236612306072678400": {"followers": "215", "datetime": "2020-03-08 11:18:43", "author": "@ShyBOT7", "content_summary": "RT @Deep_In_Depth: Unsupervised Data Augmentation for Consistency Training https://t.co/BZOt43yPaX #DeepLearning #NeuralNetworks #Artifici\u2026"}, "1242979928867569664": {"followers": "818", "datetime": "2020-03-26 01:01:23", "author": "@deepgradient", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1123220796715958273": {"followers": "3,498", "datetime": "2019-04-30 13:41:21", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation https://t.co/ojGkexCf7p"}, "1151069326541279234": {"followers": "221", "datetime": "2019-07-16 10:01:27", "author": "@PapersTrending", "content_summary": "[5/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 329 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1247236886000590852": {"followers": "29", "datetime": "2020-04-06 18:57:00", "author": "@chenlailin", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123222095972847616": {"followers": "180", "datetime": "2019-04-30 13:46:30", "author": "@sriharshams", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1130302628326305792": {"followers": "0", "datetime": "2019-05-20 02:42:01", "author": "@Sam09lol", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1123180025426194433": {"followers": "7", "datetime": "2019-04-30 10:59:20", "author": "@thomasbui2914", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125081136705630213": {"followers": "395", "datetime": "2019-05-05 16:53:40", "author": "@jeffmgould", "content_summary": "Seems like a big deal. Put in plain language: until now training neural nets to do useful tasks has required large amounts of examples where the correct answer is given by humans. That's difficult and expensive. Now it may be possible to train with far f"}, "1123262079543140357": {"followers": "195", "datetime": "2019-04-30 16:25:23", "author": "@hereticreader", "content_summary": "Unsupervised Data Augmentation - https://t.co/9D1COPFWPY https://t.co/NSBKE5rbUp"}, "1152156569234214913": {"followers": "221", "datetime": "2019-07-19 10:01:46", "author": "@PapersTrending", "content_summary": "[8/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 402 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1123046428631113728": {"followers": "2,671", "datetime": "2019-04-30 02:08:28", "author": "@mosko_mule", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126310908899160064": {"followers": "1,766", "datetime": "2019-05-09 02:20:21", "author": "@jaialkdanel", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243044244186492928": {"followers": "217", "datetime": "2020-03-26 05:16:57", "author": "@sambyalAbhi", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1126366238769172480": {"followers": "319", "datetime": "2019-05-09 06:00:12", "author": "@mikikusu", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123197091776479232": {"followers": "164,080", "datetime": "2019-04-30 12:07:09", "author": "@ceobillionaire", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123220750658351104": {"followers": "4,096", "datetime": "2019-04-30 13:41:10", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation https://t.co/ppABSi1gD9"}, "1125917431728353280": {"followers": "9,437", "datetime": "2019-05-08 00:16:48", "author": "@machine_ml", "content_summary": "RT @DS_insights: #UDA or unsupervised data augmentations new technique from @google to generate synthetic data for #neuralnetworks #AI #mac\u2026"}, "1149982094640201728": {"followers": "221", "datetime": "2019-07-13 10:01:11", "author": "@PapersTrending", "content_summary": "[3/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 244 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxjBsu - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1151431661877387264": {"followers": "221", "datetime": "2019-07-17 10:01:15", "author": "@PapersTrending", "content_summary": "[7/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 353 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1242990798846570496": {"followers": "0", "datetime": "2020-03-26 01:44:34", "author": "@Sam09lol", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123135733613592576": {"followers": "128", "datetime": "2019-04-30 08:03:20", "author": "@feedmari", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1125558105205403648": {"followers": "216", "datetime": "2019-05-07 00:28:58", "author": "@KSKSKSKS2", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1133951186254606337": {"followers": "94", "datetime": "2019-05-30 04:20:05", "author": "@christiankothe", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1187480816584187909": {"followers": "11,927", "datetime": "2019-10-24 21:27:43", "author": "@Rosenchild", "content_summary": "RT @BioDecoded: Inference of clonal selection in cancer populations using single-cell sequencing data | Bioinformatics https://t.co/hbXrtDZ\u2026"}, "1123838585210318848": {"followers": "147", "datetime": "2019-05-02 06:36:13", "author": "@rypi314", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123034048748826625": {"followers": "289", "datetime": "2019-04-30 01:19:16", "author": "@dannyehb", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1247325965010661376": {"followers": "424", "datetime": "2020-04-07 00:50:58", "author": "@iamknighton", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1126315050648498176": {"followers": "2,462", "datetime": "2019-05-09 02:36:48", "author": "@func_hs", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123178248492347392": {"followers": "456", "datetime": "2019-04-30 10:52:16", "author": "@PerthMLGroup", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1149330898631852034": {"followers": "2,278", "datetime": "2019-07-11 14:53:34", "author": "@osciiart", "content_summary": "RT @imenurok: \u8a71\u984c\u306eUnsupervised Data Augmentation (UDA)\u3002 https://t.co/IW3AgZWjdO Ablation study\u306eCropping & flipping\u306eError\u7387\u304c16.17%\u306a\u3053\u3068\u304c\u8003\u3048\u3055\u305b\u3089\u308c\u308b\u2026"}, "1125479938457399296": {"followers": "367", "datetime": "2019-05-06 19:18:22", "author": "@mdigangiPA", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123238982710693889": {"followers": "62", "datetime": "2019-04-30 14:53:36", "author": "@JoaoLSTorres", "content_summary": "RT @engsoares_gyn: Um avan\u00e7o importante. https://t.co/JrnY5DomeH"}, "1243005642102542337": {"followers": "29", "datetime": "2020-03-26 02:43:33", "author": "@chenlailin", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1129092724072882176": {"followers": "93", "datetime": "2019-05-16 18:34:17", "author": "@David_Brabant", "content_summary": "https://t.co/z9z0nVJYV7 https://t.co/z9z0nVJYV7"}, "1247489591373975552": {"followers": "16", "datetime": "2020-04-07 11:41:10", "author": "@mxxtsai", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123241489427980288": {"followers": "180", "datetime": "2019-04-30 15:03:34", "author": "@SanjeethVeigas", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1153724947254140928": {"followers": "11,927", "datetime": "2019-07-23 17:53:57", "author": "@Rosenchild", "content_summary": "RT @BioDecoded: Advancing Semi-supervised Learning with Unsupervised Data Augmentation | Google AI Blog https://t.co/hbXrtDZk7S https://t.c\u2026"}, "1136050099530981376": {"followers": "4", "datetime": "2019-06-04 23:20:25", "author": "@ZilongZhong", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123088355342766080": {"followers": "626", "datetime": "2019-04-30 04:55:04", "author": "@choongng", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123925538861719552": {"followers": "1,993", "datetime": "2019-05-02 12:21:44", "author": "@emilyagras", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1177986581636026368": {"followers": "3,498", "datetime": "2019-09-28 16:41:01", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1126409075569283073": {"followers": "22", "datetime": "2019-05-09 08:50:25", "author": "@kh20190129", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123254558724116481": {"followers": "49", "datetime": "2019-04-30 15:55:30", "author": "@MhitInformatica", "content_summary": "RT @engsoares_gyn: Um avan\u00e7o importante. https://t.co/JrnY5DomeH"}, "1123799520884736001": {"followers": "14", "datetime": "2019-05-02 04:00:59", "author": "@aarman", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123200654481215488": {"followers": "297", "datetime": "2019-04-30 12:21:18", "author": "@jmcimula", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123060121595203590": {"followers": "1", "datetime": "2019-04-30 03:02:53", "author": "@hieuqng26", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123166420244803584": {"followers": "1,240", "datetime": "2019-04-30 10:05:16", "author": "@drewfarris", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126332402819784704": {"followers": "316", "datetime": "2019-05-09 03:45:45", "author": "@XzPFhGXhc8nDTIP", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1131118440591138816": {"followers": "66", "datetime": "2019-05-22 08:43:46", "author": "@khuongav", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1149619733387345921": {"followers": "221", "datetime": "2019-07-12 10:01:17", "author": "@PapersTrending", "content_summary": "[4/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 191 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxBck2 - \ud83d\udd17 https://t.co/PL92FzPFTq"}, "1235330534777262081": {"followers": "15,224", "datetime": "2020-03-04 22:25:25", "author": "@lmthang", "content_summary": "Our UDA work (https://t.co/Uoj2RbpfS7) proposes the use of strong augmentation (RandAugment) which subsequent works (FixMatch, NoisyStudent) follow. UDA uses soft pseudo-labels whereas FixMatch uses hard ones after \"weak\" augmentation in consistency traini"}, "1247565446490001408": {"followers": "259", "datetime": "2020-04-07 16:42:35", "author": "@jcchinhui", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1130441637438660609": {"followers": "1,456", "datetime": "2019-05-20 11:54:23", "author": "@Gabriel_Oguna", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1129948864474243072": {"followers": "10", "datetime": "2019-05-19 03:16:17", "author": "@yarphs", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1182168647533391873": {"followers": "28", "datetime": "2019-10-10 05:39:03", "author": "@Cherrypick8", "content_summary": "UNSUPERVISED DATA AUGMENTATION (UDA) https://t.co/dYY5spGT1y https://t.co/ebRDRDMGtC trying to use for stock market sentiment analysis (pytorch and BERT)"}, "1134650033796595713": {"followers": "3", "datetime": "2019-06-01 02:37:03", "author": "@CartusK", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1124051430200029188": {"followers": "109", "datetime": "2019-05-02 20:41:59", "author": "@joseluisalcala", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126331090501656577": {"followers": "16,954", "datetime": "2019-05-09 03:40:32", "author": "@kazoo04", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1131460936680783872": {"followers": "401", "datetime": "2019-05-23 07:24:43", "author": "@jan_boehm", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126472703660023809": {"followers": "36", "datetime": "2019-05-09 13:03:16", "author": "@kuz44ma69", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1129871024537919488": {"followers": "593", "datetime": "2019-05-18 22:06:58", "author": "@soumen_eclectic", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123351251545198597": {"followers": "374", "datetime": "2019-04-30 22:19:43", "author": "@MatteoMasperoNL", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123101042843897856": {"followers": "1,080", "datetime": "2019-04-30 05:45:29", "author": "@_josh_meyer_", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126647990200889344": {"followers": "1,309", "datetime": "2019-05-10 00:39:47", "author": "@akihiro_akichan", "content_summary": "https://t.co/FQXT9Ed7CV \u30e9\u30d9\u30eb\u306a\u3057\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u3066\u7cbe\u5ea6\u5411\u4e0a\u3055\u305b\u308b\u624b\u6bb5\u3067SOTA\u3002\u30e9\u30d9\u30eb\u306a\u3057\u30c7\u30fc\u30bf\u3068\u30c7\u30fc\u30bf\u62e1\u5f35\u306e\u5909\u63db\u3092\u52a0\u3048\u305f\u30e9\u30d9\u30eb\u306a\u3057\u30c7\u30fc\u30bf\u306eKL\u8ddd\u96e2\u3092\u640d\u5931\u95a2\u6570\u306b\u7d44\u307f\u8fbc\u3080\u3053\u3068\u3001\u5f90\u3005\u306b\u5f37\u3044\u8a13\u7df4\u4fe1\u53f7\u3092\u4e0e\u3048\u3066\u3044\u304fTSA\u3067\u904e\u5b66\u7fd2\u3092\u9632\u3050\u3053\u3068\u3001\u306e\uff12\u70b9\u304c\u30dd\u30a4\u30f3\u30c8\u3002\u5b9f\u88c5\u7c21\u5358\u305d\u3046\u3067\u3001NLP\u3068\u753b\u50cf\u4e21\u65b9\u3067\u5b9f\u7e3e\u3042\u308a https://t.co/NNHIUTJE3x"}, "1133551300556156928": {"followers": "21", "datetime": "2019-05-29 01:51:05", "author": "@ys1045097987", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123196665681158144": {"followers": "41", "datetime": "2019-04-30 12:05:27", "author": "@aiton5", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243017505108627456": {"followers": "168", "datetime": "2020-03-26 03:30:42", "author": "@dr_levan", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123252602479697920": {"followers": "164", "datetime": "2019-04-30 15:47:44", "author": "@ZachBessinger", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123183503733084161": {"followers": "95", "datetime": "2019-04-30 11:13:09", "author": "@Appanacca", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1242989449622896641": {"followers": "0", "datetime": "2020-03-26 01:39:13", "author": "@Sam09lol", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1123195711284174850": {"followers": "4", "datetime": "2019-04-30 12:01:40", "author": "@tomaxent", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123243253770227712": {"followers": "424", "datetime": "2019-04-30 15:10:35", "author": "@iamknighton", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1177443218037719041": {"followers": "3,498", "datetime": "2019-09-27 04:41:53", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexkDIP"}, "1123520604915658753": {"followers": "70", "datetime": "2019-05-01 09:32:40", "author": "@hjguyhan", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123317214248091648": {"followers": "96", "datetime": "2019-04-30 20:04:28", "author": "@nacim_belkhir", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1255636138393579521": {"followers": "551", "datetime": "2020-04-29 23:12:38", "author": "@mtugrull", "content_summary": "Benim kulland\u0131\u011f\u0131m ve i\u00e7eri\u011fini sevdi\u011fim #MachineLearning Bilinmesi Gereken Ara\u015ft\u0131rma Makaleleri 1)https://t.co/QAofv0DBGm 2)https://t.co/VyeLZZ1Pss 3)https://t.co/Zn4deZEuKg 4)https://t.co/TPeDZgI7Z1 5)https://t.co/UrPbzY1PVk 6)https://t.co/9rN7GM7NGs 7)ht"}, "1123164489543634944": {"followers": "70", "datetime": "2019-04-30 09:57:36", "author": "@sumitsethy", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1187217981954117632": {"followers": "1,130", "datetime": "2019-10-24 04:03:18", "author": "@BioDecoded", "content_summary": "Inference of clonal selection in cancer populations using single-cell sequencing data | Bioinformatics https://t.co/hbXrtDZk7S https://t.co/Er7lLI2hmp #MachineLearning https://t.co/AWt9hBaOGr"}, "1123454377933594624": {"followers": "11", "datetime": "2019-05-01 05:09:31", "author": "@bananadata48", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123066415215403008": {"followers": "310", "datetime": "2019-04-30 03:27:53", "author": "@arxiv_cs_LG", "content_summary": "Unsupervised Data Augmentation. Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V. Le https://t.co/fvWfIwvXIf"}, "1123195269804380160": {"followers": "164,080", "datetime": "2019-04-30 11:59:54", "author": "@ceobillionaire", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1154654358480408576": {"followers": "0", "datetime": "2019-07-26 07:27:06", "author": "@Sam09lol", "content_summary": "RT @julianharris: Unsupervised data augmentation details: Paper (10 July'19): https://t.co/5zWaCwTTWa Source for images and text. Includes\u2026"}, "1123124061834498048": {"followers": "172", "datetime": "2019-04-30 07:16:57", "author": "@ggdupont", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123112123775610881": {"followers": "8,538", "datetime": "2019-04-30 06:29:31", "author": "@rbhar90", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1178336327315509249": {"followers": "303", "datetime": "2019-09-29 15:50:47", "author": "@subhobrata1", "content_summary": "RT @arxiv_cscv: Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1235337947442016257": {"followers": "2,672", "datetime": "2020-03-04 22:54:52", "author": "@ayirpelle", "content_summary": "RT @lmthang: Our UDA work (https://t.co/Uoj2RbpfS7) proposes the use of strong augmentation (RandAugment) which subsequent works (FixMatch,\u2026"}, "1242997444767436800": {"followers": "2", "datetime": "2020-03-26 02:10:59", "author": "@Sheuancts", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1152081221519699977": {"followers": "42", "datetime": "2019-07-19 05:02:22", "author": "@MishakinSergey", "content_summary": "RT @PapersTrending: [10/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 374 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.c\u2026"}, "1123099208397934593": {"followers": "459", "datetime": "2019-04-30 05:38:12", "author": "@dolhani", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123399272374779905": {"followers": "57", "datetime": "2019-05-01 01:30:32", "author": "@MundherAlshabi", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123247030221058049": {"followers": "268", "datetime": "2019-04-30 15:25:35", "author": "@ReginaMeszlenyi", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123835883441086465": {"followers": "6,125", "datetime": "2019-05-02 06:25:29", "author": "@StephenPiment", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123935971538558977": {"followers": "16", "datetime": "2019-05-02 13:03:11", "author": "@_NicolasHenry", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1125599971464470528": {"followers": "474", "datetime": "2019-05-07 03:15:20", "author": "@yasuokajihei", "content_summary": "RT @hillbig: In semi-supervised learning, VAT adds adversarial noise to unsupervised data and makes its prediction distribution matches the\u2026"}, "1123126079894384640": {"followers": "2,204", "datetime": "2019-04-30 07:24:58", "author": "@MarkNeumannnn", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123205072073175040": {"followers": "9", "datetime": "2019-04-30 12:38:51", "author": "@TyvNguyen", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1129974203900420096": {"followers": "356", "datetime": "2019-05-19 04:56:58", "author": "@vbellet", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123112392039194624": {"followers": "72", "datetime": "2019-04-30 06:30:35", "author": "@gabeibagon", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123275586770735104": {"followers": "229", "datetime": "2019-04-30 17:19:03", "author": "@_TheodoreM_", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123157133921439744": {"followers": "3,195", "datetime": "2019-04-30 09:28:22", "author": "@A_K_Nain", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123127973903601664": {"followers": "723", "datetime": "2019-04-30 07:32:30", "author": "@plusepsilon", "content_summary": "Cool work. Coincidently I have a PR up right now at my company that implements TSA (training signal annealing), haha."}, "1125917008124686336": {"followers": "116", "datetime": "2019-05-08 00:15:07", "author": "@DS_insights", "content_summary": "#UDA or unsupervised data augmentations new technique from @google to generate synthetic data for #neuralnetworks #AI #machinelearning https://t.co/AJoEUfvBHO"}, "1123461282391371777": {"followers": "336", "datetime": "2019-05-01 05:36:57", "author": "@jeanphix", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1148431735530696704": {"followers": "3,522", "datetime": "2019-07-09 03:20:37", "author": "@NVSData", "content_summary": "RT @jiristo: Today with @AISC_TO: Gordon presented the work about Unsupervised Data Augmentation https://t.co/OdIgfliKF5 Conclusion: TSA t\u2026"}, "1123038842678722560": {"followers": "1,413", "datetime": "2019-04-30 01:38:19", "author": "@RexDouglass", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126309422379044865": {"followers": "2,043", "datetime": "2019-05-09 02:14:26", "author": "@imenurok", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123753407972556800": {"followers": "5", "datetime": "2019-05-02 00:57:45", "author": "@pluviophile16", "content_summary": "\ud83d\ude2f"}, "1130330640723800065": {"followers": "38", "datetime": "2019-05-20 04:33:19", "author": "@experiencor", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1123147592743804928": {"followers": "18", "datetime": "2019-04-30 08:50:27", "author": "@amansinha09", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126311236105191424": {"followers": "1,609", "datetime": "2019-05-09 02:21:39", "author": "@syinari0123", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123228927823007745": {"followers": "222", "datetime": "2019-04-30 14:13:39", "author": "@ashrayme", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126409720560926720": {"followers": "303", "datetime": "2019-05-09 08:52:59", "author": "@wakadori_Mk2", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1247521780312338432": {"followers": "2,483", "datetime": "2020-04-07 13:49:04", "author": "@Aravind7694", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1247438501341089792": {"followers": "12", "datetime": "2020-04-07 08:18:09", "author": "@AIPulp", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1130428828587741184": {"followers": "121", "datetime": "2019-05-20 11:03:29", "author": "@vakratundd", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1179028418857521152": {"followers": "4,096", "datetime": "2019-10-01 13:40:55", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1248880274110205952": {"followers": "30", "datetime": "2020-04-11 07:47:15", "author": "@GuoXiaohui", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123484627572862976": {"followers": "13,228", "datetime": "2019-05-01 07:09:43", "author": "@arnicas", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130441581943808001": {"followers": "1,456", "datetime": "2019-05-20 11:54:10", "author": "@Gabriel_Oguna", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126333971883630595": {"followers": "2,861", "datetime": "2019-05-09 03:51:59", "author": "@Tarpon_red2", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1126448346120347648": {"followers": "471", "datetime": "2019-05-09 11:26:28", "author": "@daytb_twy", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1247358363639279616": {"followers": "1", "datetime": "2020-04-07 02:59:43", "author": "@LanLe58698794", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1126318018349359105": {"followers": "1,023", "datetime": "2019-05-09 02:48:36", "author": "@NmaViv", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1125358111202660352": {"followers": "41", "datetime": "2019-05-06 11:14:16", "author": "@marshallchris", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243088995522949121": {"followers": "20", "datetime": "2020-03-26 08:14:46", "author": "@Boristream", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123096526178283520": {"followers": "15,224", "datetime": "2019-04-30 05:27:32", "author": "@lmthang", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123476924511268864": {"followers": "261", "datetime": "2019-05-01 06:39:06", "author": "@GuptaRajat033", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123859268560662529": {"followers": "51", "datetime": "2019-05-02 07:58:24", "author": "@prabhuiitdhn", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1236607599900086273": {"followers": "8,933", "datetime": "2020-03-08 11:00:01", "author": "@Deep_In_Depth", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/BZOt43yPaX #DeepLearning #NeuralNetworks #ArtificialIntelligence #MachineLearning #ReinforcementLearning #AGI #NeuroMorphic #NPU #AutonomousCar #NewMobility #DL #AI #ML #NLP #TensorFlow"}, "1125637010004348928": {"followers": "781", "datetime": "2019-05-07 05:42:31", "author": "@HrSaghir", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123087646526443521": {"followers": "773", "datetime": "2019-04-30 04:52:15", "author": "@arxivml", "content_summary": "\"Unsupervised Data Augmentation\", Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, Quoc V\uff0e Le https://t.co/5Ncf80eZbk"}, "1126348445243940864": {"followers": "190", "datetime": "2019-05-09 04:49:30", "author": "@nskm_m", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123130515521847297": {"followers": "59", "datetime": "2019-04-30 07:42:36", "author": "@flapdoodle_sand", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123181491415068678": {"followers": "1,417", "datetime": "2019-04-30 11:05:09", "author": "@seanmylaw", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123275859702337536": {"followers": "9", "datetime": "2019-04-30 17:20:09", "author": "@c0uchs_p0tat0", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1131250023335956480": {"followers": "8", "datetime": "2019-05-22 17:26:37", "author": "@doombris", "content_summary": "RT @madrugad0: a nice work from Google on [unsupervised] data augmentation, the key idea is to add specific smoothness loss on perturbed da\u2026"}, "1123197717641981959": {"followers": "160", "datetime": "2019-04-30 12:09:38", "author": "@Foivos_Diak", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1149204795091066880": {"followers": "2,663", "datetime": "2019-07-11 06:32:28", "author": "@sigitpurnomo", "content_summary": "RT @arxiv_cscl: Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1235563079787630592": {"followers": "5,312", "datetime": "2020-03-05 13:49:28", "author": "@HubBucket", "content_summary": "RT @lmthang: Our UDA work (https://t.co/Uoj2RbpfS7) proposes the use of strong augmentation (RandAugment) which subsequent works (FixMatch,\u2026"}, "1126509484333920256": {"followers": "82", "datetime": "2019-05-09 15:29:25", "author": "@RyoHWS", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1242986840568840192": {"followers": "89", "datetime": "2020-03-26 01:28:51", "author": "@singularpattern", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1125640499178745856": {"followers": "236", "datetime": "2019-05-07 05:56:23", "author": "@flowing", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123136621883170817": {"followers": "25", "datetime": "2019-04-30 08:06:52", "author": "@NLP_Grayming", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1150057950943141889": {"followers": "24", "datetime": "2019-07-13 15:02:37", "author": "@oyeGopi_", "content_summary": "RT @arxiv_cscl: Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1123552932241166337": {"followers": "185", "datetime": "2019-05-01 11:41:08", "author": "@suresh_p", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123544406101913600": {"followers": "185", "datetime": "2019-05-01 11:07:15", "author": "@ParryBhatia243", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123351213280514054": {"followers": "374", "datetime": "2019-04-30 22:19:34", "author": "@MatteoMasperoNL", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125610831432093696": {"followers": "157", "datetime": "2019-05-07 03:58:29", "author": "@Nbring", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123397795749097473": {"followers": "228", "datetime": "2019-05-01 01:24:40", "author": "@hengcherkeng", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123844837265018880": {"followers": "2,262", "datetime": "2019-05-02 07:01:03", "author": "@AdilMouja", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123208736535908352": {"followers": "49", "datetime": "2019-04-30 12:53:25", "author": "@paulomannjr", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123231701877035008": {"followers": "64", "datetime": "2019-04-30 14:24:41", "author": "@ONKaraHSTS", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123197050051596288": {"followers": "43", "datetime": "2019-04-30 12:06:59", "author": "@frabarbuto", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123834469276889091": {"followers": "323", "datetime": "2019-05-02 06:19:51", "author": "@dnlcrl", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1153763639356268547": {"followers": "5,312", "datetime": "2019-07-23 20:27:42", "author": "@HubBucket", "content_summary": "RT @BioDecoded: Advancing Semi-supervised Learning with Unsupervised Data Augmentation | Google AI Blog https://t.co/hbXrtDZk7S https://t.c\u2026"}, "1123241093989060608": {"followers": "317", "datetime": "2019-04-30 15:02:00", "author": "@phi_nate", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123557384713134081": {"followers": "16", "datetime": "2019-05-01 11:58:49", "author": "@Tzeny25", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123379034178539523": {"followers": "7", "datetime": "2019-05-01 00:10:07", "author": "@xiaoxiong", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1242988885812097025": {"followers": "164,080", "datetime": "2020-03-26 01:36:58", "author": "@ceobillionaire", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1126510798216388609": {"followers": "134", "datetime": "2019-05-09 15:34:38", "author": "@mawatan6x", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1126767304266530816": {"followers": "2", "datetime": "2019-05-10 08:33:54", "author": "@chris_bonitz", "content_summary": "Found on Arxiv: Unsupervised Data Augmentation. Uses consistency between original and augmented samples as additional signal, complementing supervised training. https://t.co/tlXgOJ4kMj"}, "1123206975431618561": {"followers": "82", "datetime": "2019-04-30 12:46:25", "author": "@erichansm", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123648110352224256": {"followers": "248", "datetime": "2019-05-01 17:59:20", "author": "@gsksantosh", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126660477902147584": {"followers": "71", "datetime": "2019-05-10 01:29:24", "author": "@semiinvariant", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130278253212491779": {"followers": "15,224", "datetime": "2019-05-20 01:05:09", "author": "@lmthang", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1242988891713327106": {"followers": "56", "datetime": "2020-03-26 01:37:00", "author": "@aptr322", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1243119319845711872": {"followers": "515", "datetime": "2020-03-26 10:15:16", "author": "@pijili", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123619303096373248": {"followers": "67", "datetime": "2019-05-01 16:04:52", "author": "@tenzinchang", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123358457170513920": {"followers": "15", "datetime": "2019-04-30 22:48:21", "author": "@sunprinceS_0822", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123232036293103617": {"followers": "2,217", "datetime": "2019-04-30 14:26:00", "author": "@gkossakowski", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1242980356350861313": {"followers": "292", "datetime": "2020-03-26 01:03:05", "author": "@Shujian_Liu", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123037477302784002": {"followers": "337", "datetime": "2019-04-30 01:32:54", "author": "@chunmlpage", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123170372755574787": {"followers": "365", "datetime": "2019-04-30 10:20:59", "author": "@JeanMarcJAzzi", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1129978427543437312": {"followers": "180", "datetime": "2019-05-19 05:13:45", "author": "@SanjeethVeigas", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1149327601888051201": {"followers": "4,096", "datetime": "2019-07-11 14:40:28", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1124193064006774791": {"followers": "39", "datetime": "2019-05-03 06:04:47", "author": "@Qiuzhuang", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243083489932648448": {"followers": "44", "datetime": "2020-03-26 07:52:54", "author": "@jeandut14000", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1123579926500691970": {"followers": "152", "datetime": "2019-05-01 13:28:24", "author": "@ayansm23", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123231926305689602": {"followers": "215", "datetime": "2019-04-30 14:25:34", "author": "@Akihiro_Sanada", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123226734386659328": {"followers": "818", "datetime": "2019-04-30 14:04:56", "author": "@ErmiaBivatan", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126311254027464704": {"followers": "14,188", "datetime": "2019-05-09 02:21:43", "author": "@upura0", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123162021518823425": {"followers": "302", "datetime": "2019-04-30 09:47:47", "author": "@cepera_ang", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243195586636943362": {"followers": "4,531", "datetime": "2020-03-26 15:18:19", "author": "@ChrSzegedy", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123400949085634560": {"followers": "21,221", "datetime": "2019-05-01 01:37:12", "author": "@DataSciNews", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126322127747948546": {"followers": "293", "datetime": "2019-05-09 03:04:55", "author": "@chachay", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1236627830882144256": {"followers": "2,464", "datetime": "2020-03-08 12:20:24", "author": "@wiomax_cn", "content_summary": "RT @Deep_In_Depth: Unsupervised Data Augmentation for Consistency Training https://t.co/BZOt43yPaX #DeepLearning #NeuralNetworks #Artifici\u2026"}, "1148431406344880133": {"followers": "55", "datetime": "2019-07-09 03:19:18", "author": "@jiristo", "content_summary": "Today with @AISC_TO: Gordon presented the work about Unsupervised Data Augmentation https://t.co/OdIgfliKF5 Conclusion: TSA technique can effectively prevent UDA method from #overfitting the #supervised data. #ML #DataScience https://t.co/lqqCoN9Nxo"}, "1247318287328870402": {"followers": "81", "datetime": "2020-04-07 00:20:28", "author": "@mihaidobri", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123064544274681857": {"followers": "2,927", "datetime": "2019-04-30 03:20:27", "author": "@evolvingstuff", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1124428783434522624": {"followers": "11,927", "datetime": "2019-05-03 21:41:27", "author": "@Rosenchild", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123111792069230592": {"followers": "277", "datetime": "2019-04-30 06:28:12", "author": "@ZimMatthias", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130135893656911873": {"followers": "179,061", "datetime": "2019-05-19 15:39:28", "author": "@Montreal_AI", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1178630272092237825": {"followers": "1", "datetime": "2019-09-30 11:18:49", "author": "@hellomatttteo", "content_summary": "RT @arxiv_cscv: Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1159251046994272256": {"followers": "5,312", "datetime": "2019-08-07 23:52:42", "author": "@HubBucket", "content_summary": "RT @BioDecoded: Advancing Semi-supervised Learning with Unsupervised Data Augmentation | Google AI Blog https://t.co/hbXrtDZk7S https://t.c\u2026"}, "1133833853234061312": {"followers": "87", "datetime": "2019-05-29 20:33:50", "author": "@knatetucker", "content_summary": "The two most popular papers in arxiv sanity right now, MixMatch and UDA, are both about using models to make more/better data to make better models. https://t.co/rum7tswBQU https://t.co/YqYMGjIxf2"}, "1123157893048487938": {"followers": "87", "datetime": "2019-04-30 09:31:23", "author": "@ChiahsuanL", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123044328060936194": {"followers": "858", "datetime": "2019-04-30 02:00:07", "author": "@deep_rl", "content_summary": "Unsupervised Data Augmentation - Qizhe Xie https://t.co/v2cVoGV1IY"}, "1123251777598513153": {"followers": "206", "datetime": "2019-04-30 15:44:27", "author": "@bnjasim", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123099266723958785": {"followers": "29", "datetime": "2019-04-30 05:38:26", "author": "@chenlailin", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1131230611216060416": {"followers": "432", "datetime": "2019-05-22 16:09:29", "author": "@bhargavbardipur", "content_summary": "RT @madrugad0: a nice work from Google on [unsupervised] data augmentation, the key idea is to add specific smoothness loss on perturbed da\u2026"}, "1123284452912840704": {"followers": "276", "datetime": "2019-04-30 17:54:17", "author": "@honasu", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243012537995661313": {"followers": "8", "datetime": "2020-03-26 03:10:57", "author": "@FelipeM39904454", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1125559365337899008": {"followers": "2,061", "datetime": "2019-05-07 00:33:59", "author": "@yo_ehara", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1123253287048876033": {"followers": "736", "datetime": "2019-04-30 15:50:27", "author": "@unsorsodicorda", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126310739151429632": {"followers": "1,766", "datetime": "2019-05-09 02:19:40", "author": "@jaialkdanel", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123196935345725442": {"followers": "478", "datetime": "2019-04-30 12:06:32", "author": "@jmsl", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1130325013956108289": {"followers": "1,287", "datetime": "2019-05-20 04:10:58", "author": "@heghbalz", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123065636509310976": {"followers": "662", "datetime": "2019-04-30 03:24:47", "author": "@sam_havens", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123320827372433408": {"followers": "1", "datetime": "2019-04-30 20:18:50", "author": "@Frances85464844", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123264595316158464": {"followers": "1,116", "datetime": "2019-04-30 16:35:23", "author": "@rdzeniu", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123448713018576898": {"followers": "307", "datetime": "2019-05-01 04:47:00", "author": "@michaeld7", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126322107225296896": {"followers": "11", "datetime": "2019-05-09 03:04:51", "author": "@AIUEO_Rhythm", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1243873577016987649": {"followers": "683", "datetime": "2020-03-28 12:12:25", "author": "@artsiom_s", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1235260277014138881": {"followers": "15,224", "datetime": "2020-03-04 17:46:14", "author": "@lmthang", "content_summary": "UDA (https://t.co/Uoj2Rb7Etx) proposes the usage of strong augmentation (RandAugment) which subsequent works (ReMixMatch, MixMatch, NoisyStudent) follow. On the path through \"weak\" augmentation, UDA uses soft pseudo-labels whereas FixMatch uses hard pseudo"}, "1126335635499806722": {"followers": "298", "datetime": "2019-05-09 03:58:36", "author": "@KaazTech", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123184267520036864": {"followers": "10,021", "datetime": "2019-04-30 11:16:11", "author": "@prrgutierrez", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1129953759533117441": {"followers": "818", "datetime": "2019-05-19 03:35:44", "author": "@ErmiaBivatan", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1125661754812444672": {"followers": "240", "datetime": "2019-05-07 07:20:50", "author": "@vdelatorrelabs", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123202611593793538": {"followers": "24", "datetime": "2019-04-30 12:29:05", "author": "@healthonrails", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123315281223389184": {"followers": "381", "datetime": "2019-04-30 19:56:47", "author": "@shyamal_chandra", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126335751866556416": {"followers": "84", "datetime": "2019-05-09 03:59:04", "author": "@ashi__no", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1247232775091937280": {"followers": "15,224", "datetime": "2020-04-06 18:40:40", "author": "@lmthang", "content_summary": "Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStudent (https://t.co/cBvSLwq9O3). It also highlights VAT, Pi-Model, MeanTeacher, and MixMatch. Slides: https://t.co/aUmG45RmW6"}, "1123166188547141632": {"followers": "322", "datetime": "2019-04-30 10:04:21", "author": "@indrango", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1247375727239892992": {"followers": "6", "datetime": "2020-04-07 04:08:43", "author": "@Rigvita1", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123382656245256193": {"followers": "105", "datetime": "2019-05-01 00:24:31", "author": "@minoobeyzavi", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123690824477310977": {"followers": "4,806", "datetime": "2019-05-01 20:49:04", "author": "@IntuitMachine", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123603884474114050": {"followers": "664", "datetime": "2019-05-01 15:03:36", "author": "@crude2refined", "content_summary": "RT @SalehCU: Really nice work by Quoc Le and colleagues at Google & CMU on unsupervised data augmentation. Highly recommend checking out th\u2026"}, "1123179697309798400": {"followers": "581", "datetime": "2019-04-30 10:58:02", "author": "@gregvidy", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125803910499848192": {"followers": "106", "datetime": "2019-05-07 16:45:43", "author": "@EsteveGallego", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123300055220277249": {"followers": "28", "datetime": "2019-04-30 18:56:17", "author": "@superzht", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123123887527432198": {"followers": "41", "datetime": "2019-04-30 07:16:16", "author": "@aiton5", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1131219611372933125": {"followers": "299", "datetime": "2019-05-22 15:25:47", "author": "@madrugad0", "content_summary": "a nice work from Google on [unsupervised] data augmentation, the key idea is to add specific smoothness loss on perturbed data; new SotA on IMDB using only 20 (sic!) labelled examples; authors introduce TF-IDF based word replacement for augmentation https:"}, "1126742943862120449": {"followers": "250", "datetime": "2019-05-10 06:57:06", "author": "@o8v0i1", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123646955752706049": {"followers": "425", "datetime": "2019-05-01 17:54:45", "author": "@ryo_masumura", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1178333847739621376": {"followers": "4,096", "datetime": "2019-09-29 15:40:56", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123238055232409600": {"followers": "2,202", "datetime": "2019-04-30 14:49:55", "author": "@dansitu", "content_summary": "\"on the IMDb text classification dataset, with only 20 labeled examples, UDA outperforms the state-of-the-art model trained on 25,000 labeled examples\" - woah. Learning with minimal data is the most exciting thing IMO"}, "1130325053017657345": {"followers": "1,287", "datetime": "2019-05-20 04:11:07", "author": "@heghbalz", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1123114296613986304": {"followers": "167", "datetime": "2019-04-30 06:38:09", "author": "@fferousi", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1130251839104999424": {"followers": "536", "datetime": "2019-05-19 23:20:12", "author": "@sangha_deb", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1123293759968616454": {"followers": "1,262", "datetime": "2019-04-30 18:31:16", "author": "@arjunmanrai", "content_summary": "Wow: \"on IMDb, UDA with 20 labeled examples outperforms the state-of-the-art model trained on 1250x more labeled data\" https://t.co/szP9xN1wQL"}, "1131224937316913152": {"followers": "728", "datetime": "2019-05-22 15:46:56", "author": "@sarnthil", "content_summary": "RT @madrugad0: a nice work from Google on [unsupervised] data augmentation, the key idea is to add specific smoothness loss on perturbed da\u2026"}, "1236646792848080896": {"followers": "5,125", "datetime": "2020-03-08 13:35:45", "author": "@clairebotai", "content_summary": "RT @Deep_In_Depth: Unsupervised Data Augmentation for Consistency Training https://t.co/BZOt43yPaX #DeepLearning #NeuralNetworks #Artifici\u2026"}, "1123108448638590976": {"followers": "635", "datetime": "2019-04-30 06:14:55", "author": "@lievAnastazia", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123485046650933248": {"followers": "294", "datetime": "2019-05-01 07:11:23", "author": "@fgianferrari", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1151431684413411329": {"followers": "221", "datetime": "2019-07-17 10:01:20", "author": "@PapersTrending", "content_summary": "[8/10] \ud83d\udcc8 - Unsupervised Data Augmentation - 353 \u2b50 - \ud83d\udcc4 https://t.co/T2nkVxjBsu - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1177790396224724992": {"followers": "4,096", "datetime": "2019-09-28 03:41:27", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123239964500643843": {"followers": "345", "datetime": "2019-04-30 14:57:30", "author": "@arora_manuel", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123099076537376770": {"followers": "1,647", "datetime": "2019-04-30 05:37:40", "author": "@hllo_wrld", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123111181143744512": {"followers": "2,280", "datetime": "2019-04-30 06:25:46", "author": "@pgroth", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123255548835766277": {"followers": "187", "datetime": "2019-04-30 15:59:26", "author": "@gascosta", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123230453299851264": {"followers": "165", "datetime": "2019-04-30 14:19:43", "author": "@giovenko", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123203015937277954": {"followers": "651", "datetime": "2019-04-30 12:30:41", "author": "@iamsidd", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123141756718075904": {"followers": "574", "datetime": "2019-04-30 08:27:16", "author": "@_stefan_munich", "content_summary": "Very impressing: \"On the IMDb text classification dataset, with only 20 labeled examples, UDA outperforms the state-of-the-art model trained on 25,000 labeled examples\" \ud83e\udd17"}, "1123107336409833473": {"followers": "6", "datetime": "2019-04-30 06:10:29", "author": "@_ironbar_", "content_summary": "[1904.12848] Unsupervised Data Augmentation https://t.co/Uqva3VZB7N"}, "1247301762609905666": {"followers": "0", "datetime": "2020-04-06 23:14:48", "author": "@Sam09lol", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1247244285377794049": {"followers": "232", "datetime": "2020-04-06 19:26:24", "author": "@Mian_Usaf", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1243202794007429120": {"followers": "103", "datetime": "2020-03-26 15:46:58", "author": "@urosn", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1242977305405747201": {"followers": "15,224", "datetime": "2020-03-26 00:50:57", "author": "@lmthang", "content_summary": "Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentation, https://t.co/Uoj2Rb7Etx) on low-data regimes! https://t.co/e2HTx4H1K1"}, "1137842929115029510": {"followers": "3,100", "datetime": "2019-06-09 22:04:29", "author": "@PoetterThomas", "content_summary": "RT @quocleix: To add to Vincent's point above, new findings also include: 1. The method is general (works well for images & texts). 2. Th\u2026"}, "1126326429128351751": {"followers": "95", "datetime": "2019-05-09 03:22:01", "author": "@summer4an", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1180286423301283840": {"followers": "1,217", "datetime": "2019-10-05 00:59:46", "author": "@pragmaticml", "content_summary": "@dcpage3 Reminds me of the Training Signal Annealing approach from the \"Unsupervised Data Augmentation...\" paper: https://t.co/2wnH91Pcdz"}, "1243238345280565257": {"followers": "42", "datetime": "2020-03-26 18:08:14", "author": "@nsivacki", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123097139238674432": {"followers": "3", "datetime": "2019-04-30 05:29:58", "author": "@codiaryofficial", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123088684008509441": {"followers": "169", "datetime": "2019-04-30 04:56:22", "author": "@brunoboutteau", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123219917929496576": {"followers": "12", "datetime": "2019-04-30 13:37:51", "author": "@oliviastartrip", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126314167135232001": {"followers": "216", "datetime": "2019-05-09 02:33:18", "author": "@KSKSKSKS2", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1149463740183531520": {"followers": "3,498", "datetime": "2019-07-11 23:41:26", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexkDIP"}, "1123205136258609152": {"followers": "9", "datetime": "2019-04-30 12:39:07", "author": "@TyvNguyen", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123214081492758529": {"followers": "289", "datetime": "2019-04-30 13:14:39", "author": "@dannyehb", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1247273876146606080": {"followers": "164,080", "datetime": "2020-04-06 21:23:59", "author": "@ceobillionaire", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1247489612311703554": {"followers": "167", "datetime": "2020-04-07 11:41:15", "author": "@shalinidemello", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123141078595424258": {"followers": "85", "datetime": "2019-04-30 08:24:34", "author": "@daiquocng", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125917344918855682": {"followers": "1,830", "datetime": "2019-05-08 00:16:28", "author": "@msarozz", "content_summary": "RT @DS_insights: #UDA or unsupervised data augmentations new technique from @google to generate synthetic data for #neuralnetworks #AI #mac\u2026"}, "1123239977217941516": {"followers": "753", "datetime": "2019-04-30 14:57:34", "author": "@suneelmarthi", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123446985875447808": {"followers": "291", "datetime": "2019-05-01 04:40:08", "author": "@QizheXie", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125738335022923778": {"followers": "1,379", "datetime": "2019-05-07 12:25:08", "author": "@momiji_fullmoon", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1123420673131462661": {"followers": "196", "datetime": "2019-05-01 02:55:35", "author": "@SalehCU", "content_summary": "Really nice work by Quoc Le and colleagues at Google & CMU on unsupervised data augmentation. Highly recommend checking out their latest paper at the arXiv."}, "1123536247782354947": {"followers": "134", "datetime": "2019-05-01 10:34:50", "author": "@AllBachedOut17", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126447329832136704": {"followers": "273", "datetime": "2019-05-09 11:22:26", "author": "@morinosuke__p", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123130643855159296": {"followers": "12", "datetime": "2019-04-30 07:43:06", "author": "@KleistLeo", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1178337603373789185": {"followers": "67", "datetime": "2019-09-29 15:55:51", "author": "@dksdc", "content_summary": "RT @arxiv_cscv: Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1125581431516946433": {"followers": "86", "datetime": "2019-05-07 02:01:40", "author": "@DevHunterYZ", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123301511528796160": {"followers": "7", "datetime": "2019-04-30 19:02:04", "author": "@drlego9", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1129866987675406341": {"followers": "18,260", "datetime": "2019-05-18 21:50:56", "author": "@quocleix", "content_summary": "Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123165572794073088": {"followers": "3,416", "datetime": "2019-04-30 10:01:54", "author": "@alxndrkalinin", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123065682344673280": {"followers": "511", "datetime": "2019-04-30 03:24:58", "author": "@AndrewMendez19", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123592006851280898": {"followers": "39", "datetime": "2019-05-01 14:16:24", "author": "@eLIENONNON", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1153722128560054272": {"followers": "1,130", "datetime": "2019-07-23 17:42:45", "author": "@BioDecoded", "content_summary": "Advancing Semi-supervised Learning with Unsupervised Data Augmentation | Google AI Blog https://t.co/hbXrtDZk7S https://t.co/fnSASm8sfH #MachineLearning https://t.co/qzMNH0r4eq"}, "1150706797122150401": {"followers": "221", "datetime": "2019-07-15 10:00:54", "author": "@PapersTrending", "content_summary": "[2/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 303 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1124789599300128769": {"followers": "1,441", "datetime": "2019-05-04 21:35:12", "author": "@RoryJosephQuinn", "content_summary": "Data augmentation - alleviating the need for labelled datasets #datascience https://t.co/87O9jypU38"}, "1146080337791016961": {"followers": "117", "datetime": "2019-07-02 15:37:00", "author": "@Red_Buffer", "content_summary": "This research shows that better augmentation methods can lead to greater improvements on different machine learning tasks. https://t.co/T2kX6ABP7e"}, "1125285568504631301": {"followers": "1,120", "datetime": "2019-05-06 06:26:00", "author": "@thinking_code", "content_summary": "Unsupervised Data Augmentation https://t.co/Qmenb0gJcl"}, "1126330280367800321": {"followers": "2,338", "datetime": "2019-05-09 03:37:19", "author": "@yshhrknmr", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1127013164678180864": {"followers": "224", "datetime": "2019-05-11 00:50:52", "author": "@ElectronNest", "content_summary": "\"Unsupervised Data Augmentation\" https://t.co/AJIiJjc4Xf"}, "1144345935763218432": {"followers": "18,260", "datetime": "2019-06-27 20:45:06", "author": "@quocleix", "content_summary": "@ivan_bezdomny In NLP, there is backtranslation method that works quite well as a data augmentation method. You can check out its use in UDA: https://t.co/J74Nn4i8no Link to code: https://t.co/wMqUUVFM8u"}, "1188325345805643776": {"followers": "11,927", "datetime": "2019-10-27 05:23:35", "author": "@Rosenchild", "content_summary": "RT @BioDecoded: Inference of clonal selection in cancer populations using single-cell sequencing data | Bioinformatics https://t.co/hbXrtDZ\u2026"}, "1123924884181200898": {"followers": "382", "datetime": "2019-05-02 12:19:08", "author": "@JLefortBesnard", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1236636407340445697": {"followers": "200", "datetime": "2020-03-08 12:54:29", "author": "@FernandoAvanzo", "content_summary": "RT @Deep_In_Depth: Unsupervised Data Augmentation for Consistency Training https://t.co/BZOt43yPaX #DeepLearning #NeuralNetworks #Artifici\u2026"}, "1123109101595176960": {"followers": "55", "datetime": "2019-04-30 06:17:30", "author": "@khaledvic", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126660042487357440": {"followers": "71", "datetime": "2019-05-10 01:27:41", "author": "@semiinvariant", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1247313341875453956": {"followers": "2,067", "datetime": "2020-04-07 00:00:49", "author": "@EricSchles", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1178847223829929984": {"followers": "4,096", "datetime": "2019-10-01 01:40:54", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123584785446768641": {"followers": "206", "datetime": "2019-05-01 13:47:42", "author": "@rcbarros", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1247345965750554624": {"followers": "2,672", "datetime": "2020-04-07 02:10:27", "author": "@ayirpelle", "content_summary": "RT @lmthang: Nice recent tutorial on semi-supervised learning, covering our recent works on UDA (https://t.co/Uoj2Rb7Etx) and #NoisyStuden\u2026"}, "1123226999546351616": {"followers": "818", "datetime": "2019-04-30 14:05:59", "author": "@ErmiaBivatan", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123238631152291841": {"followers": "2,672", "datetime": "2019-04-30 14:52:13", "author": "@ayirpelle", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1187440666235809793": {"followers": "5,312", "datetime": "2019-10-24 18:48:11", "author": "@HubBucket", "content_summary": "RT @BioDecoded: Inference of clonal selection in cancer populations using single-cell sequencing data | Bioinformatics https://t.co/hbXrtDZ\u2026"}, "1235508450081132544": {"followers": "128", "datetime": "2020-03-05 10:12:23", "author": "@shimopino", "content_summary": "\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u3067\u9ad8\u7cbe\u5ea6\u3092\u9054\u6210\u3057\u3066\u3044\u308b\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u5897\u5f37\u624b\u6cd5\u304c\u3001\u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u3082\u9069\u7528\u3067\u304d\u308b\u3053\u3068\u3092\u793a\u3057\u305f\u3002\u307e\u305f\u3001\u30e2\u30c7\u30eb\u304c\u5c11\u6570\u306e\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u306b\u904e\u5270\u9069\u5408\u3057\u3066\u3057\u307e\u3044\u3001\u591a\u6570\u306e\u30e9\u30d9\u30eb\u306a\u3057\u30c7\u30fc\u30bf\u306b\u306f\u904e\u5c11\u9069\u5408\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u3092\u9632\u3050\u5b66\u7fd2\u624b\u6cd5TSA\u3092\u63d0\u6848\u3057\u305f https://t.co/NGWPokgFYF"}, "1123104130933895168": {"followers": "517", "datetime": "2019-04-30 05:57:45", "author": "@mazancourt", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123396538041077765": {"followers": "5,312", "datetime": "2019-05-01 01:19:41", "author": "@HubBucket", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126667110153736192": {"followers": "1", "datetime": "2019-05-10 01:55:46", "author": "@PoisonNow", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123948980134731776": {"followers": "352", "datetime": "2019-05-02 13:54:53", "author": "@almostMike", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126638503582781440": {"followers": "485", "datetime": "2019-05-10 00:02:05", "author": "@eve_yk", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1125553099878293504": {"followers": "99", "datetime": "2019-05-07 00:09:05", "author": "@treasured_write", "content_summary": "RT @hillbig: In semi-supervised learning, VAT adds adversarial noise to unsupervised data and makes its prediction distribution matches the\u2026"}, "1149117691283812353": {"followers": "627", "datetime": "2019-07-11 00:46:21", "author": "@helioRocha_", "content_summary": "\"Unsupervised Data Augmentation for Consistency Training. (arXiv:1904.12848v2 [cs.LG] UPDATED)\" #arXiv https://t.co/28QLeQWSzn"}, "1125727091238903808": {"followers": "216", "datetime": "2019-05-07 11:40:28", "author": "@KSKSKSKS2", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1126584306493640704": {"followers": "3,418", "datetime": "2019-05-09 20:26:44", "author": "@azriel1rf", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123057658477436929": {"followers": "109", "datetime": "2019-04-30 02:53:05", "author": "@Charles9n", "content_summary": "Nice results with very little data. Both for text as well as images."}, "1123231757820542981": {"followers": "293", "datetime": "2019-04-30 14:24:54", "author": "@gabriel_ilharco", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1243017575614701568": {"followers": "38", "datetime": "2020-03-26 03:30:58", "author": "@experiencor", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1126327993167560704": {"followers": "635", "datetime": "2019-05-09 03:28:14", "author": "@rkakamilan", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123127821914787840": {"followers": "781", "datetime": "2019-04-30 07:31:54", "author": "@HrSaghir", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123033946600685568": {"followers": "160", "datetime": "2019-04-30 01:18:52", "author": "@tuvuumass", "content_summary": "Very impressive! On IMDB, unsupervised data augmentation + 20 labeled examples can beat the state-of-the-art model trained on 25,000 labeled examples."}, "1123904598824058885": {"followers": "2,307", "datetime": "2019-05-02 10:58:32", "author": "@abeusher", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1134268200881811456": {"followers": "211", "datetime": "2019-05-31 01:19:47", "author": "@yuri66176", "content_summary": "Back Translation https://t.co/j3hncVMXwZ Unsupervised Data Augmentation https://t.co/PkucEA5cw4"}, "1149131539546087424": {"followers": "3,498", "datetime": "2019-07-11 01:41:23", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1129922116298559490": {"followers": "60", "datetime": "2019-05-19 01:30:00", "author": "@foxhu007", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1123542226301112320": {"followers": "245", "datetime": "2019-05-01 10:58:35", "author": "@__jm", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123598264492642305": {"followers": "10,655", "datetime": "2019-05-01 14:41:16", "author": "@kaalam_ai", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123032293868802054": {"followers": "4,201", "datetime": "2019-04-30 01:12:18", "author": "@arxiv_cs_cl", "content_summary": "https://t.co/bQtZm9YGad Unsupervised Data Augmentation. (arXiv:1904.12848v1 [cs.LG]) #NLProc"}, "1123112122227904513": {"followers": "98", "datetime": "2019-04-30 06:29:31", "author": "@kgwmath", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1144393718104879105": {"followers": "259", "datetime": "2019-06-27 23:54:58", "author": "@jcchinhui", "content_summary": "RT @quocleix: @ivan_bezdomny In NLP, there is backtranslation method that works quite well as a data augmentation method. You can check out\u2026"}, "1178364059143593984": {"followers": "3,498", "datetime": "2019-09-29 17:40:59", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1243066793817563137": {"followers": "1,082", "datetime": "2020-03-26 06:46:33", "author": "@gcetinkaya", "content_summary": "RT @lmthang: Nice additional gains achieved by MPL (Meta Pseudo Labels, https://t.co/GyTMUeUPlE) on top of UDA (Unsupervised Data Augmentat\u2026"}, "1123109403803176962": {"followers": "44", "datetime": "2019-04-30 06:18:42", "author": "@jeandut14000", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123039510793740289": {"followers": "3,498", "datetime": "2019-04-30 01:40:59", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation https://t.co/ojGkexCf7p"}, "1123334398852653058": {"followers": "5,433", "datetime": "2019-04-30 21:12:45", "author": "@Arabic_CL", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1125542854825091072": {"followers": "18,231", "datetime": "2019-05-06 23:28:22", "author": "@hillbig", "content_summary": "\u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u3092\u63d0\u6848 https://t.co/M6JAICOKPo"}, "1123295727596253185": {"followers": "6", "datetime": "2019-04-30 18:39:05", "author": "@nahidcse05", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125908167391682561": {"followers": "689", "datetime": "2019-05-07 23:40:00", "author": "@BenSingletonNYC", "content_summary": "Unsupervised Data Augmentation #BigData #Analytics https://t.co/BVcyQsFTSs"}, "1126360076388716544": {"followers": "739", "datetime": "2019-05-09 05:35:43", "author": "@vmpmember", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1125601519707910144": {"followers": "4,825", "datetime": "2019-05-07 03:21:29", "author": "@prototechno", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1125794106049884160": {"followers": "457", "datetime": "2019-05-07 16:06:45", "author": "@SingingData", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1130088262331244544": {"followers": "7,650", "datetime": "2019-05-19 12:30:12", "author": "@KyleCranmer", "content_summary": "RT @quocleix: Links to the mentioned papers. MixMatch: https://t.co/34ztIFttUQ Unsupervised Data Augmentation: https://t.co/J74Nn4i8no"}, "1126319242112974848": {"followers": "825", "datetime": "2019-05-09 02:53:27", "author": "@morioka", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1125563709479251968": {"followers": "5,581", "datetime": "2019-05-07 00:51:14", "author": "@Tim_Dettmers", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123097022494642178": {"followers": "58", "datetime": "2019-04-30 05:29:30", "author": "@nguyenvo09", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123255556624531458": {"followers": "171", "datetime": "2019-04-30 15:59:28", "author": "@aIrb4ck", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123412649629274113": {"followers": "118", "datetime": "2019-05-01 02:23:42", "author": "@JunsongW", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1126311287342788610": {"followers": "1,055", "datetime": "2019-05-09 02:21:51", "author": "@stealthinu", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123373002593169408": {"followers": "536", "datetime": "2019-04-30 23:46:09", "author": "@ssgrn", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1126623850639155200": {"followers": "558", "datetime": "2019-05-09 23:03:52", "author": "@ohtaman", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1123136622776729600": {"followers": "365", "datetime": "2019-04-30 08:06:52", "author": "@JeanMarcJAzzi", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123163728105623554": {"followers": "771", "datetime": "2019-04-30 09:54:34", "author": "@aCraigPfeifer", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123041395139153920": {"followers": "0", "datetime": "2019-04-30 01:48:28", "author": "@Sam09lol", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123264497131634691": {"followers": "390", "datetime": "2019-04-30 16:35:00", "author": "@gpandeylab", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}, "1123214542375407616": {"followers": "510", "datetime": "2019-04-30 13:16:29", "author": "@drjohncliu", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1123187392955994113": {"followers": "14", "datetime": "2019-04-30 11:28:36", "author": "@subhc4", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1158004124841054208": {"followers": "1,859", "datetime": "2019-08-04 13:17:52", "author": "@planarrowspace", "content_summary": "\u201cUnsupervised Data Augmentation for Consistency Training\u201d https://t.co/BafaNsuqUm"}, "1123234205540831232": {"followers": "5", "datetime": "2019-04-30 14:34:37", "author": "@Koundinya33", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1125597890246656001": {"followers": "457", "datetime": "2019-05-07 03:07:04", "author": "@bluejin55", "content_summary": "RT @hillbig: \u534a\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306b\u304a\u3044\u3066\u3001VAT\u306f\u6559\u5e2b\u306a\u3057\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u5206\u5e03\u304c\u6700\u3082\u5909\u308f\u308b\u65b9\u5411\u306b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u3066\u3082\u5143\u306e\u4e88\u6e2c\u5206\u5e03\u3068\u4e00\u81f4\u3059\u308b\u3088\u3046\u5b66\u7fd2\u3057\u305f\u304c\u3001\u4ee3\u308f\u308a\u306b\u30c7\u30fc\u30bf\u30aa\u30fc\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u308f\u308c\u308b\u30ce\u30a4\u30ba\u3092\u52a0\u3048\u308b\u3088\u3046\u306b\u3057\u3001\u307e\u305f\u6559\u5e2b\u3042\u308a\u30c7\u30fc\u30bf\u304b\u3089\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u5f90\u3005\u306b\u5927\u304d\u304f\u3059\u308bTSA\u2026"}, "1123234570789380104": {"followers": "128", "datetime": "2019-04-30 14:36:05", "author": "@QuebecAI", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1149982072016179200": {"followers": "221", "datetime": "2019-07-13 10:01:06", "author": "@PapersTrending", "content_summary": "[2/10] \ud83d\udcc8 - Unsupervised Data Augmentation for Consistency Training - 244 \u2b50 - \ud83d\udcc4 https://t.co/bDaxfFaQLh - \ud83d\udd17 https://t.co/PL92Fzy51S"}, "1123110637729566725": {"followers": "71", "datetime": "2019-04-30 06:23:37", "author": "@frozencerebrum", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1131975638049411072": {"followers": "6,125", "datetime": "2019-05-24 17:29:57", "author": "@StephenPiment", "content_summary": "Unsupervised Data Augmentation https://t.co/SFnwmDWJGF"}, "1243056657833263104": {"followers": "153", "datetime": "2020-03-26 06:06:16", "author": "@jolibrain", "content_summary": "RT @quocleix: This work continues our efforts on semi-supervised learning such as UDA: https://t.co/J74Nn4i8no MixMatch: https://t.co/34zt\u2026"}, "1179043479055425536": {"followers": "3,498", "datetime": "2019-10-01 14:40:45", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1177790447437193216": {"followers": "3,498", "datetime": "2019-09-28 03:41:39", "author": "@arxiv_cscl", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ojGkexCf7p"}, "1130989068823740420": {"followers": "280", "datetime": "2019-05-22 00:09:41", "author": "@HotCompScience", "content_summary": "Most popular computer science paper of the day: \"Unsupervised Data Augmentation\" https://t.co/owRFNxgfX3 https://t.co/xUYWVWvUdx"}, "1126316218036568064": {"followers": "595", "datetime": "2019-05-09 02:41:26", "author": "@cddadr", "content_summary": "RT @icoxfog417: Data Augmentation\u306f\u30e9\u30d9\u30eb\u4ed8\u304d\u30c7\u30fc\u30bf\u3092\u304b\u3055\u5897\u3057\u3059\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u306e\u304c\u901a\u4f8b\u3060\u304c\u3001\u30e9\u30d9\u30eb\u306a\u3057\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u9069\u7528\u3059\u308b\u624b\u6cd5\u306e\u63d0\u6848\u3002\u91cd\u307f\u3092\u56fa\u5b9a\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3001\u5143\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3001Augment\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5206\u5e03\u3068\u3067\u5dee\u7570\u304c\u2026"}, "1125517568653979648": {"followers": "265", "datetime": "2019-05-06 21:47:54", "author": "@akashjainx", "content_summary": "RT @mihail_eric: Yum! Unsupervised data augmentation that works from @GoogleAI @QizheXie @quocleix. New state-of-the-art on various langua\u2026"}, "1126711237457276932": {"followers": "252", "datetime": "2019-05-10 04:51:06", "author": "@bgangk", "content_summary": "RT @quocleix: Data augmentation is often associated with supervised learning. We find *unsupervised* data augmentation works better. It com\u2026"}, "1177594017594400768": {"followers": "4,096", "datetime": "2019-09-27 14:41:07", "author": "@arxiv_cscv", "content_summary": "Unsupervised Data Augmentation for Consistency Training https://t.co/ppABSi1gD9"}, "1123305282682085376": {"followers": "1,203", "datetime": "2019-04-30 19:17:04", "author": "@F_Vaggi", "content_summary": "RT @lmthang: Introducing UDA, our new work on \"Unsupervised data augmentation\" for semi-supervised learning (SSL) with Qizhe Xie, Zihang Da\u2026"}}}