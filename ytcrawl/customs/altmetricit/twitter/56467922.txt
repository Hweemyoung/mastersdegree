{"citation_id": "56467922", "tab": "twitter", "twitter": {"1104544213297815552": {"author": "@arxiv_pop", "followers": "711", "datetime": "2019-03-10 00:47:16", "content_summary": "2019/03/03 \u6295\u7a3f 2\u4f4d LG(Machine Learning) NoRML: No-Reward Meta Learning https://t.co/uBt67Yl4X1 7 Tweets 2 Retweets 12 Favorites"}, "1102758188171042816": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-03-05 02:30:14", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/iZl7msUy2Y NoRML: No-Reward Meta Learning. (arXiv:1903.01063v1 [cs.LG])"}, "1102761483711275008": {"author": "@deep_rl", "followers": "870", "datetime": "2019-03-05 02:43:20", "content_summary": "NoRML: No-Reward Meta Learning - Yuxiang Yang https://t.co/AOigS3Sy38"}, "1102902651375808512": {"author": "@arxiv_cs_LG", "followers": "322", "datetime": "2019-03-05 12:04:17", "content_summary": "NoRML: No-Reward Meta Learning. Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, and Chelsea Finn https://t.co/y92Nk1M8vG"}, "1104470992259305474": {"author": "@jackiefloyd", "followers": "1,232", "datetime": "2019-03-09 19:56:19", "content_summary": "RT @mat_kelcey: \"NoRML: No-Reward Meta Learning. In this paper, we introduce a new meta reinforcement learning algorithm that adapts to cha\u2026"}, "1102757710540562432": {"author": "@helioRocha_", "followers": "631", "datetime": "2019-03-05 02:28:21", "content_summary": "\"NoRML: No-Reward Meta Learning. (arXiv:1903.01063v1 [cs.LG])\" #arXiv https://t.co/Ak38BFb1wx"}, "1104464949177311232": {"author": "@mat_kelcey", "followers": "8,295", "datetime": "2019-03-09 19:32:18", "content_summary": "\"NoRML: No-Reward Meta Learning. In this paper, we introduce a new meta reinforcement learning algorithm that adapts to changes in dynamics & sensor drifts, without the need for external reward signals during adapta- tion\" https://t.co/FMYKZlTEoI"}, "1104482600964493312": {"author": "@omnidelic", "followers": "171", "datetime": "2019-03-09 20:42:27", "content_summary": "RT @mat_kelcey: \"NoRML: No-Reward Meta Learning. In this paper, we introduce a new meta reinforcement learning algorithm that adapts to cha\u2026"}, "1102803741370142720": {"author": "@arxivml", "followers": "785", "datetime": "2019-03-05 05:31:15", "content_summary": "\"NoRML: No-Reward Meta Learning\", Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, Chelsea Finn https://t.co/Ry8iTe36NR"}, "1104795377599946752": {"author": "@JeanMarcJAzzi", "followers": "365", "datetime": "2019-03-10 17:25:18", "content_summary": "RT @mat_kelcey: \"NoRML: No-Reward Meta Learning. In this paper, we introduce a new meta reinforcement learning algorithm that adapts to cha\u2026"}, "1102763006818205696": {"author": "@BrundageBot", "followers": "3,908", "datetime": "2019-03-05 02:49:23", "content_summary": "NoRML: No-Reward Meta Learning. Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, and Chelsea Finn https://t.co/Ioatd2sTW0"}, "1107266472038920193": {"author": "@luckyJane12", "followers": "0", "datetime": "2019-03-17 13:04:33", "content_summary": "RT @mat_kelcey: \"NoRML: No-Reward Meta Learning. In this paper, we introduce a new meta reinforcement learning algorithm that adapts to cha\u2026"}, "1102907125603291136": {"author": "@StatsPapers", "followers": "5,454", "datetime": "2019-03-05 12:22:04", "content_summary": "NoRML: No-Reward Meta Learning. https://t.co/oPDgcSduly"}}, "completed": "1", "queriedAt": "2020-06-03 02:13:46"}