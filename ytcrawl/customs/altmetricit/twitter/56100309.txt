{"citation_id": "56100309", "tab": "twitter", "twitter": {"1100592489990373377": {"author": "@BrundageBot", "followers": "3,889", "datetime": "2019-02-27 03:04:32", "content_summary": "Fully Distributed Bayesian Optimization with Stochastic Policies. Javier Garcia-Barcos and Ruben Martinez-Cantin https://t.co/1GwAkqa5jK"}, "1148027953986592774": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-07-08 00:36:08", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/XC2DXYdzGo Fully Distributed Bayesian Optimization with Stochastic Policies. (arXiv:1902.09992v2 [cs.LG] UPDATED)"}, "1148518725735342087": {"author": "@DIIS_UZ", "followers": "750", "datetime": "2019-07-09 09:06:17", "content_summary": "RT @rmcantin: New paper: Advantages of seeing Bayesian Optimization as a POMDP. Use softmax for the acquisition function to gain extra expl\u2026"}, "1100576907270201344": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-27 02:02:37", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/XC2DXYdzGo Fully Distributed Bayesian Optimization with Stochastic Policies. (arXiv:1902.09992v1 [cs.LG])"}, "1148029514057994240": {"author": "@gastronomy", "followers": "1,389", "datetime": "2019-07-08 00:42:20", "content_summary": "[arXiv] Fully Distributed Bayesian Optimization with Stochastic Policies. (arXiv:1902.09992v2 [cs.LG] UPDATED) --> Bayesian optimization has become a popular method for high-throughput computing, like the design of computer experiments or hyperparamete"}, "1100577594741870592": {"author": "@helioRocha_", "followers": "628", "datetime": "2019-02-27 02:05:20", "content_summary": "\"Fully Distributed Bayesian Optimization with Stochastic Policies. (arXiv:1902.09992v1 [cs.LG])\" #arXiv https://t.co/ymTeLR9yG1"}, "1148027973347565579": {"author": "@helioRocha_", "followers": "628", "datetime": "2019-07-08 00:36:12", "content_summary": "\"Fully Distributed Bayesian Optimization with Stochastic Policies. (arXiv:1902.09992v2 [cs.LG] UPDATED)\" #arXiv https://t.co/ymTeLR9yG1"}, "1148514892271575040": {"author": "@rmcantin", "followers": "467", "datetime": "2019-07-09 08:51:03", "content_summary": "New paper: Advantages of seeing Bayesian Optimization as a POMDP. Use softmax for the acquisition function to gain extra exploration, robustness to wrong models, near-optimal bounds \"without tricks\" and... embarrassingly parallel BO for free! https://t.co/"}, "1101214135386361856": {"author": "@arxiv_in_review", "followers": "1,311", "datetime": "2019-02-28 20:14:44", "content_summary": "#IJCAI19 Fully Distributed Bayesian Optimization with Stochastic Policies. (arXiv:1902.09992v1 [cs\\.LG]) https://t.co/QftT3zm8zX"}, "1148609142807912449": {"author": "@thanhnguyentang", "followers": "118", "datetime": "2019-07-09 15:05:34", "content_summary": "RT @rmcantin: New paper: Advantages of seeing Bayesian Optimization as a POMDP. Use softmax for the acquisition function to gain extra expl\u2026"}, "1100597203222085639": {"author": "@arxiv_cs_LG", "followers": "318", "datetime": "2019-02-27 03:23:16", "content_summary": "Fully Distributed Bayesian Optimization with Stochastic Policies. Javier Garcia-Barcos and Ruben Martinez-Cantin https://t.co/x6AUmKqm0c"}}, "completed": "1", "queriedAt": "2020-06-03 01:39:53"}