{"citation_id": "74377151", "queriedAt": "2020-05-09 14:32:05", "completed": "0", "twitter": {"1224313432171696129": {"followers": "549", "content_summary": "RT @AkiraTOSEI: https://t.co/E3N3sV7Pi2 ImageBERT that pre-trains by embedding Text and images simultaneously. A two-stage method in which\u2026", "author": "@FBWM8888", "datetime": "2020-02-03 12:47:23"}, "1225700969096175616": {"followers": "1", "content_summary": "RT @Tinux80: ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data By @MSFTResearch new state-of-the-art re\u2026", "author": "@gaofront", "datetime": "2020-02-07 08:40:58"}, "1249418116079259657": {"followers": "350", "content_summary": "@raccooncoder Have you seen this paper? https://t.co/prvpLyHILi", "author": "@norpadon", "datetime": "2020-04-12 19:24:26"}, "1224313374042771456": {"followers": "549", "content_summary": "RT @AkiraTOSEI: https://t.co/E3N3sV7Pi2 Text\u3068\u753b\u50cf\u3092\u540c\u6642\u306bEmbedding\u3057\u3066pre-train\u3059\u308bImageBERT\u3092\u63d0\u6848\u30024\u3064\u306e\u30bf\u30b9\u30af\u89e3\u304d\u306a\u304c\u3089\u4e8b\u524d\u5b66\u7fd2\u3092\u5b9f\u65bd\u3057\u3001\u30bf\u5bfe\u8c61\u30bf\u30b9\u30af\u3067Fine-tuning\u3059\u308b2 stage\u65b9\u5f0f\u3002MSC\u2026", "author": "@FBWM8888", "datetime": "2020-02-03 12:47:09"}}, "tab": "twitter"}