{"citation_id": "57392826", "tab": "twitter", "twitter": {"1108577672764887040": {"author": "@chelseabfinn", "followers": "24,597", "datetime": "2019-03-21 03:54:48", "content_summary": "We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than the best prior method. I'm excited to see what this method enables us to do in the real world! w/ K Rakelly, A Zhou, D Quillen @svlevine"}, "1108954734260449281": {"author": "@bhagirathl", "followers": "513", "datetime": "2019-03-22 04:53:06", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108611870552784896": {"author": "@Foivos_Diak", "followers": "161", "datetime": "2019-03-21 06:10:41", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109131340958457856": {"author": "@kadotanimitsuru", "followers": "1,110", "datetime": "2019-03-22 16:34:53", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108887204456071168": {"author": "@AstarADIEU", "followers": "709", "datetime": "2019-03-22 00:24:46", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1119672935617183749": {"author": "@2000Qiu", "followers": "11", "datetime": "2019-04-20 18:43:25", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1109093754529435649": {"author": "@8kazu3", "followers": "467", "datetime": "2019-03-22 14:05:31", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108638707496747008": {"author": "@p_kot1", "followers": "16", "datetime": "2019-03-21 07:57:20", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108592901951496193": {"author": "@ovidalp1", "followers": "45", "datetime": "2019-03-21 04:55:19", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119692191822229505": {"author": "@d_kangin", "followers": "118", "datetime": "2019-04-20 19:59:56", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1119980163473625088": {"author": "@AssistedEvolve", "followers": "217", "datetime": "2019-04-21 15:04:13", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108777791733010434": {"author": "@ahmaurya", "followers": "0", "datetime": "2019-03-21 17:10:00", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108758640066998277": {"author": "@Quebec_AI", "followers": "160,304", "datetime": "2019-03-21 15:53:54", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108681183993491456": {"author": "@timbail24", "followers": "50", "datetime": "2019-03-21 10:46:07", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109030264456396801": {"author": "@ElectronNest", "followers": "231", "datetime": "2019-03-22 09:53:14", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108732920615702528": {"author": "@ampereir", "followers": "266", "datetime": "2019-03-21 14:11:42", "content_summary": "I\u2019m really excited about meta-learning approaches to RL. These and unsupervised learning techniques are likely to be the movers on the next big front of improvements to AI. Cool work here!"}, "1108625307592908800": {"author": "@jaguring1", "followers": "13,499", "datetime": "2019-03-21 07:04:05", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108812552002138112": {"author": "@MatDrinksTea", "followers": "2,619", "datetime": "2019-03-21 19:28:07", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109789691895783424": {"author": "@xu3kev", "followers": "18", "datetime": "2019-03-24 12:10:56", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108733579503140864": {"author": "@sidbrahma", "followers": "179", "datetime": "2019-03-21 14:14:19", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108944000545767429": {"author": "@Mt_El_Sheep", "followers": "26", "datetime": "2019-03-22 04:10:27", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108872511880486912": {"author": "@icoxfog417", "followers": "11,575", "datetime": "2019-03-21 23:26:23", "content_summary": "\u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u3044\u3046Off-Policy\u306a\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u3068\u3063\u3066\u3044\u308b"}, "1109164026108563463": {"author": "@arxiv_cs_LG", "followers": "322", "datetime": "2019-03-22 18:44:45", "content_summary": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, and Sergey Levine https://t.co/oiCN3SqLNb"}, "1109067253461512192": {"author": "@soumen_eclectic", "followers": "593", "datetime": "2019-03-22 12:20:13", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108646804126687232": {"author": "@jd_mashiro", "followers": "1,158", "datetime": "2019-03-21 08:29:30", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108803173018329088": {"author": "@npew", "followers": "1,220", "datetime": "2019-03-21 18:50:51", "content_summary": "Promising work on meta-learning: learn to encode the history of a task into a \"context\", and let policy use the context of a new task to master it faster. Combine with sample-efficient RL algorithm (soft actor critic). Super good results (20-100x) on a num"}, "1108694597297942528": {"author": "@grzegorzcaban", "followers": "305", "datetime": "2019-03-21 11:39:25", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108872973463810049": {"author": "@Mokeam", "followers": "818", "datetime": "2019-03-21 23:28:13", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109132400989069312": {"author": "@tricellll", "followers": "18", "datetime": "2019-03-22 16:39:05", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1110320311713583110": {"author": "@natycalvob", "followers": "572", "datetime": "2019-03-25 23:19:25", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108880734238863360": {"author": "@SquirrelYellow", "followers": "175", "datetime": "2019-03-21 23:59:03", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108624263010021378": {"author": "@jeandut14000", "followers": "43", "datetime": "2019-03-21 06:59:56", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108628599530110976": {"author": "@KSKSKSKS2", "followers": "216", "datetime": "2019-03-21 07:17:10", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108757036433637376": {"author": "@AmbientIsotopy", "followers": "42", "datetime": "2019-03-21 15:47:31", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108574118838829056": {"author": "@tomaxent", "followers": "4", "datetime": "2019-03-21 03:40:40", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108576024885751810": {"author": "@63556poiuytrewq", "followers": "435", "datetime": "2019-03-21 03:48:15", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1120720513704194049": {"author": "@AtulAcharya", "followers": "1,882", "datetime": "2019-04-23 16:06:07", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108711655238762500": {"author": "@Hrishi_kesh", "followers": "197", "datetime": "2019-03-21 12:47:12", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108758988730986496": {"author": "@deeplearning4j", "followers": "25,311", "datetime": "2019-03-21 15:55:17", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108571165214138369": {"author": "@sk413025", "followers": "37", "datetime": "2019-03-21 03:28:56", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109365850044289024": {"author": "@yieldthought", "followers": "788", "datetime": "2019-03-23 08:06:44", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119698068629327878": {"author": "@_Alex_Borghi_", "followers": "163", "datetime": "2019-04-20 20:23:17", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1110814316532363264": {"author": "@zihyunchiu", "followers": "2", "datetime": "2019-03-27 08:02:25", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108958106476670976": {"author": "@AssistedEvolve", "followers": "217", "datetime": "2019-03-22 05:06:30", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108747965001330688": {"author": "@farhanhubble", "followers": "158", "datetime": "2019-03-21 15:11:29", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108890077239738368": {"author": "@pijili", "followers": "524", "datetime": "2019-03-22 00:36:11", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1138449921085005824": {"author": "@ricklentz", "followers": "81", "datetime": "2019-06-11 14:16:27", "content_summary": "Impressive gains in training sample efficiency by disentangling belief (task inference) from control: https://t.co/7p6dKew3MG"}, "1119962779824181250": {"author": "@stl950116", "followers": "11", "datetime": "2019-04-21 13:55:09", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1109509526477144064": {"author": "@mahesh_goud", "followers": "141", "datetime": "2019-03-23 17:37:39", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108915166224093184": {"author": "@morioka", "followers": "824", "datetime": "2019-03-22 02:15:52", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108676238036688896": {"author": "@miguelalonsojr", "followers": "1,072", "datetime": "2019-03-21 10:26:28", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108794518751625216": {"author": "@BartHanssens", "followers": "916", "datetime": "2019-03-21 18:16:28", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108711317211398151": {"author": "@Montreal_AI", "followers": "177,002", "datetime": "2019-03-21 12:45:51", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108582450936995840": {"author": "@dfm794", "followers": "162", "datetime": "2019-03-21 04:13:47", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108690491657183233": {"author": "@RyutaroYamauchi", "followers": "79", "datetime": "2019-03-21 11:23:06", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108630765447856128": {"author": "@olgaiv39", "followers": "93", "datetime": "2019-03-21 07:25:46", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1110452129746046976": {"author": "@Abhinav91675149", "followers": "3", "datetime": "2019-03-26 08:03:13", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108704794674454529": {"author": "@PabloMessinaG", "followers": "6", "datetime": "2019-03-21 12:19:56", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108599808229412864": {"author": "@copasta_", "followers": "637", "datetime": "2019-03-21 05:22:45", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108880312069750784": {"author": "@Montreal_AI", "followers": "177,002", "datetime": "2019-03-21 23:57:23", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108691946782875648": {"author": "@miyayou", "followers": "18,356", "datetime": "2019-03-21 11:28:53", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119706121151889408": {"author": "@sguada", "followers": "1,442", "datetime": "2019-04-20 20:55:17", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108947890653691908": {"author": "@AssistedEvolve", "followers": "217", "datetime": "2019-03-22 04:25:55", "content_summary": "RT @Miles_Brundage: \"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables,\" Rakelly and Zhou et al.: https\u2026"}, "1119987713963257861": {"author": "@PerthMLGroup", "followers": "456", "datetime": "2019-04-21 15:34:14", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108593593801822208": {"author": "@sguada", "followers": "1,442", "datetime": "2019-03-21 04:58:04", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108861838673018880": {"author": "@TheLeanAcademic", "followers": "334", "datetime": "2019-03-21 22:43:58", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109909487954128897": {"author": "@InMARIetSTELLAS", "followers": "321", "datetime": "2019-03-24 20:06:57", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108542038620991489": {"author": "@deep_rl", "followers": "866", "datetime": "2019-03-21 01:33:12", "content_summary": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables - Kate Rakelly https://t.co/48tGfQOCng"}, "1108765067724509185": {"author": "@jaguring1", "followers": "13,499", "datetime": "2019-03-21 16:19:26", "content_summary": "RT @peisuke: \u30e1\u30bf\u5b66\u7fd2\u3067Off Policy\u306e\u5f37\u5316\u5b66\u7fd2\u3092\u5b9f\u73fe\u305720-100\u500d\u306e\u52b9\u7387\u5316\u3002\u72b6\u614b\u30fb\u884c\u52d5\u7b49\u304b\u3089\u6210\u308b\u30b9\u30c6\u30c3\u30d7\u6bce\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u96a0\u308c\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8z\u3092\u63a8\u8ad6\u3057\u3001z\u306e\u60c5\u5831\u3092\u4f75\u7528\u3057\u3066\u5f37\u5316\u5b66\u7fd2\u3092\u884c\u3046\u3002\u5f37\u5316\u5b66\u7fd2\u306b\u306fsoft actor critic\u3092\u5229\u7528\u3002 https:/\u2026"}, "1108740362078568448": {"author": "@mofas223", "followers": "22", "datetime": "2019-03-21 14:41:16", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119763333568053248": {"author": "@neil_uai", "followers": "213", "datetime": "2019-04-21 00:42:37", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1109101256096841728": {"author": "@alexginsca", "followers": "132", "datetime": "2019-03-22 14:35:20", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109909502508351489": {"author": "@InMARIetSTELLAS", "followers": "321", "datetime": "2019-03-24 20:07:01", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108559177461329920": {"author": "@garygarywang", "followers": "156", "datetime": "2019-03-21 02:41:18", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119787004303040515": {"author": "@__nggih", "followers": "416", "datetime": "2019-04-21 02:16:41", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108886448474742784": {"author": "@kuz44ma69", "followers": "36", "datetime": "2019-03-22 00:21:46", "content_summary": "RT @peisuke: \u30e1\u30bf\u5b66\u7fd2\u3067Off Policy\u306e\u5f37\u5316\u5b66\u7fd2\u3092\u5b9f\u73fe\u305720-100\u500d\u306e\u52b9\u7387\u5316\u3002\u72b6\u614b\u30fb\u884c\u52d5\u7b49\u304b\u3089\u6210\u308b\u30b9\u30c6\u30c3\u30d7\u6bce\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u96a0\u308c\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8z\u3092\u63a8\u8ad6\u3057\u3001z\u306e\u60c5\u5831\u3092\u4f75\u7528\u3057\u3066\u5f37\u5316\u5b66\u7fd2\u3092\u884c\u3046\u3002\u5f37\u5316\u5b66\u7fd2\u306b\u306fsoft actor critic\u3092\u5229\u7528\u3002 https:/\u2026"}, "1109560655374368770": {"author": "@udmrzn", "followers": "1,347", "datetime": "2019-03-23 21:00:49", "content_summary": "RT @arxiv_org: Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. https://t.co/z2jqk529uX https://t.co/P\u2026"}, "1119825232691331072": {"author": "@Attila0K", "followers": "100", "datetime": "2019-04-21 04:48:35", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108804668132605958": {"author": "@yagwar183", "followers": "463", "datetime": "2019-03-21 18:56:48", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108628803293581312": {"author": "@koulanurag", "followers": "67", "datetime": "2019-03-21 07:17:58", "content_summary": "RT @arxiv_in_review: #ICML2019 Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [c\u2026"}, "1120493960785473538": {"author": "@TrungHi55915429", "followers": "1", "datetime": "2019-04-23 01:05:52", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108675024079208448": {"author": "@nchinaev", "followers": "2", "datetime": "2019-03-21 10:21:38", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119736621740380163": {"author": "@UkiwhY", "followers": "24", "datetime": "2019-04-20 22:56:28", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108654613299761153": {"author": "@mat_kelcey", "followers": "8,295", "datetime": "2019-03-21 09:00:32", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108735398342209537": {"author": "@Koundinya33", "followers": "5", "datetime": "2019-03-21 14:21:32", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108541864817373184": {"author": "@BrundageBot", "followers": "3,908", "datetime": "2019-03-21 01:32:30", "content_summary": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, and Sergey Levine https://t.co/KDklJcESXa"}, "1108694406268420096": {"author": "@suraj_donthi", "followers": "44", "datetime": "2019-03-21 11:38:39", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108709492940828672": {"author": "@runaldis", "followers": "117", "datetime": "2019-03-21 12:38:36", "content_summary": "(RT pra eu olhar depois)"}, "1108953359782809601": {"author": "@DSPonFPGA", "followers": "418", "datetime": "2019-03-22 04:47:38", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108715004981706752": {"author": "@shrvsmb", "followers": "2,036", "datetime": "2019-03-21 13:00:30", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108747147048947712": {"author": "@dharmeshkakadia", "followers": "922", "datetime": "2019-03-21 15:08:14", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108609334764695552": {"author": "@itratrahman", "followers": "20", "datetime": "2019-03-21 06:00:37", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1110814210059976706": {"author": "@zihyunchiu", "followers": "2", "datetime": "2019-03-27 08:02:00", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108873072415633408": {"author": "@jaguring1", "followers": "13,499", "datetime": "2019-03-21 23:28:36", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108749748058492930": {"author": "@peisuke", "followers": "1,396", "datetime": "2019-03-21 15:18:34", "content_summary": "\u30e1\u30bf\u5b66\u7fd2\u3067Off Policy\u306e\u5f37\u5316\u5b66\u7fd2\u3092\u5b9f\u73fe\u305720-100\u500d\u306e\u52b9\u7387\u5316\u3002\u72b6\u614b\u30fb\u884c\u52d5\u7b49\u304b\u3089\u6210\u308b\u30b9\u30c6\u30c3\u30d7\u6bce\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u96a0\u308c\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8z\u3092\u63a8\u8ad6\u3057\u3001z\u306e\u60c5\u5831\u3092\u4f75\u7528\u3057\u3066\u5f37\u5316\u5b66\u7fd2\u3092\u884c\u3046\u3002\u5f37\u5316\u5b66\u7fd2\u306b\u306fsoft actor critic\u3092\u5229\u7528\u3002"}, "1108572141341966336": {"author": "@viktor_m81", "followers": "123", "datetime": "2019-03-21 03:32:49", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1110196757692997632": {"author": "@ljastrzebski", "followers": "74", "datetime": "2019-03-25 15:08:28", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1120016348036390912": {"author": "@unsorsodicorda", "followers": "739", "datetime": "2019-04-21 17:28:00", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1119681792783421440": {"author": "@viktor_m81", "followers": "123", "datetime": "2019-04-20 19:18:36", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108617720793313280": {"author": "@AiSkellig", "followers": "275", "datetime": "2019-03-21 06:33:56", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108945187449917443": {"author": "@GoncharenkoIg", "followers": "18", "datetime": "2019-03-22 04:15:10", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108707112773931011": {"author": "@alfo_512", "followers": "106", "datetime": "2019-03-21 12:29:09", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109752405179187200": {"author": "@SingularityIs", "followers": "835", "datetime": "2019-03-24 09:42:46", "content_summary": "@KirkDBorne @mgualtieri @shervinea @afshinea @github @Stanford Via @Berkeley_AI cc @BerkeleyData https://t.co/UbTHxbRa3m Also worth a mention @StanfordAILab @StanfordHAI @StanfordNLP"}, "1108875981073408000": {"author": "@depijama", "followers": "12,657", "datetime": "2019-03-21 23:40:10", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109128979582091269": {"author": "@Liparas1729", "followers": "2,500", "datetime": "2019-03-22 16:25:30", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1109157779250376704": {"author": "@shenger", "followers": "10", "datetime": "2019-03-22 18:19:56", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108774400143384576": {"author": "@pabaldonedo", "followers": "117", "datetime": "2019-03-21 16:56:31", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108595078275059712": {"author": "@mnrmja007", "followers": "70", "datetime": "2019-03-21 05:03:58", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109129269672701953": {"author": "@vmpmember", "followers": "746", "datetime": "2019-03-22 16:26:39", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108778255111196672": {"author": "@evolvingstuff", "followers": "2,929", "datetime": "2019-03-21 17:11:50", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108752341711441920": {"author": "@Dimon_Lers", "followers": "793", "datetime": "2019-03-21 15:28:52", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108839563324211200": {"author": "@psteinb_", "followers": "406", "datetime": "2019-03-21 21:15:27", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108871420644376576": {"author": "@JeanMarcJAzzi", "followers": "365", "datetime": "2019-03-21 23:22:03", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108962512790130689": {"author": "@prototechno", "followers": "4,825", "datetime": "2019-03-22 05:24:01", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108653030721945601": {"author": "@ThomasNiebler", "followers": "313", "datetime": "2019-03-21 08:54:14", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108947126539575297": {"author": "@ico_TC", "followers": "5,430", "datetime": "2019-03-22 04:22:52", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108587771206103040": {"author": "@koulanurag", "followers": "67", "datetime": "2019-03-21 04:34:55", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109183162314182656": {"author": "@kawauso_kun", "followers": "438", "datetime": "2019-03-22 20:00:48", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1121250077232644096": {"author": "@sk413025", "followers": "37", "datetime": "2019-04-25 03:10:24", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108547100780838912": {"author": "@andrey_kurenkov", "followers": "3,466", "datetime": "2019-03-21 01:53:19", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108679465226256385": {"author": "@stl950116", "followers": "11", "datetime": "2019-03-21 10:39:17", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1112328562831515648": {"author": "@AndreyDulub", "followers": "44", "datetime": "2019-03-31 12:19:30", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108612295096041472": {"author": "@treasured_write", "followers": "101", "datetime": "2019-03-21 06:12:22", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1110235619031027712": {"author": "@Discover_Matt", "followers": "116", "datetime": "2019-03-25 17:42:53", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108541933658357760": {"author": "@svlevine", "followers": "19,130", "datetime": "2019-03-21 01:32:47", "content_summary": "PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-invariant context embedding: https://t.co/Ebiwsdg4nH w/ K. Rakelly, A. Zhou, D. Quillen, @chelseabfinn (ours is the blue one) https"}, "1108542020581294083": {"author": "@tyrell_turing", "followers": "7,937", "datetime": "2019-03-21 01:33:08", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109740562125455361": {"author": "@aryaikrobo", "followers": "61", "datetime": "2019-03-24 08:55:42", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108709231149109249": {"author": "@brandondamos", "followers": "7,647", "datetime": "2019-03-21 12:37:34", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119934519879057411": {"author": "@AbdullahMdKhan", "followers": "16", "datetime": "2019-04-21 12:02:51", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108596662375727104": {"author": "@teenvan1995", "followers": "365", "datetime": "2019-03-21 05:10:15", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108608828637999104": {"author": "@caprest", "followers": "219", "datetime": "2019-03-21 05:58:36", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108554069839212545": {"author": "@yoshida_taketo", "followers": "191", "datetime": "2019-03-21 02:21:00", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1121965113408245760": {"author": "@vsinghalus", "followers": "332", "datetime": "2019-04-27 02:31:42", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108807103353966593": {"author": "@waynemystir", "followers": "58", "datetime": "2019-03-21 19:06:28", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108874434679472128": {"author": "@gongon2018", "followers": "2,493", "datetime": "2019-03-21 23:34:01", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108550557436801024": {"author": "@zenrousai", "followers": "152", "datetime": "2019-03-21 02:07:03", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108561174067478528": {"author": "@McaleerStephen", "followers": "395", "datetime": "2019-03-21 02:49:14", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108776075406929923": {"author": "@toto_toilet", "followers": "120", "datetime": "2019-03-21 17:03:11", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108627982342590465": {"author": "@arxiv_in_review", "followers": "1,337", "datetime": "2019-03-21 07:14:42", "content_summary": "#ICML2019 Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [cs\\.LG]) https://t.co/0H69chVGiv"}, "1109336447016820736": {"author": "@1jaskiratsingh", "followers": "0", "datetime": "2019-03-23 06:09:54", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108731164393504768": {"author": "@dariocazzani", "followers": "337", "datetime": "2019-03-21 14:04:43", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108979041770455040": {"author": "@PerthMLGroup", "followers": "456", "datetime": "2019-03-22 06:29:42", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108834039970988032": {"author": "@chenlailin", "followers": "31", "datetime": "2019-03-21 20:53:30", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108796663798235136": {"author": "@smruti_amarjyot", "followers": "11", "datetime": "2019-03-21 18:24:59", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108558632508100608": {"author": "@mimoralea", "followers": "703", "datetime": "2019-03-21 02:39:08", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108847296345718785": {"author": "@jvmancuso", "followers": "653", "datetime": "2019-03-21 21:46:11", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108554873237180417": {"author": "@isaiahtaguibao", "followers": "113", "datetime": "2019-03-21 02:24:12", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108819322317819904": {"author": "@VasantTeja", "followers": "76", "datetime": "2019-03-21 19:55:01", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108532271559176192": {"author": "@helioRocha_", "followers": "631", "datetime": "2019-03-21 00:54:23", "content_summary": "\"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [cs.LG])\" #arXiv https://t.co/FybNnrK0fH"}, "1109016852796067840": {"author": "@arxiv_org", "followers": "12,796", "datetime": "2019-03-22 08:59:56", "content_summary": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. https://t.co/z2jqk529uX https://t.co/P9T947BM6X"}, "1113081195829452800": {"author": "@ht0L3Jyabpghxa6", "followers": "54", "datetime": "2019-04-02 14:10:11", "content_summary": "off-policy\u306eMeta-Learning\u624b\u6cd5\u3002MAML\u3068\u9055\u3044\u3001\u30bf\u30b9\u30af\u3054\u3068\u306b\u52fe\u914d\u52b9\u679c\u306f\u3057\u306a\u3044\u3002\u30bf\u30b9\u30af\u3092\u8868\u73fe\u3059\u308b\u6f5c\u5728\u5909\u6570z\u3092\u4fa1\u5024\u95a2\u6570\u3001\u65b9\u7b56\u306b\u5165\u308c\u308b\u3053\u3068\u3067\u3001\u5404\u30bf\u30b9\u30af\u306e\u30e2\u30fc\u30c9\u306b\u306a\u308b\u3002\u6f5c\u5728\u8868\u73fe\u306e\u63a8\u5b9a\u306f\u6bce\u30b9\u30c6\u30c3\u30d7\u306e\u60c5\u5831\u3092\u4f7f\u3063\u3066\u30aa\u30f3\u30e9\u30a4\u30f3\u3067\u4e8b\u5f8c\u5206\u5e03\u63a8\u5b9a\u3059\u308b\u306e\u3067\u52b9\u7387\u7684\u306b\u63a8\u5b9a\u53ef\u80fd\u3002"}, "1109143815426854912": {"author": "@jacquesludik", "followers": "779", "datetime": "2019-03-22 17:24:27", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108687618336796673": {"author": "@jbmrlt", "followers": "7", "datetime": "2019-03-21 11:11:41", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108800330156769280": {"author": "@berkeley_ai", "followers": "31,251", "datetime": "2019-03-21 18:39:33", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108875124491448320": {"author": "@dicekicker", "followers": "1,446", "datetime": "2019-03-21 23:36:46", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1195286134193963009": {"author": "@jinbeizame007", "followers": "2,479", "datetime": "2019-11-15 10:23:16", "content_summary": "Task2Vec\u3063\u3066\u3001\u8a00\u8449\u3060\u3051\u307f\u308b\u3068PEARL(https://t.co/df7rXLN2KS)\u307f\u305f\u3044\u3060\u3002"}, "1119667804175618048": {"author": "@svlevine", "followers": "19,130", "datetime": "2019-04-20 18:23:01", "content_summary": "The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This is our best-performing meta-RL framework, implemented on top of SAC. In case you want to build on it for NeurIPS or compare :) ht"}, "1108874340064387072": {"author": "@ZachBessinger", "followers": "165", "datetime": "2019-03-21 23:33:39", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108567016351453184": {"author": "@johnnyprothero", "followers": "198", "datetime": "2019-03-21 03:12:27", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108739794937565184": {"author": "@future_of_AI", "followers": "2,356", "datetime": "2019-03-21 14:39:01", "content_summary": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables https://t.co/LU4RMF5uNz #AI #Research via @glouppe"}, "1108581666409205760": {"author": "@sandipanh05", "followers": "80", "datetime": "2019-03-21 04:10:40", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108664744766914560": {"author": "@morioka", "followers": "824", "datetime": "2019-03-21 09:40:47", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119736327946194944": {"author": "@sigitpurnomo", "followers": "2,668", "datetime": "2019-04-20 22:55:18", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108977760653828097": {"author": "@PerthMLGroup", "followers": "456", "datetime": "2019-03-22 06:24:36", "content_summary": "RT @Miles_Brundage: \"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables,\" Rakelly and Zhou et al.: https\u2026"}, "1109071885046898690": {"author": "@dannyehb", "followers": "307", "datetime": "2019-03-22 12:38:37", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109074676880420864": {"author": "@morgangiraud", "followers": "583", "datetime": "2019-03-22 12:49:43", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108851163322044416": {"author": "@MarkR3333", "followers": "84", "datetime": "2019-03-21 22:01:33", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108940522045865986": {"author": "@ReedRoof", "followers": "28", "datetime": "2019-03-22 03:56:38", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108882669033512960": {"author": "@tnarihi", "followers": "199", "datetime": "2019-03-22 00:06:44", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108724182559293440": {"author": "@devnag", "followers": "1,216", "datetime": "2019-03-21 13:36:58", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108555768100474880": {"author": "@ceobillionaire", "followers": "163,388", "datetime": "2019-03-21 02:27:45", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109055688611790848": {"author": "@jinbeizame007", "followers": "2,479", "datetime": "2019-03-22 11:34:16", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108642469023895552": {"author": "@subhobrata1", "followers": "309", "datetime": "2019-03-21 08:12:16", "content_summary": "RT @arxiv_in_review: #ICML2019 Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [c\u2026"}, "1108599371883401216": {"author": "@jinbeizame007", "followers": "2,479", "datetime": "2019-03-21 05:21:01", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1122764110892896256": {"author": "@9ie23dtVWxoS3oa", "followers": "0", "datetime": "2019-04-29 07:26:38", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108529447483760640": {"author": "@Miles_Brundage", "followers": "25,873", "datetime": "2019-03-21 00:43:10", "content_summary": "\"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables,\" Rakelly and Zhou et al.: https://t.co/PMgrpdvvcW"}, "1108770158795907072": {"author": "@nsdgpn", "followers": "82", "datetime": "2019-03-21 16:39:40", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108800378856824832": {"author": "@Deepans44922477", "followers": "14", "datetime": "2019-03-21 18:39:45", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119864152820977664": {"author": "@alexk_z", "followers": "1,654", "datetime": "2019-04-21 07:23:14", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108579523178577925": {"author": "@xxxnell", "followers": "419", "datetime": "2019-03-21 04:02:09", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108581716883468288": {"author": "@syinari0123", "followers": "1,611", "datetime": "2019-03-21 04:10:52", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108986443706314752": {"author": "@liu_shuhua", "followers": "7", "datetime": "2019-03-22 06:59:06", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119851805683240961": {"author": "@janislavjankov", "followers": "61", "datetime": "2019-04-21 06:34:10", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1177257313561796608": {"author": "@subhobrata1", "followers": "309", "datetime": "2019-09-26 16:23:10", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108747705285660672": {"author": "@jekbradbury", "followers": "4,354", "datetime": "2019-03-21 15:10:27", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108634417914961926": {"author": "@bgalbraith", "followers": "958", "datetime": "2019-03-21 07:40:17", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108765913631899648": {"author": "@samanthafmccabe", "followers": "235", "datetime": "2019-03-21 16:22:48", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108814501854564355": {"author": "@j0nlussier", "followers": "916", "datetime": "2019-03-21 19:35:52", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108804847267127297": {"author": "@drvbvr", "followers": "21", "datetime": "2019-03-21 18:57:30", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109908696107307009": {"author": "@tSILIChtetL", "followers": "358", "datetime": "2019-03-24 20:03:48", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119709253495873541": {"author": "@muhammadali111", "followers": "1,235", "datetime": "2019-04-20 21:07:43", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1109909146676146176": {"author": "@aeRIsincOsmos", "followers": "269", "datetime": "2019-03-24 20:05:36", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108645234827821056": {"author": "@gastronomy", "followers": "1,390", "datetime": "2019-03-21 08:23:16", "content_summary": "[arXiv] Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [cs.LG]) --> Deep reinforcement learning algorithms require large amounts of experience to learn an individual task. While in principle me"}, "1120037586649509888": {"author": "@ryancjulian", "followers": "46", "datetime": "2019-04-21 18:52:24", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1124333187922968577": {"author": "@hasansaikatt", "followers": "122", "datetime": "2019-05-03 15:21:35", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1119813166765096960": {"author": "@Delfox29", "followers": "96", "datetime": "2019-04-21 04:00:38", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1120398730396610560": {"author": "@manuelschmidt90", "followers": "37", "datetime": "2019-04-22 18:47:27", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108612136115146752": {"author": "@neil_uai", "followers": "213", "datetime": "2019-03-21 06:11:44", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109066944353832962": {"author": "@ta_makino", "followers": "1,208", "datetime": "2019-03-22 12:18:59", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108534149047087105": {"author": "@StatMLPapers", "followers": "9,756", "datetime": "2019-03-21 01:01:51", "content_summary": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [cs.LG]) https://t.co/Fg8jGO4C7j"}, "1109108302649135104": {"author": "@Montreal_IA", "followers": "159,742", "datetime": "2019-03-22 15:03:20", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109073839043108864": {"author": "@KloudStrife", "followers": "920", "datetime": "2019-03-22 12:46:23", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108869760840798209": {"author": "@Vollte", "followers": "1", "datetime": "2019-03-21 23:15:27", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108720430007898112": {"author": "@PMZepto", "followers": "2,030", "datetime": "2019-03-21 13:22:04", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108988572688941056": {"author": "@daniel_heres", "followers": "50", "datetime": "2019-03-22 07:07:34", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108822033721364480": {"author": "@Cal_Engineer", "followers": "28,346", "datetime": "2019-03-21 20:05:48", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108600990431772672": {"author": "@bnjasim", "followers": "206", "datetime": "2019-03-21 05:27:27", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1120130381137604608": {"author": "@tomaxent", "followers": "4", "datetime": "2019-04-22 01:01:08", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108670565768970240": {"author": "@jastner109", "followers": "194", "datetime": "2019-03-21 10:03:55", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108764019865911296": {"author": "@Quantu_MX", "followers": "335", "datetime": "2019-03-21 16:15:16", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108659148537978880": {"author": "@gmhealy", "followers": "611", "datetime": "2019-03-21 09:18:33", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108661812143099904": {"author": "@KouroshMeshgi", "followers": "621", "datetime": "2019-03-21 09:29:08", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108546509002473472": {"author": "@vasan_ashwin", "followers": "36", "datetime": "2019-03-21 01:50:58", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108546846824120320": {"author": "@2000Qiu", "followers": "11", "datetime": "2019-03-21 01:52:18", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1121395912784470016": {"author": "@Montreal_IA", "followers": "159,742", "datetime": "2019-04-25 12:49:54", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108594872561340416": {"author": "@glouppe", "followers": "6,134", "datetime": "2019-03-21 05:03:08", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108969256559890432": {"author": "@ysaito8015", "followers": "1,060", "datetime": "2019-03-22 05:50:49", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1119700289379098625": {"author": "@PavaniTripathi", "followers": "12", "datetime": "2019-04-20 20:32:06", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108655671443116032": {"author": "@AIActorCritic", "followers": "128", "datetime": "2019-03-21 09:04:44", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1110072841607745536": {"author": "@facontidavide", "followers": "838", "datetime": "2019-03-25 06:56:04", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108711466780090368": {"author": "@ayirpelle", "followers": "2,677", "datetime": "2019-03-21 12:46:27", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108694532491788288": {"author": "@ramana_95", "followers": "266", "datetime": "2019-03-21 11:39:09", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108834854098079752": {"author": "@gnperdue", "followers": "202", "datetime": "2019-03-21 20:56:45", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108897403527032833": {"author": "@udayadampage", "followers": "479", "datetime": "2019-03-22 01:05:17", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108750859612184576": {"author": "@sennraf", "followers": "50", "datetime": "2019-03-21 15:22:59", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108948022879092737": {"author": "@seba1511", "followers": "411", "datetime": "2019-03-22 04:26:26", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108924669283860481": {"author": "@nav74neet", "followers": "17", "datetime": "2019-03-22 02:53:38", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108595211846864896": {"author": "@positivearrow", "followers": "220", "datetime": "2019-03-21 05:04:29", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108610397530148864": {"author": "@atveit", "followers": "2,480", "datetime": "2019-03-21 06:04:50", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1110000819464749056": {"author": "@cole_gulino", "followers": "89", "datetime": "2019-03-25 02:09:52", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108879594151514112": {"author": "@jaguring1", "followers": "13,499", "datetime": "2019-03-21 23:54:31", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109177987398807553": {"author": "@Rosenchild", "followers": "11,974", "datetime": "2019-03-22 19:40:14", "content_summary": "RT @arxiv_org: Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. https://t.co/z2jqk529uX https://t.co/P\u2026"}, "1108532827589619713": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-03-21 00:56:36", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/sTBZiXeryW Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [cs.LG])"}, "1108607469503303681": {"author": "@indy9000", "followers": "358", "datetime": "2019-03-21 05:53:12", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108533532970962944": {"author": "@yapp1e", "followers": "49", "datetime": "2019-03-21 00:59:24", "content_summary": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. (arXiv:1903.08254v1 [cs.LG]) https://t.co/8ueYVCkjYV Deep reinforcement learning algorithms require large amounts of experience to learn an individual task. While in pri"}, "1109908711361966080": {"author": "@tSILIChtetL", "followers": "358", "datetime": "2019-03-24 20:03:52", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108653675986198528": {"author": "@AVSave", "followers": "19", "datetime": "2019-03-21 08:56:48", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119674533512974337": {"author": "@ceobillionaire", "followers": "163,388", "datetime": "2019-04-20 18:49:45", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108877249594286082": {"author": "@ainewsantenna", "followers": "55", "datetime": "2019-03-21 23:45:12", "content_summary": "RT @icoxfog417: \u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u30e1\u30bf\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3044\u3066\u3001\u6226\u7565\u3067\u306f\u306a\u304f\u74b0\u5883\u306b\u30d5\u30a9\u30fc\u30ab\u30b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3002\u65e2\u5b58\u306e\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u6226\u7565(\u65b0\u3057\u3044\u74b0\u5883\u306b\u3059\u3050\u9069\u5408\u3059\u308b\u9023\u7565)\u306e\u4f5c\u6210\u3092\u8a66\u307f\u308b\u3053\u3068\u304c\u591a\u3044\u304c\u3001\u672c\u7814\u7a76\u3067\u306f\u30e1\u30bf\u306a\u74b0\u5883\u8a8d\u8b58(\u5177\u4f53\u7684\u306b\u306f\u6f5c\u5728\u8868\u73fe)\u3092\u5b66\u7fd2\u3055\u305b\u3001\u305d\u308c\u3092\u57fa\u306b\u884c\u52d5\u3092\u3068\u308b\u3068\u2026"}, "1108603153497219072": {"author": "@ML_deep", "followers": "4,738", "datetime": "2019-03-21 05:36:03", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108587696635535360": {"author": "@AIforMankind", "followers": "89", "datetime": "2019-03-21 04:34:38", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108775081025699840": {"author": "@RoryBramwell", "followers": "1,130", "datetime": "2019-03-21 16:59:14", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1111688234696953857": {"author": "@orl_London", "followers": "289", "datetime": "2019-03-29 17:55:03", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119680340933644288": {"author": "@miguelalonsojr", "followers": "1,072", "datetime": "2019-04-20 19:12:50", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1114231220966166528": {"author": "@amrmkayid", "followers": "285", "datetime": "2019-04-05 18:19:59", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108698730297995264": {"author": "@moss_dalvi", "followers": "119", "datetime": "2019-03-21 11:55:50", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108860282015604736": {"author": "@chachay", "followers": "293", "datetime": "2019-03-21 22:37:47", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119698537644789760": {"author": "@500zainraza", "followers": "299", "datetime": "2019-04-20 20:25:09", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108605202934816769": {"author": "@lecocco", "followers": "10", "datetime": "2019-03-21 05:44:11", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108852097850593280": {"author": "@alexis_b_cook", "followers": "2,091", "datetime": "2019-03-21 22:05:16", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108896192803438592": {"author": "@tea_mf_", "followers": "41", "datetime": "2019-03-22 01:00:29", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108620344808472576": {"author": "@hoangcuong0605", "followers": "53", "datetime": "2019-03-21 06:44:22", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1118694206141153280": {"author": "@Indirabrajesh", "followers": "1,718", "datetime": "2019-04-18 01:54:17", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108870836491075584": {"author": "@marknabil", "followers": "907", "datetime": "2019-03-21 23:19:43", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108596210405904384": {"author": "@Tsingggg", "followers": "22", "datetime": "2019-03-21 05:08:27", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108923956575244288": {"author": "@dimatolsto", "followers": "23", "datetime": "2019-03-22 02:50:48", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109030520443158528": {"author": "@ElectronNest", "followers": "231", "datetime": "2019-03-22 09:54:15", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108618556260929538": {"author": "@alexk_z", "followers": "1,654", "datetime": "2019-03-21 06:37:15", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108791192672759808": {"author": "@GilgameshNusku", "followers": "283", "datetime": "2019-03-21 18:03:15", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108927904740605952": {"author": "@tanmay7270_", "followers": "23", "datetime": "2019-03-22 03:06:30", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108596951057121281": {"author": "@arxivml", "followers": "785", "datetime": "2019-03-21 05:11:24", "content_summary": "\"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables\", Kate Rakelly, Aurick Zhou, \u2026 https://t.co/mCWrfgSCck"}, "1110901226596519937": {"author": "@rfrsarmiento", "followers": "1,472", "datetime": "2019-03-27 13:47:46", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119910503650713600": {"author": "@jcchinhui", "followers": "255", "datetime": "2019-04-21 10:27:25", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1120721866753077248": {"author": "@ReedRoof", "followers": "28", "datetime": "2019-04-23 16:11:29", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108750440231919616": {"author": "@63556poiuytrewq", "followers": "435", "datetime": "2019-03-21 15:21:19", "content_summary": "RT @peisuke: \u30e1\u30bf\u5b66\u7fd2\u3067Off Policy\u306e\u5f37\u5316\u5b66\u7fd2\u3092\u5b9f\u73fe\u305720-100\u500d\u306e\u52b9\u7387\u5316\u3002\u72b6\u614b\u30fb\u884c\u52d5\u7b49\u304b\u3089\u6210\u308b\u30b9\u30c6\u30c3\u30d7\u6bce\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u96a0\u308c\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8z\u3092\u63a8\u8ad6\u3057\u3001z\u306e\u60c5\u5831\u3092\u4f75\u7528\u3057\u3066\u5f37\u5316\u5b66\u7fd2\u3092\u884c\u3046\u3002\u5f37\u5316\u5b66\u7fd2\u306b\u306fsoft actor critic\u3092\u5229\u7528\u3002 https:/\u2026"}, "1119708707451838464": {"author": "@korymath", "followers": "4,331", "datetime": "2019-04-20 21:05:33", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108745085997498368": {"author": "@fonnesbeck", "followers": "3,516", "datetime": "2019-03-21 15:00:02", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119850407897944064": {"author": "@suraj_donthi", "followers": "44", "datetime": "2019-04-21 06:28:37", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108803901631938560": {"author": "@abhijithtn", "followers": "77", "datetime": "2019-03-21 18:53:45", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108703882027429888": {"author": "@ceobillionaire", "followers": "163,388", "datetime": "2019-03-21 12:16:18", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1119804402532065280": {"author": "@indy9000", "followers": "358", "datetime": "2019-04-21 03:25:49", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108646314433232902": {"author": "@_Alex_Borghi_", "followers": "163", "datetime": "2019-03-21 08:27:33", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108648217967656961": {"author": "@sigitpurnomo", "followers": "2,668", "datetime": "2019-03-21 08:35:07", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108552889390247936": {"author": "@saikrishna_gvs", "followers": "673", "datetime": "2019-03-21 02:16:19", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1119928156809510912": {"author": "@chirghosh", "followers": "281", "datetime": "2019-04-21 11:37:34", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108573573772271616": {"author": "@cghosh_", "followers": "281", "datetime": "2019-03-21 03:38:30", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108544561197006849": {"author": "@tsp_thomas", "followers": "236", "datetime": "2019-03-21 01:43:13", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108765212080001024": {"author": "@unsorsodicorda", "followers": "739", "datetime": "2019-03-21 16:20:01", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108935287273480198": {"author": "@XULAN007", "followers": "10", "datetime": "2019-03-22 03:35:50", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1120286101082603520": {"author": "@KeviDenam", "followers": "86", "datetime": "2019-04-22 11:19:55", "content_summary": "RT @svlevine: The open-source PEARL code has been refactored (by Kate R and Aurick Z) to be much more usable: https://t.co/rU1eaOVIhc This\u2026"}, "1108544262767931393": {"author": "@abdel_m", "followers": "537", "datetime": "2019-03-21 01:42:02", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108817730810101761": {"author": "@cosmo_bruce", "followers": "675", "datetime": "2019-03-21 19:48:42", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1109030584347557888": {"author": "@gatheluck", "followers": "200", "datetime": "2019-03-22 09:54:30", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108806385083604992": {"author": "@leticiapintoa", "followers": "156", "datetime": "2019-03-21 19:03:37", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108817658059776000": {"author": "@iamknighton", "followers": "426", "datetime": "2019-03-21 19:48:25", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1108963345099452416": {"author": "@amolchanov86", "followers": "59", "datetime": "2019-03-22 05:27:19", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108750612986892290": {"author": "@__tmats__", "followers": "805", "datetime": "2019-03-21 15:22:00", "content_summary": "RT @peisuke: \u30e1\u30bf\u5b66\u7fd2\u3067Off Policy\u306e\u5f37\u5316\u5b66\u7fd2\u3092\u5b9f\u73fe\u305720-100\u500d\u306e\u52b9\u7387\u5316\u3002\u72b6\u614b\u30fb\u884c\u52d5\u7b49\u304b\u3089\u6210\u308b\u30b9\u30c6\u30c3\u30d7\u6bce\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u96a0\u308c\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8z\u3092\u63a8\u8ad6\u3057\u3001z\u306e\u60c5\u5831\u3092\u4f75\u7528\u3057\u3066\u5f37\u5316\u5b66\u7fd2\u3092\u884c\u3046\u3002\u5f37\u5316\u5b66\u7fd2\u306b\u306fsoft actor critic\u3092\u5229\u7528\u3002 https:/\u2026"}, "1108561370952413184": {"author": "@sudan_shoe", "followers": "38", "datetime": "2019-03-21 02:50:01", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1114228070393606144": {"author": "@parnianbarekat", "followers": "451", "datetime": "2019-04-05 18:07:27", "content_summary": "RT @chelseabfinn: We introduce PEARL, a new meta-reinforcement learning method that is 20-100x faster and has better end performance than t\u2026"}, "1108834022153687066": {"author": "@SenteticSense", "followers": "254", "datetime": "2019-03-21 20:53:26", "content_summary": "RT @svlevine: PEARL: Meta-RL that is 20-100x faster than prior methods, with better final performance, using soft actor-critic and order-in\u2026"}, "1109407859291365379": {"author": "@shubh_300595", "followers": "66", "datetime": "2019-03-23 10:53:40", "content_summary": "RT @arxiv_org: Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables. https://t.co/z2jqk529uX https://t.co/P\u2026"}}, "completed": "1", "queriedAt": "2020-06-03 02:36:13"}