{"citation_id": "55055142", "tab": "twitter", "twitter": {"1093341435192070145": {"author": "@MLandDL_papers", "followers": "380", "datetime": "2019-02-07 02:51:26", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v1 [cs.LG]) https://t.co/e6OoPwEaez"}, "1093696286883233793": {"author": "@udmrzn", "followers": "1,348", "datetime": "2019-02-08 02:21:29", "content_summary": "RT @arxiv_org: Fooling Neural Network Interpretations via Adversarial Model Manipulation. https://t.co/0pggzeptxj https://t.co/43aqVptQGi"}, "1191199903193559041": {"author": "@arXiv_reaDer", "followers": "140", "datetime": "2019-11-04 03:46:03", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation \u6575\u5bfe\u7684\u30e2\u30c7\u30eb\u64cd\u4f5c\u3092\u4ecb\u3057\u305f\u3060\u307e\u3055\u308c\u305f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u89e3\u91c8 2019-11-01T00:16:17+00:00 arXiv: https://t.co/GwGpj28VMS summary: https://t.co/FTNyLVz9Hz"}, "1191178355233771521": {"author": "@gastronomy", "followers": "1,389", "datetime": "2019-11-04 02:20:25", "content_summary": "[arXiv] Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v3 [cs.LG] UPDATED) --> We ask whether the neural network interpretation methods can be fooled via adversarial model manipulation, which is defined as a"}, "1093338774464053250": {"author": "@arxiv_cscv", "followers": "4,111", "datetime": "2019-02-07 02:40:51", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20wMDOu"}, "1191169792922796033": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-11-04 01:46:24", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/s4Giu8G4r3 Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v3 [cs.LG] UPDATED)"}, "1093424502518833152": {"author": "@gastronomy", "followers": "1,389", "datetime": "2019-02-07 08:21:30", "content_summary": "[arXiv] Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v1 [cs.LG]) --> We ask whether the neural network interpretation methods can be fooled via adversarial model manipulation, which is defined as a model f"}, "1161090259180019718": {"author": "@arxiv_cscv", "followers": "4,111", "datetime": "2019-08-13 01:41:04", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20wMDOu"}, "1093692479851847680": {"author": "@owltrainlab", "followers": "45", "datetime": "2019-02-08 02:06:21", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v1 [cs.LG]) https://t.co/3HcOCYnrix"}, "1161271537439322112": {"author": "@arxiv_cscv", "followers": "4,111", "datetime": "2019-08-13 13:41:24", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20wMDOu"}, "1093535115161026561": {"author": "@arxiv_cscv", "followers": "4,111", "datetime": "2019-02-07 15:41:03", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20wMDOu"}, "1191170221031211013": {"author": "@pm_girl", "followers": "2,169", "datetime": "2019-11-04 01:48:06", "content_summary": "#Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v3 [cs.LG] UPDATED) https://t.co/L2gM2YziiL #artificialintelligence #ai"}, "1093394405568983040": {"author": "@arxivml", "followers": "780", "datetime": "2019-02-07 06:21:55", "content_summary": "\"Fooling Neural Network Interpretations via Adversarial Model Manipulation\", Juyeon Heo, Sunghwan Joo, Taesup Moon https://t.co/Rn2QJWZ20b"}, "1094166964635877376": {"author": "@Rosenchild", "followers": "11,933", "datetime": "2019-02-09 09:31:47", "content_summary": "RT @arxiv_org: Fooling Neural Network Interpretations via Adversarial Model Manipulation. https://t.co/0pggzeptxj https://t.co/43aqVptQGi"}, "1185120881426567168": {"author": "@_kalngyk", "followers": "2", "datetime": "2019-10-18 09:10:11", "content_summary": "RT @anmarasovic: @zacharylipton https://t.co/xpsK64XKk0 https://t.co/0YGTKUEsgm https://t.co/oY19bOXgsv"}, "1093325650381950977": {"author": "@StatMLPapers", "followers": "9,721", "datetime": "2019-02-07 01:48:42", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v1 [cs.LG]) https://t.co/lQfThV2Oc5"}, "1093663607127195648": {"author": "@disigandalf", "followers": "780", "datetime": "2019-02-08 00:11:37", "content_summary": "RT @arxiv_cscv: Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20x4eG2"}, "1161082005762842630": {"author": "@helioRocha_", "followers": "629", "datetime": "2019-08-13 01:08:16", "content_summary": "\"Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v2 [cs.LG] UPDATED)\" #arXiv https://t.co/vOsmMiiTF2"}, "1093341645205065728": {"author": "@BrundageBot", "followers": "3,891", "datetime": "2019-02-07 02:52:16", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation. Juyeon Heo, Sunghwan Joo, and Taesup Moon https://t.co/4wjZtcJV0B"}, "1093667116652220416": {"author": "@arxiv_org", "followers": "12,761", "datetime": "2019-02-08 00:25:34", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation. https://t.co/0pggzeptxj https://t.co/43aqVptQGi"}, "1191170273527173120": {"author": "@helioRocha_", "followers": "629", "datetime": "2019-11-04 01:48:18", "content_summary": "\"Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v3 [cs.LG] UPDATED)\" #arXiv https://t.co/vOsmMiiTF2"}, "1181458874060214273": {"author": "@koushik_here", "followers": "242", "datetime": "2019-10-08 06:38:40", "content_summary": "@hima_lakkaraju 2) Fooling Neural Network Interpretations via Adversarial Model Manipulation (https://t.co/mmE2dQbmU3)"}, "1093335294114291712": {"author": "@MelroLeandro", "followers": "57", "datetime": "2019-02-07 02:27:01", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v1 [cs.LG]) https://t.co/jyjxwwAa45"}, "1093667201230331904": {"author": "@jaialkdanel", "followers": "1,770", "datetime": "2019-02-08 00:25:54", "content_summary": "RT @arxiv_org: Fooling Neural Network Interpretations via Adversarial Model Manipulation. https://t.co/0pggzeptxj https://t.co/43aqVptQGi"}, "1093325302665744384": {"author": "@helioRocha_", "followers": "629", "datetime": "2019-02-07 01:47:19", "content_summary": "\"Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v1 [cs.LG])\" #arXiv https://t.co/vOsmMiiTF2"}, "1191168299972939776": {"author": "@arxiv_cscv", "followers": "4,111", "datetime": "2019-11-04 01:40:28", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20wMDOu"}, "1161081830906433541": {"author": "@pm_girl", "followers": "2,169", "datetime": "2019-08-13 01:07:35", "content_summary": "#Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v2 [cs.LG] UPDATED) https://t.co/L2gM2YziiL #artificialintelligence #ai"}, "1093655701572837377": {"author": "@arxiv_cscv", "followers": "4,111", "datetime": "2019-02-07 23:40:13", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20x4eG2"}, "1184936748494643200": {"author": "@anmarasovic", "followers": "532", "datetime": "2019-10-17 20:58:30", "content_summary": "@zacharylipton https://t.co/xpsK64XKk0 https://t.co/0YGTKUEsgm https://t.co/oY19bOXgsv"}, "1093753547575955456": {"author": "@shubh_300595", "followers": "66", "datetime": "2019-02-08 06:09:01", "content_summary": "RT @arxiv_org: Fooling Neural Network Interpretations via Adversarial Model Manipulation. https://t.co/0pggzeptxj https://t.co/43aqVptQGi"}, "1093431437171322882": {"author": "@JMAi1729", "followers": "4", "datetime": "2019-02-07 08:49:04", "content_summary": "https://t.co/W7MnhnlnND"}, "1191349698461872129": {"author": "@arxiv_cscv", "followers": "4,111", "datetime": "2019-11-04 13:41:16", "content_summary": "Fooling Neural Network Interpretations via Adversarial Model Manipulation https://t.co/rDO20wMDOu"}, "1161082016542154753": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-08-13 01:08:19", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/s4Giu8G4r3 Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v2 [cs.LG] UPDATED)"}, "1093325565229174785": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-07 01:48:22", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/TQPZ9JRNBe Fooling Neural Network Interpretations via Adversarial Model Manipulation. (arXiv:1902.02041v1 [cs.LG])"}}, "completed": "1", "queriedAt": "2020-06-03 00:52:03"}