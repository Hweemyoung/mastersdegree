{"citation_id": "55371636", "tab": "twitter", "twitter": {"1095895887262502913": {"author": "@udmrzn", "followers": "1,348", "datetime": "2019-02-14 04:01:54", "content_summary": "RT @StatMLPapers: Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG]) https://t.co/9A5vze7L1f"}, "1095808371331133443": {"author": "@heghbalz", "followers": "1,286", "datetime": "2019-02-13 22:14:09", "content_summary": "RT @StatMLPapers: Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG]) https://t.co/9A5vze7L1f"}, "1096077445323608065": {"author": "@owltrainlab", "followers": "42", "datetime": "2019-02-14 16:03:21", "content_summary": "Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG]) https://t.co/LvKJKD4oFw #papers- ai #ml #feedly"}, "1095518613606461440": {"author": "@deep_rl", "followers": "857", "datetime": "2019-02-13 03:02:45", "content_summary": "Stochastic Reinforcement Learning - Nikki Lijing Kuang https://t.co/1zjdjjK6ps"}, "1125523468865421312": {"author": "@ml_unam", "followers": "244", "datetime": "2019-05-06 22:11:20", "content_summary": "Esto esta padrisimo: \"stochastic reinforcement learning\" https://t.co/V5gFBnAkEm"}, "1095681894576836610": {"author": "@owltrainlab", "followers": "42", "datetime": "2019-02-13 13:51:35", "content_summary": "Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG]) https://t.co/LvKJKD4oFw #papers- ai #ml #feedly"}, "1095501948495822849": {"author": "@helioRocha_", "followers": "623", "datetime": "2019-02-13 01:56:32", "content_summary": "\"Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG])\" #arXiv https://t.co/RoPRKFIMcU"}, "1095515074943479808": {"author": "@BrundageBot", "followers": "3,850", "datetime": "2019-02-13 02:48:42", "content_summary": "Stochastic Reinforcement Learning. Nikki Lijing Kuang, Clement H. C. Leung, and Vienne W. K. Sung https://t.co/6wbCZxiUzt"}, "1095658471364747264": {"author": "@gammamongwe", "followers": "104", "datetime": "2019-02-13 12:18:30", "content_summary": "RT @StatMLPapers: Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG]) https://t.co/9A5vze7L1f"}, "1096169747132153862": {"author": "@bgoncalves", "followers": "4,070", "datetime": "2019-02-14 22:10:08", "content_summary": "Stochastic Reinforcement Learning https://t.co/qOuFG7y79i"}, "1095502258186407937": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-13 01:57:46", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/sNw82abdSb Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG])"}, "1095615085035352064": {"author": "@gastronomy", "followers": "1,386", "datetime": "2019-02-13 09:26:06", "content_summary": "[arXiv] Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG]) --> In reinforcement learning episodes, the rewards and punishments are often non-deterministic, and there are invariably stochastic elements governing the underlying situation. Su"}, "1095593880462999552": {"author": "@arxivml", "followers": "768", "datetime": "2019-02-13 08:01:50", "content_summary": "\"Stochastic Reinforcement Learning\", Nikki Lijing Kuang, Clement H\uff0e C\uff0e Leung, Vienne W\uff0e K\uff0e Sung https://t.co/O98PbOmJMH"}, "1095501981765066752": {"author": "@StatMLPapers", "followers": "9,659", "datetime": "2019-02-13 01:56:40", "content_summary": "Stochastic Reinforcement Learning. (arXiv:1902.04178v1 [cs.LG]) https://t.co/9A5vze7L1f"}}, "completed": "1", "queriedAt": "2020-06-03 01:07:02"}