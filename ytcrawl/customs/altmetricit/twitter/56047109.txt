{"tab": "twitter", "completed": "1", "twitter": {"1100662939827228673": {"author": "@cynicalsecurity", "followers": "7,393", "datetime": "2019-02-27 07:44:28", "content_summary": "B. Jayaraman and D. Evans, \u201cWhen Relaxations Go Bad: \"Differentially-Private\" Machine Learning\u201d [\u2026main findings are that current mechanisms for differential privacy for machine learning rarely offer acceptable utility-privacy tradeoffs:\u2026] https://t.co/o9D"}, "1100233537515651072": {"author": "@arXiv__ml", "followers": "1,804", "datetime": "2019-02-26 03:18:11", "content_summary": "#arXiv #machinelearning [cs.LG] When Relaxations Go Bad: \"Differentially-Private\" Machine Learning. (arXiv:1902.08874v1 [cs.LG]) https://t.co/RFRBZZlV5e Differential privacy is becoming a standard notion for performing privacy-preserving machine learning"}, "1101205492037226496": {"author": "@rharang", "followers": "605", "datetime": "2019-02-28 19:40:23", "content_summary": "RT @emilianoucl: When Relaxations Go Bad: \u201cDifferentially-Private\u201d Machine Learning. Very interesting work by Bargav Jayaraman and David Ev\u2026"}, "1161691191840301056": {"author": "@ak1010", "followers": "1,086", "datetime": "2019-08-14 17:28:57", "content_summary": "Evaluating Differentially Private Machine Learning in Practice https://t.co/Cks6nxipEj"}, "1100288514552406017": {"author": "@SantchiWeb", "followers": "8,259", "datetime": "2019-02-26 06:56:38", "content_summary": "RT @StatMLPapers: When Relaxations Go Bad: \"Differentially-Private\" Machine Learning. (arXiv:1902.08874v1 [cs.LG]) https://t.co/L8dUxZttuD"}, "1162520345649094656": {"author": "@worldwise001", "followers": "3,820", "datetime": "2019-08-17 00:23:43", "content_summary": "updated results: https://t.co/77fk5yk7wW"}, "1182267546491408385": {"author": "@SDRoem", "followers": "1,934", "datetime": "2019-10-10 12:12:03", "content_summary": "A lot has been asserted about usefulness (or uselessness) of stripping personal data to provide anonymous #analytics. This paper is a good summary of background & #mathematics of that - concludes #privacy & utility are inversely related, much lik"}, "1100222575483990016": {"author": "@BrundageBot", "followers": "3,913", "datetime": "2019-02-26 02:34:37", "content_summary": "When Relaxations Go Bad: \"Differentially-Private\" Machine Learning. Bargav Jayaraman and David Evans https://t.co/zZZRkuPw8R"}, "1179870724871340032": {"author": "@ayirpelle", "followers": "2,675", "datetime": "2019-10-03 21:27:56", "content_summary": "RT @sweis: \"Evaluating Differentially Private Machine Learning in Practice\" covers a lot of practical \u03b5 values and DP variants: https://t.c\u2026"}, "1100310090140315648": {"author": "@arxivml", "followers": "793", "datetime": "2019-02-26 08:22:22", "content_summary": "\"When Relaxations Go Bad: \"Differentially-Private\" Machine Learning\", Bargav Jayaraman, David Evans https://t.co/bb1er6UqG8"}, "1162556628400349184": {"author": "@UdacityDave", "followers": "1,601", "datetime": "2019-08-17 02:47:54", "content_summary": "Thanks for all the great #usesec19 live tweeting @LeaKissner! See https://t.co/hDrlkqFS5H for the code and updated paper in arxiv https://t.co/4635QYpctx"}, "1182146260146348032": {"author": "@VanRijmenam", "followers": "45,862", "datetime": "2019-10-10 04:10:06", "content_summary": "RT @karlhigley: An evaluation of current differential privacy mechanisms for complex machine learning tasks: \u201csettings that provide limited\u2026"}, "1100226228127260675": {"author": "@StatMLPapers", "followers": "9,763", "datetime": "2019-02-26 02:49:08", "content_summary": "When Relaxations Go Bad: \"Differentially-Private\" Machine Learning. (arXiv:1902.08874v1 [cs.LG]) https://t.co/L8dUxZttuD"}, "1179896226126483456": {"author": "@elwrv", "followers": "402", "datetime": "2019-10-03 23:09:16", "content_summary": "RT @sweis: \"Evaluating Differentially Private Machine Learning in Practice\" covers a lot of practical \u03b5 values and DP variants: https://t.c\u2026"}, "1100288444872511488": {"author": "@iamgroot42", "followers": "162", "datetime": "2019-02-26 06:56:22", "content_summary": "RT @StatMLPapers: When Relaxations Go Bad: \"Differentially-Private\" Machine Learning. (arXiv:1902.08874v1 [cs.LG]) https://t.co/L8dUxZttuD"}, "1101645110641479680": {"author": "@arxiv_pop", "followers": "715", "datetime": "2019-03-02 00:47:16", "content_summary": "2019/02/23 \u6295\u7a3f 2\u4f4d LG(Machine Learning) When Relaxations Go Bad: \"Differentially-Private\" Machine Learning https://t.co/EdfN4vo3PF 7 Tweets 4 Retweets 9 Favorites"}, "1179867611993034753": {"author": "@sweis", "followers": "7,307", "datetime": "2019-10-03 21:15:34", "content_summary": "\"Evaluating Differentially Private Machine Learning in Practice\" covers a lot of practical \u03b5 values and DP variants: https://t.co/EiFdVsvLf5"}, "1182280741935292417": {"author": "@SDRoem", "followers": "1,934", "datetime": "2019-10-10 13:04:29", "content_summary": "RT @SDRoem: A lot has been asserted about usefulness (or uselessness) of stripping personal data to provide anonymous #analytics. This pa\u2026"}, "1100366936381153280": {"author": "@StatsPapers", "followers": "5,454", "datetime": "2019-02-26 12:08:16", "content_summary": "When Relaxations Go Bad: \"Differentially-Private\" Machine Learning. https://t.co/gHSFMvMkzx"}, "1182134664632385536": {"author": "@karlhigley", "followers": "785", "datetime": "2019-10-10 03:24:01", "content_summary": "An evaluation of current differential privacy mechanisms for complex machine learning tasks: \u201csettings that provide limited accuracy loss provide meaningless privacy guarantees, and settings that provide strong privacy guarantees result in useless models\u201d"}, "1100256085582249984": {"author": "@mlmemoirs", "followers": "1,291", "datetime": "2019-02-26 04:47:47", "content_summary": "#arXiv #machinelearning [cs.LG] When Relaxations Go Bad: \"Differentially-Private\" Machine Learning. (arXiv:1902.08874v1 [cs.LG]) https://t.co/8As1QSJ2Y8 Differential privacy is becoming a standard notion for performing privacy-preserving machine learning"}}, "citation_id": "56047109", "queriedAt": "2020-06-04 00:20:39"}