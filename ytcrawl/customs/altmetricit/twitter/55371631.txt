{"tab": "twitter", "completed": "1", "twitter": {"1095949436038119425": {"author": "@Rosenchild", "followers": "11,929", "datetime": "2019-02-14 07:34:41", "content_summary": "RT @arxiv_org: Deep Reinforcement Learning from Policy-Dependent Human Feedback. https://t.co/1L6iMWrbaa https://t.co/0J4iQK5NtA"}, "1095516450100400129": {"author": "@Miles_Brundage", "followers": "25,873", "datetime": "2019-02-13 02:54:10", "content_summary": "\"Deep Reinforcement Learning from Policy-Dependent Human Feedback,\" Arumugam et al.: https://t.co/mq3jTLKF6M"}, "1095518635504877570": {"author": "@deep_rl", "followers": "858", "datetime": "2019-02-13 03:02:51", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback - Dilip Arumugam https://t.co/1X6dyAS3xl"}, "1095826860196417536": {"author": "@teenvan1995", "followers": "354", "datetime": "2019-02-13 23:27:37", "content_summary": "RT @arxiv_org: Deep Reinforcement Learning from Policy-Dependent Human Feedback. https://t.co/1L6iMWrbaa https://t.co/0J4iQK5NtA"}, "1095501950962016257": {"author": "@StatMLPapers", "followers": "9,717", "datetime": "2019-02-13 01:56:33", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback. (arXiv:1902.04257v1 [cs.LG]) https://t.co/S0p4OGx0WC"}, "1095679917788868608": {"author": "@AssistedEvolve", "followers": "217", "datetime": "2019-02-13 13:43:43", "content_summary": "RT @Miles_Brundage: \"Deep Reinforcement Learning from Policy-Dependent Human Feedback,\" Arumugam et al.: https://t.co/mq3jTLKF6M"}, "1095514895825752064": {"author": "@arxiv_cs_LG", "followers": "318", "datetime": "2019-02-13 02:47:59", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback. Dilip Arumugam, Jun Ki Lee, Sophie Saskin, and Michael L. Littman https://t.co/bR55EUeGBC"}, "1095803555049586694": {"author": "@future_of_AI", "followers": "2,305", "datetime": "2019-02-13 21:55:01", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback https://t.co/UaK34v3UZE #AI #Research via @Miles_Brundage"}, "1096077704997134336": {"author": "@owltrainlab", "followers": "45", "datetime": "2019-02-14 16:04:23", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback. (arXiv:1902.04257v1 [cs.LG]) https://t.co/EfG6s0b9fk #papers- ai #ml #feedly"}, "1095863899855904774": {"author": "@hereticreader", "followers": "195", "datetime": "2019-02-14 01:54:48", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback - https://t.co/9D1COPFWPY https://t.co/K5I70vi9UV"}, "1095685072890454016": {"author": "@PerthMLGroup", "followers": "456", "datetime": "2019-02-13 14:04:12", "content_summary": "RT @Miles_Brundage: \"Deep Reinforcement Learning from Policy-Dependent Human Feedback,\" Arumugam et al.: https://t.co/mq3jTLKF6M"}, "1095829920138383362": {"author": "@JeanMarcJAzzi", "followers": "365", "datetime": "2019-02-13 23:39:47", "content_summary": "RT @Miles_Brundage: \"Deep Reinforcement Learning from Policy-Dependent Human Feedback,\" Arumugam et al.: https://t.co/mq3jTLKF6M"}, "1095897678330974208": {"author": "@udmrzn", "followers": "1,348", "datetime": "2019-02-14 04:09:01", "content_summary": "RT @arxiv_org: Deep Reinforcement Learning from Policy-Dependent Human Feedback. https://t.co/1L6iMWrbaa https://t.co/0J4iQK5NtA"}, "1095517990697656321": {"author": "@alexdaviscmu", "followers": "711", "datetime": "2019-02-13 03:00:17", "content_summary": "RT @Miles_Brundage: \"Deep Reinforcement Learning from Policy-Dependent Human Feedback,\" Arumugam et al.: https://t.co/mq3jTLKF6M"}, "1095825825620848640": {"author": "@arxiv_org", "followers": "12,767", "datetime": "2019-02-13 23:23:30", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback. https://t.co/1L6iMWrbaa https://t.co/0J4iQK5NtA"}, "1095515065489518592": {"author": "@BrundageBot", "followers": "3,889", "datetime": "2019-02-13 02:48:39", "content_summary": "Deep Reinforcement Learning from Policy-Dependent Human Feedback. Dilip Arumugam, Jun Ki Lee, Sophie Saskin, and Michael L. Littman https://t.co/brxrPv4j0E"}, "1095558646526824449": {"author": "@arxivml", "followers": "780", "datetime": "2019-02-13 05:41:50", "content_summary": "\"Deep Reinforcement Learning from Policy-Dependent Human Feedback\", Dilip Arumugam, Jun Ki Lee, Sophie Saskin, Mich\u2026 https://t.co/Cmf2PT4LMI"}, "1095958233209102337": {"author": "@HubBucket", "followers": "5,319", "datetime": "2019-02-14 08:09:39", "content_summary": "RT @arxiv_org: Deep Reinforcement Learning from Policy-Dependent Human Feedback. https://t.co/1L6iMWrbaa https://t.co/0J4iQK5NtA"}}, "citation_id": "55371631", "queriedAt": "2020-06-03 23:13:06"}