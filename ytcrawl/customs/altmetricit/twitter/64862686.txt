{"citation_id": "64862686", "completed": "1", "queriedAt": "2020-05-14 12:47:52", "tab": "twitter", "twitter": {"1164981212437458946": {"content_summary": "RT @PapersTrending: [2/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,040 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYeXMn - \ud83d\udd17 https://t\u2026", "followers": "43", "datetime": "2019-08-23 19:22:20", "author": "@MishakinSergey"}, "1160718143356133377": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond. (arXiv:1908.03265v1 [cs.LG]) https://t.co/nwMYgnqraX The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization\u2026 h", "followers": "48", "datetime": "2019-08-12 01:02:25", "author": "@yapp1e"}, "1162264406031392773": {"content_summary": "Very interesting idea by Liyuan Liu et al.! Adam optimisation has too large variance in the early stages of training, see details in paper: https://t.co/ugCW7oLoMC and code: https://t.co/0Wv5NzFoJE @MSFTResearch #AI #MachineLearning https://t.co/GKQMr7owg", "followers": "186", "datetime": "2019-08-16 07:26:42", "author": "@faabom"}, "1164387566390407169": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "72", "datetime": "2019-08-22 04:03:23", "author": "@semiinvariant"}, "1164299675400228864": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "824", "datetime": "2019-08-21 22:14:08", "author": "@morioka"}, "1252501624238399489": {"content_summary": "RAdam (ICLR2020) Adam + Warmup \u306b\u4f3c\u305f\u3088\u3046\u306a\u6a5f\u80fd\u3092\u6301\u3064optimizer https://t.co/CaA1c8h64u Warmup \u306e\u6709\u7528\u6027\u306b\u3064\u3044\u3066\u306f\u30ea\u30d7\u3078\u7d9a\u304f", "followers": "0", "datetime": "2020-04-21 07:37:12", "author": "@__sarrrrry2"}, "1235001399768780801": {"content_summary": "https://t.co/omTj8GVUl8 \u3061\u3083\u3093\u3068\u8aad\u3093\u3067\u306a\u3044\u3051\u3069\u3001RAdam\u306e\u8ad6\u6587\u3067LR\u3092\u9069\u5207\u306b\u8a2d\u5b9a\u3059\u308c\u3070\u753b\u50cf\u8a8d\u8b58\u3067\u306fSGD>Adam\u7cfb\u3068\u3057\u3066\u3044\u308b.? https://t.co/5u2fn41Uwc", "followers": "657", "datetime": "2020-03-04 00:37:33", "author": "@arutema47"}, "1164789298618519553": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "11", "datetime": "2019-08-23 06:39:44", "author": "@gaten3"}, "1163721379570749440": {"content_summary": "A new optimizer built on top of Adam New State of the Art AI Optimizer: Rectified Adam (RAdam). Improve your AI accuracy instantly versus Adam, and why it works https://t.co/5clTtTHarm code https://t.co/psYHmMlOFm paper : https://t.co/mrjuMQA5w9", "followers": "174", "datetime": "2019-08-20 07:56:12", "author": "@re_mahmoudi"}, "1163308829041233920": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "548", "datetime": "2019-08-19 04:36:52", "author": "@FBWM8888"}, "1229466577675767810": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "40", "datetime": "2020-02-17 18:04:09", "author": "@koba3_jon"}, "1160893985566679040": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmzgwZ", "followers": "3,488", "datetime": "2019-08-12 12:41:09", "author": "@arxiv_cscl"}, "1162264497236500480": {"content_summary": "RT @faabom: Very interesting idea by Liyuan Liu et al.! Adam optimisation has too large variance in the early stages of training, see detai\u2026", "followers": "4,550", "datetime": "2019-08-16 07:27:04", "author": "@TheCuriousLuke"}, "1164374157334740994": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "1,882", "datetime": "2019-08-22 03:10:06", "author": "@sesquipedale"}, "1163876901418672129": {"content_summary": "RT @PapersTrending: [1/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 775 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.c\u2026", "followers": "43", "datetime": "2019-08-20 18:14:11", "author": "@MishakinSergey"}, "1229388024246489089": {"content_summary": "\u3072\u3083\u3063\u306f\u30fc\uff01 \u65b0\u9bae\u306a\u6700\u9069\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3060(\u00b4\u30fb\u03c9\u30fb`)", "followers": "356", "datetime": "2020-02-17 12:52:00", "author": "@Miyaran99"}, "1164282366916874241": {"content_summary": "Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive rate in early-stage causes the problem and proposed RAdam that automatically switch to adaptive when the variance is tractable. ht", "followers": "18,217", "datetime": "2019-08-21 21:05:22", "author": "@hillbig"}, "1169908833717641217": {"content_summary": "RT @Deep_In_Depth: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/YVLI3A1Hml #DeepLearning #MachineLearning #Artific\u2026", "followers": "986", "datetime": "2019-09-06 09:42:56", "author": "@bjone6"}, "1164336034324213761": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "231", "datetime": "2019-08-22 00:38:37", "author": "@bamboo4031"}, "1164287081230635008": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "431", "datetime": "2019-08-21 21:24:06", "author": "@kawauso_kun"}, "1252034498797219840": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmzgwZ", "followers": "3,488", "datetime": "2020-04-20 00:41:00", "author": "@arxiv_cscl"}, "1229387718003572737": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "356", "datetime": "2020-02-17 12:50:47", "author": "@Miyaran99"}, "1161094350283034624": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond. https://t.co/8x3MNzVR6l https://t.co/GVPm1UhBEy", "followers": "12,714", "datetime": "2019-08-13 01:57:19", "author": "@arxiv_org"}, "1163029992944615424": {"content_summary": "RT @carlolepelaars: @kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: ht\u2026", "followers": "169", "datetime": "2019-08-18 10:08:53", "author": "@data4gud"}, "1164290115067248641": {"content_summary": "RT @hillbig: Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive\u2026", "followers": "497", "datetime": "2019-08-21 21:36:09", "author": "@nagakagachi"}, "1237614469586407424": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmQRox", "followers": "3,488", "datetime": "2020-03-11 05:40:57", "author": "@arxiv_cscl"}, "1164215502559952896": {"content_summary": "Interesting findings by our french team @thomaspeel_ @HongcThng17 : the image illustrates the use of RAdam to recognise traffic signs. #MachineLearning #internships", "followers": "449", "datetime": "2019-08-21 16:39:40", "author": "@euranova"}, "1163101194333503493": {"content_summary": "RT @mosko_mule: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/ljvUh1ReFI Adam\u306a\u3069\u306e\u9069\u5fdc\u7684\u306a\u6700\u9069\u5316\u624b\u6cd5\u306f\u5b66\u7fd2\u521d\u671f\u306b\u52fe\u914d\u306e\u5206\u6563\u304c\u5927\u304d\u304f\u3001\u305d\u308c\u304c\u5b66\u7fd2\u5f8c\u671f\u306e\u6027\u80fd\u2026", "followers": "380", "datetime": "2019-08-18 14:51:48", "author": "@harujoh"}, "1162303731376910336": {"content_summary": "https://t.co/tWFkM8fIOM", "followers": "0", "datetime": "2019-08-16 10:02:58", "author": "@shin0618ff"}, "1161274187471892480": {"content_summary": "RT @arxiv_org: On the Variance of the Adaptive Learning Rate and Beyond. https://t.co/8x3MNzVR6l https://t.co/GVPm1UhBEy", "followers": "1,168", "datetime": "2019-08-13 13:51:56", "author": "@DrPjenFI"}, "1229451125461356550": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "1,231", "datetime": "2020-02-17 17:02:45", "author": "@kazuph"}, "1165922106317492225": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "3", "datetime": "2019-08-26 09:41:06", "author": "@shriver_light"}, "1164326681504444416": {"content_summary": "RT @hillbig: Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive\u2026", "followers": "162", "datetime": "2019-08-22 00:01:27", "author": "@yokotatsuya"}, "1163022881141481472": {"content_summary": "RT @carlolepelaars: @kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: ht\u2026", "followers": "880", "datetime": "2019-08-18 09:40:37", "author": "@RichmanRonald"}, "1163818864884326403": {"content_summary": "Spent time today testing out the Regularised ADAM optimiser. As a drop-in replacement for vanilla ADAM, it seems to provide some mild improvements, with no increase in train-time when running for the same number of epochs. https://t.co/6VFBldeiZK https://", "followers": "353", "datetime": "2019-08-20 14:23:34", "author": "@Giles_C_Strong"}, "1163415298675896323": {"content_summary": "RT @bhutanisanyam1: Join us this Saturday, 8PM IST/7:30AM PT for the first KaggleNoobs x @DSNetOrg paper discussion meetup, about the RAdam\u2026", "followers": "148", "datetime": "2019-08-19 11:39:57", "author": "@kartik_godawat"}, "1229309115492491264": {"content_summary": "Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u8981\u3067\u5b66\u7fd2\u7387\u306e\u9078\u3073\u65b9\u306b\u9811\u5065\u306aRAdam\u3092\u63d0\u6848\u3057\u305f\u3002 https://t.co/26g0CHTHwe #NowReading https://t.co/xcPA8CsGWa", "followers": "2,446", "datetime": "2020-02-17 07:38:27", "author": "@shion_honda"}, "1163504237545971712": {"content_summary": "RT @thomaspeel_: Illustration de l'efficacit\u00e9 de RAdam (https://t.co/Ux8h8c3VbL) sur une t\u00e2che de reconnaissance de panneaux routiers. Merc\u2026", "followers": "56", "datetime": "2019-08-19 17:33:21", "author": "@malianderon"}, "1169902706158268418": {"content_summary": "RT @Deep_In_Depth: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/YVLI3A1Hml #DeepLearning #MachineLearning #Artific\u2026", "followers": "214", "datetime": "2019-09-06 09:18:35", "author": "@ShyBOT7"}, "1252351701773770752": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmQRox", "followers": "3,488", "datetime": "2020-04-20 21:41:27", "author": "@arxiv_cscl"}, "1167995639088603137": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "560", "datetime": "2019-09-01 03:00:35", "author": "@chrofieyue"}, "1229524257790541824": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "299", "datetime": "2020-02-17 21:53:21", "author": "@takafumikoike"}, "1160823881378095105": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond. Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han https://t.co/0fWIKUUN6R", "followers": "308", "datetime": "2019-08-12 08:02:35", "author": "@arxiv_cs_LG"}, "1237538872965206017": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmQRox", "followers": "3,488", "datetime": "2020-03-11 00:40:34", "author": "@arxiv_cscl"}, "1200689459273977857": {"content_summary": "Meta-Learning Update Rules for Unsupervised Representation Learning https://t.co/BJsGsZxbeL On the Variance of the Adaptive Learning Rate and Beyond https://t.co/1edwZFySqt XLNet: Generalized Autoregressive Pretraining for Language Understanding https://", "followers": "12,768", "datetime": "2019-11-30 08:14:09", "author": "@jaguring1"}, "1163363433460490241": {"content_summary": "RT @carlolepelaars: @kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: ht\u2026", "followers": "1,932", "datetime": "2019-08-19 08:13:51", "author": "@mandubian"}, "1161061884017221639": {"content_summary": "#arXiv #machinelearning [cs.LG] On the Variance of the Adaptive Learning Rate and Beyond. (arXiv:1908.03265v1 [cs.LG]) https://t.co/Qk0yoRDAza The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating converge\u2026 h", "followers": "1,700", "datetime": "2019-08-12 23:48:19", "author": "@arXiv__ml"}, "1165927522900553730": {"content_summary": "[8/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,114 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-26 10:02:38", "author": "@PapersTrending"}, "1160712638353031170": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmzgwZ", "followers": "3,488", "datetime": "2019-08-12 00:40:32", "author": "@arxiv_cscl"}, "1229381295546830848": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "9", "datetime": "2020-02-17 12:25:16", "author": "@literacynor"}, "1162348066701217793": {"content_summary": "Has Adam been beaten? Will experiment. Perhaps GANs will benefit from this. https://t.co/K5p7FFW2U8", "followers": "11", "datetime": "2019-08-16 12:59:09", "author": "@maximkhv"}, "1229418371805929479": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "380", "datetime": "2020-02-17 14:52:35", "author": "@harujoh"}, "1164281316642136064": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "480", "datetime": "2019-08-21 21:01:11", "author": "@P_tan"}, "1163379605937410048": {"content_summary": "RT @bhutanisanyam1: Join us this Saturday, 8PM IST/7:30AM PT for the first KaggleNoobs x @DSNetOrg paper discussion meetup, about the RAdam\u2026", "followers": "247", "datetime": "2019-08-19 09:18:07", "author": "@DSNetOrg"}, "1162268188165341185": {"content_summary": "Let's combat the unstable warmup issues in Adam with *RAdam* (Rectified Adam) by Liyuan Liu et al. Paper: https://t.co/0xAAbmCZCU GitHub: https://t.co/BvILrnc3Py", "followers": "1,703", "datetime": "2019-08-16 07:41:44", "author": "@RisingSayak"}, "1229411880889933825": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "19", "datetime": "2020-02-17 14:26:48", "author": "@MassBassLol"}, "1163278981719740416": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "78", "datetime": "2019-08-19 02:38:16", "author": "@watchdog20xx"}, "1163391105548935168": {"content_summary": "RT @bhutanisanyam1: Join us this Saturday, 8PM IST/7:30AM PT for the first KaggleNoobs x @DSNetOrg paper discussion meetup, about the RAdam\u2026", "followers": "880", "datetime": "2019-08-19 10:03:48", "author": "@RichmanRonald"}, "1162329715455270915": {"content_summary": "https://t.co/766lbHJ4Yf", "followers": "160", "datetime": "2019-08-16 11:46:13", "author": "@Foivos_Diak"}, "1161379527186112513": {"content_summary": "RT @arxiv_org: On the Variance of the Adaptive Learning Rate and Beyond. https://t.co/8x3MNzVR6l https://t.co/GVPm1UhBEy", "followers": "11,914", "datetime": "2019-08-13 20:50:31", "author": "@Rosenchild"}, "1163485322673475585": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "26", "datetime": "2019-08-19 16:18:12", "author": "@tokoton01"}, "1162211735832416256": {"content_summary": "\u8ad6\u6587 https://t.co/kBHvbBKeht", "followers": "80", "datetime": "2019-08-16 03:57:25", "author": "@matsuren7"}, "1162273731365859328": {"content_summary": "New optimizer - underlying idea: High variance is bad. controlled variance using adaptive warm-up throughout training help stabilizing results https://t.co/L5G0Hb96eZ", "followers": "4", "datetime": "2019-08-16 08:03:46", "author": "@oriel_zabar"}, "1163423089004122113": {"content_summary": "RT @bhutanisanyam1: Join us this Saturday, 8PM IST/7:30AM PT for the first KaggleNoobs x @DSNetOrg paper discussion meetup, about the RAdam\u2026", "followers": "3,167", "datetime": "2019-08-19 12:10:54", "author": "@A_K_Nain"}, "1163064971799887872": {"content_summary": "RT @carlolepelaars: @kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: ht\u2026", "followers": "123", "datetime": "2019-08-18 12:27:52", "author": "@sakthigeek"}, "1163028373297356801": {"content_summary": "[1/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 499 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-18 10:02:26", "author": "@PapersTrending"}, "1163752832996204544": {"content_summary": "[1/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 775 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/uKaFmqR7zr", "followers": "220", "datetime": "2019-08-20 10:01:11", "author": "@PapersTrending"}, "1164452709119844352": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "740", "datetime": "2019-08-22 08:22:14", "author": "@vmpmember"}, "1162666251770052608": {"content_summary": "[2/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 404 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-17 10:03:30", "author": "@PapersTrending"}, "1163444662410997761": {"content_summary": "I was at my school's computer lab today and finally tried out the Recitified Adam (RAdam) optimizer. It's so cool! Y'all can stop using RMSProp and Adam for your networks coz this one takes the cake. Amazing job @S2freew and team \ud83d\udc4f\ud83c\udffb\ud83d\udc4f\ud83c\udffb Check it out here: h", "followers": "387", "datetime": "2019-08-19 13:36:37", "author": "@rishabh16_"}, "1237546870483738624": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond. (arXiv:1908.03265v2 [cs.LG] UPDATED) https://t.co/gwvTdZDFFF", "followers": "658", "datetime": "2020-03-11 01:12:21", "author": "@ContinualAI"}, "1164313915175518209": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "196", "datetime": "2019-08-21 23:10:43", "author": "@ogiek_amukawi"}, "1162146842219446272": {"content_summary": "RT @k_un_bike: Radam https://t.co/F9U7sSCqtM blog post https://t.co/qjLquIYELr", "followers": "1,608", "datetime": "2019-08-15 23:39:33", "author": "@syinari0123"}, "1237825991810129920": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmzgwZ", "followers": "3,488", "datetime": "2020-03-11 19:41:28", "author": "@arxiv_cscl"}, "1164332522756382720": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "261", "datetime": "2019-08-22 00:24:40", "author": "@it00960500"}, "1229309368547459072": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "2,432", "datetime": "2020-02-17 07:39:27", "author": "@jinbeizame007"}, "1167014471468027905": {"content_summary": "[4/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,225 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-29 10:01:46", "author": "@PapersTrending"}, "1169898060698112001": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/YVLI3A1Hml #DeepLearning #MachineLearning #ArtificialIntelligence #DataScience #DL #ML #DS #AI #DNN #NeuralNetworks #NLP #GPU #TensorFlow #Keras #Pytorch #Python #HPC #Automation #Autono", "followers": "8,852", "datetime": "2019-09-06 09:00:07", "author": "@Deep_In_Depth"}, "1162992237384368128": {"content_summary": "RAdam Paper: https://t.co/BOP7SgnrZx Keras implementation: https://t.co/UYGdPy7XLH PyTorch implementation: https://t.co/gHKKcUdQrR #DeepLearning #RAdam", "followers": "374", "datetime": "2019-08-18 07:38:51", "author": "@sky0_1"}, "1165541577399443457": {"content_summary": "RAdam--a new optimizer that addresses high variance early in training neural networks. \"On the Variance of the Adaptive Learning Rate and Beyond\" #DataScience https://t.co/O58INnFeiT https://t.co/7OmyHC3wf7", "followers": "121", "datetime": "2019-08-25 08:29:01", "author": "@blaine_bateman"}, "1162731797614125062": {"content_summary": "RT @PapersTrending: [2/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 404 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.c\u2026", "followers": "43", "datetime": "2019-08-17 14:23:57", "author": "@MishakinSergey"}, "1229455298747863040": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "293", "datetime": "2020-02-17 17:19:20", "author": "@chachay"}, "1164334844358385666": {"content_summary": "RT @hillbig: Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive\u2026", "followers": "821", "datetime": "2019-08-22 00:33:53", "author": "@deepgradient"}, "1167207393643638784": {"content_summary": "RT @PapersTrending: [4/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,225 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t\u2026", "followers": "287", "datetime": "2019-08-29 22:48:22", "author": "@dannyehb"}, "1166652192826241024": {"content_summary": "[6/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,197 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-28 10:02:12", "author": "@PapersTrending"}, "1164479542284738562": {"content_summary": "RAdam seems to outperform vanilla Adam most of the time. Take a look if you are looking for more accuracy. @arxiv_org Official paper : https://t.co/WQW39KCORd Unofficial Python implementation : https://t.co/d1zSOVeQzM #DataScience #Python", "followers": "14", "datetime": "2019-08-22 10:08:52", "author": "@Radiant_Data"}, "1238496098324566016": {"content_summary": "@5agado Switching to 'RAdam' (basically, warming up Adam by using a very low LR initially until the per-parameter adjustments are reasonably accurate and the gradients can be trusted) may help: https://t.co/Co4jMrJnSX Not sure how one would do that in Styl", "followers": "20,465", "datetime": "2020-03-13 16:04:14", "author": "@gwern"}, "1163377336647081985": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "1,882", "datetime": "2019-08-19 09:09:06", "author": "@sesquipedale"}, "1163096727307485185": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/ljvUh1ReFI Adam\u306a\u3069\u306e\u9069\u5fdc\u7684\u306a\u6700\u9069\u5316\u624b\u6cd5\u306f\u5b66\u7fd2\u521d\u671f\u306b\u52fe\u914d\u306e\u5206\u6563\u304c\u5927\u304d\u304f\u3001\u305d\u308c\u304c\u5b66\u7fd2\u5f8c\u671f\u306e\u6027\u80fd\u4f4e\u4e0b\u306b\u3064\u306a\u304c\u3063\u3066\u3044\u305f\u3002warmup\u306f\u3053\u308c\u3092\u9632\u3044\u3067\u3044\u305f\u3002\u52fe\u914d\u306e\u5206\u6563\u3092\u6291\u3048\u308bRAdam\u3082\u63d0\u6848\u3057\u3001\u8907\u6570\u306e\u30bf\u30b9\u30af\u3067\u9ad8\u3044\u6027\u80fd\u3092\u767a\u63ee\u3002 https://t.co/j1ZxoHc708", "followers": "2,653", "datetime": "2019-08-18 14:34:03", "author": "@mosko_mule"}, "1161109753960882176": {"content_summary": "RT @arxiv_org: On the Variance of the Adaptive Learning Rate and Beyond. https://t.co/8x3MNzVR6l https://t.co/GVPm1UhBEy", "followers": "24", "datetime": "2019-08-13 02:58:32", "author": "@oyeGopi_"}, "1163431835268812801": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "53", "datetime": "2019-08-19 12:45:39", "author": "@kakeijin"}, "1163285585676533760": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "824", "datetime": "2019-08-19 03:04:31", "author": "@morioka"}, "1164302200916496384": {"content_summary": "RT @hillbig: Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive\u2026", "followers": "1,520", "datetime": "2019-08-21 22:24:11", "author": "@nyker_goto"}, "1168555628538687488": {"content_summary": "RT @hillbig: Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive\u2026", "followers": "14", "datetime": "2019-09-02 16:05:47", "author": "@totti970131"}, "1163108552677871618": {"content_summary": "RT @mosko_mule: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/ljvUh1ReFI Adam\u306a\u3069\u306e\u9069\u5fdc\u7684\u306a\u6700\u9069\u5316\u624b\u6cd5\u306f\u5b66\u7fd2\u521d\u671f\u306b\u52fe\u914d\u306e\u5206\u6563\u304c\u5927\u304d\u304f\u3001\u305d\u308c\u304c\u5b66\u7fd2\u5f8c\u671f\u306e\u6027\u80fd\u2026", "followers": "12,768", "datetime": "2019-08-18 15:21:03", "author": "@jaguring1"}, "1164341511917645825": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "18,316", "datetime": "2019-08-22 01:00:23", "author": "@miyayou"}, "1164284040133763072": {"content_summary": "RT @hillbig: Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive\u2026", "followers": "472", "datetime": "2019-08-21 21:12:01", "author": "@yasuokajihei"}, "1237840899276558338": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmQRox", "followers": "3,488", "datetime": "2020-03-11 20:40:43", "author": "@arxiv_cscl"}, "1252230804731760640": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmzgwZ", "followers": "3,488", "datetime": "2020-04-20 13:41:03", "author": "@arxiv_cscl"}, "1163345379741454336": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "544", "datetime": "2019-08-19 07:02:07", "author": "@1789aorhow"}, "1229339098176864256": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "155", "datetime": "2020-02-17 09:37:35", "author": "@Trtd6Trtd"}, "1229431224654893056": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "1,152", "datetime": "2020-02-17 15:43:40", "author": "@jd_mashiro"}, "1162448444386156544": {"content_summary": "A new optimizer, which I'd like to try soon: RAdam. https://t.co/8C1nk4O2a4", "followers": "138", "datetime": "2019-08-16 19:38:01", "author": "@anne_lauscher"}, "1162142629389225984": {"content_summary": "Radam https://t.co/F9U7sSCqtM blog post https://t.co/qjLquIYELr", "followers": "83", "datetime": "2019-08-15 23:22:49", "author": "@k_un_bike"}, "1165565130811351042": {"content_summary": "[7/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,090 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-25 10:02:36", "author": "@PapersTrending"}, "1163272774388838400": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "12,768", "datetime": "2019-08-19 02:13:36", "author": "@jaguring1"}, "1229310001245642753": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "490", "datetime": "2020-02-17 07:41:58", "author": "@kambarakun"}, "1163275433598525440": {"content_summary": "RT @mosko_mule: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/ljvUh1ReFI Adam\u306a\u3069\u306e\u9069\u5fdc\u7684\u306a\u6700\u9069\u5316\u624b\u6cd5\u306f\u5b66\u7fd2\u521d\u671f\u306b\u52fe\u914d\u306e\u5206\u6563\u304c\u5927\u304d\u304f\u3001\u305d\u308c\u304c\u5b66\u7fd2\u5f8c\u671f\u306e\u6027\u80fd\u2026", "followers": "296", "datetime": "2019-08-19 02:24:10", "author": "@rose_miura"}, "1164284677550567424": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "550", "datetime": "2019-08-21 21:14:33", "author": "@keno_ss"}, "1169911750398865408": {"content_summary": "RT @Deep_In_Depth: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/YVLI3A1Hml #DeepLearning #MachineLearning #Artific\u2026", "followers": "2,464", "datetime": "2019-09-06 09:54:31", "author": "@wiomax_cn"}, "1164798458743513094": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "26", "datetime": "2019-08-23 07:16:08", "author": "@tokoton01"}, "1216124556974403584": {"content_summary": "@TimKietzmann I just meant searching for the optimal learning rate per seed. ADAM is sensitive to the learning rate especially during early epochs of training https://t.co/JYgPAZjSTE", "followers": "53", "datetime": "2020-01-11 22:27:43", "author": "@josephdviviano"}, "1162887636064854017": {"content_summary": "RT @arxiv_org: On the Variance of the Adaptive Learning Rate and Beyond. https://t.co/8x3MNzVR6l https://t.co/GVPm1UhBEy", "followers": "11,914", "datetime": "2019-08-18 00:43:12", "author": "@Rosenchild"}, "1164375473226317826": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "1,834", "datetime": "2019-08-22 03:15:20", "author": "@m_nabu55"}, "1165202582022868992": {"content_summary": "[5/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,076 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-24 10:01:58", "author": "@PapersTrending"}, "1229403173460144128": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "369", "datetime": "2020-02-17 13:52:12", "author": "@ms3rdzone"}, "1166289753668554758": {"content_summary": "[7/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,149 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/A0rM5YMik2", "followers": "220", "datetime": "2019-08-27 10:02:00", "author": "@PapersTrending"}, "1162829232940208128": {"content_summary": "@kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: https://t.co/lbocYKjE5b #DeepLearning #RAdam", "followers": "710", "datetime": "2019-08-17 20:51:08", "author": "@carlolepelaars"}, "1163237121588547585": {"content_summary": "RT @mosko_mule: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/ljvUh1ReFI Adam\u306a\u3069\u306e\u9069\u5fdc\u7684\u306a\u6700\u9069\u5316\u624b\u6cd5\u306f\u5b66\u7fd2\u521d\u671f\u306b\u52fe\u914d\u306e\u5206\u6563\u304c\u5927\u304d\u304f\u3001\u305d\u308c\u304c\u5b66\u7fd2\u5f8c\u671f\u306e\u6027\u80fd\u2026", "followers": "75", "datetime": "2019-08-18 23:51:56", "author": "@RyutaroYamauchi"}, "1229349471277838336": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "126", "datetime": "2020-02-17 10:18:48", "author": "@shimopino"}, "1164280071894343680": {"content_summary": "Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead Optimizer, Novograd\u3068\u4e26\u3073\u4e09\u5f37 https://t.co/daP5lcEROV", "followers": "18,217", "datetime": "2019-08-21 20:56:15", "author": "@hillbig"}, "1237640670371876864": {"content_summary": "https://t.co/djQ9x8TknY On the Variance of the Adaptive Learning Rate and Beyond. (arXiv:1908.03265v2 [cs.LG] UPDATED) #NLProc", "followers": "4,198", "datetime": "2020-03-11 07:25:04", "author": "@arxiv_cs_cl"}, "1164840056235761664": {"content_summary": "[2/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 1,040 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYeXMn - \ud83d\udd17 https://t.co/A0rM5Z3TbA", "followers": "220", "datetime": "2019-08-23 10:01:25", "author": "@PapersTrending"}, "1160758896400580610": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond. https://t.co/fRo2mgrG0z", "followers": "5,454", "datetime": "2019-08-12 03:44:21", "author": "@StatsPapers"}, "1163254887120924672": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "1,762", "datetime": "2019-08-19 01:02:31", "author": "@jaialkdanel"}, "1164284209483018240": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "472", "datetime": "2019-08-21 21:12:41", "author": "@yasuokajihei"}, "1229354273827196930": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "824", "datetime": "2020-02-17 10:37:53", "author": "@morioka"}, "1229444569856499712": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "22", "datetime": "2020-02-17 16:36:42", "author": "@mimic60728077"}, "1163310873215037440": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "497", "datetime": "2019-08-19 04:45:00", "author": "@nagakagachi"}, "1163115268723208192": {"content_summary": "RT @carlolepelaars: @kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: ht\u2026", "followers": "4", "datetime": "2019-08-18 15:47:44", "author": "@Dhinesh_Raja3"}, "1163275062763384832": {"content_summary": "RT @icoxfog417: \u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u2026", "followers": "296", "datetime": "2019-08-19 02:22:42", "author": "@rose_miura"}, "1164283577846026240": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "12,768", "datetime": "2019-08-21 21:10:10", "author": "@jaguring1"}, "1229318941249429504": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "2,049", "datetime": "2020-02-17 08:17:29", "author": "@sei_shinagawa"}, "1237629658688086016": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/a7fXSmzgwZ", "followers": "3,488", "datetime": "2020-03-11 06:41:19", "author": "@arxiv_cscl"}, "1163993692148924417": {"content_summary": "managing the variance esp during warmup seems to have a huge impact on robustness and convergence of Adam https://t.co/vY9Ajz9lUp", "followers": "25", "datetime": "2019-08-21 01:58:16", "author": "@vivekkalyansk"}, "1163534343463165954": {"content_summary": "RT @carlolepelaars: @kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: ht\u2026", "followers": "287", "datetime": "2019-08-19 19:32:59", "author": "@dannyehb"}, "1163475599400296448": {"content_summary": "@rasbt correct link: https://t.co/RpAZLb7fe4", "followers": "69", "datetime": "2019-08-19 15:39:33", "author": "@timobernard"}, "1163379500630994944": {"content_summary": "RT @bhutanisanyam1: Join us this Saturday, 8PM IST/7:30AM PT for the first KaggleNoobs x @DSNetOrg paper discussion meetup, about the RAdam\u2026", "followers": "306", "datetime": "2019-08-19 09:17:42", "author": "@subhobrata1"}, "1163429156845215750": {"content_summary": "Illustration de l'efficacit\u00e9 de RAdam (https://t.co/Ux8h8c3VbL) sur une t\u00e2che de reconnaissance de panneaux routiers. Merci @HongcThng17 pour le notebook ! https://t.co/YLmOSaIjHx", "followers": "70", "datetime": "2019-08-19 12:35:01", "author": "@thomaspeel_"}, "1164391888595537920": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "119", "datetime": "2019-08-22 04:20:34", "author": "@dPVvLRTOLUyhA2C"}, "1163428150833012736": {"content_summary": "\"Rectified Adam\": one less hyperparameter to tune. On the Variance of the Adaptive Learning Rate and Beyond https://t.co/BPqfc3Im5p.", "followers": "791", "datetime": "2019-08-19 12:31:01", "author": "@AISC_TO"}, "1163774137048764417": {"content_summary": "RT @bhutanisanyam1: Join us this Saturday, 8PM IST/7:30AM PT for the first KaggleNoobs x @DSNetOrg paper discussion meetup, about the RAdam\u2026", "followers": "270", "datetime": "2019-08-20 11:25:50", "author": "@kotti_sasikanth"}, "1229528040381640704": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "114", "datetime": "2020-02-17 22:08:23", "author": "@vanTateno"}, "1229315417497190400": {"content_summary": "RT @shion_honda: Rectified Adam [Liu+, 2020, ICLR] Adam\u3084RMSprop\u306e\u5b89\u5b9a\u5316\u306b\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u304c\u5fc5\u8981\u306a\u306e\u306f\u3001\u9069\u5fdc\u7684\u306a\u5b66\u7fd2\u7387\u304c\u5b66\u7fd2\u521d\u671f\u306b\u767a\u6563\u3057\u3084\u3059\u3044\u304b\u3089\u3060\u3068\u7a81\u304d\u6b62\u3081\u305f\u3002\u3055\u3089\u306b\u3001\u5206\u6563\u3092\u8abf\u6574\u3059\u308b\u9805\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\u3001\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u4e0d\u2026", "followers": "3,808", "datetime": "2020-02-17 08:03:29", "author": "@Anthunter1212"}, "1163495820731310080": {"content_summary": "RT @AISC_TO: \"Rectified Adam\": one less hyperparameter to tune. On the Variance of the Adaptive Learning Rate and Beyond https://t.co/BPqfc\u2026", "followers": "821", "datetime": "2019-08-19 16:59:55", "author": "@deepgradient"}, "1169902687732649984": {"content_summary": "RT @Deep_In_Depth: On the Variance of the Adaptive Learning Rate and Beyond https://t.co/YVLI3A1Hml #DeepLearning #MachineLearning #Artific\u2026", "followers": "1,837", "datetime": "2019-09-06 09:18:31", "author": "@gdprAI"}, "1163390758721900544": {"content_summary": "[1/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 576 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/uKaFmqR7zr", "followers": "220", "datetime": "2019-08-19 10:02:26", "author": "@PapersTrending"}, "1161358901436190721": {"content_summary": "RT @arxiv_org: On the Variance of the Adaptive Learning Rate and Beyond. https://t.co/8x3MNzVR6l https://t.co/GVPm1UhBEy", "followers": "66", "datetime": "2019-08-13 19:28:33", "author": "@shubh_300595"}, "1164115246900011008": {"content_summary": "[1/10] \ud83d\udcc8 - On the Variance of the Adaptive Learning Rate and Beyond - 880 \u2b50 - \ud83d\udcc4 https://t.co/BQM6YYwzaX - \ud83d\udd17 https://t.co/uKaFmqR7zr", "followers": "220", "datetime": "2019-08-21 10:01:17", "author": "@PapersTrending"}, "1160712049137205250": {"content_summary": "https://t.co/djQ9x8TknY On the Variance of the Adaptive Learning Rate and Beyond. (arXiv:1908.03265v1 [cs.LG]) #NLProc", "followers": "4,198", "datetime": "2019-08-12 00:38:12", "author": "@arxiv_cs_cl"}, "1163379153862705152": {"content_summary": "Join us this Saturday, 8PM IST/7:30AM PT for the first KaggleNoobs x @DSNetOrg paper discussion meetup, about the RAdam paper: https://t.co/00Rko1jPkv It will be a zoom call (will be recorded), led by @A_K_Nain. All details here: https://t.co/NaI5mKiNbV", "followers": "7,905", "datetime": "2019-08-19 09:16:19", "author": "@bhutanisanyam1"}, "1160770778058678272": {"content_summary": "\"On the Variance of the Adaptive Learning Rate and Beyond\", Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, X\u2026 https://t.co/F4FuqgVrRt", "followers": "767", "datetime": "2019-08-12 04:31:34", "author": "@arxivml"}, "1160710895842070529": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond. (arXiv:1908.03265v1 [cs.LG]) https://t.co/BZXelEuM22", "followers": "9,669", "datetime": "2019-08-12 00:33:37", "author": "@StatMLPapers"}, "1162529446579953664": {"content_summary": "[1908.03265v1] On the Variance of the Adaptive Learning Rate and Beyond RAdam https://t.co/YLnNYthxsG", "followers": "12", "datetime": "2019-08-17 00:59:53", "author": "@AIUEO_Rhythm"}, "1162174983398817792": {"content_summary": "On the Variance of the Adaptive Learning Rate and Beyond https://t.co/qCNkIMYdsY \u8ad6\u6587\u306eURL\u3092\u5fd8\u308c\u3066\u3044\u307e\u3057\u305f", "followers": "1,520", "datetime": "2019-08-16 01:31:22", "author": "@nyker_goto"}, "1164340635085574145": {"content_summary": "RT @hillbig: Adaptive optimizations (e.g., Adam) require warm-up to stabilize the training. They identified the large variance of adaptive\u2026", "followers": "98", "datetime": "2019-08-22 00:56:54", "author": "@treasured_write"}, "1200720727797665792": {"content_summary": "RT @jaguring1: Meta-Learning Update Rules for Unsupervised Representation Learning https://t.co/BJsGsZxbeL On the Variance of the Adaptive\u2026", "followers": "548", "datetime": "2019-11-30 10:18:24", "author": "@FBWM8888"}, "1163118848289099776": {"content_summary": "RT @carlolepelaars: @kaggle RAdam Paper: https://t.co/TWf9oUDKrp Keras implementation: https://t.co/JoV814Uz4A PyTorch implementation: ht\u2026", "followers": "27", "datetime": "2019-08-18 16:01:57", "author": "@mahesh21aug"}, "1164326643730542592": {"content_summary": "RT @hillbig: Adam\u3067\u5b66\u7fd2\u521d\u671f\u3092\u5b89\u5b9a\u5316\u3055\u305b\u308b\u305f\u3081\u306b\u5f90\u3005\u306b\u5b66\u7fd2\u7387\u3092\u3042\u3052\u308bwarmup\u304c\u5fc5\u8981\u306a\u306e\u306f\u5b66\u7fd2\u7387\u3092\u9069\u5fdc\u3055\u305b\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u305f\u3081\u3002\u5206\u6563\u304c\u5c0f\u3055\u304f\u306a\u3063\u305f\u6642\u306b\u81ea\u52d5\u7684\u306b\u9069\u5fdc\u578b\u306b\u3059\u308bRAdam\u3092\u63d0\u6848\u3001warmup\u306a\u3057\u3067\u5b89\u5b9a\u3002\u6700\u9069\u5316\u3067\u306fLookahead\u2026", "followers": "1,667", "datetime": "2019-08-22 00:01:18", "author": "@Scaled_Wurm"}, "1163253680923009024": {"content_summary": "\u7d4c\u9a13\u7684\u306b\u826f\u3044\u3068\u77e5\u3089\u308c\u3066\u3044\u305fWarm-up(\u5b66\u7fd2\u521d\u671f\u3067\u4f4e\u3044\u5b66\u7fd2\u7387\u3092\u4f7f\u7528\u3059\u308b)\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u624b\u6cd5\u3002Adam\u306e\u3088\u3046\u306a\u5b66\u7fd2\u7387\u3092\u81ea\u52d5\u8abf\u6574\u3059\u308b\u624b\u6cd5\u306f\u3001\u5b66\u7fd2\u521d\u671f(=\u307e\u3060\u30b5\u30f3\u30d7\u30eb\u304c\u306a\u3044\u72b6\u614b)\u306e\u8abf\u6574\u3067\u8aa4\u3063\u305f\u65b9\u5411\u306b\u8a98\u5c0e\u3055\u308c\u304c\u3061\u306a\u3053\u3068\u3092\u6307\u6458\u3002\u305d\u3053\u3067\u65b9\u5411(\u52fe\u914d)\u306e\u5206\u6563\u3092\u6291\u3048\u308b\u8abf\u6574\u3092\u5c0e\u5165\u3057\u3066\u3044\u308b https://t.co/4IboZEuplh", "followers": "11,436", "datetime": "2019-08-19 00:57:44", "author": "@icoxfog417"}}}