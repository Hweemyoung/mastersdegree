{"tab": "twitter", "queriedAt": "2020-05-21 20:32:08", "citation_id": "57193517", "twitter": {"1107490707676246021": {"datetime": "2019-03-18 03:55:35", "followers": "628", "author": "@WorldEnder_9001", "content_summary": "Tuning Hyperparameters without Grad Students\u3068\u306a https://t.co/fpyg0KykjE"}, "1107529952470159360": {"datetime": "2019-03-18 06:31:32", "followers": "780", "author": "@arxivml", "content_summary": "\"Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly\", Kirthevas\u2026 https://t.co/ucNEEUWgvF"}, "1160696795988520960": {"datetime": "2019-08-11 23:37:35", "followers": "27", "author": "@KwhRd100", "content_summary": "ChemBO\uff1a\u5408\u6210\u53ef\u80fd\u306a\u63a8\u5968\u4e8b\u9805\u3092\u5099\u3048\u305f\u5c0f\u6709\u6a5f\u5206\u5b50\u306e\u30d9\u30a4\u30ba\u6700\u9069\u5316\u3000\u8457\u66f8\u3089\u306e\u30e9\u30a4\u30d6\u30e9\u30eaDragonfly(https://t.co/lbMFNo68tM)\u3092\u5229\u7528\u3057\u305f\u5408\u6210\u4e88\u6e2c\u56e0\u5b50\u306e\u4fe1\u983c\u6027\u3092\u5411\u4e0a\u3055\u305b\u3001\u5316\u5b66\u7a7a\u9593\u3092\u63a2\u7d22\u3059\u308b\u3088\u308a\u30b9\u30de\u30fc\u30c8\u306a\u65b9\u6cd5\u3002\u8981\u6c42\u3059\u308b\u30c7\u30fc\u30bf\u91cf\u306f\u5c11\u306a\u304f\u3001\u7cbe\u5ea6\u306f\u5148\u884c\u7814\u7a76\u3068\u307b\u307c\u540c\u7b49\u30ec\u30d9\u30eb\u306b\u5230\u9054\u3002https://t.co/ivWd8b2iK2"}, "1107602243275182080": {"datetime": "2019-03-18 11:18:47", "followers": "318", "author": "@arxiv_cs_LG", "content_summary": "Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly. Kandasamy, Vysyaraju, Neiswanger, Paria, Collins, Schneider, Poczos, and Xing https://t.co/fjJ4AjlvaT"}, "1107446945243713536": {"datetime": "2019-03-18 01:01:41", "followers": "61", "author": "@SoEngineering", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/7vwu1jLRtM Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly. (arXiv:1903.06694v1 [https://t.co/7W25u7yuPe])"}, "1107518730718887937": {"datetime": "2019-03-18 05:46:56", "followers": "3,786", "author": "@oulasvirta", "content_summary": "A promising new package for BO: \"Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly\" https://t.co/pHSmBtu71U"}, "1107445879949180928": {"datetime": "2019-03-18 00:57:27", "followers": "628", "author": "@helioRocha_", "content_summary": "\"Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly. (arXiv:1903.06694v1 [https://t.co/rnjY1tRrwN])\" #arXiv https://t.co/8WzRQm1rf5"}, "1107678059434598402": {"datetime": "2019-03-18 16:20:03", "followers": "783", "author": "@muktabh", "content_summary": "RT @arxiv_cs_LG: Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly. Kandasamy, Vysyara\u2026"}, "1108031460055941120": {"datetime": "2019-03-19 15:44:20", "followers": "7,572", "author": "@brandondamos", "content_summary": "Oops, here's a link to their paper: https://t.co/DGah8Wxd4w"}}, "completed": "1"}