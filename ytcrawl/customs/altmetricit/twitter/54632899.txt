{"twitter": {"1090604926076620805": {"author": "@tteofili", "datetime": "2019-01-30 13:37:31", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "688"}, "1090367483972894726": {"author": "@NandoDF", "datetime": "2019-01-29 21:54:00", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "77,162"}, "1090523694873657345": {"author": "@arxiv_in_review", "datetime": "2019-01-30 08:14:44", "content_summary": "#ICML2019 Reward Shaping via Meta-Learning. (arXiv:1901.09330v1 [cs\\.LG]) https://t.co/NBaFtfa7Pn", "followers": "1,310"}, "1090064416769376261": {"author": "@Miles_Brundage", "datetime": "2019-01-29 01:49:44", "content_summary": "\"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "25,873"}, "1090730044765470724": {"author": "@VladimirRybako9", "datetime": "2019-01-30 21:54:42", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "31"}, "1090079465571577856": {"author": "@BrundageBot", "datetime": "2019-01-29 02:49:31", "content_summary": "Reward Shaping via Meta-Learning. Haosheng Zou, Tongzheng Ren, Dong Yan, Hang Su, and Jun Zhu https://t.co/KHSn3Unds0", "followers": "3,890"}, "1090075681415987200": {"author": "@deep_rl", "datetime": "2019-01-29 02:34:29", "content_summary": "Reward Shaping via Meta-Learning - Haosheng Zou https://t.co/Kk15lq4Vtn", "followers": "858"}, "1090183493009559553": {"author": "@PerthMLGroup", "datetime": "2019-01-29 09:42:54", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "456"}, "1091860624856870913": {"author": "@arxiv_pop", "datetime": "2019-02-03 00:47:13", "content_summary": "2019/01/27 \u6295\u7a3f 3\u4f4d LG(Machine Learning) Reward Shaping via Meta-Learning https://t.co/uVX0GNVmc0 5 Tweets 9 Retweets 32 Favorites", "followers": "703"}, "1090208394504531971": {"author": "@arxivml", "datetime": "2019-01-29 11:21:50", "content_summary": "\"Reward Shaping via Meta-Learning\", Haosheng Zou, Tongzheng Ren, Dong Yan, Hang Su, Jun Zhu https://t.co/ww3vdQDYF6", "followers": "779"}, "1090179921345839104": {"author": "@AssistedEvolve", "datetime": "2019-01-29 09:28:42", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "217"}, "1090369199598432256": {"author": "@orlandomr_", "datetime": "2019-01-29 22:00:49", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "45"}, "1090164054390439936": {"author": "@teenvan1995", "datetime": "2019-01-29 08:25:39", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "354"}, "1090176321106337792": {"author": "@andrey_kurenkov", "datetime": "2019-01-29 09:14:24", "content_summary": "Surprising this has not been done before! The comparison to MAML-DQN is unimpressive and eval is quite limited, but still neat.", "followers": "3,416"}, "1090375036559478784": {"author": "@sigitpurnomo", "datetime": "2019-01-29 22:24:01", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "2,663"}, "1090347864398749696": {"author": "@heghbalz", "datetime": "2019-01-29 20:36:03", "content_summary": "RT @Miles_Brundage: \"Reward Shaping via Meta-Learning,\" Zou and Ren et al.: https://t.co/inSt4LODz2", "followers": "1,303"}}, "queriedAt": "2020-05-21 20:20:04", "completed": "1", "citation_id": "54632899", "tab": "twitter"}