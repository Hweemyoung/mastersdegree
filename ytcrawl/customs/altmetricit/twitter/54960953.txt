{"completed": "1", "queriedAt": "2020-06-03 16:09:05", "tab": "twitter", "twitter": {"1092607335170801664": {"followers": "9,746", "datetime": "2019-02-05 02:14:23", "content_summary": "Minmax Optimization: Stable Limit Points of Gradient Descent Ascent are Locally Optimal. (arXiv:1902.00618v1 [cs.LG]) https://t.co/VY1dtuccvM", "author": "@StatMLPapers"}, "1092616346419036160": {"followers": "3,903", "datetime": "2019-02-05 02:50:11", "content_summary": "Minmax Optimization: Stable Limit Points of Gradient Descent Ascent are Locally Optimal. Chi Jin, Praneeth Netrapalli, and Michael I. Jordan https://t.co/FlisEzybie", "author": "@BrundageBot"}, "1092625997831307265": {"followers": "320", "datetime": "2019-02-05 03:28:32", "content_summary": "Minmax Optimization: Stable Limit Points of Gradient Descent Ascent are Locally Optimal. Chi Jin, Praneeth Netrapalli, and Michael I. Jordan https://t.co/Z0dQLwbE7v", "author": "@arxiv_cs_LG"}, "1092742756999593991": {"followers": "783", "datetime": "2019-02-05 11:12:30", "content_summary": "\"Minmax Optimization: Stable Limit Points of Gradient Descent Ascent are Locally Optimal\", Chi Jin, Praneeth Netrap\u2026 https://t.co/ppE7kB1fN6", "author": "@arxivml"}, "1092661485589938182": {"followers": "13", "datetime": "2019-02-05 05:49:33", "content_summary": "RT @StatMLPapers: Minmax Optimization: Stable Limit Points of Gradient Descent Ascent are Locally Optimal. (arXiv:1902.00618v1 [cs.LG]) htt\u2026", "author": "@MarsPlus01"}, "1093287776479375361": {"followers": "45", "datetime": "2019-02-06 23:18:12", "content_summary": "Minmax Optimization: Stable Limit Points of Gradient Descent Ascent are Locally Optimal. (arXiv:1902.00618v1 [cs.LG]) https://t.co/aqDCjoiKP1", "author": "@owltrainlab"}}, "citation_id": "54960953"}