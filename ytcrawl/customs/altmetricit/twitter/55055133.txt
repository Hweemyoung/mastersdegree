{"citation_id": "55055133", "tab": "twitter", "twitter": {"1093325274215780354": {"author": "@helioRocha_", "followers": "628", "datetime": "2019-02-07 01:47:13", "content_summary": "\"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?. (arXiv:1902.02322v1 [cs.LG])\" #arXiv https://t.co/s6IpbrYHTy"}, "1093534739649093632": {"author": "@katanon712", "followers": "642", "datetime": "2019-02-07 15:39:33", "content_summary": "RT @hiromu1996: Abstract\u306bYes or No\u3057\u304b\u66f8\u304b\u306a\u3044\u30bf\u30a4\u30d7\u306e\u5f37\u3044\u3084\u3064 https://t.co/tgDy7cYST8"}, "1095926290043985926": {"author": "@dtsbourg", "followers": "529", "datetime": "2019-02-14 06:02:43", "content_summary": "Abstract game is strong with this one \ud83d\ude4a --- Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples? by Nicolas Carlini https://t.co/A7YllfhnP4 https://t.co/fseTSpnY8N"}, "1093869391333060609": {"author": "@tjmlab", "followers": "3,178", "datetime": "2019-02-08 13:49:20", "content_summary": "RT @hiromu1996: Abstract\u306bYes or No\u3057\u304b\u66f8\u304b\u306a\u3044\u30bf\u30a4\u30d7\u306e\u5f37\u3044\u3084\u3064 https://t.co/tgDy7cYST8"}, "1094569883445018624": {"author": "@shihakata3456", "followers": "8", "datetime": "2019-02-10 12:12:50", "content_summary": "RT @hiromu1996: ICLR 2018\u306eAdversarial Example\u9632\u5fa1\u624b\u6cd5\u3092\u3059\u3050\u306b\u7a81\u7834\u3057\u305f\u30ac\u30c1\u30d7\u30ed\u306e\u4eba\u304c\u3001NeurIPS 2018\u306eSpotlight Paper\u306e\u624b\u6cd5\u304c\u3059\u3050\u306b\u7834\u308c\u308b\u3068\u3044\u3046\u3053\u3068\u3092\u8aac\u660e\u3057\u3066\u3044\u308b https://t.co/WXcRHTzN2u"}, "1093554344253968389": {"author": "@nikitab", "followers": "3,970", "datetime": "2019-02-07 16:57:27", "content_summary": "RT @paul_pearce: Nick Carlini is perhaps my favorite researcher. https://t.co/wmYH2mQ74q https://t.co/Qoe0P35B5E"}, "1093427826504679424": {"author": "@FlorentStorme", "followers": "83", "datetime": "2019-02-07 08:34:43", "content_summary": "un abstract magique : https://t.co/o6g3kM3CLP"}, "1093521837441470465": {"author": "@hiromu1996", "followers": "2,618", "datetime": "2019-02-07 14:48:17", "content_summary": "Abstract\u306bYes or No\u3057\u304b\u66f8\u304b\u306a\u3044\u30bf\u30a4\u30d7\u306e\u5f37\u3044\u3084\u3064 https://t.co/tgDy7cYST8"}, "1196014601982267393": {"author": "@dlowd", "followers": "1,274", "datetime": "2019-11-17 10:37:56", "content_summary": "Great paper by Nicholas Carlini! Title: \"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" Abstract: \"No.\" https://t.co/FYBGX8cKVF"}, "1093525395314536448": {"author": "@sp4ghet", "followers": "986", "datetime": "2019-02-07 15:02:25", "content_summary": "RT @hiromu1996: Abstract\u306bYes or No\u3057\u304b\u66f8\u304b\u306a\u3044\u30bf\u30a4\u30d7\u306e\u5f37\u3044\u3084\u3064 https://t.co/tgDy7cYST8"}, "1095009414963257344": {"author": "@biggiobattista", "followers": "1,251", "datetime": "2019-02-11 17:19:23", "content_summary": "RT @filar: \"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" A one page \"mic drop\" by N. Carlini on why researcher\u2026"}, "1093431327251156992": {"author": "@JMAi1729", "followers": "4", "datetime": "2019-02-07 08:48:38", "content_summary": "https://t.co/XQguF9u3jX"}, "1093528383152103424": {"author": "@djsaunde", "followers": "399", "datetime": "2019-02-07 15:14:17", "content_summary": "RT @BrundageBot: Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?. Nicholas Carlini https://t.co/L99WZ5RNr6"}, "1093381816411660288": {"author": "@ak1010", "followers": "1,088", "datetime": "2019-02-07 05:31:53", "content_summary": "Lol - https://t.co/S0RswsK8sT Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples? - check the abstract - one word. cc @AcademicsSay"}, "1095484524748652544": {"author": "@arxiv_pop", "followers": "699", "datetime": "2019-02-13 00:47:18", "content_summary": "2019/02/06 \u6295\u7a3f 4\u4f4d LG(Machine Learning) Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples? https://t.co/uYYBfJ2QUq 8 Tweets 10 Retweets 32 Favorites"}, "1093353548895662080": {"author": "@moyix", "followers": "6,880", "datetime": "2019-02-07 03:39:34", "content_summary": "RT @BrundageBot: Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?. Nicholas Carlini https://t.co/L99WZ5RNr6"}, "1095204475235692544": {"author": "@drakenberg786", "followers": "61", "datetime": "2019-02-12 06:14:29", "content_summary": "RT @filar: \"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" A one page \"mic drop\" by N. Carlini on why researcher\u2026"}, "1095224053000998913": {"author": "@zangobot", "followers": "144", "datetime": "2019-02-12 07:32:17", "content_summary": "Simple and clean."}, "1095011255851589633": {"author": "@rehakmar", "followers": "334", "datetime": "2019-02-11 17:26:42", "content_summary": "RT @filar: \"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" A one page \"mic drop\" by N. Carlini on why researcher\u2026"}, "1093351623944998913": {"author": "@arxivml", "followers": "774", "datetime": "2019-02-07 03:31:55", "content_summary": "\"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\", Nicholas Carlini https://t.co/if8xeSw7Pc"}, "1093674051359240192": {"author": "@D_Plius", "followers": "1,221", "datetime": "2019-02-08 00:53:07", "content_summary": "RT @hiromu1996: Abstract\u306bYes or No\u3057\u304b\u66f8\u304b\u306a\u3044\u30bf\u30a4\u30d7\u306e\u5f37\u3044\u3084\u3064 https://t.co/tgDy7cYST8"}, "1093598815809138689": {"author": "@stjaco", "followers": "1,356", "datetime": "2019-02-07 19:54:10", "content_summary": "abstract of the year 2019 https://t.co/XvekliTpCa"}, "1095012531335249920": {"author": "@f0rki", "followers": "560", "datetime": "2019-02-11 17:31:46", "content_summary": "RT @filar: \"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" A one page \"mic drop\" by N. Carlini on why researcher\u2026"}, "1093325548506529793": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-07 01:48:18", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/XTGKmoEKYm Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?. (arXiv:1902.02322v1 [cs.LG])"}, "1093716657808109570": {"author": "@jasonmhxue", "followers": "94", "datetime": "2019-02-08 03:42:26", "content_summary": "RT @paul_pearce: Nick Carlini is perhaps my favorite researcher. https://t.co/wmYH2mQ74q https://t.co/Qoe0P35B5E"}, "1093522889813291010": {"author": "@dsk_saito", "followers": "1,328", "datetime": "2019-02-07 14:52:28", "content_summary": "RT @hiromu1996: Abstract\u306bYes or No\u3057\u304b\u66f8\u304b\u306a\u3044\u30bf\u30a4\u30d7\u306e\u5f37\u3044\u3084\u3064 https://t.co/tgDy7cYST8"}, "1094995694744715264": {"author": "@filar", "followers": "1,689", "datetime": "2019-02-11 16:24:52", "content_summary": "\"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" A one page \"mic drop\" by N. Carlini on why researchers should spend more time investigating attack failures before reporting novel defense techniques a success. https://t.co/9877Zr"}, "1196018564676894720": {"author": "@NisansaDdS", "followers": "4,278", "datetime": "2019-11-17 10:53:41", "content_summary": "RT @dlowd: Great paper by Nicholas Carlini! Title: \"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" Abstract: \"No\u2026"}, "1093392305476722688": {"author": "@paul_pearce", "followers": "1,491", "datetime": "2019-02-07 06:13:34", "content_summary": "Nick Carlini is perhaps my favorite researcher. https://t.co/wmYH2mQ74q https://t.co/Qoe0P35B5E"}, "1093868517164691458": {"author": "@ek_ss", "followers": "563", "datetime": "2019-02-08 13:45:52", "content_summary": "RT @hiromu1996: Abstract\u306bYes or No\u3057\u304b\u66f8\u304b\u306a\u3044\u30bf\u30a4\u30d7\u306e\u5f37\u3044\u3084\u3064 https://t.co/tgDy7cYST8"}, "1093522590667161600": {"author": "@Sz4rny", "followers": "1,402", "datetime": "2019-02-07 14:51:16", "content_summary": "RT @takemioIO: https://t.co/txQbcqEEb7 \u300cNO\u300d\u5f37\u3044\u306a\u3053\u306e\u30a2\u30d6\u30b9\u30c8\u30e9\u30af\u30c8\u30fb\u30fb\u30fb"}, "1093522013233270785": {"author": "@cynicalsecurity", "followers": "7,382", "datetime": "2019-02-07 14:48:59", "content_summary": "N. Carlini, \u201cIs AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\u201d [No. (sic, that\u2019s the abstract)] https://t.co/2nRZjp0MBe"}, "1093374222213304321": {"author": "@rajivpoc", "followers": "77", "datetime": "2019-02-07 05:01:43", "content_summary": "Fantastic Abstract source: https://t.co/pAUc76gx6H https://t.co/SZG0an2CFn"}, "1093522461411311616": {"author": "@hiromu1996", "followers": "2,618", "datetime": "2019-02-07 14:50:46", "content_summary": "ICLR 2018\u306eAdversarial Example\u9632\u5fa1\u624b\u6cd5\u3092\u3059\u3050\u306b\u7a81\u7834\u3057\u305f\u30ac\u30c1\u30d7\u30ed\u306e\u4eba\u304c\u3001NeurIPS 2018\u306eSpotlight Paper\u306e\u624b\u6cd5\u304c\u3059\u3050\u306b\u7834\u308c\u308b\u3068\u3044\u3046\u3053\u3068\u3092\u8aac\u660e\u3057\u3066\u3044\u308b"}, "1093341560308224001": {"author": "@BrundageBot", "followers": "3,887", "datetime": "2019-02-07 02:51:55", "content_summary": "Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?. Nicholas Carlini https://t.co/L99WZ5RNr6"}, "1093522378166943744": {"author": "@takemioIO", "followers": "2,224", "datetime": "2019-02-07 14:50:26", "content_summary": "https://t.co/txQbcqEEb7 \u300cNO\u300d\u5f37\u3044\u306a\u3053\u306e\u30a2\u30d6\u30b9\u30c8\u30e9\u30af\u30c8\u30fb\u30fb\u30fb"}, "1093625234660487171": {"author": "@manlius84", "followers": "3,567", "datetime": "2019-02-07 21:39:09", "content_summary": "RT @stjaco: abstract of the year 2019 https://t.co/XvekliTpCa"}, "1093351848436592640": {"author": "@poolio", "followers": "7,580", "datetime": "2019-02-07 03:32:48", "content_summary": "Nicholas Carlini doing the difficult and important work to keep the adversarial defenses community honest. Great abstract too :)"}, "1095029554660499459": {"author": "@dlowd", "followers": "1,274", "datetime": "2019-02-11 18:39:25", "content_summary": "RT @filar: \"Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?\" A one page \"mic drop\" by N. Carlini on why researcher\u2026"}}, "completed": "1", "queriedAt": "2020-06-03 00:54:31"}