{"citation_id": "20919561", "queriedAt": "2020-05-09 13:18:55", "completed": "0", "twitter": {"1235643132978417664": {"followers": "2,102", "content_summary": "@Ozan__Caglayan Yup! With bigger batch sizes you have more accurate estimates of the gradient. So you can take more aggressive steps and converge faster. That is the key idea behind a lot of the scaling papers e.g., https://t.co/aF2rrkpNEL, https://t.co/Ya", "author": "@Eric_Wallace_", "datetime": "2020-03-05 19:07:34"}, "1243485686986166275": {"followers": "12", "content_summary": "RT @mrdbourke: Day 33/42 replicating @AirbnbEng's amenity detection: 2 final experiments w/ 10% of data. 1. Train with transfer learning\u2026", "author": "@paganim_", "datetime": "2020-03-27 10:31:05"}, "1243475642290601984": {"followers": "2,610", "content_summary": "Day 33/42 replicating @AirbnbEng's amenity detection: 2 final experiments w/ 10% of data. 1. Train with transfer learning 2. Train from scratch Also learned a bunch about linear learning rate scaling: https://t.co/h1pvOzATsX Next: - Train a model with", "author": "@mrdbourke", "datetime": "2020-03-27 09:51:10"}, "1225750175303356416": {"followers": "13", "content_summary": "\u30df\u30cb\u30d0\u30c3\u30c1\u3068\u5b66\u7fd2\u4fc2\u6570\u3092\u7dda\u5f62\u306b\u5897\u3084\u3057\u3066\u5b66\u7fd2\u3057\u3001Validation\u3067\u30a8\u30e9\u30fc\u7387\u3092\u8a55\u4fa1\u3002\u30df\u30cb\u30d0\u30c3\u30c1\u65708000\u307e\u3067\u306f\u30a8\u30e9\u30fc\u7387\u304c\u4e00\u5b9a\u306b MultiGPU\u4f7f\u3046\u3068\u304d\u306f\u5b66\u7fd2\u4fc2\u6570\u3092\u7dda\u5f62\u306b\u5897\u3084\u305b\u3070\u826f\u3055\u305d\u3046 https://t.co/TKCKwxs86N https://t.co/gL4l0CnSP0", "author": "@poasc_f", "datetime": "2020-02-07 11:56:29"}}, "tab": "twitter"}