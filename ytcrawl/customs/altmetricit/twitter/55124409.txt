{"citation_id": "55124409", "tab": "twitter", "twitter": {"1223154752109907970": {"author": "@helioRocha_", "followers": "622", "datetime": "2020-01-31 08:03:12", "content_summary": "\"Bayesian Reinforcement Learning via Deep, Sparse Sampling. (arXiv:1902.02661v3 [cs.LG] UPDATED)\" #arXiv https://t.co/Ljbs9rld6K"}, "1093731491459354629": {"author": "@arxivml", "followers": "769", "datetime": "2019-02-08 04:41:22", "content_summary": "\"Deeper & Sparser Exploration\", Divya Grover, Christos Dimitrakakis https://t.co/FecdpXkbsm"}, "1093701895749799936": {"author": "@deep_rl", "followers": "852", "datetime": "2019-02-08 02:43:46", "content_summary": "Deeper & Sparser Exploration - Divya Grover https://t.co/kRaACAOUIg"}, "1184632403656089600": {"author": "@helioRocha_", "followers": "622", "datetime": "2019-10-17 00:49:09", "content_summary": "\"Deeper & Sparser Exploration. (arXiv:1902.02661v2 [cs.LG] UPDATED)\" #arXiv https://t.co/Ljbs9rld6K"}, "1093689017399459840": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-08 01:52:36", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/5C1WONYrZy Deeper & Sparser Exploration. (arXiv:1902.02661v1 [cs.LG])"}, "1223169685363011586": {"author": "@pm_girl", "followers": "2,168", "datetime": "2020-01-31 09:02:33", "content_summary": "#Bayesian Reinforcement Learning via Deep, Sparse Sampling. (arXiv:1902.02661v3 [cs.LG] UPDATED) https://t.co/LoBlaQRpE5 #artificialintelligence #ai"}, "1093689189873389568": {"author": "@StatMLPapers", "followers": "9,641", "datetime": "2019-02-08 01:53:17", "content_summary": "Deeper & Sparser Exploration. (arXiv:1902.02661v1 [cs.LG]) https://t.co/GTfTNV386D"}, "1223208623549177856": {"author": "@gastronomy", "followers": "1,391", "datetime": "2020-01-31 11:37:16", "content_summary": "[arXiv] Bayesian Reinforcement Learning via Deep, Sparse Sampling. (arXiv:1902.02661v3 [cs.LG] UPDATED) --> We address the problem of Bayesian reinforcement learning using efficient model-based online planning. We propose an optimism-free Bayes-adaptiv"}, "1094410773525278720": {"author": "@owltrainlab", "followers": "42", "datetime": "2019-02-10 01:40:36", "content_summary": "Deeper & Sparser Exploration. (arXiv:1902.02661v1 [cs.LG]) https://t.co/qsiHx9JK3Q #papers- ai #ml #feedly"}, "1093702933433204736": {"author": "@BrundageBot", "followers": "3,837", "datetime": "2019-02-08 02:47:54", "content_summary": "Deeper & Sparser Exploration. Divya Grover and Christos Dimitrakakis https://t.co/vnY6dQHFT1"}, "1184632439001497600": {"author": "@pm_girl", "followers": "2,168", "datetime": "2019-10-17 00:49:17", "content_summary": "#Deeper & Sparser Exploration. (arXiv:1902.02661v2 [cs.LG] UPDATED) https://t.co/LoBlaQRpE5 #artificialintelligence #ai"}, "1184631917037215744": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-10-17 00:47:13", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/aoF7d7b4XF Deeper & Sparser Exploration. (arXiv:1902.02661v2 [cs.LG] UPDATED)"}, "1093786822340169728": {"author": "@gastronomy", "followers": "1,391", "datetime": "2019-02-08 08:21:14", "content_summary": "[arXiv] Deeper & Sparser Exploration. (arXiv:1902.02661v1 [cs.LG]) --> We address the problem of efficient exploration by proposing a new meta algorithm in the context of model-based online planning for Bayesian Reinforcement Learning (BRL). We bea"}}, "completed": "1", "queriedAt": "2020-06-03 00:56:34"}