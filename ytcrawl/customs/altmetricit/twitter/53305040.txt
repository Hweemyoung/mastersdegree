{"citation_id": "53305040", "tab": "twitter", "completed": "1", "queriedAt": "2020-05-14 15:38:32", "twitter": {"1165226021219655680": {"followers": "740", "datetime": "2019-08-24 11:35:06", "author": "@JoaoVictor_AC", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165258046030745600": {"followers": "437", "datetime": "2019-08-24 13:42:22", "author": "@grousselle", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180657778844504066": {"followers": "1,262", "datetime": "2019-10-06 01:35:24", "author": "@da_masu", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165220745892356097": {"followers": "569", "datetime": "2019-08-24 11:14:09", "author": "@EscalateAdvisor", "content_summary": "\u201cIn this paper, we bridge the two regimes by exhibiting a new \"double descent\" risk curve that extends the traditional U-shaped bias-variance curve beyond the point of interpolation....\u201d https://t.co/oC54E88jlz"}, "1165483904805089286": {"followers": "169", "datetime": "2019-08-25 04:39:51", "author": "@2010T2020", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167834438274670594": {"followers": "43", "datetime": "2019-08-31 16:20:02", "author": "@oseose_11", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166420656222695424": {"followers": "6,010", "datetime": "2019-08-27 18:42:10", "author": "@michaellgraves", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1199001045378035712": {"followers": "78", "datetime": "2019-11-25 16:25:00", "author": "@warren_k_miller", "content_summary": "ICYMI: This is an incredible result in the world of machine learning. It suggests that in many cases, models that fit a curve straight through all your data points could be better than ones that try to find a true representation. Very counterintuitive and"}, "1081485775722577921": {"followers": "235", "datetime": "2019-01-05 09:41:16", "author": "@yenhuan_li", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1165480969949736962": {"followers": "23", "datetime": "2019-08-25 04:28:11", "author": "@deehzee", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167756696078278657": {"followers": "56", "datetime": "2019-08-31 11:11:06", "author": "@haru_256", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165529554217103360": {"followers": "65", "datetime": "2019-08-25 07:41:14", "author": "@kli_nlpr", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1164967300966969345": {"followers": "813", "datetime": "2019-08-23 18:27:03", "author": "@SurgeBiswas", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165213997152518144": {"followers": "4,812", "datetime": "2019-08-24 10:47:20", "author": "@IntuitMachine", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166516401315692551": {"followers": "198", "datetime": "2019-08-28 01:02:37", "author": "@HaoTan5", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165272985353281536": {"followers": "405", "datetime": "2019-08-24 14:41:44", "author": "@guru_radhakr", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165287755334725632": {"followers": "22", "datetime": "2019-08-24 15:40:25", "author": "@kinsellaraymond", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165537310039035904": {"followers": "37", "datetime": "2019-08-25 08:12:04", "author": "@manuelschmidt90", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165185398273765378": {"followers": "304", "datetime": "2019-08-24 08:53:41", "author": "@ahmaddarkisc", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1186531793186500608": {"followers": "8,290", "datetime": "2019-10-22 06:36:38", "author": "@SantchiWeb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1145035607149694977": {"followers": "275", "datetime": "2019-06-29 18:25:37", "author": "@sdachen", "content_summary": "Yikes... https://t.co/wtgmTPMG4L https://t.co/SyyqMNVFxH"}, "1165389538270883840": {"followers": "24", "datetime": "2019-08-24 22:24:52", "author": "@nikoz_kar", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166485048284999680": {"followers": "392", "datetime": "2019-08-27 22:58:02", "author": "@HanGuo97", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165273490766880768": {"followers": "200", "datetime": "2019-08-24 14:43:44", "author": "@aesuli", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180714315482943488": {"followers": "113", "datetime": "2019-10-06 05:20:04", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj <2/4>... for small N, adding more features yields improvements in both the training and test risks. ...#nextAI https://t.co/6gbHDQ0Oru"}, "1165378742543249408": {"followers": "3", "datetime": "2019-08-24 21:41:58", "author": "@their_r", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166397108120952832": {"followers": "297", "datetime": "2019-08-27 17:08:35", "author": "@johnjnay", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168482094072377345": {"followers": "111", "datetime": "2019-09-02 11:13:35", "author": "@alsombra7", "content_summary": "RT @francoisfleuret: So is the idea in Belkin's paper simply that when the training error is zero and you increase your model space, you ca\u2026"}, "1194149884825391104": {"followers": "86", "datetime": "2019-11-12 07:08:13", "author": "@NikosNi41644559", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1168720312701087745": {"followers": "2,945", "datetime": "2019-09-03 03:00:10", "author": "@PierreAlquier", "content_summary": "RT @francoisfleuret: So is the idea in Belkin's paper simply that when the training error is zero and you increase your model space, you ca\u2026"}, "1165583423756480512": {"followers": "335", "datetime": "2019-08-25 11:15:18", "author": "@tailcalled", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166396304236273664": {"followers": "107", "datetime": "2019-08-27 17:05:24", "author": "@sdemyanov", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166168884384169984": {"followers": "914", "datetime": "2019-08-27 02:01:43", "author": "@ougai_quantum", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166340179746967552": {"followers": "22", "datetime": "2019-08-27 13:22:23", "author": "@kh20190129", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1081541081546805248": {"followers": "7,670", "datetime": "2019-01-05 13:21:02", "author": "@KyleCranmer", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1166390267865268224": {"followers": "640", "datetime": "2019-08-27 16:41:24", "author": "@copasta_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165410696605175810": {"followers": "134", "datetime": "2019-08-24 23:48:57", "author": "@alvinjamur", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165274954339733504": {"followers": "459", "datetime": "2019-08-24 14:49:33", "author": "@dolhani", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1193986166011375617": {"followers": "229", "datetime": "2019-11-11 20:17:39", "author": "@AmartyaSanyal", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166723296357830657": {"followers": "830", "datetime": "2019-08-28 14:44:45", "author": "@miguelEmendoza", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165413035093061632": {"followers": "320", "datetime": "2019-08-24 23:58:14", "author": "@microsurgeonbot", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off \"...boosting with decision trees and Random Forests also show similar generalization behavior as neural nets, both before and after the interpolation threshold\" https://t.co/ScEMOufGIO #"}, "1166157832577867778": {"followers": "5", "datetime": "2019-08-27 01:17:48", "author": "@elvcastelo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166352110264471553": {"followers": "14", "datetime": "2019-08-27 14:09:47", "author": "@Rena65723423", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1204514695782137856": {"followers": "477", "datetime": "2019-12-10 21:34:16", "author": "@yasuokajihei", "content_summary": "RT @hillbig: The bias-variance tradeoff shows that a model with appropriate complexity can generalize. Recent \"double descent\" indicates th\u2026"}, "1198307993244311552": {"followers": "238", "datetime": "2019-11-23 18:31:03", "author": "@jairo_luciano", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165653995366572032": {"followers": "382", "datetime": "2019-08-25 15:55:43", "author": "@jan_gemert", "content_summary": "Is deep learning falling outside the bias-variance curve a rediscovery of the 'peaking phenomenon'? https://t.co/CEL1dmWAjL"}, "1165022421377642496": {"followers": "7,299", "datetime": "2019-08-23 22:06:04", "author": "@punkstrategy", "content_summary": "Love this and you should to"}, "1165337791322120193": {"followers": "552", "datetime": "2019-08-24 18:59:15", "author": "@markjwebb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180770663507775489": {"followers": "224", "datetime": "2019-10-06 09:03:58", "author": "@ElectronNest", "content_summary": "RT @hillbig: The bias-variance tradeoff shows that a model with appropriate complexity can generalize. Recent \"double descent\" indicates th\u2026"}, "1168124220389429249": {"followers": "18", "datetime": "2019-09-01 11:31:31", "author": "@saint_armadillo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165370279918481408": {"followers": "922", "datetime": "2019-08-24 21:08:20", "author": "@Visionscaper", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166365963471613952": {"followers": "406", "datetime": "2019-08-27 15:04:50", "author": "@factor_null", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165226847807909888": {"followers": "7,210", "datetime": "2019-08-24 11:38:24", "author": "@fastml_extra", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1186635691637252096": {"followers": "736", "datetime": "2019-10-22 13:29:30", "author": "@unsorsodicorda", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168516429525729280": {"followers": "24", "datetime": "2019-09-02 13:30:01", "author": "@organazized", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165074814379278337": {"followers": "455", "datetime": "2019-08-24 01:34:16", "author": "@SingingData", "content_summary": "@noodlefrenzy"}, "1165223587126697989": {"followers": "768", "datetime": "2019-08-24 11:25:26", "author": "@Footballpurism", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165021500891521025": {"followers": "1,244", "datetime": "2019-08-23 22:02:25", "author": "@shaohua0116", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165480210608689152": {"followers": "18", "datetime": "2019-08-25 04:25:10", "author": "@tuanpt93", "content_summary": "https://t.co/IQL2nN9Gp6"}, "1079569920768253952": {"followers": "3,881", "datetime": "2018-12-31 02:48:21", "author": "@BrundageBot", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off. Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal https://t.co/ZG72jtTqRD"}, "1165564456102854656": {"followers": "83", "datetime": "2019-08-25 09:59:56", "author": "@s_daptardar", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166162597042737152": {"followers": "142", "datetime": "2019-08-27 01:36:44", "author": "@PrimevalControl", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166326321766707200": {"followers": "1,208", "datetime": "2019-08-27 12:27:19", "author": "@ta_makino", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165402748004839424": {"followers": "217", "datetime": "2019-08-24 23:17:21", "author": "@diegogaleano05", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165397583537364992": {"followers": "277", "datetime": "2019-08-24 22:56:50", "author": "@guangleicui", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165222512072040449": {"followers": "1,528", "datetime": "2019-08-24 11:21:10", "author": "@AnalyticsFr", "content_summary": "Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff: https://t.co/Kr2uVFwIgu The \"bias-variance\" you knew was just the first piece of the story! https://t."}, "1165043600356499461": {"followers": "57", "datetime": "2019-08-23 23:30:14", "author": "@nasty_haterz", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166206834786689024": {"followers": "9", "datetime": "2019-08-27 04:32:31", "author": "@iamx9000", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166187431692881921": {"followers": "196", "datetime": "2019-08-27 03:15:25", "author": "@gatheluck", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165284590920982528": {"followers": "40", "datetime": "2019-08-24 15:27:51", "author": "@pktippa", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1202961565257027584": {"followers": "477", "datetime": "2019-12-06 14:42:41", "author": "@jmsl", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1166304572492484608": {"followers": "345", "datetime": "2019-08-27 11:00:53", "author": "@enj0u", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166180741476048896": {"followers": "147", "datetime": "2019-08-27 02:48:50", "author": "@lilacs777a", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1128264954233196544": {"followers": "27", "datetime": "2019-05-14 11:45:01", "author": "@Mxbonn", "content_summary": "Interesting seminar by Prof. Padhraic Smyth about the connections between statistics and deep learning. Especially the part about deep networks being miscalibrated (https://t.co/nH1aTuuN0N) and \"Double Descent\" theory (https://t.co/cW33WgF1cE). https://t."}, "1165738900456902656": {"followers": "111", "datetime": "2019-08-25 21:33:06", "author": "@ogustavo_com", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180847341416271872": {"followers": "221", "datetime": "2019-10-06 14:08:39", "author": "@kog", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1180694572726288384": {"followers": "1,312", "datetime": "2019-10-06 04:01:37", "author": "@tsubosaka", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1180770699700342784": {"followers": "1,876", "datetime": "2019-10-06 09:04:07", "author": "@sesquipedale", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1167653227153645568": {"followers": "875", "datetime": "2019-08-31 04:19:57", "author": "@pineplaaaain", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166885076807929856": {"followers": "358", "datetime": "2019-08-29 01:27:36", "author": "@JFernandoGRE", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165142098561118208": {"followers": "1,634", "datetime": "2019-08-24 06:01:38", "author": "@markomanka", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180774017977876482": {"followers": "1,195", "datetime": "2019-10-06 09:17:18", "author": "@hrs1985", "content_summary": "@yuuna_tu https://t.co/dQZWCOWuca \u305d\u308c\u306f\u3053\u3063\u3061\u3078\u306e\u30b3\u30e1\u30f3\u30c8\u3067\u3059\u306d\u2026\u2026\u3002 \u307e\u3042\u3001\u591a\u5206\u305d\u308c\u306f\u305d\u3046\u306a\u306e\u304b\u306a\uff1f\u3000\u3061\u3083\u3093\u3068\u30c7\u30fc\u30bf\u898b\u3066\u307f\u306a\u3044\u3068\u308f\u304b\u3089\u306a\u3044\u3067\u3059\u304c\u3002"}, "1166197238718009344": {"followers": "147", "datetime": "2019-08-27 03:54:23", "author": "@skawagt", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165569958299848704": {"followers": "2,043", "datetime": "2019-08-25 10:21:47", "author": "@imenurok", "content_summary": "RT @nyker_goto: Deep \u306f\u53e4\u5178\u7684\u306a\u30d0\u30a4\u30a2\u30b9\u30d0\u30ea\u30a2\u30f3\u30b9\u306e\u8b70\u8ad6\u304c\u901a\u3058\u306a\u3044\u3063\u3066\u3044\u3046\u306e\u306f\u8074\u3044\u305f\u3053\u3068\u3042\u3063\u305f\u3051\u3069\u3001\u305d\u308c\u4ee5\u5916\u306e\u30e2\u30c7\u30eb\u3001\u4f8b\u3048\u3070\u8ad6\u6587\u4e2d\u306a\u3089RandomForest\u3067\u3082 Over Parameterized \u306a\u30e2\u30c7\u30eb\u306e\u307b\u3046\u304c\u6027\u80fd\u826f\u304f\u306a\u308b\u30dd\u30a4\u30f3\u30c8\u304c\u3042\u308b\u306e\u3001\u304a\u3082\u308d\u3044\u306a\u2026"}, "1202664578578030592": {"followers": "449", "datetime": "2019-12-05 19:02:34", "author": "@michalwols", "content_summary": "RT @wojczarnecki: @ilyasut By unnoticed you mean published for just a year?https://t.co/MJtP0s3Qd4"}, "1166158520460271618": {"followers": "344", "datetime": "2019-08-27 01:20:32", "author": "@i_za_world360", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1193865939651121152": {"followers": "73", "datetime": "2019-11-11 12:19:55", "author": "@adn_twitts", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1167669693022449665": {"followers": "313", "datetime": "2019-08-31 05:25:23", "author": "@auctumrem", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165175969222680582": {"followers": "299", "datetime": "2019-08-24 08:16:13", "author": "@Jaimezorno", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180842103628156928": {"followers": "4,311", "datetime": "2019-10-06 13:47:51", "author": "@ibaibabaibai", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165390430437105666": {"followers": "165", "datetime": "2019-08-24 22:28:25", "author": "@kirthifame", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165246359345291264": {"followers": "88", "datetime": "2019-08-24 12:55:55", "author": "@guilhermefickel", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165524806311305216": {"followers": "4,371", "datetime": "2019-08-25 07:22:22", "author": "@nopiedra", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166008679855865856": {"followers": "169", "datetime": "2019-08-26 15:25:07", "author": "@motor_ai", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180737133826527232": {"followers": "3,018", "datetime": "2019-10-06 06:50:44", "author": "@cd_fuller", "content_summary": "RT @SHIMOMURATakuji: https://t.co/FFXHsebuhj We first consider a popular class of non-linear parametric models called Random Fourier Featur\u2026"}, "1166760833818517506": {"followers": "6", "datetime": "2019-08-28 17:13:54", "author": "@Kara92809573", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165080663168622592": {"followers": "2,686", "datetime": "2019-08-24 01:57:30", "author": "@unbalancedparen", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1205548437443231745": {"followers": "225", "datetime": "2019-12-13 18:02:00", "author": "@ScotsRecreation", "content_summary": "Good point"}, "1166661575035408386": {"followers": "121", "datetime": "2019-08-28 10:39:29", "author": "@justaro", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165667634559561731": {"followers": "63", "datetime": "2019-08-25 16:49:55", "author": "@kuanchen22", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165318145743216640": {"followers": "1,639", "datetime": "2019-08-24 17:41:11", "author": "@AnalyticsFrance", "content_summary": "Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff: https://t.co/uXvwUE9COg  The \"bias-variance\" you knew was just the first piece of the story!https://t"}, "1180992298236051457": {"followers": "238", "datetime": "2019-10-06 23:44:40", "author": "@Jean_Coc_Teau", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1164966017635954688": {"followers": "2,603", "datetime": "2019-08-23 18:21:57", "author": "@AdamMarblestone", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1191547620738682880": {"followers": "3", "datetime": "2019-11-05 02:47:45", "author": "@FrankPreiswerk", "content_summary": "@VisionBernie https://t.co/uYsCqVgYp2"}, "1166295453442433025": {"followers": "792", "datetime": "2019-08-27 10:24:39", "author": "@rushworth_a", "content_summary": "RT @orestistsinalis: Very interesting paper with empirical observations of \"double descent\"/two-regime behaviour in test performance of com\u2026"}, "1165221860839059457": {"followers": "16", "datetime": "2019-08-24 11:18:35", "author": "@LeowYao", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165008092930682885": {"followers": "771", "datetime": "2019-08-23 21:09:08", "author": "@karlhigley", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165405137990369280": {"followers": "215", "datetime": "2019-08-24 23:26:51", "author": "@jbowayles", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166697334505230336": {"followers": "735", "datetime": "2019-08-28 13:01:35", "author": "@Nate__Haines", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1206288753553223680": {"followers": "125", "datetime": "2019-12-15 19:03:45", "author": "@boringsegfault", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1165383045651808256": {"followers": "1,575", "datetime": "2019-08-24 21:59:04", "author": "@pacoramon", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1172210572437245952": {"followers": "948", "datetime": "2019-09-12 18:09:13", "author": "@0xNikhilRathor", "content_summary": "RT @halvarflake: To my great surprise, I found a few minutes of downtime today to read https://t.co/Y4GyQx1XeQ. If you are into ML or stati\u2026"}, "1202892830923837440": {"followers": "6,183", "datetime": "2019-12-06 10:09:34", "author": "@adhara_mathphys", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1187594761223340033": {"followers": "4,130", "datetime": "2019-10-25 05:00:30", "author": "@hayashiyus", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165290581792215041": {"followers": "1,857", "datetime": "2019-08-24 15:51:39", "author": "@MattChallacombe", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167680225242734593": {"followers": "247", "datetime": "2019-08-31 06:07:14", "author": "@KazuyaUjihara", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165281906860220416": {"followers": "907", "datetime": "2019-08-24 15:17:11", "author": "@oluies", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165328401462439939": {"followers": "116", "datetime": "2019-08-24 18:21:56", "author": "@TeddyAmpian", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180691444828258304": {"followers": "2,610", "datetime": "2019-10-06 03:49:11", "author": "@0_u0", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1259415099615281152": {"followers": "5", "datetime": "2020-05-10 09:28:53", "author": "@aman_karra", "content_summary": "@Cofre24 @PhysSophia @gabrielpeyre @QasimMP A work that I came across recently that seems to shed more light on this: https://t.co/BzoOm0dFgt"}, "1165501290203484160": {"followers": "3", "datetime": "2019-08-25 05:48:56", "author": "@imcs_dl", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1193863110118871044": {"followers": "186", "datetime": "2019-11-11 12:08:41", "author": "@NoSyu", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165572799232008194": {"followers": "7,108", "datetime": "2019-08-25 10:33:05", "author": "@rahulk_p", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180855908454133760": {"followers": "56", "datetime": "2019-10-06 14:42:42", "author": "@haru_256", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1206287727173537806": {"followers": "7,444", "datetime": "2019-12-15 18:59:40", "author": "@o_guest", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1180652586417868802": {"followers": "2,067", "datetime": "2019-10-06 01:14:46", "author": "@yo_ehara", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165309993341595649": {"followers": "63", "datetime": "2019-08-24 17:08:47", "author": "@justinptompkins", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165250348900114433": {"followers": "169", "datetime": "2019-08-24 13:11:47", "author": "@Maryorquin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165266820179402753": {"followers": "103", "datetime": "2019-08-24 14:17:14", "author": "@urosn", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165363477533343744": {"followers": "480", "datetime": "2019-08-24 20:41:19", "author": "@Pablogomez3", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180685952684974080": {"followers": "2,290", "datetime": "2019-10-06 03:27:21", "author": "@fronori", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165285099400679426": {"followers": "7,738", "datetime": "2019-08-24 15:29:52", "author": "@geomblog", "content_summary": "This paper makes very interesting claims. Definitely thought provoking."}, "1165290496257925120": {"followers": "28", "datetime": "2019-08-24 15:51:19", "author": "@a_fequi", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166900616498733056": {"followers": "611", "datetime": "2019-08-29 02:29:21", "author": "@thouis", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165256423267287041": {"followers": "332", "datetime": "2019-08-24 13:35:55", "author": "@pabloibieta", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167764347709534209": {"followers": "239", "datetime": "2019-08-31 11:41:31", "author": "@chiefaiofficers", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166415522113761286": {"followers": "340", "datetime": "2019-08-27 18:21:46", "author": "@Cedias_", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166159437637115904": {"followers": "220", "datetime": "2019-08-27 01:24:10", "author": "@NorikazuYamada", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165392753368403968": {"followers": "263", "datetime": "2019-08-24 22:37:39", "author": "@beedotkiran", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165715002730385414": {"followers": "33,955", "datetime": "2019-08-25 19:58:09", "author": "@montrealdotai", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165315410289405952": {"followers": "210", "datetime": "2019-08-24 17:30:18", "author": "@daniwi79", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165033399117070337": {"followers": "35", "datetime": "2019-08-23 22:49:42", "author": "@jahmerican876", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180650946453356545": {"followers": "113", "datetime": "2019-10-06 01:08:15", "author": "@SHIMOMURATakuji", "content_summary": "This connection between the performance and the structure of machine learning models delineates the limits of classical analyses, and has implications for both the theory and practice of machine learning."}, "1180851663231275008": {"followers": "177", "datetime": "2019-10-06 14:25:50", "author": "@meshidenn", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165252681017040896": {"followers": "37", "datetime": "2019-08-24 13:21:03", "author": "@Caaaaatherinehy", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1081561394947022850": {"followers": "137", "datetime": "2019-01-05 14:41:45", "author": "@LucaFabbrini", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1166157628185014272": {"followers": "81,553", "datetime": "2019-08-27 01:16:59", "author": "@hardmaru", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165156979876212737": {"followers": "5,874", "datetime": "2019-08-24 07:00:46", "author": "@alfcnz", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165579982837637121": {"followers": "118", "datetime": "2019-08-25 11:01:37", "author": "@matthewopala", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166318890772619265": {"followers": "17", "datetime": "2019-08-27 11:57:47", "author": "@eDndnXFgorVN9Xe", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165622144895553536": {"followers": "401", "datetime": "2019-08-25 13:49:10", "author": "@AixinSG", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165345209229557760": {"followers": "664", "datetime": "2019-08-24 19:28:43", "author": "@crude2refined", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165222403884113920": {"followers": "136", "datetime": "2019-08-24 11:20:44", "author": "@norvid_studies", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1180548679238914049": {"followers": "1,859", "datetime": "2019-10-05 18:21:53", "author": "@planarrowspace", "content_summary": "RT @KameronDHarris: Check out this paper: \"Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off\" by Mikha\u2026"}, "1165246076619755526": {"followers": "125", "datetime": "2019-08-24 12:54:48", "author": "@boringsegfault", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165508084879495168": {"followers": "102", "datetime": "2019-08-25 06:15:56", "author": "@drChromiak", "content_summary": "#Ml #DeepLearning"}, "1165519882064187392": {"followers": "42", "datetime": "2019-08-25 07:02:48", "author": "@MishakinSergey", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165104025311666176": {"followers": "95", "datetime": "2019-08-24 03:30:20", "author": "@chiaolun", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166201623812743169": {"followers": "2,409", "datetime": "2019-08-27 04:11:48", "author": "@kdpsinghlab", "content_summary": "The \u201cdouble-descent\u201d observed in this paper doesn\u2019t make any sense to me intuitively. As model complexity increases (\u2b07\ufe0fEPV), out-of-sample performance worsens then improves for neural nets and RFs? Why? https://t.co/0LH1vMcIFc"}, "1202961633301151745": {"followers": "767", "datetime": "2019-12-06 14:42:57", "author": "@johndburger", "content_summary": "@CGCooke @OpenAI What's interesting is that Belkin has show this phenomenon occurs even in \"shallow\" learners. https://t.co/QWnGxx5R3V"}, "1166236389471506432": {"followers": "52", "datetime": "2019-08-27 06:29:57", "author": "@midsumwork", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165235458852286467": {"followers": "144", "datetime": "2019-08-24 12:12:37", "author": "@pranjaltandon2", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166453714967814146": {"followers": "813", "datetime": "2019-08-27 20:53:31", "author": "@UberVD", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165316997909028865": {"followers": "4,662", "datetime": "2019-08-24 17:36:37", "author": "@BigData_Fr", "content_summary": "Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff: https://t.co/J2WqNu4yzd  The \"bias-variance\" you knew was just the first piece of the story!https://t"}, "1165666079806541829": {"followers": "103", "datetime": "2019-08-25 16:43:45", "author": "@jongen87", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166547076831825921": {"followers": "60", "datetime": "2019-08-28 03:04:31", "author": "@SanghyukChun", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1190978964128440322": {"followers": "78", "datetime": "2019-11-03 13:08:07", "author": "@warren_k_miller", "content_summary": "Is traditional wisdom on the bias-variance trade-off wrong? This is a provacative paper on the subject that makes a compelling case for rethinking how to fit your models. https://t.co/FeW2eV5PEM #MachineLearning https://t.co/5lssGGgzD8"}, "1142913544624705547": {"followers": "38", "datetime": "2019-06-23 21:53:18", "author": "@notorious_digi", "content_summary": "I know no one comes to Twitter for math, but this paper messed me up tl;dr: turns out in *some* cases overfitting of predictive models doesn't really exist. you just didn't make the model complex enough https://t.co/GFn8Zwmw34"}, "1165565775505235969": {"followers": "495", "datetime": "2019-08-25 10:05:10", "author": "@DrSimonHarris", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165069604378382338": {"followers": "1,294", "datetime": "2019-08-24 01:13:34", "author": "@tak_yamm", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202884008318820352": {"followers": "2,475", "datetime": "2019-12-06 09:34:30", "author": "@sindero", "content_summary": "Interesting extensions/additions building on the body of work kicked off by https://t.co/3rUYIBs2uQ & successors. (This article adds results for data-size and training-time, which I hadn't seen before.) Feels like we're tantalizingly close to a step-c"}, "1202647475628183555": {"followers": "1,850", "datetime": "2019-12-05 17:54:36", "author": "@MaxALittle", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1166181385414987776": {"followers": "824", "datetime": "2019-08-27 02:51:23", "author": "@morioka", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165112115742613507": {"followers": "226", "datetime": "2019-08-24 04:02:29", "author": "@malicannoyan", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1169716404158791680": {"followers": "1,336", "datetime": "2019-09-05 20:58:17", "author": "@jigarkdoshi", "content_summary": "From Classical Statistics to Modern Machine Learning. This attempts to explain why we don't overfit when we train for a very long time. Beautiful talk as well Paper: https://t.co/stkiE7IDj0 Talk: https://t.co/zPPLc24Fvm https://t.co/J93wvzuNJd"}, "1166167557943914496": {"followers": "148", "datetime": "2019-08-27 01:56:26", "author": "@Tata_oac", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165233124273295360": {"followers": "439", "datetime": "2019-08-24 12:03:20", "author": "@lukasberns", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1194587759819624448": {"followers": "684", "datetime": "2019-11-13 12:08:10", "author": "@apissQX70", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1180678758501511171": {"followers": "477", "datetime": "2019-10-06 02:58:46", "author": "@yasuokajihei", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165239735868170241": {"followers": "132", "datetime": "2019-08-24 12:29:36", "author": "@KmillanR", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165723543121928193": {"followers": "7", "datetime": "2019-08-25 20:32:05", "author": "@LYTiQ_ai", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166645502810755072": {"followers": "397", "datetime": "2019-08-28 09:35:37", "author": "@AfoUnofficial", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1172214478542450688": {"followers": "85", "datetime": "2019-09-12 18:24:45", "author": "@ReversingWithMe", "content_summary": "RT @halvarflake: To my great surprise, I found a few minutes of downtime today to read https://t.co/Y4GyQx1XeQ. If you are into ML or stati\u2026"}, "1166648152172244993": {"followers": "826", "datetime": "2019-08-28 09:46:09", "author": "@tangled_zans", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1180756238520520704": {"followers": "161", "datetime": "2019-10-06 08:06:39", "author": "@WilldVaz", "content_summary": "RT @hillbig: The bias-variance tradeoff shows that a model with appropriate complexity can generalize. Recent \"double descent\" indicates th\u2026"}, "1165050576075255808": {"followers": "252", "datetime": "2019-08-23 23:57:57", "author": "@yzhang49", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1194323917772673025": {"followers": "24", "datetime": "2019-11-12 18:39:46", "author": "@ragatti_", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165449119541776384": {"followers": "66", "datetime": "2019-08-25 02:21:37", "author": "@yaodong_yu", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1180652298847965186": {"followers": "18,250", "datetime": "2019-10-06 01:13:38", "author": "@hillbig", "content_summary": "The bias-variance tradeoff shows that a model with appropriate complexity can generalize. Recent \"double descent\" indicates that a larger (than the necessary) model can generalize better in some situations. https://t.co/mWq1R4mAPr https://t.co/sczUUix6Qo h"}, "1166173324566642688": {"followers": "979", "datetime": "2019-08-27 02:19:21", "author": "@Tako_tw", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165333607558176768": {"followers": "161", "datetime": "2019-08-24 18:42:37", "author": "@nightwalker", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165379839110418432": {"followers": "19,073", "datetime": "2019-08-24 21:46:20", "author": "@xamat", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165637633373917184": {"followers": "1", "datetime": "2019-08-25 14:50:42", "author": "@ZhiWeiLee3", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165246310682955776": {"followers": "45", "datetime": "2019-08-24 12:55:44", "author": "@artuskg", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166451593086218241": {"followers": "559", "datetime": "2019-08-27 20:45:06", "author": "@JayChance5", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1180668422599786496": {"followers": "74", "datetime": "2019-10-06 02:17:42", "author": "@pec_hajime", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165237297798950917": {"followers": "36", "datetime": "2019-08-24 12:19:55", "author": "@hussainatwadi", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166560840352436230": {"followers": "2,610", "datetime": "2019-08-28 03:59:12", "author": "@0_u0", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166316613743738880": {"followers": "485", "datetime": "2019-08-27 11:48:44", "author": "@eve_yk", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1188830750818394112": {"followers": "868", "datetime": "2019-10-28 14:51:53", "author": "@cinjoncin", "content_summary": "@seth_stafford are you referring to https://t.co/zINV9igtkU?"}, "1202855828547653633": {"followers": "84", "datetime": "2019-12-06 07:42:32", "author": "@guitaricet", "content_summary": "@antgr81 @sudharsansai123 @ilyasut Reconciling modern machine learning practice and the bias-variance trade-off Belkin et al. 2018 https://t.co/gxPgKaqwfu"}, "1165744947766734849": {"followers": "17,624", "datetime": "2019-08-25 21:57:08", "author": "@OpenMarketingTV", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165368443371024385": {"followers": "468", "datetime": "2019-08-24 21:01:03", "author": "@GodsoeWilliam", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1226718291952984064": {"followers": "1,519", "datetime": "2020-02-10 04:03:26", "author": "@sakata_ryuji", "content_summary": "\u7d50\u69cb\u8a71\u984c\u3067\u3059\u3088\u306d\u3053\u308c\u3002\uff08\u3046\u3061\u3067\u3082\u8a71\u984c\u306b\u4e0a\u304c\u3063\u305f\u306e\u3067\u3056\u3063\u3068\u8aad\u3093\u3067\u305f\u3002\uff09 3\u7ae0\u306e\u6c7a\u5b9a\u6728\u3068\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u306e\u3068\u3053\u308d\u306f\u3001\u4f55\u304b\u53d6\u3063\u3066\u4ed8\u3051\u305f\u5370\u8c61\u3067\u3001\u3053\u3058\u3064\u3051\u611f\u304c\u5426\u3081\u306a\u304b\u3063\u305f\u3002\u305f\u3060\u3001\u524d\u534a\u306f\u7d14\u7c8b\u306b\u9762\u767d\u3044\u5185\u5bb9\u3060\u3068\u601d\u3063\u3066\u307e\u3059\u3002"}, "1167044168348311552": {"followers": "49", "datetime": "2019-08-29 11:59:47", "author": "@Matchable_io", "content_summary": "Interesting paper of the question of generalization in ML. How can the classical understanding of generalization can be reconciled with observations from modern #machinelearning practice by exhibiting a new \"double descent\" risk curve? Thanks to @IanOsband"}, "1165229313656066048": {"followers": "19", "datetime": "2019-08-24 11:48:11", "author": "@xpdxtd", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166007789887664129": {"followers": "195", "datetime": "2019-08-26 15:21:35", "author": "@scac1041", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165377689617915906": {"followers": "375", "datetime": "2019-08-24 21:37:47", "author": "@josue_ma_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1193889362972422144": {"followers": "94", "datetime": "2019-11-11 13:53:00", "author": "@bkailkhu", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1167863893621760000": {"followers": "30", "datetime": "2019-08-31 18:17:04", "author": "@LoterioPonto", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165266818941849600": {"followers": "15", "datetime": "2019-08-24 14:17:13", "author": "@chi_thanh_lam", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165541404539523073": {"followers": "31", "datetime": "2019-08-25 08:28:20", "author": "@sfernando131", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180847490930634757": {"followers": "366", "datetime": "2019-10-06 14:09:15", "author": "@daik_", "content_summary": "\uff1f\uff1f\uff1f\uff1f\uff1f"}, "1165084672562360320": {"followers": "48", "datetime": "2019-08-24 02:13:26", "author": "@dai_sh29", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165175983336493056": {"followers": "136", "datetime": "2019-08-24 08:16:17", "author": "@FaisalMaqbool94", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166016523066105856": {"followers": "150", "datetime": "2019-08-26 15:56:17", "author": "@yasserglez", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180708252016709633": {"followers": "113", "datetime": "2019-10-06 04:55:58", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj We first consider a popular class of non-linear parametric models called Random Fourier Features (RFF) [30], which can be viewed as a class of two-layer neural networks with fixed weights in the first layer. #nextAI https://t.co/RC6"}, "1165695467021201409": {"followers": "144", "datetime": "2019-08-25 18:40:31", "author": "@jcearls", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165473151654006793": {"followers": "95", "datetime": "2019-08-25 03:57:07", "author": "@latinostats", "content_summary": "this paper explain a lot!!"}, "1166736444066545665": {"followers": "95", "datetime": "2019-08-28 15:36:59", "author": "@vialenet", "content_summary": "\"...the curve shows that as soon as the model complexity is high enough to achieve interpolation on the training sample---a point that we call the \"interpolation threshold\"-the risk of suitably chosen interpolating predictors from these models can, in fact"}, "1165033193243721729": {"followers": "5", "datetime": "2019-08-23 22:48:53", "author": "@MCEChiu", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166566000982142976": {"followers": "50", "datetime": "2019-08-28 04:19:43", "author": "@yumeto_inaoka", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165416965059428353": {"followers": "552", "datetime": "2019-08-25 00:13:51", "author": "@kjahanbakhsh", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165855915272261637": {"followers": "5,413", "datetime": "2019-08-26 05:18:05", "author": "@firoozye", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165426249503842307": {"followers": "24", "datetime": "2019-08-25 00:50:45", "author": "@DavidCh93266503", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168891850645807106": {"followers": "25,796", "datetime": "2019-09-03 14:21:48", "author": "@daveaitel", "content_summary": "RT @halvarflake: Stats/ML followers: This paper https://t.co/GqSUd4gJWX argues that the risk curve when overparametrizing models is \"w\"-sha\u2026"}, "1165271200655978497": {"followers": "27", "datetime": "2019-08-24 14:34:38", "author": "@igorsouzaf", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165491867728994306": {"followers": "177", "datetime": "2019-08-25 05:11:29", "author": "@egemensert", "content_summary": "Woah! \ud83d\ude2e"}, "1166161924578402305": {"followers": "3,633", "datetime": "2019-08-27 01:34:03", "author": "@HirokatuKataoka", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166574440089628675": {"followers": "12,765", "datetime": "2019-08-28 04:53:15", "author": "@hyounpark", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166409044153659392": {"followers": "87", "datetime": "2019-08-27 17:56:01", "author": "@imsonug", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168669147083018242": {"followers": "3,018", "datetime": "2019-09-02 23:36:52", "author": "@cd_fuller", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165212941433626624": {"followers": "49", "datetime": "2019-08-24 10:43:08", "author": "@paulomannjr", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1081370007383277573": {"followers": "47", "datetime": "2019-01-05 02:01:15", "author": "@Sapana_007", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1165309590533050368": {"followers": "1,595", "datetime": "2019-08-24 17:07:11", "author": "@nyker_goto", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165435428121563136": {"followers": "43", "datetime": "2019-08-25 01:27:13", "author": "@jeandut14000", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165467018058854401": {"followers": "52", "datetime": "2019-08-25 03:32:45", "author": "@earny_joe", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166198773577474049": {"followers": "147", "datetime": "2019-08-27 04:00:29", "author": "@taashi_s", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1167692874764308480": {"followers": "399", "datetime": "2019-08-31 06:57:30", "author": "@sun_ozon", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166333003359866880": {"followers": "54", "datetime": "2019-08-27 12:53:52", "author": "@kakeijin", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1190303512103489536": {"followers": "308", "datetime": "2019-11-01 16:24:06", "author": "@QFTlover", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165620506982092801": {"followers": "169", "datetime": "2019-08-25 13:42:39", "author": "@stevenhoi", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168412044061749248": {"followers": "1,288", "datetime": "2019-09-02 06:35:14", "author": "@heghbalz", "content_summary": "RT @francoisfleuret: So is the idea in Belkin's paper simply that when the training error is zero and you increase your model space, you ca\u2026"}, "1165685374615773185": {"followers": "1,033", "datetime": "2019-08-25 18:00:25", "author": "@amestadmx", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1193833807260114944": {"followers": "6,118", "datetime": "2019-11-11 10:12:14", "author": "@glouppe", "content_summary": "Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL Looking for a friend :-) https://t.co/6GgKsyAiSm"}, "1169253711258013696": {"followers": "245", "datetime": "2019-09-04 14:19:43", "author": "@Rovio_Red", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180700945480474624": {"followers": "113", "datetime": "2019-10-06 04:26:56", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj there has been an emerging recognition that certain interpolating predictors (not based on ERM) can indeed be provably statistically optimal or near-optimal [3, 5], which is compatible with our empirical observations in the interpol"}, "1165308929804591104": {"followers": "957", "datetime": "2019-08-24 17:04:33", "author": "@emilioleton", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1226725414711767040": {"followers": "345", "datetime": "2020-02-10 04:31:44", "author": "@enj0u", "content_summary": "RT @sakata_ryuji: \u7d50\u69cb\u8a71\u984c\u3067\u3059\u3088\u306d\u3053\u308c\u3002\uff08\u3046\u3061\u3067\u3082\u8a71\u984c\u306b\u4e0a\u304c\u3063\u305f\u306e\u3067\u3056\u3063\u3068\u8aad\u3093\u3067\u305f\u3002\uff09 3\u7ae0\u306e\u6c7a\u5b9a\u6728\u3068\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u306e\u3068\u3053\u308d\u306f\u3001\u4f55\u304b\u53d6\u3063\u3066\u4ed8\u3051\u305f\u5370\u8c61\u3067\u3001\u3053\u3058\u3064\u3051\u611f\u304c\u5426\u3081\u306a\u304b\u3063\u305f\u3002\u305f\u3060\u3001\u524d\u534a\u306f\u7d14\u7c8b\u306b\u9762\u767d\u3044\u5185\u5bb9\u3060\u3068\u601d\u3063\u3066\u307e\u3059\u3002"}, "1165317423073021954": {"followers": "39", "datetime": "2019-08-24 17:38:18", "author": "@stalhabukhari", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165693289569275907": {"followers": "15", "datetime": "2019-08-25 18:31:52", "author": "@The_UBD", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165149661549780992": {"followers": "42", "datetime": "2019-08-24 06:31:41", "author": "@MishakinSergey", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165261984973148160": {"followers": "4,255", "datetime": "2019-08-24 13:58:01", "author": "@weballergy", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166190178282532864": {"followers": "983", "datetime": "2019-08-27 03:26:19", "author": "@inoudayo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1214985277342670850": {"followers": "8,564", "datetime": "2020-01-08 19:00:38", "author": "@anderssandberg", "content_summary": "Indeed, it looks like what we thought was a never-ending rise of test errors as the # parameters increased was just a peak. https://t.co/fozU39XVLv https://t.co/z1q8p0ZxAR Why? Very good question I am not up to speed on, but shows how surprising these sy"}, "1165318490770661376": {"followers": "264", "datetime": "2019-08-24 17:42:33", "author": "@mukundmr", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165208988469932034": {"followers": "4,891", "datetime": "2019-08-24 10:27:26", "author": "@IgorCarron", "content_summary": "RT @ukmlv: This was the paper you mentioned to me at BASP @mariotelfig? https://t.co/mZzSrRRo3H"}, "1164962710682890240": {"followers": "3,416", "datetime": "2019-08-23 18:08:48", "author": "@andrey_kurenkov", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166170509219745793": {"followers": "2,028", "datetime": "2019-08-27 02:08:10", "author": "@kuronekodaisuki", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166162308017487872": {"followers": "1,608", "datetime": "2019-08-27 01:35:35", "author": "@syinari0123", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165499151351611392": {"followers": "190", "datetime": "2019-08-25 05:40:26", "author": "@JoeDodson", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165370576556285952": {"followers": "1,612", "datetime": "2019-08-24 21:09:31", "author": "@leonpalafox", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165080753056563201": {"followers": "74", "datetime": "2019-08-24 01:57:52", "author": "@RichardYRLi", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165692327324790784": {"followers": "80", "datetime": "2019-08-25 18:28:03", "author": "@samweis", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1170299992063369218": {"followers": "2,671", "datetime": "2019-09-07 11:37:15", "author": "@ayirpelle", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166474509651566592": {"followers": "81", "datetime": "2019-08-27 22:16:09", "author": "@moyaff", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165649449349275648": {"followers": "13", "datetime": "2019-08-25 15:37:40", "author": "@gw03", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165252253223215105": {"followers": "1,047", "datetime": "2019-08-24 13:19:21", "author": "@Pkdilly", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165336549627555840": {"followers": "252", "datetime": "2019-08-24 18:54:18", "author": "@HydryHydra", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165216271396474880": {"followers": "1,474", "datetime": "2019-08-24 10:56:22", "author": "@RokoMijicUK", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1164919091884376065": {"followers": "412", "datetime": "2019-08-23 15:15:29", "author": "@iacopo_poli", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165233250115018753": {"followers": "783", "datetime": "2019-08-24 12:03:50", "author": "@muktabh", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166426598570151943": {"followers": "194", "datetime": "2019-08-27 19:05:46", "author": "@ikdeepl", "content_summary": "https://t.co/8aW5BzV2xt - The question of generalization in machine learning\u2014how algorithms are able to learn predictors from a training sample to make accurate predictions out-of-sample\u2014is revisited in light of the recent breakthroughs in modern machine l"}, "1166229895040471043": {"followers": "159", "datetime": "2019-08-27 06:04:09", "author": "@fomalhaut31415", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1176340273418227713": {"followers": "549", "datetime": "2019-09-24 03:39:11", "author": "@k_matsuzaki", "content_summary": "\u3053\u3044\u3064\u306f\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306b\u3088\u308b\u904e\u5b66\u7fd2\u306b\u3064\u3044\u3066\u3060\u3063\u305f\u30021\u5e74\u304f\u3089\u3044\u524d\u306b\u306a\u3093\u304b\u8aad\u3093\u3060\u6c17\u304c\u3059\u308b\u3093\u3060\u3051\u3069\u2026 https://t.co/6SXOt3VUpN"}, "1194373053590978560": {"followers": "736", "datetime": "2019-11-12 21:55:01", "author": "@unsorsodicorda", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166871359701602304": {"followers": "4,599", "datetime": "2019-08-29 00:33:06", "author": "@TheCuriousLuke", "content_summary": "RT @dataelixir: Reconciling modern machine learning and the bias-variance trade-off via @arxiv_org https://t.co/CbgzEbi6ec #MachineLearning"}, "1165527069192835072": {"followers": "809", "datetime": "2019-08-25 07:31:22", "author": "@zhaoran_wang", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166002765707001858": {"followers": "8,696", "datetime": "2019-08-26 15:01:37", "author": "@MartinGaedt", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165011032676474880": {"followers": "245", "datetime": "2019-08-23 21:20:49", "author": "@sangmichaelxie", "content_summary": "\"double descent\" and the interpolating regime. One caveat is that with dropout / BN on large datasets (Imagenet), I believe ResNets and the like don't actually obtain 100% training accuracy. So are we actually in this interpolating regime?"}, "1168410855966498816": {"followers": "3,202", "datetime": "2019-09-02 06:30:30", "author": "@francoisfleuret", "content_summary": "So is the idea in Belkin's paper simply that when the training error is zero and you increase your model space, you can reduce even more *whatever measure of capacity you defined initially*? https://t.co/ab9Kss50bu"}, "1166005580282155008": {"followers": "10,655", "datetime": "2019-08-26 15:12:48", "author": "@kaalam_ai", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165279370904100865": {"followers": "10", "datetime": "2019-08-24 15:07:06", "author": "@qjgod", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165072331582169093": {"followers": "179", "datetime": "2019-08-24 01:24:24", "author": "@rajneeshagrawal", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165272682851495937": {"followers": "205", "datetime": "2019-08-24 14:40:31", "author": "@a_random_obsrvr", "content_summary": "What the hell!"}, "1166327491117469697": {"followers": "159", "datetime": "2019-08-27 12:31:57", "author": "@mika_ken", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1168302369735499776": {"followers": "297", "datetime": "2019-09-01 23:19:25", "author": "@tig33739130", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166180122963038209": {"followers": "162", "datetime": "2019-08-27 02:46:22", "author": "@__tuxi__", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166540056829595648": {"followers": "945", "datetime": "2019-08-28 02:36:37", "author": "@Ghelardini", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1205513606067916800": {"followers": "265", "datetime": "2019-12-13 15:43:35", "author": "@phkragel", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1165055430923390977": {"followers": "1,412", "datetime": "2019-08-24 00:17:15", "author": "@cournape", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165658554033946624": {"followers": "253", "datetime": "2019-08-25 16:13:50", "author": "@mansoorfayyaz", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165244880735604736": {"followers": "290", "datetime": "2019-08-24 12:50:03", "author": "@dannyehb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180671017556951040": {"followers": "175", "datetime": "2019-10-06 02:28:01", "author": "@SquirrelYellow", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165650737927479296": {"followers": "445", "datetime": "2019-08-25 15:42:47", "author": "@RLCommunity8", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165783402634547200": {"followers": "0", "datetime": "2019-08-26 00:29:57", "author": "@luckyJane12", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165518452674744320": {"followers": "118", "datetime": "2019-08-25 06:57:08", "author": "@a_new_moody", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166202879306190854": {"followers": "339", "datetime": "2019-08-27 04:16:48", "author": "@TakaakiUmedu", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180968821957386240": {"followers": "860", "datetime": "2019-10-06 22:11:23", "author": "@FuedaKaoru", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165345883774509056": {"followers": "1,670", "datetime": "2019-08-24 19:31:24", "author": "@metricausa", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165372848065564672": {"followers": "50", "datetime": "2019-08-24 21:18:33", "author": "@stumptownfin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180697039190904833": {"followers": "218", "datetime": "2019-10-06 04:11:25", "author": "@NHigashino", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1194209357065531392": {"followers": "35", "datetime": "2019-11-12 11:04:32", "author": "@t_zoeller", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1180665300422778880": {"followers": "103", "datetime": "2019-10-06 02:05:17", "author": "@lot_carnage", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166959927241261058": {"followers": "304", "datetime": "2019-08-29 06:25:02", "author": "@ildefons", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1214749368135213056": {"followers": "0", "datetime": "2020-01-08 03:23:12", "author": "@Sam09lol", "content_summary": "RT @narges_razavian: Adding the double descent paper to lecture 1 of my introductory ML course.. Who would've thought? Reconciling modern\u2026"}, "1166558518616498177": {"followers": "206", "datetime": "2019-08-28 03:49:59", "author": "@14prakash", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165285721873244160": {"followers": "221", "datetime": "2019-08-24 15:32:20", "author": "@Davide__Cirillo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166912875128078337": {"followers": "758", "datetime": "2019-08-29 03:18:04", "author": "@welcomedwelling", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off #MachineLearning via https://t.co/laWnQuosOT https://t.co/19ELZyPEv2"}, "1205501412479840256": {"followers": "2,566", "datetime": "2019-12-13 14:55:08", "author": "@ar0mcintosh", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1167823351781310465": {"followers": "316", "datetime": "2019-08-31 15:35:58", "author": "@keito1sasaki", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180651475153739776": {"followers": "113", "datetime": "2019-10-06 01:10:21", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj given a sample of training examples (x1, y1), . . . ,(xn, yn) from R d \u00d7R, we learn a predictor hn : R d \u2192 R that is used to predict the label y of a new point x, unseen in training. #nextAI https://t.co/7tZIoe2U5t"}, "1165498299647954945": {"followers": "7", "datetime": "2019-08-25 05:37:03", "author": "@hussainmuzahid7", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165166502967951361": {"followers": "1,371", "datetime": "2019-08-24 07:38:36", "author": "@robanhk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165359375185137664": {"followers": "32", "datetime": "2019-08-24 20:25:01", "author": "@At7788546", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1204664907158786048": {"followers": "6", "datetime": "2019-12-11 07:31:10", "author": "@Nikolai13263465", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1226710772614488064": {"followers": "1,414", "datetime": "2020-02-10 03:33:34", "author": "@natsutan", "content_summary": "RT @nardtree: \u4f1a\u793e\u3067\u3081\u3063\u3061\u3083\u6279\u5224\u7684\u306a\u8ad6\u8a55\u3060\u3063\u305f\u3002\u50d5\u3082\u305d\u3046\u601d\u3046\u304c\u3001Deep\u3060\u3068\u3088\u304f\u306a\u308b\u3053\u3068\u3082\u3042\u3063\u3066\u4e00\u822c\u5316\u3059\u308b\u3088\u3046\u306a\u7406\u8ad6\u3058\u3083\u306a\u3044\u307f\u305f\u3044\u306a\u610f\u898b\u3002 / 2\u4ef6\u306e\u30b3\u30e1\u30f3\u30c8 https://t.co/dakKZUE0zl \u201c[1812.11118] Reconciling mo\u2026"}, "1180676563462868992": {"followers": "113", "datetime": "2019-10-06 02:50:03", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj The goal of machine learning is to find hn that performs well on new data, unseen in training.#nextAI https://t.co/EqT1paCBoZ"}, "1165015245783470080": {"followers": "328", "datetime": "2019-08-23 21:37:34", "author": "@Suuraj", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165206023864557568": {"followers": "61", "datetime": "2019-08-24 10:15:39", "author": "@intelapp", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1203019576155484161": {"followers": "26", "datetime": "2019-12-06 18:33:12", "author": "@BeckerooBonsai", "content_summary": "@gabrielweymouth @zacharylipton @OpenAI I can't say I've seen 1000 papers on the topic of double descent curve. Here is one though, https://t.co/DGevZAk7RQ. A journal club I go to read that in conjunction with https://t.co/4QQfNc4SFd."}, "1173575009777922049": {"followers": "907", "datetime": "2019-09-16 12:31:00", "author": "@AISC_TO", "content_summary": "Reconciling modern machine learning practice and the bias-variance trade-off https://t.co/faD8t5vCl9"}, "1165981628629430272": {"followers": "156", "datetime": "2019-08-26 13:37:37", "author": "@macaco142857", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165324277182283778": {"followers": "6", "datetime": "2019-08-24 18:05:33", "author": "@PennJenks", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166409450795798529": {"followers": "84", "datetime": "2019-08-27 17:57:38", "author": "@betse_DV", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165234179438723072": {"followers": "178", "datetime": "2019-08-24 12:07:32", "author": "@namhoonlee09", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165246201970810881": {"followers": "134", "datetime": "2019-08-24 12:55:18", "author": "@RobHarrigan89", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166184445080035333": {"followers": "221", "datetime": "2019-08-27 03:03:33", "author": "@CsTarepanda", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1230252437446909952": {"followers": "76", "datetime": "2020-02-19 22:06:52", "author": "@Binette228", "content_summary": "@freakonometrics I'm not at all an expert here, but this is an interesting reference on the subject: https://t.co/T7pzSyDGxf"}, "1166323558986813441": {"followers": "1,838", "datetime": "2019-08-27 12:16:20", "author": "@PAClearning", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165351341654515716": {"followers": "460", "datetime": "2019-08-24 19:53:05", "author": "@confusedmatrix", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165159748863500289": {"followers": "235", "datetime": "2019-08-24 07:11:46", "author": "@Ivan_Lupelli", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167631000576200709": {"followers": "265", "datetime": "2019-08-31 02:51:38", "author": "@125shunar", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165172837495083008": {"followers": "1,217", "datetime": "2019-08-24 08:03:46", "author": "@bwinterrose", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165566797409587201": {"followers": "4,249", "datetime": "2019-08-25 10:09:14", "author": "@SilverVVulpes", "content_summary": "luv that we develop an AI tech and have to wait a few years for someone to explain how it maybe works, this couldn't backfire over the decades as AI becomes more important or only one group figures it out before others https://t.co/ORrvL8gkGb"}, "1166560426559201282": {"followers": "98", "datetime": "2019-08-28 03:57:33", "author": "@EduAruberuto", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165070535501520896": {"followers": "13", "datetime": "2019-08-24 01:17:16", "author": "@Vic_Avac", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1218837502674554880": {"followers": "7,444", "datetime": "2020-01-19 10:08:00", "author": "@o_guest", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1166297740483145728": {"followers": "2,315", "datetime": "2019-08-27 10:33:44", "author": "@babeheim", "content_summary": "RT @orestistsinalis: Very interesting paper with empirical observations of \"double descent\"/two-regime behaviour in test performance of com\u2026"}, "1172250157234163715": {"followers": "1,155", "datetime": "2019-09-12 20:46:31", "author": "@isciurus", "content_summary": "RT @halvarflake: To my great surprise, I found a few minutes of downtime today to read https://t.co/Y4GyQx1XeQ. If you are into ML or stati\u2026"}, "1165281871615287296": {"followers": "2,436", "datetime": "2019-08-24 15:17:02", "author": "@HMRoff", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166284123305959424": {"followers": "30", "datetime": "2019-08-27 09:39:38", "author": "@gbiwer", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165409817147478016": {"followers": "7", "datetime": "2019-08-24 23:45:27", "author": "@nneal25", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1194206175203643392": {"followers": "14", "datetime": "2019-11-12 10:51:54", "author": "@e7mul", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165227582670827520": {"followers": "328", "datetime": "2019-08-24 11:41:19", "author": "@leloykun", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166297526116528128": {"followers": "12,883", "datetime": "2019-08-27 10:32:53", "author": "@venkmurthy", "content_summary": "RT @kdpsinghlab: The \u201cdouble-descent\u201d observed in this paper doesn\u2019t make any sense to me intuitively. As model complexity increases (\u2b07\ufe0fEPV\u2026"}, "1166686279565742080": {"followers": "197", "datetime": "2019-08-28 12:17:39", "author": "@svateboje", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180694402768887813": {"followers": "113", "datetime": "2019-10-06 04:00:56", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj This dependence, empirically witnessed with important model classes including neural networks and a range of datasets, is summarized in the \u201cdouble descent\u201d risk curve shown in Figure 1(b).#nextAI https://t.co/Ak76kQrp5Y"}, "1165300075213414400": {"followers": "6,012", "datetime": "2019-08-24 16:29:22", "author": "@lavanyaai", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165163659355742209": {"followers": "1,251", "datetime": "2019-08-24 07:27:18", "author": "@biggiobattista", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180722764971311104": {"followers": "45,424", "datetime": "2019-10-06 05:53:38", "author": "@VanRijmenam", "content_summary": "RT @SHIMOMURATakuji: https://t.co/FFXHsebuhj We first consider a popular class of non-linear parametric models called Random Fourier Featur\u2026"}, "1169354554430971905": {"followers": "8", "datetime": "2019-09-04 21:00:25", "author": "@Millet40835692", "content_summary": "An explanation of why a DL model with 99% accuracy on train and validation data doesn't overfit. It is shown that DL models follow a different bias variance curve different from the traditional u- shaped curve. https://t.co/656YZbaekf https://t.co/gnC4fJYr"}, "1180982334335508482": {"followers": "1,164", "datetime": "2019-10-06 23:05:04", "author": "@hrtmnr", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165210170940633089": {"followers": "3", "datetime": "2019-08-24 10:32:07", "author": "@cagrigokce", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1081285795779104771": {"followers": "14,882", "datetime": "2019-01-04 20:26:37", "author": "@roydanroy", "content_summary": "Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1166199231289249792": {"followers": "213", "datetime": "2019-08-27 04:02:18", "author": "@goldfish_lab", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166637629485539328": {"followers": "1,451", "datetime": "2019-08-28 09:04:20", "author": "@Gabriel_Oguna", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1168056333586665472": {"followers": "3,314", "datetime": "2019-09-01 07:01:46", "author": "@AndySugs", "content_summary": "RT: DataSciNews: RT IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff: https://t.co/YjiNqmRHCY The \"bias-variance\" you knew was just the fi\u2026 h"}, "1180981449006043136": {"followers": "470", "datetime": "2019-10-06 23:01:33", "author": "@minami_siki", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165188182679277568": {"followers": "151", "datetime": "2019-08-24 09:04:45", "author": "@Tchandra458", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180664017439690752": {"followers": "62", "datetime": "2019-10-06 02:00:12", "author": "@tomoyuki71320", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166544588552704000": {"followers": "1,412", "datetime": "2019-08-28 02:54:37", "author": "@BlueLantern92", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166185389591158784": {"followers": "475", "datetime": "2019-08-27 03:07:18", "author": "@censored__", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166549064927760384": {"followers": "1,142", "datetime": "2019-08-28 03:12:25", "author": "@i_pascu", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166645948916781058": {"followers": "26", "datetime": "2019-08-28 09:37:24", "author": "@tokoton01", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166871083682816002": {"followers": "6,148", "datetime": "2019-08-29 00:32:00", "author": "@dataelixir", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off via @arxiv_org https://t.co/CbgzEbi6ec #MachineLearning"}, "1164999880202477570": {"followers": "38", "datetime": "2019-08-23 20:36:30", "author": "@schellekensv", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180653592933330945": {"followers": "216", "datetime": "2019-10-06 01:18:46", "author": "@KSKSKSKS2", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166451836842233856": {"followers": "927", "datetime": "2019-08-27 20:46:04", "author": "@take_cheeze", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1205501967478312960": {"followers": "3,314", "datetime": "2019-12-13 14:57:20", "author": "@pierre_bellec", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1166549995937390592": {"followers": "10", "datetime": "2019-08-28 03:16:07", "author": "@_dabasajay", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165231188950376448": {"followers": "354", "datetime": "2019-08-24 11:55:39", "author": "@indy9000", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165184713788575744": {"followers": "22", "datetime": "2019-08-24 08:50:58", "author": "@nandan_cse", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166205544815710208": {"followers": "710", "datetime": "2019-08-27 04:27:23", "author": "@Hako_matsu", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166383374132371456": {"followers": "180", "datetime": "2019-08-27 16:14:01", "author": "@MuhammadPuter12", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166320878478487557": {"followers": "79", "datetime": "2019-08-27 12:05:41", "author": "@nejimass", "content_summary": "\u904e\u5b66\u7fd2\u306e\u5411\u3053\u3046\u5074\u304c\u3042\u308b\u3089\u3057\u3044 \u305d\u306e\u540d\u3082\u4e8c\u91cd\u4e0b\u964d \u753b\u50cf\u306f\u3053\u3053\u306e\u30b9\u30e9\u30a4\u30c9\u304b\u3089 https://t.co/LheqghO6EU \u8ad6\u6587\u306f\u3053\u308c\u304b\u306a\uff1f https://t.co/RIccVdy5sN https://t.co/7FXJ02zlwu"}, "1166561485033758726": {"followers": "42", "datetime": "2019-08-28 04:01:46", "author": "@hmakbool", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1180659784204242945": {"followers": "1,110", "datetime": "2019-10-06 01:43:22", "author": "@sakura_jpn", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1194571234740076544": {"followers": "409", "datetime": "2019-11-13 11:02:31", "author": "@jainnitk", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165317426571022336": {"followers": "2,428", "datetime": "2019-08-24 17:38:19", "author": "@DataScientistsF", "content_summary": "Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff: https://t.co/tIuyrQHGF0  The \"bias-variance\" you knew was just the first piece of the story!https://t"}, "1166720134175764480": {"followers": "3,630", "datetime": "2019-08-28 14:32:11", "author": "@alexpghayes", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166447078920327169": {"followers": "306", "datetime": "2019-08-27 20:27:09", "author": "@juarelerrr", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165480836226932737": {"followers": "23", "datetime": "2019-08-25 04:27:39", "author": "@deehzee", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1180680028352217088": {"followers": "716", "datetime": "2019-10-06 03:03:49", "author": "@minux302", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165261151485255686": {"followers": "92", "datetime": "2019-08-24 13:54:42", "author": "@raquellh", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166462082105036800": {"followers": "206", "datetime": "2019-08-27 21:26:46", "author": "@yanxia_wh", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166483077830516737": {"followers": "28,418", "datetime": "2019-08-27 22:50:12", "author": "@ogrisel", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1167986714696044548": {"followers": "45", "datetime": "2019-09-01 02:25:07", "author": "@nullbytep", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166166921869283330": {"followers": "879", "datetime": "2019-08-27 01:53:55", "author": "@i_am_nicolen_07", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1177299491403137024": {"followers": "897", "datetime": "2019-09-26 19:10:46", "author": "@Solomon_Slate", "content_summary": "RT @KameronDHarris: Check out this paper: \"Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off\" by Mikha\u2026"}, "1111412680160481289": {"followers": "3,449", "datetime": "2019-03-28 23:40:06", "author": "@reiver", "content_summary": "\"Reconciling modern machine learning and the bias-variance trade-off\" by Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal https://t.co/KjVAiwIpIP (machine learning) H/T @alekseynp"}, "1165223232678633474": {"followers": "117", "datetime": "2019-08-24 11:24:02", "author": "@pabaldonedo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166484436860293120": {"followers": "688", "datetime": "2019-08-27 22:55:36", "author": "@dovgalec", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202649870642880512": {"followers": "237", "datetime": "2019-12-05 18:04:07", "author": "@fluck_5", "content_summary": "It's great to see more work on the double descent phenomenon. It comes as a good reminder for me to re-visit Belkin et al. (https://t.co/XzkpWtM9OI) https://t.co/sBCINqeKYc"}, "1165271257262297089": {"followers": "1,026", "datetime": "2019-08-24 14:34:52", "author": "@orestistsinalis", "content_summary": "Very interesting paper with empirical observations of \"double descent\"/two-regime behaviour in test performance of complex ML models as a function of (L2 norm-based) model complexity. \"Reconciling Modern Machine Learning and the Bias-Variance Tradeoff\" h"}, "1166274936060567553": {"followers": "1,337", "datetime": "2019-08-27 09:03:07", "author": "@boxoa", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165546330053234688": {"followers": "1,595", "datetime": "2019-08-25 08:47:54", "author": "@nyker_goto", "content_summary": "Deep \u306f\u53e4\u5178\u7684\u306a\u30d0\u30a4\u30a2\u30b9\u30d0\u30ea\u30a2\u30f3\u30b9\u306e\u8b70\u8ad6\u304c\u901a\u3058\u306a\u3044\u3063\u3066\u3044\u3046\u306e\u306f\u8074\u3044\u305f\u3053\u3068\u3042\u3063\u305f\u3051\u3069\u3001\u305d\u308c\u4ee5\u5916\u306e\u30e2\u30c7\u30eb\u3001\u4f8b\u3048\u3070\u8ad6\u6587\u4e2d\u306a\u3089RandomForest\u3067\u3082 Over Parameterized \u306a\u30e2\u30c7\u30eb\u306e\u307b\u3046\u304c\u6027\u80fd\u826f\u304f\u306a\u308b\u30dd\u30a4\u30f3\u30c8\u304c\u3042\u308b\u306e\u3001\u304a\u3082\u308d\u3044\u306a\u30fc https://t.co/lDvTRPTXUs https://t.co/qIsY1UBcC7"}, "1229837632227725312": {"followers": "1", "datetime": "2020-02-18 18:38:35", "author": "@realAtxCrypto", "content_summary": "#good_content Tue Feb 18 18:23:33 2020 <9e126bf3> <https://t.co/0Ms7e8Rc0o> https://t.co/m5YcJ2Qvvh"}, "1202642511807700992": {"followers": "3,651", "datetime": "2019-12-05 17:34:53", "author": "@TheGregYang", "content_summary": "@OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1166335769016819712": {"followers": "933", "datetime": "2019-08-27 13:04:51", "author": "@hanneko3", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165210376243429380": {"followers": "73", "datetime": "2019-08-24 10:32:56", "author": "@adn_twitts", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165230839824863232": {"followers": "2,407", "datetime": "2019-08-24 11:54:15", "author": "@calmsannic", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1193844557517139968": {"followers": "4,891", "datetime": "2019-11-11 10:54:57", "author": "@IgorCarron", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166202521192321025": {"followers": "147", "datetime": "2019-08-27 04:15:22", "author": "@TakeshiHase", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166234835666395137": {"followers": "562", "datetime": "2019-08-27 06:23:47", "author": "@nazenazeboy", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166398462625079296": {"followers": "258", "datetime": "2019-08-27 17:13:58", "author": "@supakjk", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166205567322378240": {"followers": "203", "datetime": "2019-08-27 04:27:28", "author": "@wayama_ryousuke", "content_summary": "\u30d0\u30a4\u30a2\u30b9\u3068\u5206\u6563\u306e\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306b\u3064\u3044\u3066\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u5897\u3048\u308b\u3068\u4e8c\u91cd\u52b9\u679c\u66f2\u7dda\u304c\u3067\u308b\u3093\u304b\u3002\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3067\u3082\u51fa\u3066\u308b\u306e\u306f\u65b0\u3057\u3044\u767a\u898b\u304b\u3082\u3057\u308c\u306a\u3044\u3002 https://t.co/a8TEjntmTU \u4f3c\u305f\u3088\u3046\u306a\u8a71\u304c\u540c\u3058\u304f\u3089\u3044\u306e\u6642\u671f\u306b\u767a\u8868\u3055\u308c\u308b\u306e\u3082\u307e\u305f\u9762\u767d\u3044\u3002 https://t.co/zlYNY2mZZ6"}, "1166448822689705987": {"followers": "168", "datetime": "2019-08-27 20:34:05", "author": "@brunoboutteau", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1202665402716708864": {"followers": "1,203", "datetime": "2019-12-05 19:05:51", "author": "@F_Vaggi", "content_summary": "@jonathanrraiman I guess this is a generalization of https://t.co/ueQpdGuVsA? I guess @lilianweng will have to update her excellent blog entry on https://t.co/yKayEy3EXE even more - surprised she's not a co-author on this paper."}, "1181007049393524736": {"followers": "3", "datetime": "2019-10-07 00:43:17", "author": "@test0_0test", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1203793744266330112": {"followers": "14", "datetime": "2019-12-08 21:49:28", "author": "@ZhaiAndrew", "content_summary": "mind blowing: https://t.co/7iIH7lD3TH. tldr: Increasing model capacity leads to test set overfitting. but keep on adding more capacity and you may *improve* performance. The existence of the \"double descent curve\" beyond traditional bias-variance tradeoff"}, "1165867789313351687": {"followers": "50", "datetime": "2019-08-26 06:05:16", "author": "@remiconnesson", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1081413119400910849": {"followers": "22", "datetime": "2019-01-05 04:52:34", "author": "@Tsingggg", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1181544935364808705": {"followers": "50", "datetime": "2019-10-08 12:20:39", "author": "@NRC_pythoneer", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165090068358287361": {"followers": "122", "datetime": "2019-08-24 02:34:53", "author": "@cwperth", "content_summary": "Indeed, that explains a lot."}, "1164953654886952960": {"followers": "584", "datetime": "2019-08-23 17:32:49", "author": "@morgangiraud", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165215938330996737": {"followers": "163,852", "datetime": "2019-08-24 10:55:03", "author": "@ceobillionaire", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180649473988415489": {"followers": "545", "datetime": "2019-10-06 01:02:24", "author": "@RE_Minory", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166167723061071873": {"followers": "500", "datetime": "2019-08-27 01:57:06", "author": "@sususus40958198", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165465770291130369": {"followers": "899", "datetime": "2019-08-25 03:27:47", "author": "@cristiproist", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165464375177531393": {"followers": "44,863", "datetime": "2019-08-25 03:22:14", "author": "@chrisalbon", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165931063031586816": {"followers": "17", "datetime": "2019-08-26 10:16:42", "author": "@nick_moshkov", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180683440632389633": {"followers": "113", "datetime": "2019-10-06 03:17:22", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj The challenge stems from the mismatch between the goals of minimizing the empirical risk (the explicit goal of ERM algorithms, optimization) and minimizing the true (or test) risk E(x,y)\u223cP [`(h(x), y)] (the goal of machine learning)"}, "1165364531276611585": {"followers": "168", "datetime": "2019-08-24 20:45:30", "author": "@ShumonLahiri", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1164900840106274817": {"followers": "3,930", "datetime": "2019-08-23 14:02:57", "author": "@IanOsband", "content_summary": "Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff: https://t.co/hubyXZATHQ The \"bias-variance\" you knew was just the first piece of the story! https://t."}, "1165371026097594368": {"followers": "1,724", "datetime": "2019-08-24 21:11:18", "author": "@whisponchan", "content_summary": "RT @orcinus_orca: \u3053\u308c\u306f\u3082\u3063\u3068\u77e5\u3089\u308c\u308b\u3079\u304d\u8ad6\u6587 https://t.co/Tkhbx3bF7z"}, "1180650354888695809": {"followers": "275", "datetime": "2019-10-06 01:05:54", "author": "@takawitter", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1212444657625550848": {"followers": "1,832", "datetime": "2020-01-01 18:45:07", "author": "@drahmadbazzi", "content_summary": "RT @halvarflake: @zacharylipton Not sure there's a \"single\" paper to note, but the entire discussion about double-descent has been the most\u2026"}, "1166200319597891584": {"followers": "1,530", "datetime": "2019-08-27 04:06:37", "author": "@SJ_PROJECT", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165416517175058432": {"followers": "477", "datetime": "2019-08-25 00:12:04", "author": "@jmsl", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165277621967392768": {"followers": "66", "datetime": "2019-08-24 15:00:09", "author": "@tenzinchang", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165546202852679682": {"followers": "561", "datetime": "2019-08-25 08:47:24", "author": "@josepemanzano", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180651394329538560": {"followers": "824", "datetime": "2019-10-06 01:10:02", "author": "@morioka", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1172210046928859136": {"followers": "28,195", "datetime": "2019-09-12 18:07:08", "author": "@halvarflake", "content_summary": "To my great surprise, I found a few minutes of downtime today to read https://t.co/Y4GyQx1XeQ. If you are into ML or statistics, I greatly recommend the paper; I will read the follow-ups but the empirical results showing double-descent risk curves are real"}, "1166719052397580288": {"followers": "302", "datetime": "2019-08-28 14:27:53", "author": "@PabloAlbn", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166168475175251971": {"followers": "554", "datetime": "2019-08-27 02:00:05", "author": "@FBWM8888", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165211275741155330": {"followers": "156", "datetime": "2019-08-24 10:36:31", "author": "@tsauri_eecs", "content_summary": "Scale up with data and dropout"}, "1165504631771992064": {"followers": "176", "datetime": "2019-08-25 06:02:12", "author": "@smkia83", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165444874423848960": {"followers": "38", "datetime": "2019-08-25 02:04:45", "author": "@astroCosmos4k", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165375393618169856": {"followers": "36", "datetime": "2019-08-24 21:28:40", "author": "@louislongin", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165260709845983232": {"followers": "22", "datetime": "2019-08-24 13:52:57", "author": "@wardvanbreda", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165222603277180928": {"followers": "1,087", "datetime": "2019-08-24 11:21:32", "author": "@ak1010", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166360247080050690": {"followers": "46", "datetime": "2019-08-27 14:42:07", "author": "@kakikukeko996", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1081493046678691840": {"followers": "103", "datetime": "2019-01-05 10:10:10", "author": "@urosn", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1180753807296188416": {"followers": "373", "datetime": "2019-10-06 07:56:59", "author": "@YasuhiroMatz", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166549490997874688": {"followers": "12,729", "datetime": "2019-08-28 03:14:06", "author": "@paulgp", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166392999552671744": {"followers": "30", "datetime": "2019-08-27 16:52:16", "author": "@CrankMuffler", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165452819748421633": {"followers": "23", "datetime": "2019-08-25 02:36:19", "author": "@CapotudoToys", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168893484461412355": {"followers": "1,251", "datetime": "2019-09-03 14:28:18", "author": "@biggiobattista", "content_summary": "RT @halvarflake: Stats/ML followers: This paper https://t.co/GqSUd4gJWX argues that the risk curve when overparametrizing models is \"w\"-sha\u2026"}, "1166407994772545536": {"followers": "11", "datetime": "2019-08-27 17:51:51", "author": "@FilipMellgren", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165669885655080960": {"followers": "812", "datetime": "2019-08-25 16:58:52", "author": "@alpinegizmo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166503635653558272": {"followers": "281", "datetime": "2019-08-28 00:11:53", "author": "@HotCompScience", "content_summary": "Most popular computer science paper of the day: \"Reconciling modern machine learning and the bias-variance trade-off\" https://t.co/fMmyCF2dQ1 https://t.co/uTiWQQXxRe"}, "1187421019423813637": {"followers": "50", "datetime": "2019-10-24 17:30:06", "author": "@rimfo", "content_summary": "@docente_errante @AlexandreIMPA https://t.co/mwcK6qWfWE"}, "1165238361977741312": {"followers": "6", "datetime": "2019-08-24 12:24:09", "author": "@deep_bansal", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166171676167393280": {"followers": "112", "datetime": "2019-08-27 02:12:48", "author": "@7Wd3Fdjam1cnqaX", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1164974023295434752": {"followers": "231", "datetime": "2019-08-23 18:53:45", "author": "@caseychu9", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166483692124024832": {"followers": "305", "datetime": "2019-08-27 22:52:39", "author": "@webpusher", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166426094544642048": {"followers": "206", "datetime": "2019-08-27 19:03:46", "author": "@Jiny2001", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165312009837142019": {"followers": "1,335", "datetime": "2019-08-24 17:16:48", "author": "@ETSIIUNED", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180867666803712001": {"followers": "234", "datetime": "2019-10-06 15:29:25", "author": "@quantumbtc", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166722992463912960": {"followers": "8,290", "datetime": "2019-08-28 14:43:32", "author": "@SantchiWeb", "content_summary": "RT @rlingle: RT KirkDBorne: RT IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling\u2026"}, "1166202620236697600": {"followers": "100", "datetime": "2019-08-27 04:15:46", "author": "@TBandingus", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165524117707083776": {"followers": "36", "datetime": "2019-08-25 07:19:38", "author": "@boredsrk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165456775962755072": {"followers": "25", "datetime": "2019-08-25 02:52:03", "author": "@NLP_Grayming", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165830217241452545": {"followers": "71", "datetime": "2019-08-26 03:35:58", "author": "@MatthieuPerrot", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1172506972236574720": {"followers": "112", "datetime": "2019-09-13 13:47:00", "author": "@THsama2", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165299595435339777": {"followers": "6", "datetime": "2019-08-24 16:27:28", "author": "@pnwpedro", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165284414332571653": {"followers": "75", "datetime": "2019-08-24 15:27:08", "author": "@MikeHudgell", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166158093832658944": {"followers": "42", "datetime": "2019-08-27 01:18:50", "author": "@pablotalavante", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166162539194941441": {"followers": "12,511", "datetime": "2019-08-27 01:36:30", "author": "@suzatweet", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165309192233717762": {"followers": "62", "datetime": "2019-08-24 17:05:36", "author": "@syhuangfrance", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165625236420612097": {"followers": "642", "datetime": "2019-08-25 14:01:27", "author": "@an_nindouph", "content_summary": "RT @nyker_goto: Deep \u306f\u53e4\u5178\u7684\u306a\u30d0\u30a4\u30a2\u30b9\u30d0\u30ea\u30a2\u30f3\u30b9\u306e\u8b70\u8ad6\u304c\u901a\u3058\u306a\u3044\u3063\u3066\u3044\u3046\u306e\u306f\u8074\u3044\u305f\u3053\u3068\u3042\u3063\u305f\u3051\u3069\u3001\u305d\u308c\u4ee5\u5916\u306e\u30e2\u30c7\u30eb\u3001\u4f8b\u3048\u3070\u8ad6\u6587\u4e2d\u306a\u3089RandomForest\u3067\u3082 Over Parameterized \u306a\u30e2\u30c7\u30eb\u306e\u307b\u3046\u304c\u6027\u80fd\u826f\u304f\u306a\u308b\u30dd\u30a4\u30f3\u30c8\u304c\u3042\u308b\u306e\u3001\u304a\u3082\u308d\u3044\u306a\u2026"}, "1180979813747527680": {"followers": "281", "datetime": "2019-10-06 22:55:03", "author": "@sankyoh", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166163861335994368": {"followers": "4,403", "datetime": "2019-08-27 01:41:45", "author": "@mrkn", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165282670751830023": {"followers": "166", "datetime": "2019-08-24 15:20:13", "author": "@kapiljaising", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165998328242458627": {"followers": "50", "datetime": "2019-08-26 14:43:59", "author": "@_GR4HAM", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166742526574956544": {"followers": "2,473", "datetime": "2019-08-28 16:01:10", "author": "@Pac_Kd", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165297748758974465": {"followers": "813", "datetime": "2019-08-24 16:20:08", "author": "@UberVD", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166492405937262592": {"followers": "109", "datetime": "2019-08-27 23:27:16", "author": "@KatoOrigami", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180714334705446912": {"followers": "113", "datetime": "2019-10-06 05:20:08", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj <3/4>...However, as the number of features approaches n (the interpolation threshold), features not present or only weakly present in the data are forced to fit the training data nearly perfectly. ... #nextAI https://t.co/CwoN"}, "1166198139965071361": {"followers": "82", "datetime": "2019-08-27 03:57:58", "author": "@junjungoal", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165206358075068416": {"followers": "1,738", "datetime": "2019-08-24 10:16:58", "author": "@JoeRaimondo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1081661621934669826": {"followers": "736", "datetime": "2019-01-05 21:20:01", "author": "@unsorsodicorda", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1180649424042643456": {"followers": "18,250", "datetime": "2019-10-06 01:02:12", "author": "@hillbig", "content_summary": "\u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mAPr https://t.co/sczUUix6Qo https://t.co/iBtPSDMkLX"}, "1166156744290009088": {"followers": "12,765", "datetime": "2019-08-27 01:13:28", "author": "@jaguring1", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165335237121007616": {"followers": "397", "datetime": "2019-08-24 18:49:06", "author": "@KordoniN", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167763104672944128": {"followers": "56,127", "datetime": "2019-08-31 11:36:34", "author": "@IntelligenceTV", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165569025742557184": {"followers": "161", "datetime": "2019-08-25 10:18:05", "author": "@GoodGood014", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167681634948173824": {"followers": "11", "datetime": "2019-08-31 06:12:50", "author": "@AIUEO_Rhythm", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165271310701871104": {"followers": "8,290", "datetime": "2019-08-24 14:35:04", "author": "@SantchiWeb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166173147386634240": {"followers": "130", "datetime": "2019-08-27 02:18:39", "author": "@go_aue", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166226370516541440": {"followers": "294", "datetime": "2019-08-27 05:50:08", "author": "@rose_miura", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165614797804752897": {"followers": "401", "datetime": "2019-08-25 13:19:58", "author": "@offbyjuan", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202506509801811968": {"followers": "106", "datetime": "2019-12-05 08:34:28", "author": "@jethroksy", "content_summary": "@ejames_c @KrisAbdelmessih @ReformedTrader You're probably referring to the extended bias-variance tradeoff curve, but if so I'm not sure if performance \"starts declining again\", and as usual the story is much more complicated. If you're interested you can"}, "1165234645895483392": {"followers": "41", "datetime": "2019-08-24 12:09:23", "author": "@aiton5", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166133208112496640": {"followers": "456", "datetime": "2019-08-26 23:39:57", "author": "@PerthMLGroup", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180677294102175744": {"followers": "82", "datetime": "2019-10-06 02:52:57", "author": "@RyoHWS", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166304548442406912": {"followers": "345", "datetime": "2019-08-27 11:00:47", "author": "@enj0u", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165607003768655873": {"followers": "167", "datetime": "2019-08-25 12:49:00", "author": "@DavidAdelson3", "content_summary": "#MachineLearning Extending the bias-variance curve beyong the point of interpolation. https://t.co/7QK4dkOCNc"}, "1166962885211246593": {"followers": "54", "datetime": "2019-08-29 06:36:47", "author": "@ttnam93", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1194412713251729408": {"followers": "65", "datetime": "2019-11-13 00:32:36", "author": "@kli_nlpr", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165352638738661376": {"followers": "7,780", "datetime": "2019-08-24 19:58:14", "author": "@yisongyue", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166554833639182336": {"followers": "420", "datetime": "2019-08-28 03:35:20", "author": "@PavlushaSa", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166181931408445440": {"followers": "824", "datetime": "2019-08-27 02:53:33", "author": "@morioka", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166201773561761792": {"followers": "230", "datetime": "2019-08-27 04:12:24", "author": "@ko_ash", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1168519598330798081": {"followers": "267", "datetime": "2019-09-02 13:42:36", "author": "@gokhanyu", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166494491274072065": {"followers": "130", "datetime": "2019-08-27 23:35:33", "author": "@Monsieur__22", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165054785885749248": {"followers": "16,550", "datetime": "2019-08-24 00:14:41", "author": "@itknowingness", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166185500777992192": {"followers": "696", "datetime": "2019-08-27 03:07:44", "author": "@takatoh1", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1099117684300615681": {"followers": "1,010", "datetime": "2019-02-23 01:24:11", "author": "@spokutta", "content_summary": "Interesting paper \"Reconciling modern machine learning and the bias-variance trade-off\" https://t.co/sIHZmj4WzM #ml #ai #biasvariancetradeoff"}, "1180672404999176192": {"followers": "91", "datetime": "2019-10-06 02:33:31", "author": "@d9sugiha", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1178198947732447232": {"followers": "12,671", "datetime": "2019-09-29 06:44:53", "author": "@genkuroki", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166685403560255488": {"followers": "42", "datetime": "2019-08-28 12:14:10", "author": "@MishakinSergey", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165240173359181830": {"followers": "84", "datetime": "2019-08-24 12:31:21", "author": "@chrisfreder", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166394042839707649": {"followers": "483", "datetime": "2019-08-27 16:56:25", "author": "@felbalazard", "content_summary": "RT @kdpsinghlab: The \u201cdouble-descent\u201d observed in this paper doesn\u2019t make any sense to me intuitively. As model complexity increases (\u2b07\ufe0fEPV\u2026"}, "1166430032774012928": {"followers": "14", "datetime": "2019-08-27 19:19:25", "author": "@emanpleb", "content_summary": "Just discovered that the \"interpolating regime\" was anticipated by 6 months by Bansal et al: https://t.co/2weLMCLW0w (look at Fig 1!) It also shows the link with low-norm parameters (https://t.co/Bga1hcdmvp)"}, "1165259115763048448": {"followers": "91", "datetime": "2019-08-24 13:46:37", "author": "@ManuelSH", "content_summary": "This paper was quite shocking... and really insightful."}, "1165215375551631361": {"followers": "361", "datetime": "2019-08-24 10:52:48", "author": "@jadhavamitb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165271505258725376": {"followers": "98", "datetime": "2019-08-24 14:35:51", "author": "@andrewliao11", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166484769141473280": {"followers": "11,787", "datetime": "2019-08-27 22:56:55", "author": "@yutakashino", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180702519485321222": {"followers": "206", "datetime": "2019-10-06 04:33:11", "author": "@shintaro_minami", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1079653976554000384": {"followers": "771", "datetime": "2018-12-31 08:22:21", "author": "@arxivml", "content_summary": "\"Reconciling modern machine learning and the bias-variance trade-off\", Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumi\u2026 https://t.co/1JZR5TcxdH"}, "1165268645674672129": {"followers": "23,533", "datetime": "2019-08-24 14:24:29", "author": "@haldaume3", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1164950762268631040": {"followers": "31", "datetime": "2019-08-23 17:21:20", "author": "@koenboeckx", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165328735933018114": {"followers": "82", "datetime": "2019-08-24 18:23:16", "author": "@srmq", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165335915797078017": {"followers": "55", "datetime": "2019-08-24 18:51:47", "author": "@sergei3000", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165124721077379073": {"followers": "163", "datetime": "2019-08-24 04:52:35", "author": "@ChurchillMic", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166398744901718016": {"followers": "929", "datetime": "2019-08-27 17:15:06", "author": "@saosob2", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180817216452751361": {"followers": "463", "datetime": "2019-10-06 12:08:57", "author": "@8kazu3", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1231955279945912320": {"followers": "7,444", "datetime": "2020-02-24 14:53:22", "author": "@o_guest", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1165621638408241152": {"followers": "2,169", "datetime": "2019-08-25 13:47:09", "author": "@mentorcapital1", "content_summary": "RT @microsurgeonbot: Reconciling modern machine learning and the bias-variance trade-off \"...boosting with decision trees and Random Fores\u2026"}, "1166450005483245568": {"followers": "446", "datetime": "2019-08-27 20:38:47", "author": "@fikurin", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165343092997857281": {"followers": "10", "datetime": "2019-08-24 19:20:19", "author": "@T920134", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165226101284773888": {"followers": "58", "datetime": "2019-08-24 11:35:26", "author": "@ccanojavi", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165220970069549056": {"followers": "246", "datetime": "2019-08-24 11:15:02", "author": "@hafeezmhd", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165676483743846400": {"followers": "10", "datetime": "2019-08-25 17:25:05", "author": "@MadhavKhosla3", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165323200349298688": {"followers": "284", "datetime": "2019-08-24 18:01:16", "author": "@narayanps_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1227004877575843840": {"followers": "118", "datetime": "2020-02-10 23:02:14", "author": "@zaidanfund", "content_summary": "RT @nardtree: \u4f1a\u793e\u3067\u3081\u3063\u3061\u3083\u6279\u5224\u7684\u306a\u8ad6\u8a55\u3060\u3063\u305f\u3002\u50d5\u3082\u305d\u3046\u601d\u3046\u304c\u3001Deep\u3060\u3068\u3088\u304f\u306a\u308b\u3053\u3068\u3082\u3042\u3063\u3066\u4e00\u822c\u5316\u3059\u308b\u3088\u3046\u306a\u7406\u8ad6\u3058\u3083\u306a\u3044\u307f\u305f\u3044\u306a\u610f\u898b\u3002 / 2\u4ef6\u306e\u30b3\u30e1\u30f3\u30c8 https://t.co/dakKZUE0zl \u201c[1812.11118] Reconciling mo\u2026"}, "1166197797047042049": {"followers": "155", "datetime": "2019-08-27 03:56:36", "author": "@hitsgub", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165913862857736192": {"followers": "5,049", "datetime": "2019-08-26 09:08:21", "author": "@mortensode", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166165948857909248": {"followers": "280", "datetime": "2019-08-27 01:50:03", "author": "@ADMIS_Walker", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166208515855151104": {"followers": "232", "datetime": "2019-08-27 04:39:11", "author": "@mayataka_", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166315658788737029": {"followers": "227", "datetime": "2019-08-27 11:44:56", "author": "@White_Desire", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165654908940537857": {"followers": "266", "datetime": "2019-08-25 15:59:21", "author": "@MwendaMugendi", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180656799470379011": {"followers": "251", "datetime": "2019-10-06 01:31:31", "author": "@mshero_y", "content_summary": "RT @hillbig: The bias-variance tradeoff shows that a model with appropriate complexity can generalize. Recent \"double descent\" indicates th\u2026"}, "1228420335986528257": {"followers": "919", "datetime": "2020-02-14 20:46:45", "author": "@dgarcia_eu", "content_summary": "This paper just blew my mind: https://t.co/4ZnhuMO1Od"}, "1166183987758321664": {"followers": "155", "datetime": "2019-08-27 03:01:43", "author": "@Trtd6Trtd", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166497374983708672": {"followers": "512", "datetime": "2019-08-27 23:47:01", "author": "@outlandkarasu", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165394904610168833": {"followers": "21,221", "datetime": "2019-08-24 22:46:11", "author": "@DataSciNews", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168820155788353536": {"followers": "129", "datetime": "2019-09-03 09:36:55", "author": "@RndWalk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180979728850833408": {"followers": "27,678", "datetime": "2019-10-06 22:54:43", "author": "@h_okumura", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1180659708044050433": {"followers": "1,043", "datetime": "2019-10-06 01:43:04", "author": "@hidekikawahara", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1167661307962769408": {"followers": "11,078", "datetime": "2019-08-31 04:52:04", "author": "@tdualdir", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165522908388757504": {"followers": "322", "datetime": "2019-08-25 07:14:50", "author": "@anirbanakash", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166182076741083136": {"followers": "549", "datetime": "2019-08-27 02:54:08", "author": "@k_matsuzaki", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1164945312198189057": {"followers": "1,411", "datetime": "2019-08-23 16:59:40", "author": "@RexDouglass", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165336569902845952": {"followers": "100", "datetime": "2019-08-24 18:54:23", "author": "@LucaLonini", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1202690460080377856": {"followers": "2,658", "datetime": "2019-12-05 20:45:25", "author": "@AlexGDimakis", "content_summary": "@NishanthDikkala yup- see https://t.co/FpEt6DjqQp for Random Fourier Feature models"}, "1079576220562534401": {"followers": "311", "datetime": "2018-12-31 03:13:23", "author": "@arxiv_cs_LG", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off. Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal https://t.co/ZJZfiCustW"}, "1165589404905291777": {"followers": "127", "datetime": "2019-08-25 11:39:04", "author": "@moody_scientist", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165208387111596033": {"followers": "35", "datetime": "2019-08-24 10:25:02", "author": "@datasavyguy", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168752963851915264": {"followers": "24", "datetime": "2019-09-03 05:09:55", "author": "@NORA__0013", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165565420591620096": {"followers": "30,127", "datetime": "2019-08-25 10:03:46", "author": "@pathogenomenick", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165444057566470144": {"followers": "290", "datetime": "2019-08-25 02:01:30", "author": "@VESTEDTECH", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1204335837875490822": {"followers": "1,938", "datetime": "2019-12-10 09:43:33", "author": "@EldarSilver", "content_summary": "RT @LuigiFreda: A new surprising perspective:  a \"double descent\" curve that subsumes the U-shaped bias-variance trade-off curve and shows\u2026"}, "1214745508901785606": {"followers": "948", "datetime": "2020-01-08 03:07:52", "author": "@narges_razavian", "content_summary": "Adding the double descent paper to lecture 1 of my introductory ML course.. Who would've thought? Reconciling modern machine learning practice and the bias-variance trade-off Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal https://t.co/fzMTv4Jd6P (&a"}, "1166833765978521602": {"followers": "48", "datetime": "2019-08-28 22:03:43", "author": "@mpsampat", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165271330431782913": {"followers": "818", "datetime": "2019-08-24 14:35:09", "author": "@btcplanet", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165822477823442944": {"followers": "41", "datetime": "2019-08-26 03:05:13", "author": "@aiton5", "content_summary": "RT @orcinus_orca: \u3053\u308c\u306f\u3082\u3063\u3068\u77e5\u3089\u308c\u308b\u3079\u304d\u8ad6\u6587 https://t.co/Tkhbx3bF7z"}, "1180683212277731329": {"followers": "171", "datetime": "2019-10-06 03:16:28", "author": "@ac_tle_wa", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165054763152678912": {"followers": "271", "datetime": "2019-08-24 00:14:35", "author": "@jejjohnson", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168976493675974656": {"followers": "112", "datetime": "2019-09-03 19:58:09", "author": "@ravkalia1", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165220271982292992": {"followers": "1,025", "datetime": "2019-08-24 11:12:16", "author": "@desertnaut", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165205385709522944": {"followers": "76,883", "datetime": "2019-08-24 10:13:07", "author": "@NandoDF", "content_summary": "I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further."}, "1165235503374823425": {"followers": "20", "datetime": "2019-08-24 12:12:47", "author": "@ChigaliNikhil", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180687828553854976": {"followers": "82", "datetime": "2019-10-06 03:34:49", "author": "@mitsunaka1984", "content_summary": "Sounds interesting. The idea that starting from over-fitted models is not bad."}, "1166443662915579904": {"followers": "127", "datetime": "2019-08-27 20:13:35", "author": "@AmosOketch", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166550718762946562": {"followers": "122", "datetime": "2019-08-28 03:18:59", "author": "@BCultice4", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166677829213286408": {"followers": "382", "datetime": "2019-08-28 11:44:04", "author": "@JLefortBesnard", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180659827640430592": {"followers": "12", "datetime": "2019-10-06 01:43:33", "author": "@phdax", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165050103813398528": {"followers": "455", "datetime": "2019-08-23 23:56:04", "author": "@SingingData", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180666029153775616": {"followers": "1,554", "datetime": "2019-10-06 02:08:11", "author": "@tackman", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165325508080357376": {"followers": "82", "datetime": "2019-08-24 18:10:26", "author": "@yopi_yk", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166179491439235072": {"followers": "28", "datetime": "2019-08-27 02:43:51", "author": "@waishimu0", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165221407409790978": {"followers": "1,025", "datetime": "2019-08-24 11:16:46", "author": "@desertnaut", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166391484121341953": {"followers": "88,923", "datetime": "2019-08-27 16:46:14", "author": "@OriolVinyalsML", "content_summary": "The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some answers / new theories since then!"}, "1166392713891209217": {"followers": "359", "datetime": "2019-08-27 16:51:08", "author": "@Anselmo_C_Paiva", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166187594960388096": {"followers": "41", "datetime": "2019-08-27 03:16:04", "author": "@ATK34911370", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180725141736579072": {"followers": "113", "datetime": "2019-10-06 06:03:05", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj We conclude with some final remarks. \u30fbHistorical absence. \u30fbInductive bias. \u30fbOptimization and practical considerations. \u30fbOutlook. #nextAI https://t.co/8847vXJSoC"}, "1165437455165579264": {"followers": "2,671", "datetime": "2019-08-25 01:35:16", "author": "@ayirpelle", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1241134085075914752": {"followers": "409", "datetime": "2020-03-20 22:46:39", "author": "@jainnitk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166406643459842048": {"followers": "49", "datetime": "2019-08-27 17:46:29", "author": "@_still_green_", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165707376994840576": {"followers": "195", "datetime": "2019-08-25 19:27:51", "author": "@hereticreader", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off - https://t.co/9D1COPFWPY https://t.co/FBru0zuRO9"}, "1165544446055911424": {"followers": "308", "datetime": "2019-08-25 08:40:25", "author": "@_screaming_mm_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1227001121861820417": {"followers": "11,476", "datetime": "2020-02-10 22:47:18", "author": "@icoxfog417", "content_summary": "RT @nardtree: \u4f1a\u793e\u3067\u3081\u3063\u3061\u3083\u6279\u5224\u7684\u306a\u8ad6\u8a55\u3060\u3063\u305f\u3002\u50d5\u3082\u305d\u3046\u601d\u3046\u304c\u3001Deep\u3060\u3068\u3088\u304f\u306a\u308b\u3053\u3068\u3082\u3042\u3063\u3066\u4e00\u822c\u5316\u3059\u308b\u3088\u3046\u306a\u7406\u8ad6\u3058\u3083\u306a\u3044\u307f\u305f\u3044\u306a\u610f\u898b\u3002 / 2\u4ef6\u306e\u30b3\u30e1\u30f3\u30c8 https://t.co/dakKZUE0zl \u201c[1812.11118] Reconciling mo\u2026"}, "1165235055897317376": {"followers": "566", "datetime": "2019-08-24 12:11:01", "author": "@selimonder", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165076974164819968": {"followers": "109", "datetime": "2019-08-24 01:42:51", "author": "@ID9112150632304", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166391694561959936": {"followers": "165", "datetime": "2019-08-27 16:47:05", "author": "@Srikanta_prasad", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165491641454456832": {"followers": "95", "datetime": "2019-08-25 05:10:35", "author": "@seiyab_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1081617463354290176": {"followers": "98", "datetime": "2019-01-05 18:24:33", "author": "@shpotes", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1166457716799397893": {"followers": "1,025", "datetime": "2019-08-27 21:09:26", "author": "@desertnaut", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166306693564829697": {"followers": "1,494", "datetime": "2019-08-27 11:09:19", "author": "@CardiacJoshi", "content_summary": "RT @kdpsinghlab: The \u201cdouble-descent\u201d observed in this paper doesn\u2019t make any sense to me intuitively. As model complexity increases (\u2b07\ufe0fEPV\u2026"}, "1170045067358134272": {"followers": "161", "datetime": "2019-09-06 18:44:17", "author": "@farhanhubble", "content_summary": "RT @jigarkdoshi: From Classical Statistics to Modern Machine Learning. This attempts to explain why we don't overfit when we train for a ve\u2026"}, "1165321120175640577": {"followers": "88", "datetime": "2019-08-24 17:53:00", "author": "@thoughtomata", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180665408983973888": {"followers": "557", "datetime": "2019-10-06 02:05:43", "author": "@ocaokgbu", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165237192022773761": {"followers": "3,414", "datetime": "2019-08-24 12:19:30", "author": "@alxndrkalinin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166158115089371137": {"followers": "287", "datetime": "2019-08-27 01:18:55", "author": "@SPHIX_1", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166412739658551298": {"followers": "1,421", "datetime": "2019-08-27 18:10:42", "author": "@1RealLawrence", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165703377214291968": {"followers": "1", "datetime": "2019-08-25 19:11:57", "author": "@_tatdat", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180654412684873729": {"followers": "12,765", "datetime": "2019-10-06 01:22:02", "author": "@jaguring1", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165075858589138944": {"followers": "1,084", "datetime": "2019-08-24 01:38:25", "author": "@Atabey_Kaygun", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1227017131646164993": {"followers": "816", "datetime": "2020-02-10 23:50:55", "author": "@BlkHwk0ps", "content_summary": "RT @nardtree: \u4f1a\u793e\u3067\u3081\u3063\u3061\u3083\u6279\u5224\u7684\u306a\u8ad6\u8a55\u3060\u3063\u305f\u3002\u50d5\u3082\u305d\u3046\u601d\u3046\u304c\u3001Deep\u3060\u3068\u3088\u304f\u306a\u308b\u3053\u3068\u3082\u3042\u3063\u3066\u4e00\u822c\u5316\u3059\u308b\u3088\u3046\u306a\u7406\u8ad6\u3058\u3083\u306a\u3044\u307f\u305f\u3044\u306a\u610f\u898b\u3002 / 2\u4ef6\u306e\u30b3\u30e1\u30f3\u30c8 https://t.co/dakKZUE0zl \u201c[1812.11118] Reconciling mo\u2026"}, "1165515758492934145": {"followers": "716", "datetime": "2019-08-25 06:46:25", "author": "@pvtodorov", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165217971905671168": {"followers": "166", "datetime": "2019-08-24 11:03:07", "author": "@NishanthVAnand", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1188385039592984577": {"followers": "234", "datetime": "2019-10-27 09:20:47", "author": "@quantumbtc", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1180719208058904576": {"followers": "482", "datetime": "2019-10-06 05:39:30", "author": "@P_tan", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1214769779501916160": {"followers": "243", "datetime": "2020-01-08 04:44:19", "author": "@CasualBrady", "content_summary": "@sandeepssrin @shashank27392 Belkin et al. (2019) run some experiments on random forests, providing some evidence for a double descent curve there too. https://t.co/oMF0UYij9z"}, "1166176583192698881": {"followers": "5,618", "datetime": "2019-08-27 02:32:18", "author": "@__MLT__", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165328819370283011": {"followers": "111", "datetime": "2019-08-24 18:23:35", "author": "@Triamus1", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1205377158614528000": {"followers": "7,444", "datetime": "2019-12-13 06:41:24", "author": "@o_guest", "content_summary": "I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep network models are overfit, so I'm mentioning it here: Preprint: https://t.co/w2Z1jxZKvj Talk: https://t.co/4yUFk06JaC https://"}, "1180774451287191554": {"followers": "2,043", "datetime": "2019-10-06 09:19:01", "author": "@imenurok", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1164955305643401218": {"followers": "1,673", "datetime": "2019-08-23 17:39:23", "author": "@RyanDavidReece", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1193982309797486592": {"followers": "868", "datetime": "2019-11-11 20:02:20", "author": "@cinjoncin", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165378322878160896": {"followers": "72", "datetime": "2019-08-24 21:40:18", "author": "@jonasrbati", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165494465420812288": {"followers": "1,860", "datetime": "2019-08-25 05:21:49", "author": "@Ritmonegro", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165230157772263424": {"followers": "366", "datetime": "2019-08-24 11:51:33", "author": "@iugoaoj", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1177279055885783041": {"followers": "469", "datetime": "2019-09-26 17:49:34", "author": "@KameronDHarris", "content_summary": "Check out this paper: \"Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off\" by Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal https://t.co/tCuXWlUm6K https://t.co/gBjnrxPqrs https://t.co/zk36mYdMhm"}, "1167657599258353664": {"followers": "1,838", "datetime": "2019-08-31 04:37:20", "author": "@acidflask", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1194189048207888384": {"followers": "76,883", "datetime": "2019-11-12 09:43:50", "author": "@NandoDF", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1164962217311252481": {"followers": "789", "datetime": "2019-08-23 18:06:51", "author": "@eprosenthal", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180688670325522433": {"followers": "133", "datetime": "2019-10-06 03:38:09", "author": "@sakaikuro5", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165286182340530176": {"followers": "1", "datetime": "2019-08-24 15:34:10", "author": "@chengadian", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165031691490091008": {"followers": "8,290", "datetime": "2019-08-23 22:42:55", "author": "@SantchiWeb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202949171759722496": {"followers": "633", "datetime": "2019-12-06 13:53:26", "author": "@danbjork", "content_summary": "Puzzle: what if a solution to overfitting is over-overfitting? See https://t.co/Hc2IkgZert"}, "1165515847860834307": {"followers": "5", "datetime": "2019-08-25 06:46:47", "author": "@MyungsubChoi", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1168666465869991937": {"followers": "1,367", "datetime": "2019-09-02 23:26:12", "author": "@quantrad", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1225942276972609537": {"followers": "97", "datetime": "2020-02-08 00:39:50", "author": "@ds_vault", "content_summary": "[1812.11118] Reconciling modern machine learning practice and the bias-variance trade-off - https://t.co/MGGnA3Bwcj - #machinelearning"}, "1165428394911305728": {"followers": "326", "datetime": "2019-08-25 00:59:16", "author": "@ifndef_define", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1181001725248847879": {"followers": "756", "datetime": "2019-10-07 00:22:07", "author": "@cobodo", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166487469769969664": {"followers": "17", "datetime": "2019-08-27 23:07:39", "author": "@maenosono", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165245598972436481": {"followers": "7,556", "datetime": "2019-08-24 12:52:54", "author": "@brandondamos", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166720918074380293": {"followers": "23,484", "datetime": "2019-08-28 14:35:18", "author": "@THEAdamGabriel", "content_summary": "HT KirkDBorne : Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff:https://t.co/ii0ECM8lPM The \"bias-variance\" you knew was just the first piece of the s"}, "1166392283912114176": {"followers": "8,290", "datetime": "2019-08-27 16:49:25", "author": "@SantchiWeb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165078160532070400": {"followers": "245", "datetime": "2019-08-24 01:47:34", "author": "@MarkTan57229491", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165377164709126144": {"followers": "43", "datetime": "2019-08-24 21:35:42", "author": "@NathanTDonnelly", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165053171607031808": {"followers": "3,772", "datetime": "2019-08-24 00:08:16", "author": "@volkuleshov", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1218832418435670016": {"followers": "7,444", "datetime": "2020-01-19 09:47:48", "author": "@o_guest", "content_summary": "@john_t_ormerod @deanmarchiori Although please remember that not all overfitting is bad. https://t.co/E3jsIdJH34"}, "1166339951526469632": {"followers": "301", "datetime": "2019-08-27 13:21:28", "author": "@hogejun", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1193866507823902721": {"followers": "218", "datetime": "2019-11-11 12:22:11", "author": "@AssistedEvolve", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166184850681843713": {"followers": "482", "datetime": "2019-08-27 03:05:09", "author": "@type613", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180714300102414336": {"followers": "113", "datetime": "2019-10-06 05:20:00", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj <1/4>When the number of features is much smaller then the sample size, N n, classical statistical arguments imply that the training risk is close to the test risk. ... #nextAI https://t.co/eWxMgVukGo"}, "1204467590774579202": {"followers": "537", "datetime": "2019-12-10 18:27:06", "author": "@albarjip", "content_summary": "More info about the mechanisms behind the double descent curve https://t.co/SS60AWvroN"}, "1166192503902461952": {"followers": "626", "datetime": "2019-08-27 03:35:34", "author": "@yan_hisa_", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166203802635997185": {"followers": "1,019", "datetime": "2019-08-27 04:20:28", "author": "@sasasasasa339", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165227054113181696": {"followers": "1,417", "datetime": "2019-08-24 11:39:13", "author": "@seanmylaw", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166505787109232645": {"followers": "1,103", "datetime": "2019-08-28 00:20:26", "author": "@scottedwards200", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165629906304348160": {"followers": "1,375", "datetime": "2019-08-25 14:20:00", "author": "@hazem_awad", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165178263091720193": {"followers": "95", "datetime": "2019-08-24 08:25:20", "author": "@Lefiish", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165361053871439872": {"followers": "7,225", "datetime": "2019-08-24 20:31:41", "author": "@DBAKevlar", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165262654199361542": {"followers": "43", "datetime": "2019-08-24 14:00:40", "author": "@J_C_Bedoya", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1226710136678256640": {"followers": "8,954", "datetime": "2020-02-10 03:31:02", "author": "@nardtree", "content_summary": "\u4f1a\u793e\u3067\u3081\u3063\u3061\u3083\u6279\u5224\u7684\u306a\u8ad6\u8a55\u3060\u3063\u305f\u3002\u50d5\u3082\u305d\u3046\u601d\u3046\u304c\u3001Deep\u3060\u3068\u3088\u304f\u306a\u308b\u3053\u3068\u3082\u3042\u3063\u3066\u4e00\u822c\u5316\u3059\u308b\u3088\u3046\u306a\u7406\u8ad6\u3058\u3083\u306a\u3044\u307f\u305f\u3044\u306a\u610f\u898b\u3002 / 2\u4ef6\u306e\u30b3\u30e1\u30f3\u30c8 https://t.co/dakKZUE0zl \u201c[1812.11118] Reconciling modern machine learning practice and the bias-variance trade-off\u201d https://t.co/NvMgrdzy3r"}, "1166187872128364547": {"followers": "157", "datetime": "2019-08-27 03:17:10", "author": "@igx63je2", "content_summary": "\u500b\u4eba\u7684\u306b\u306f\u91c8\u7136\u3068\u3057\u306a\u3044\u3051\u3069\u3001\u9762\u767d\u305d\u3046\u3067\u306f\u3042\u308b\u306e\u3067\u8aad\u3093\u3067\u307f\u3088\u3046"}, "1180669047194603521": {"followers": "36", "datetime": "2019-10-06 02:20:11", "author": "@lateralrabbit", "content_summary": "RT @hillbig: The bias-variance tradeoff shows that a model with appropriate complexity can generalize. Recent \"double descent\" indicates th\u2026"}, "1166572196929638400": {"followers": "2,165", "datetime": "2019-08-28 04:44:20", "author": "@SiQuizas", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165266835777835013": {"followers": "651", "datetime": "2019-08-24 14:17:17", "author": "@iamsidd", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165577838012952576": {"followers": "403", "datetime": "2019-08-25 10:53:06", "author": "@momijipan", "content_summary": "\u3053\u308c Reconciling modern machine learning and the bias-variance trade-off https://t.co/NQ1sexBXU5"}, "1165567449351249921": {"followers": "48", "datetime": "2019-08-25 10:11:49", "author": "@mzadrogaPL", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165269042791424001": {"followers": "66", "datetime": "2019-08-24 14:26:04", "author": "@vadim__uvarov", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165378205399814146": {"followers": "7", "datetime": "2019-08-24 21:39:50", "author": "@panteon_college", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165511010377224192": {"followers": "423", "datetime": "2019-08-25 06:27:33", "author": "@Elwardy", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1198308993254526980": {"followers": "1,832", "datetime": "2019-11-23 18:35:02", "author": "@drahmadbazzi", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166398929115799552": {"followers": "1,142", "datetime": "2019-08-27 17:15:50", "author": "@deepindex", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165143420567834625": {"followers": "104", "datetime": "2019-08-24 06:06:53", "author": "@alfo_512", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165314577258754048": {"followers": "2,568", "datetime": "2019-08-24 17:27:00", "author": "@mathz_aragao", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1193839121766195205": {"followers": "43", "datetime": "2019-11-11 10:33:21", "author": "@jeandut14000", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166719213639217153": {"followers": "1,247", "datetime": "2019-08-28 14:28:31", "author": "@rlingle", "content_summary": "RT KirkDBorne: RT IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and the Bias-Variance Tradeoff: https://t.co/tmeyudsIJr The \"bias-variance\" you knew was just the firs\u2026 h"}, "1220023973183807489": {"followers": "63", "datetime": "2020-01-22 16:42:36", "author": "@wail_baalawi", "content_summary": "Very cool paper describing an interesting phenomenon when training models! #MachineLearning #\u0639\u0644\u0645_\u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a https://t.co/HiTBQ8WttV https://t.co/6kY4MaTQ9P"}, "1170956841901146112": {"followers": "66", "datetime": "2019-09-09 07:07:21", "author": "@marcus_marcusg", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1203077158899466240": {"followers": "646", "datetime": "2019-12-06 22:22:01", "author": "@c_f_baumgartner", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1081622328885301248": {"followers": "888", "datetime": "2019-01-05 18:43:53", "author": "@RichmanRonald", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1166418570961727488": {"followers": "121", "datetime": "2019-08-27 18:33:52", "author": "@_lychrel", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1195753062620704768": {"followers": "218", "datetime": "2019-11-16 17:18:40", "author": "@ShyBOT7", "content_summary": "RT @Deep_In_Depth: Reconciling modern machine learning practice and the bias-variance trade-off https://t.co/KFOhgBLrSR #DeepLearning #Mach\u2026"}, "1212423581059170306": {"followers": "28,195", "datetime": "2020-01-01 17:21:22", "author": "@halvarflake", "content_summary": "@zacharylipton Not sure there's a \"single\" paper to note, but the entire discussion about double-descent has been the most interesting thing I read this year: 1) https://t.co/Y4GyQx1XeQ - \"Reconciling modern machine learning practice and the bias-variance"}, "1166418141506887680": {"followers": "595", "datetime": "2019-08-27 18:32:10", "author": "@popedaniels", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165077667282149377": {"followers": "541", "datetime": "2019-08-24 01:45:36", "author": "@o_ursu", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168439929564749824": {"followers": "29", "datetime": "2019-09-02 08:26:02", "author": "@ATHANOR11", "content_summary": "RT @francoisfleuret: So is the idea in Belkin's paper simply that when the training error is zero and you increase your model space, you ca\u2026"}, "1166161129325780992": {"followers": "143", "datetime": "2019-08-27 01:30:54", "author": "@srmfsan", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165309002143678464": {"followers": "2,262", "datetime": "2019-08-24 17:04:51", "author": "@AdilMouja", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166483862756589569": {"followers": "220", "datetime": "2019-08-27 22:53:19", "author": "@OztabakAli", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1169759939713228800": {"followers": "66", "datetime": "2019-09-05 23:51:17", "author": "@diegovogeid", "content_summary": "RT @jigarkdoshi: From Classical Statistics to Modern Machine Learning. This attempts to explain why we don't overfit when we train for a ve\u2026"}, "1202655629132943361": {"followers": "242", "datetime": "2019-12-05 18:27:00", "author": "@blauigris", "content_summary": "RT @fluck_5: It's great to see more work on the double descent phenomenon. It comes as a good reminder for me to re-visit Belkin et al. (ht\u2026"}, "1166199347064606721": {"followers": "2,263", "datetime": "2019-08-27 04:02:45", "author": "@myu65_laurant", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1227990031643684864": {"followers": "3,017", "datetime": "2020-02-13 16:16:53", "author": "@JDB10101", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1166350448946810882": {"followers": "793", "datetime": "2019-08-27 14:03:11", "author": "@shkoga", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165017278217445376": {"followers": "17", "datetime": "2019-08-23 21:45:38", "author": "@andybaoxv", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165524202650103808": {"followers": "9,945", "datetime": "2019-08-25 07:19:58", "author": "@ted_dunning", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165218194342043649": {"followers": "215", "datetime": "2019-08-24 11:04:00", "author": "@Akihiro_Sanada", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166249759474114562": {"followers": "194", "datetime": "2019-08-27 07:23:05", "author": "@jeremyr_ash", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1172218341295083523": {"followers": "178", "datetime": "2019-09-12 18:40:05", "author": "@ShellDozer", "content_summary": "RT @halvarflake: To my great surprise, I found a few minutes of downtime today to read https://t.co/Y4GyQx1XeQ. If you are into ML or stati\u2026"}, "1165405423001845766": {"followers": "13", "datetime": "2019-08-24 23:27:59", "author": "@MarekTempe", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165298038514098176": {"followers": "75", "datetime": "2019-08-24 16:21:17", "author": "@adityachivu", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166171279088422913": {"followers": "130", "datetime": "2019-08-27 02:11:14", "author": "@hidenori_mikami", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1205413205029339137": {"followers": "1,415", "datetime": "2019-12-13 09:04:38", "author": "@twitemp1", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1165222803404201985": {"followers": "56", "datetime": "2019-08-24 11:22:19", "author": "@wulab", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166160071094489089": {"followers": "600", "datetime": "2019-08-27 01:26:41", "author": "@TERURINi", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166176475382460419": {"followers": "3,793", "datetime": "2019-08-27 02:31:52", "author": "@IAmSamFin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1203113384469647360": {"followers": "121", "datetime": "2019-12-07 00:45:58", "author": "@blaine_bateman", "content_summary": "@datitran @neozero497 https://t.co/t0F8tvdIFU"}, "1172077920883499009": {"followers": "346", "datetime": "2019-09-12 09:22:07", "author": "@paolino", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1194513848977350657": {"followers": "86", "datetime": "2019-11-13 07:14:29", "author": "@endoaki2", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1194234088049139712": {"followers": "2", "datetime": "2019-11-12 12:42:49", "author": "@Sheuancts", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1194039718515593216": {"followers": "522", "datetime": "2019-11-11 23:50:27", "author": "@pijili", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165369721765523456": {"followers": "285", "datetime": "2019-08-24 21:06:07", "author": "@x_ohard", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180757089842413568": {"followers": "1,055", "datetime": "2019-10-06 08:10:02", "author": "@nassyemon", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166399327822110720": {"followers": "293", "datetime": "2019-08-27 17:17:25", "author": "@bala_io", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1199002541083648001": {"followers": "181", "datetime": "2019-11-25 16:30:56", "author": "@atsushi1104ak", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1203719886821826560": {"followers": "323", "datetime": "2019-12-08 16:55:59", "author": "@LuigiFreda", "content_summary": "A new surprising perspective:  a \"double descent\" curve that subsumes the U-shaped bias-variance trade-off curve and shows how increasing model capacity beyond the point of interpolation results in improved performance.  https://t.co/uGtN7TH45v https://t."}, "1165014756370997249": {"followers": "615", "datetime": "2019-08-23 21:35:37", "author": "@2prime_PKU", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180652677400686592": {"followers": "135", "datetime": "2019-10-06 01:15:08", "author": "@tao_zero", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165396944308461569": {"followers": "0", "datetime": "2019-08-24 22:54:18", "author": "@RonaldGXie1", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165304139750027264": {"followers": "16", "datetime": "2019-08-24 16:45:31", "author": "@p_kot1", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1181130705704611840": {"followers": "30", "datetime": "2019-10-07 08:54:39", "author": "@gbiwer", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165882763544801280": {"followers": "96", "datetime": "2019-08-26 07:04:46", "author": "@tivaro", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166214442536714240": {"followers": "150", "datetime": "2019-08-27 05:02:44", "author": "@HARDDOCK17", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166218250381746177": {"followers": "86", "datetime": "2019-08-27 05:17:52", "author": "@endoaki2", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180719072029229056": {"followers": "113", "datetime": "2019-10-06 05:38:58", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj The posited mechanism that underlies its emergence is based on common inductive biases, and hence can explain its appearance (and, we argue, ubiquity) in machine learning applications.#nextAI https://t.co/Yc4k0WEkN2"}, "1212624880102862849": {"followers": "2,671", "datetime": "2020-01-02 06:41:15", "author": "@ayirpelle", "content_summary": "RT @halvarflake: @zacharylipton Not sure there's a \"single\" paper to note, but the entire discussion about double-descent has been the most\u2026"}, "1166290339784642560": {"followers": "264", "datetime": "2019-08-27 10:04:20", "author": "@yauta01", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1214920399475097600": {"followers": "874", "datetime": "2020-01-08 14:42:50", "author": "@mrdrozdov", "content_summary": "RT @narges_razavian: Adding the double descent paper to lecture 1 of my introductory ML course.. Who would've thought? Reconciling modern\u2026"}, "1168287202104811520": {"followers": "94", "datetime": "2019-09-01 22:19:09", "author": "@vitobellini", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1260627433935560706": {"followers": "80", "datetime": "2020-05-13 17:46:16", "author": "@AtroX_Worf", "content_summary": "@TheGregYang Is this somehow related to this strain of research? https://t.co/kffdfj0ROu"}, "1165577983861460992": {"followers": "323", "datetime": "2019-08-25 10:53:41", "author": "@liuziwei7", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165220740901289984": {"followers": "412", "datetime": "2019-08-24 11:14:08", "author": "@iacopo_poli", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165226303085301761": {"followers": "2,231", "datetime": "2019-08-24 11:36:14", "author": "@GiuseppeB", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166204479915450368": {"followers": "1,667", "datetime": "2019-08-27 04:23:09", "author": "@Scaled_Wurm", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166168487821099008": {"followers": "554", "datetime": "2019-08-27 02:00:08", "author": "@FBWM8888", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1171167073491443718": {"followers": "7", "datetime": "2019-09-09 21:02:44", "author": "@GreenTitarenko", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165303850045071365": {"followers": "226", "datetime": "2019-08-24 16:44:22", "author": "@neprasad", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166156329511079936": {"followers": "2,532", "datetime": "2019-08-27 01:11:49", "author": "@kusano_k", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166646232749461504": {"followers": "2", "datetime": "2019-08-28 09:38:31", "author": "@_kalngyk", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166188729796448258": {"followers": "548", "datetime": "2019-08-27 03:20:34", "author": "@st_tahara", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165857331608862720": {"followers": "293", "datetime": "2019-08-26 05:23:43", "author": "@venkatesanragav", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167064461422686208": {"followers": "234", "datetime": "2019-08-29 13:20:25", "author": "@quantumbtc", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1193877237260521472": {"followers": "1,382", "datetime": "2019-11-11 13:04:49", "author": "@bouzoukipunks", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1194256577638752261": {"followers": "132", "datetime": "2019-11-12 14:12:10", "author": "@Volton007", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166461762813616128": {"followers": "435", "datetime": "2019-08-27 21:25:30", "author": "@kawauso_kun", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165268023399387136": {"followers": "78", "datetime": "2019-08-24 14:22:01", "author": "@jordi_delatorre", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165627229730156544": {"followers": "3,519", "datetime": "2019-08-25 14:09:22", "author": "@Amy_Kate_USA", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1081479028224122880": {"followers": "88", "datetime": "2019-01-05 09:14:27", "author": "@Epsilon_Lee", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1166985848086155265": {"followers": "17", "datetime": "2019-08-29 08:08:02", "author": "@Tagxys", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165219718447456256": {"followers": "2,473", "datetime": "2019-08-24 11:10:04", "author": "@Pac_Kd", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166762716880523264": {"followers": "96", "datetime": "2019-08-28 17:21:23", "author": "@lissamelodia", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165367162510487552": {"followers": "2,042", "datetime": "2019-08-24 20:55:57", "author": "@davidjayharris", "content_summary": "Wow, this is a weird approach that would never be useful for training real models, but it\u2019s perfect for gaining insight about what exactly is happening with over-parameterized models that don\u2019t overfit. I\u2019m really impressed. https://t.co/XhimNKMCKH"}, "1180715273109684224": {"followers": "113", "datetime": "2019-10-06 05:23:52", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj In general multilayer neural networks (beyond RFF or ReLU random feature models), a learning algorithm will tune all of the weights to fit the training data, typically using versions of SGD, with backpropagation to compute partial d"}, "1165339564745080832": {"followers": "397", "datetime": "2019-08-24 19:06:17", "author": "@AfoUnofficial", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1258370586562252801": {"followers": "7,444", "datetime": "2020-05-07 12:18:21", "author": "@o_guest", "content_summary": "@KordingLab I haven't read this yet, but is it related to this? Either way \u2014 this is a very cool paper below: https://t.co/E3jsIdJH34"}, "1147674133938884609": {"followers": "188", "datetime": "2019-07-07 01:10:10", "author": "@colobas_", "content_summary": "Check my new post (https://t.co/3R7QaB2OMG) summarizing Prof. Mikhail Belkin's paper \"Reconciling modern machine learning with the bias-variance trade-off\". Or better yet, read the actual paper: https://t.co/IGtbqCJNqQ . Its ideas are very cool"}, "1164950517337821185": {"followers": "20", "datetime": "2019-08-23 17:20:21", "author": "@Alvin_Zhang91", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165376553561284608": {"followers": "328", "datetime": "2019-08-24 21:33:16", "author": "@imdibene", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165498914306494466": {"followers": "5,437", "datetime": "2019-08-25 05:39:29", "author": "@Daniel_Lerch", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165280305244192768": {"followers": "689", "datetime": "2019-08-24 15:10:49", "author": "@ChrKroer", "content_summary": "Really compelling paper co-authored by a fellow @CUSEAS faculty."}, "1167003577258323970": {"followers": "7", "datetime": "2019-08-29 09:18:29", "author": "@LYTiQ_ai", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1079957972405682176": {"followers": "748", "datetime": "2019-01-01 04:30:19", "author": "@Eschersand", "content_summary": "RT @arXiv_stat_ML: https://t.co/AnoBlstjfL M Belkin et. al. Reconciling modern machine learning and the bias-variance trade-off https://t.c\u2026"}, "1165226245392453633": {"followers": "35", "datetime": "2019-08-24 11:36:00", "author": "@junsukchoe", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166709803961290753": {"followers": "131", "datetime": "2019-08-28 13:51:08", "author": "@KrishaMehta2", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166233128622575618": {"followers": "50", "datetime": "2019-08-27 06:17:00", "author": "@kushalchauhan98", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166459371569778688": {"followers": "118", "datetime": "2019-08-27 21:16:00", "author": "@matthewopala", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165565883391062018": {"followers": "8,290", "datetime": "2019-08-25 10:05:36", "author": "@SantchiWeb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1206290527743643649": {"followers": "559", "datetime": "2019-12-15 19:10:48", "author": "@zachshorne", "content_summary": "fascinating paper"}, "1172923377998336000": {"followers": "14", "datetime": "2019-09-14 17:21:39", "author": "@x0axz", "content_summary": "RT @halvarflake: To my great surprise, I found a few minutes of downtime today to read https://t.co/Y4GyQx1XeQ. If you are into ML or stati\u2026"}, "1165228134217723915": {"followers": "142", "datetime": "2019-08-24 11:43:30", "author": "@random_walk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165302667209400325": {"followers": "102", "datetime": "2019-08-24 16:39:40", "author": "@jussyasha", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1204514769786433541": {"followers": "477", "datetime": "2019-12-10 21:34:34", "author": "@yasuokajihei", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1195753084439453701": {"followers": "5,153", "datetime": "2019-11-16 17:18:46", "author": "@clairebotai", "content_summary": "RT @Deep_In_Depth: Reconciling modern machine learning practice and the bias-variance trade-off https://t.co/KFOhgBLrSR #DeepLearning #Mach\u2026"}, "1165293953366679552": {"followers": "71", "datetime": "2019-08-24 16:05:03", "author": "@eigenVishal", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165298837772263424": {"followers": "124", "datetime": "2019-08-24 16:24:27", "author": "@Gab99559017", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165713953281867776": {"followers": "615", "datetime": "2019-08-25 19:53:59", "author": "@KouroshMeshgi", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1259631057730777088": {"followers": "7,444", "datetime": "2020-05-10 23:47:01", "author": "@o_guest", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1165330209324904449": {"followers": "15", "datetime": "2019-08-24 18:29:07", "author": "@erickTorneroT", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166541348356251648": {"followers": "922", "datetime": "2019-08-28 02:41:45", "author": "@m0_no_", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1164950865641431040": {"followers": "1,020", "datetime": "2019-08-23 17:21:44", "author": "@serrjoa", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1205447009265758210": {"followers": "626", "datetime": "2019-12-13 11:18:57", "author": "@krysdolega", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1166400970974064640": {"followers": "296", "datetime": "2019-08-27 17:23:56", "author": "@mauriciogtec", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166160003041906688": {"followers": "299", "datetime": "2019-08-27 01:26:25", "author": "@dai__DDD", "content_summary": "\u3093\uff1f"}, "1165463949912862721": {"followers": "750", "datetime": "2019-08-25 03:20:33", "author": "@data__wizard", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166655949991550981": {"followers": "86", "datetime": "2019-08-28 10:17:08", "author": "@KeviDenam", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166325151576674305": {"followers": "299", "datetime": "2019-08-27 12:22:40", "author": "@CalvinJH", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166646168165572608": {"followers": "2", "datetime": "2019-08-28 09:38:16", "author": "@_kalngyk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165338947687501825": {"followers": "597", "datetime": "2019-08-24 19:03:50", "author": "@alanlaidlaw", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167287396930486273": {"followers": "100", "datetime": "2019-08-30 04:06:17", "author": "@winnietaech", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166562227392000002": {"followers": "22", "datetime": "2019-08-28 04:04:43", "author": "@manojmohan2017", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166328434957541377": {"followers": "72", "datetime": "2019-08-27 12:35:42", "author": "@semiinvariant", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165906353468203009": {"followers": "25,716", "datetime": "2019-08-26 08:38:30", "author": "@pash22", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165476705668083712": {"followers": "43", "datetime": "2019-08-25 04:11:14", "author": "@AdmChess", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165371807752478720": {"followers": "829", "datetime": "2019-08-24 21:14:25", "author": "@AliseOtilia", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166247406918348800": {"followers": "23", "datetime": "2019-08-27 07:13:44", "author": "@lsaeh", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1112179605224521729": {"followers": "8,290", "datetime": "2019-03-31 02:27:35", "author": "@SantchiWeb", "content_summary": "RT @blaine_bateman: Reconciling modern machine learning and the bias-variance trade-off--a new explanation of how neural networks that are\u2026"}, "1180776632308527104": {"followers": "624", "datetime": "2019-10-06 09:27:41", "author": "@Eseshinpu", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1193870533642731521": {"followers": "456", "datetime": "2019-11-11 12:38:10", "author": "@PerthMLGroup", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1167726216914358277": {"followers": "219", "datetime": "2019-08-31 09:10:00", "author": "@diegojavierzea", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165862300114276352": {"followers": "141", "datetime": "2019-08-26 05:43:27", "author": "@lucasvinhtran", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167684135147622400": {"followers": "4,981", "datetime": "2019-08-31 06:22:46", "author": "@physics303", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165266374085742593": {"followers": "210", "datetime": "2019-08-24 14:15:27", "author": "@vamos_alcazar", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166571433746714624": {"followers": "377", "datetime": "2019-08-28 04:41:18", "author": "@carbodeca416", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165519122815422464": {"followers": "167", "datetime": "2019-08-25 06:59:47", "author": "@fferousi", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1257721039007764483": {"followers": "985", "datetime": "2020-05-05 17:17:17", "author": "@mitkoveta", "content_summary": "@MaartenvSmeden If it's relating to a deep neural network, there's some evidence that they are difficult to over-parametrize: https://t.co/CTFfw27ii1"}, "1166170480631377920": {"followers": "28", "datetime": "2019-08-27 02:08:03", "author": "@waishimu0", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165219662315044864": {"followers": "2,473", "datetime": "2019-08-24 11:09:50", "author": "@Pac_Kd", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1079566715019804672": {"followers": "858", "datetime": "2018-12-31 02:35:36", "author": "@deep_rl", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off - Mikhail Belkin https://t.co/wzqnEGf4U9"}, "1193923373895696384": {"followers": "5,248", "datetime": "2019-11-11 16:08:09", "author": "@ParisMLgroup", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165245026613567489": {"followers": "822", "datetime": "2019-08-24 12:50:38", "author": "@JaredHeinly", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1206797353090314240": {"followers": "3,178", "datetime": "2019-12-17 04:44:44", "author": "@Bollegala", "content_summary": "Double descent happens when the model size is increased beyond the interpolation threshold, even for linear models, let alone deep NNs. https://t.co/ArI0ezRabU https://t.co/2o3sOZust8"}, "1180784808181387264": {"followers": "55", "datetime": "2019-10-06 10:00:10", "author": "@view_jp", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1195748477776617472": {"followers": "8,952", "datetime": "2019-11-16 17:00:27", "author": "@Deep_In_Depth", "content_summary": "Reconciling modern machine learning practice and the bias-variance trade-off https://t.co/KFOhgBLrSR #DeepLearning #MachineLearning #ArtificialIntelligence #DataScience #DL #ML #DS #AI #DNN #NeuralNetworks #NLP #GPU #TensorFlow #Keras #Pytorch #Python #HPC"}, "1166191542710591488": {"followers": "90", "datetime": "2019-08-27 03:31:45", "author": "@taro_0718_", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180656943343386624": {"followers": "251", "datetime": "2019-10-06 01:32:05", "author": "@mshero_y", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165206304023072773": {"followers": "615", "datetime": "2019-08-24 10:16:46", "author": "@mattmcd", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165162567146332161": {"followers": "1,288", "datetime": "2019-08-24 07:22:58", "author": "@heghbalz", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165375723076349952": {"followers": "1,491", "datetime": "2019-08-24 21:29:58", "author": "@hide_fromhikari", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166392184297463814": {"followers": "219", "datetime": "2019-08-27 16:49:01", "author": "@DamonCrockett", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166488353744797701": {"followers": "171", "datetime": "2019-08-27 23:11:10", "author": "@aIrb4ck", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165884226606006272": {"followers": "478", "datetime": "2019-08-26 07:10:35", "author": "@jmsteinw", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1205523637878448128": {"followers": "157", "datetime": "2019-12-13 16:23:27", "author": "@baxpr", "content_summary": "RT @o_guest: I was in a workshop that warned against overfitting without mentioning that it's just not the case in practice that many deep\u2026"}, "1165404230305353728": {"followers": "6", "datetime": "2019-08-24 23:23:15", "author": "@LeviMaximoViana", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1227017109571391490": {"followers": "554", "datetime": "2020-02-10 23:50:50", "author": "@FBWM8888", "content_summary": "RT @nardtree: \u4f1a\u793e\u3067\u3081\u3063\u3061\u3083\u6279\u5224\u7684\u306a\u8ad6\u8a55\u3060\u3063\u305f\u3002\u50d5\u3082\u305d\u3046\u601d\u3046\u304c\u3001Deep\u3060\u3068\u3088\u304f\u306a\u308b\u3053\u3068\u3082\u3042\u3063\u3066\u4e00\u822c\u5316\u3059\u308b\u3088\u3046\u306a\u7406\u8ad6\u3058\u3083\u306a\u3044\u307f\u305f\u3044\u306a\u610f\u898b\u3002 / 2\u4ef6\u306e\u30b3\u30e1\u30f3\u30c8 https://t.co/dakKZUE0zl \u201c[1812.11118] Reconciling mo\u2026"}, "1165209660938444800": {"followers": "2,098", "datetime": "2019-08-24 10:30:06", "author": "@ducha_aiki", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1203108627948675072": {"followers": "874", "datetime": "2019-12-07 00:27:04", "author": "@guicho271828", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1166327998615715840": {"followers": "116", "datetime": "2019-08-27 12:33:58", "author": "@masu22445496", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1164953811691159555": {"followers": "75", "datetime": "2019-08-23 17:33:27", "author": "@MozejkoMarcin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165712799286407168": {"followers": "160,790", "datetime": "2019-08-25 19:49:23", "author": "@Quebec_AI", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165298518845730816": {"followers": "154", "datetime": "2019-08-24 16:23:11", "author": "@sobu_18", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165250015498887168": {"followers": "6,146", "datetime": "2019-08-24 13:10:27", "author": "@alexcpsec", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168300177104330752": {"followers": "297", "datetime": "2019-09-01 23:10:42", "author": "@tig33739130", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165925318558920704": {"followers": "28", "datetime": "2019-08-26 09:53:52", "author": "@asdesilva", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166171431605923841": {"followers": "4,136", "datetime": "2019-08-27 02:11:50", "author": "@hanaken_n", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165365387862654982": {"followers": "1,663", "datetime": "2019-08-24 20:48:54", "author": "@george_berry", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1175766739776397312": {"followers": "98", "datetime": "2019-09-22 13:40:10", "author": "@cyber_math", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165425281164861440": {"followers": "299", "datetime": "2019-08-25 00:46:54", "author": "@PogrebnyakE", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180912083690561543": {"followers": "1,545", "datetime": "2019-10-06 18:25:55", "author": "@__shohey__", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165177074157588480": {"followers": "8", "datetime": "2019-08-24 08:20:37", "author": "@elias_sundqvist", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165601011903475712": {"followers": "5", "datetime": "2019-08-25 12:25:11", "author": "@ZidanMusk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165334252659060736": {"followers": "54", "datetime": "2019-08-24 18:45:11", "author": "@vo_d_p", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165593560726560768": {"followers": "771", "datetime": "2019-08-25 11:55:35", "author": "@aCraigPfeifer", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165182002187907072": {"followers": "75", "datetime": "2019-08-24 08:40:12", "author": "@gevero", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165660771151470592": {"followers": "4", "datetime": "2019-08-25 16:22:39", "author": "@modibokhane", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165279676664823809": {"followers": "190", "datetime": "2019-08-24 15:08:19", "author": "@Harssh_Seth", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166206284686753792": {"followers": "23", "datetime": "2019-08-27 04:30:19", "author": "@exstay_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180717782196834304": {"followers": "113", "datetime": "2019-10-06 05:33:50", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj for instance, data sets as large as ImageNet [33], which has \u223c10exp(6) examples and \u223c10exp(3) classes, may require networks with \u223c10exp(9) parameters to achieve interpolation; this is larger than many neural network models for Imag"}, "1166010787992875009": {"followers": "40", "datetime": "2019-08-26 15:33:29", "author": "@hanabanashiku", "content_summary": "Fascinating analysis of the evolution of machine learning techniques. https://t.co/7EDLIgPnWO"}, "1171719330767220736": {"followers": "266", "datetime": "2019-09-11 09:37:12", "author": "@hsh95", "content_summary": "Doesn\u2019t this great work go against Occam\u2019s razor or at least against our \u2018simplistic interpretations\u201d of it? The evidence violates the superficial interpretations of Occam\u2019s razor at least. Am I confused?"}, "1165231434522644481": {"followers": "316", "datetime": "2019-08-24 11:56:37", "author": "@gsarti_", "content_summary": "Fundamental paper to have an intuitive understanding of why overparametrization works well for NN and why we can hope to find optimal reduced representations of some sort!"}, "1165639128987381760": {"followers": "164", "datetime": "2019-08-25 14:56:39", "author": "@ZachBessinger", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165165796772995072": {"followers": "109", "datetime": "2019-08-24 07:35:48", "author": "@HerruzoPedro", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165373103259758592": {"followers": "3,201", "datetime": "2019-08-24 21:19:34", "author": "@TomiyaAkio", "content_summary": "RT @orcinus_orca: \u3053\u308c\u306f\u3082\u3063\u3068\u77e5\u3089\u308c\u308b\u3079\u304d\u8ad6\u6587 https://t.co/Tkhbx3bF7z"}, "1166173916072534016": {"followers": "427", "datetime": "2019-08-27 02:21:42", "author": "@eigencoffee", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165286045086310400": {"followers": "847", "datetime": "2019-08-24 15:33:37", "author": "@TheBradOnSE", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202856068067422209": {"followers": "4", "datetime": "2019-12-06 07:43:29", "author": "@usernametoo29", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1165302275117584384": {"followers": "66", "datetime": "2019-08-24 16:38:07", "author": "@diegovogeid", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166421809228648451": {"followers": "63", "datetime": "2019-08-27 18:46:45", "author": "@hikmatfarhat", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1186539735155691520": {"followers": "30", "datetime": "2019-10-22 07:08:12", "author": "@solvay_1927", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180683566247763968": {"followers": "8,290", "datetime": "2019-10-06 03:17:52", "author": "@SantchiWeb", "content_summary": "RT @SHIMOMURATakuji: https://t.co/FFXHsebuhj The challenge stems from the mismatch between the goals of minimizing the empirical risk (the\u2026"}, "1225585282768146432": {"followers": "1,106", "datetime": "2020-02-07 01:01:16", "author": "@permutans", "content_summary": "RT @vsbuffalo: I quite like this figure (from this paper: https://t.co/dOb10eUQvC), which I think unites why both machine learning and para\u2026"}, "1166975946601029632": {"followers": "1,178", "datetime": "2019-08-29 07:28:41", "author": "@hokuto_sd", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166895073835044864": {"followers": "39", "datetime": "2019-08-29 02:07:20", "author": "@datscien", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165270262620860416": {"followers": "134", "datetime": "2019-08-24 14:30:54", "author": "@Uzziesh", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165437007398653952": {"followers": "160", "datetime": "2019-08-25 01:33:29", "author": "@johnmsheffield", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165364271653326848": {"followers": "32,113", "datetime": "2019-08-24 20:44:28", "author": "@seanjtaylor", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1207623194112352256": {"followers": "14", "datetime": "2019-12-19 11:26:20", "author": "@Radiant_Data", "content_summary": "RT @fluck_5: It's great to see more work on the double descent phenomenon. It comes as a good reminder for me to re-visit Belkin et al. (ht\u2026"}, "1165976532378144770": {"followers": "255", "datetime": "2019-08-26 13:17:22", "author": "@andrewyates", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180744493286322178": {"followers": "1,195", "datetime": "2019-10-06 07:19:59", "author": "@hrs1985", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166318993017200641": {"followers": "2,071", "datetime": "2019-08-27 11:58:11", "author": "@Mocchi_tam", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165390014059933696": {"followers": "1,720", "datetime": "2019-08-24 22:26:45", "author": "@davidvanvalen", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166157372860944384": {"followers": "373", "datetime": "2019-08-27 01:15:58", "author": "@YasuhiroMatz", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165377014821543936": {"followers": "604", "datetime": "2019-08-24 21:35:06", "author": "@claczny", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165358766382026752": {"followers": "145", "datetime": "2019-08-24 20:22:35", "author": "@esvhd", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1242995396605087744": {"followers": "3,449", "datetime": "2020-03-26 02:02:50", "author": "@reiver", "content_summary": "\u300aReconciling modern machine learning practice and the bias-variance trade-off\u300b by Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal https://t.co/KjVAix017p (machine learning) H/T @MikeAIrvine"}, "1166160643902193664": {"followers": "1,280", "datetime": "2019-08-27 01:28:58", "author": "@if_CQ_naka", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166199231335395328": {"followers": "213", "datetime": "2019-08-27 04:02:18", "author": "@goldfish_lab", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166164267843764224": {"followers": "794", "datetime": "2019-08-27 01:43:22", "author": "@TaromaedaMaedat", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1164916769217241088": {"followers": "267", "datetime": "2019-08-23 15:06:15", "author": "@Rpatel_15", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165865155432869888": {"followers": "5", "datetime": "2019-08-26 05:54:48", "author": "@HKFinwatcher", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1183116355362578432": {"followers": "322", "datetime": "2019-10-12 20:24:55", "author": "@letranger14", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168745579511312384": {"followers": "0", "datetime": "2019-09-03 04:40:35", "author": "@Sam09lol", "content_summary": "RT @francoisfleuret: So is the idea in Belkin's paper simply that when the training error is zero and you increase your model space, you ca\u2026"}, "1165046246282645504": {"followers": "732", "datetime": "2019-08-23 23:40:45", "author": "@ghoshd", "content_summary": "\ud83d\udcafthis!!!"}, "1176801044703133697": {"followers": "591", "datetime": "2019-09-25 10:10:07", "author": "@rmaestrem", "content_summary": "The double descent curve #machineLearning \"Reconciling modern machine learning practice and the bias-variance trade-off\" https://t.co/jZXKAj6f6D https://t.co/ntZxXDWLAm"}, "1166207277159743488": {"followers": "1,438", "datetime": "2019-08-27 04:34:16", "author": "@naohisashoji", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166751411981258753": {"followers": "42", "datetime": "2019-08-28 16:36:28", "author": "@namrata249", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1191804032693743616": {"followers": "623", "datetime": "2019-11-05 19:46:38", "author": "@krosaen", "content_summary": "\"... in the modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered over-fit, and yet they often obtain high accuracy on test data\" https://t.co/jKJiMp"}, "1165353563159220224": {"followers": "242", "datetime": "2019-08-24 20:01:55", "author": "@diegoevin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1169992120729403392": {"followers": "282", "datetime": "2019-09-06 15:13:53", "author": "@maevaghonda", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165013932119117825": {"followers": "7,031", "datetime": "2019-08-23 21:32:20", "author": "@DamienERNST1", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165567876243214336": {"followers": "2,935", "datetime": "2019-08-25 10:13:31", "author": "@schwessinger", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1164950637819228160": {"followers": "294", "datetime": "2019-08-23 17:20:50", "author": "@yen_chen_lin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167184807396290561": {"followers": "236", "datetime": "2019-08-29 21:18:37", "author": "@flowing", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165279665830973442": {"followers": "213", "datetime": "2019-08-24 15:08:16", "author": "@reregenerated", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168580892245331968": {"followers": "218", "datetime": "2019-09-02 17:46:10", "author": "@david_macedo", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165046519369785346": {"followers": "158", "datetime": "2019-08-23 23:41:50", "author": "@sandeep_vedula", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165311377176768512": {"followers": "120", "datetime": "2019-08-24 17:14:17", "author": "@mfrazzini", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1227006917328793600": {"followers": "1,197", "datetime": "2020-02-10 23:10:20", "author": "@menphim", "content_summary": "RT @nardtree: \u4f1a\u793e\u3067\u3081\u3063\u3061\u3083\u6279\u5224\u7684\u306a\u8ad6\u8a55\u3060\u3063\u305f\u3002\u50d5\u3082\u305d\u3046\u601d\u3046\u304c\u3001Deep\u3060\u3068\u3088\u304f\u306a\u308b\u3053\u3068\u3082\u3042\u3063\u3066\u4e00\u822c\u5316\u3059\u308b\u3088\u3046\u306a\u7406\u8ad6\u3058\u3083\u306a\u3044\u307f\u305f\u3044\u306a\u610f\u898b\u3002 / 2\u4ef6\u306e\u30b3\u30e1\u30f3\u30c8 https://t.co/dakKZUE0zl \u201c[1812.11118] Reconciling mo\u2026"}, "1202858481377824768": {"followers": "177", "datetime": "2019-12-06 07:53:04", "author": "@gerard_sanroma", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1166644646409207808": {"followers": "289", "datetime": "2019-08-28 09:32:13", "author": "@444shimo", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165329238364475394": {"followers": "27", "datetime": "2019-08-24 18:25:15", "author": "@Ch94Will", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165247665803653120": {"followers": "2,671", "datetime": "2019-08-24 13:01:07", "author": "@ayirpelle", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165393090779209728": {"followers": "41,033", "datetime": "2019-08-24 22:38:59", "author": "@amuellerml", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202719723235840000": {"followers": "2,671", "datetime": "2019-12-05 22:41:42", "author": "@ayirpelle", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1166995188855820288": {"followers": "189", "datetime": "2019-08-29 08:45:09", "author": "@oneinfinitezero", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1180912751775870976": {"followers": "409", "datetime": "2019-10-06 18:28:34", "author": "@jainnitk", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165213052112781312": {"followers": "48", "datetime": "2019-08-24 10:43:34", "author": "@diwangs__", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180787549054226432": {"followers": "1,515", "datetime": "2019-10-06 10:11:04", "author": "@jo7ueb", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166416636158648320": {"followers": "134", "datetime": "2019-08-27 18:26:11", "author": "@kumasento_zhao", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165372958753394689": {"followers": "451", "datetime": "2019-08-24 21:18:59", "author": "@BinShowil", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166140739912372224": {"followers": "163,852", "datetime": "2019-08-27 00:09:52", "author": "@ceobillionaire", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1168524958986715137": {"followers": "8", "datetime": "2019-09-02 14:03:55", "author": "@ranathevishal", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168748840234582016": {"followers": "24", "datetime": "2019-09-03 04:53:32", "author": "@NORA__0013", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1186531702950248449": {"followers": "1,118", "datetime": "2019-10-22 06:36:17", "author": "@ziyuwang", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165730853462466561": {"followers": "30", "datetime": "2019-08-25 21:01:08", "author": "@t_s_v_k", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165602214548819968": {"followers": "2,170", "datetime": "2019-08-25 12:29:58", "author": "@iskander", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165033253780119552": {"followers": "141", "datetime": "2019-08-23 22:49:07", "author": "@waydegilliam", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1186571745182081025": {"followers": "457", "datetime": "2019-10-22 09:15:24", "author": "@FedPernici", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165170332656947201": {"followers": "354", "datetime": "2019-08-24 07:53:49", "author": "@alexpalladini", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1112179458801315840": {"followers": "121", "datetime": "2019-03-31 02:27:00", "author": "@blaine_bateman", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off--a new explanation of how neural networks that are much more complex than needed to learn the training data can generalize better. https://t.co/5nNCkKl1Ko https://t.co/39Mcu8IZmX"}, "1166646013190270977": {"followers": "1", "datetime": "2019-08-28 09:37:39", "author": "@hua_keru", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166672898746146816": {"followers": "521", "datetime": "2019-08-28 11:24:29", "author": "@CrosalZareus", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165276027867848706": {"followers": "16", "datetime": "2019-08-24 14:53:49", "author": "@Tzeny25", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166391584432304130": {"followers": "111", "datetime": "2019-08-27 16:46:38", "author": "@alsombra7", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165248436431548416": {"followers": "1,043", "datetime": "2019-08-24 13:04:11", "author": "@hidekikawahara", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165530246218702849": {"followers": "301", "datetime": "2019-08-25 07:43:59", "author": "@emmaggiees", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165272384628281344": {"followers": "321", "datetime": "2019-08-24 14:39:20", "author": "@OMNOMNOMNUMNUM", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165353954387136512": {"followers": "330", "datetime": "2019-08-24 20:03:28", "author": "@mr_ubik", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165409760914493440": {"followers": "273", "datetime": "2019-08-24 23:45:13", "author": "@Coryandar", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180649611536392193": {"followers": "89", "datetime": "2019-10-06 01:02:57", "author": "@ababab5963", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165515612770242560": {"followers": "11", "datetime": "2019-08-25 06:45:50", "author": "@managed_by_mom", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165277560470740994": {"followers": "24,454", "datetime": "2019-08-24 14:59:54", "author": "@charlyaztec", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167640004895469568": {"followers": "178", "datetime": "2019-08-31 03:27:25", "author": "@yhiss_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165590187662921728": {"followers": "209", "datetime": "2019-08-25 11:42:11", "author": "@drwyatte", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1226726357628907520": {"followers": "137", "datetime": "2020-02-10 04:35:29", "author": "@mike19811019", "content_summary": "RT @sakata_ryuji: \u7d50\u69cb\u8a71\u984c\u3067\u3059\u3088\u306d\u3053\u308c\u3002\uff08\u3046\u3061\u3067\u3082\u8a71\u984c\u306b\u4e0a\u304c\u3063\u305f\u306e\u3067\u3056\u3063\u3068\u8aad\u3093\u3067\u305f\u3002\uff09 3\u7ae0\u306e\u6c7a\u5b9a\u6728\u3068\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u306e\u3068\u3053\u308d\u306f\u3001\u4f55\u304b\u53d6\u3063\u3066\u4ed8\u3051\u305f\u5370\u8c61\u3067\u3001\u3053\u3058\u3064\u3051\u611f\u304c\u5426\u3081\u306a\u304b\u3063\u305f\u3002\u305f\u3060\u3001\u524d\u534a\u306f\u7d14\u7c8b\u306b\u9762\u767d\u3044\u5185\u5bb9\u3060\u3068\u601d\u3063\u3066\u307e\u3059\u3002"}, "1172679049833041920": {"followers": "95", "datetime": "2019-09-14 01:10:47", "author": "@latinostats", "content_summary": "@seanjtaylor have you checked at this new bias-variance paradigm? https://t.co/puGJe2d9Co"}, "1166171235702542336": {"followers": "0", "datetime": "2019-08-27 02:11:03", "author": "@Sam09lol", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166659739205459968": {"followers": "46", "datetime": "2019-08-28 10:32:11", "author": "@davidbarbera9", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165234724824125440": {"followers": "171", "datetime": "2019-08-24 12:09:42", "author": "@AmirHadifar", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1162227193688150018": {"followers": "3,449", "datetime": "2019-08-16 04:58:50", "author": "@reiver", "content_summary": "\"Reconciling modern machine learning and the bias-variance trade-off\" by Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal https://t.co/KjVAiwIpIP (machine learning) H/T @lstmemery"}, "1164953225415385089": {"followers": "2,828", "datetime": "2019-08-23 17:31:07", "author": "@WonderMicky", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1111178722797715456": {"followers": "52", "datetime": "2019-03-28 08:10:26", "author": "@hoangcuong0605", "content_summary": "https://t.co/0PjlQFToRN"}, "1165401014851252224": {"followers": "276", "datetime": "2019-08-24 23:10:28", "author": "@remram44", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1194679585465683968": {"followers": "26", "datetime": "2019-11-13 18:13:03", "author": "@Schlymhaut", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166497693666963456": {"followers": "127", "datetime": "2019-08-27 23:48:17", "author": "@shimoke4869", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165812208250609670": {"followers": "1,159", "datetime": "2019-08-26 02:24:24", "author": "@macrosenexcel", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167579381390303232": {"followers": "25", "datetime": "2019-08-30 23:26:31", "author": "@PGSwartz", "content_summary": "Fantastic paper. Loved the proposal that dramatically increased model complexity under certain optimizers+model combos might actually fit to the true data generating process rather than overfit to noise."}, "1180662307149320192": {"followers": "311", "datetime": "2019-10-06 01:53:24", "author": "@pegion_HOLE", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1194212821665558529": {"followers": "13", "datetime": "2019-11-12 11:18:18", "author": "@mitra6ce", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165276136194150400": {"followers": "16", "datetime": "2019-08-24 14:54:15", "author": "@Tzeny25", "content_summary": "@Rakuu13, trecem la 512x512 dn169? :d"}, "1165439316564357122": {"followers": "196", "datetime": "2019-08-25 01:42:40", "author": "@alimurreza", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1180652140819144704": {"followers": "2,673", "datetime": "2019-10-06 01:13:00", "author": "@mosko_mule", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166163766813384704": {"followers": "7,061", "datetime": "2019-08-27 01:41:22", "author": "@tomordonez", "content_summary": "Reconciling modern machine learning and the bias-variance trade-off https://t.co/sMZ9qUSper"}, "1167184876145139723": {"followers": "8,290", "datetime": "2019-08-29 21:18:54", "author": "@SantchiWeb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165999238230106114": {"followers": "528", "datetime": "2019-08-26 14:47:36", "author": "@aiexplorations", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1081289824408092678": {"followers": "69", "datetime": "2019-01-04 20:42:38", "author": "@bjornsandjensen", "content_summary": "RT @Memoirs: Reconciling modern machine learning and the bias-variance trade-off. https://t.co/QgZvIfoTHz"}, "1205513461117046784": {"followers": "1,429", "datetime": "2019-12-13 15:43:01", "author": "@datascigen", "content_summary": "DSPG: Hello, this is Data Support, this call is being deep learninged, what can we help you with? CALLER: My model is overfitted. DSPG: Well have you tried overfitting it HARDER???"}, "1165454205307564032": {"followers": "6", "datetime": "2019-08-25 02:41:50", "author": "@jonharperdev", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165267807782629377": {"followers": "91", "datetime": "2019-08-24 14:21:09", "author": "@_anglili", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165327173902852097": {"followers": "4,063", "datetime": "2019-08-24 18:17:03", "author": "@juliebhunt", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166484560940601346": {"followers": "1,061", "datetime": "2019-08-27 22:56:06", "author": "@mvaldenegro", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165309487365808128": {"followers": "23", "datetime": "2019-08-24 17:06:46", "author": "@jabertuhin", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1165234075285839872": {"followers": "42", "datetime": "2019-08-24 12:07:07", "author": "@slah_zer", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1193952750205358081": {"followers": "106", "datetime": "2019-11-11 18:04:52", "author": "@jau1990", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1165031586686914560": {"followers": "11", "datetime": "2019-08-23 22:42:30", "author": "@stl950116", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180665651301666816": {"followers": "1,048", "datetime": "2019-10-06 02:06:41", "author": "@ysaito8015", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166722911077617664": {"followers": "173", "datetime": "2019-08-28 14:43:13", "author": "@nyandy777", "content_summary": "RT @rlingle: RT KirkDBorne: RT IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling\u2026"}, "1166173595023708160": {"followers": "102", "datetime": "2019-08-27 02:20:26", "author": "@liseos_x140", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167578895425708032": {"followers": "25", "datetime": "2019-08-30 23:24:35", "author": "@PGSwartz", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166425973258166278": {"followers": "194", "datetime": "2019-08-27 19:03:17", "author": "@ikdeepl", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1166656072565841923": {"followers": "86", "datetime": "2019-08-28 10:17:37", "author": "@KeviDenam", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180691318005125121": {"followers": "1,250", "datetime": "2019-10-06 03:48:41", "author": "@FujitaAtsunori", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1167127524389736450": {"followers": "302", "datetime": "2019-08-29 17:31:00", "author": "@subhobrata1", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1179667133283758082": {"followers": "640", "datetime": "2019-10-03 07:58:56", "author": "@copasta_", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166268575943815168": {"followers": "44", "datetime": "2019-08-27 08:37:51", "author": "@saishikisanchu", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166408287337644032": {"followers": "1,167", "datetime": "2019-08-27 17:53:01", "author": "@TaneoKoyama", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166155104853970944": {"followers": "11,476", "datetime": "2019-08-27 01:06:57", "author": "@icoxfog417", "content_summary": "\u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u306e\u7406\u89e3?)\u3092\u5b66\u7fd2\u3059\u308b\u9818\u57df\u306b\u9032\u3080\u3068\u3044\u3046\u3002"}, "1165543307134394369": {"followers": "23", "datetime": "2019-08-25 08:35:53", "author": "@SajitSasidharan", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166159031951491072": {"followers": "119", "datetime": "2019-08-27 01:22:34", "author": "@toto_toilet", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202648127272112133": {"followers": "242", "datetime": "2019-12-05 17:57:12", "author": "@blauigris", "content_summary": "RT @TheGregYang: @OpenAI Isn't this the \"double descent\" phenomenon studied in https://t.co/EE99AYOPi6 and subsequent works?"}, "1202660804220391424": {"followers": "408", "datetime": "2019-12-05 18:47:34", "author": "@wojczarnecki", "content_summary": "@ilyasut By unnoticed you mean published for just a year?https://t.co/MJtP0s3Qd4"}, "1165676060186484738": {"followers": "445", "datetime": "2019-08-25 17:23:24", "author": "@RLCommunity8", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166567204957163520": {"followers": "140", "datetime": "2019-08-28 04:24:30", "author": "@DextWard", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165512897692413953": {"followers": "193", "datetime": "2019-08-25 06:35:03", "author": "@alexhock", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165158328680493056": {"followers": "93", "datetime": "2019-08-24 07:06:07", "author": "@Gjergji_", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166394846883581952": {"followers": "3,408", "datetime": "2019-08-27 16:59:36", "author": "@EthicalBAU", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165684405094031361": {"followers": "208", "datetime": "2019-08-25 17:56:34", "author": "@TatanMorenoN", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166200717117460480": {"followers": "99", "datetime": "2019-08-27 04:08:12", "author": "@izquiratops_CIM", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166718845329051648": {"followers": "259,498", "datetime": "2019-08-28 14:27:03", "author": "@KirkDBorne", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166679947991277568": {"followers": "2,704", "datetime": "2019-08-28 11:52:30", "author": "@fusaroli", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1209756302575992832": {"followers": "145", "datetime": "2019-12-25 08:42:33", "author": "@meta_takoroy", "content_summary": "bias-variance\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306e\u539f\u7406\u3068\u305d\u308c\u306b\u5bfe\u7acb\u3059\u308b\u5b9f\u60c5\u3092\u5305\u542b\u3057\u3066\u8aac\u660e\u3059\u308b\u300c\u4e8c\u91cd\u964d\u4e0b\u30ab\u30fc\u30d6\u300d\u3092\u63d0\u6848\u3002\u5e83\u7bc4\u56f2\u306e\u30e2\u30c7\u30eb\u3068\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u95a2\u3059\u308b\u4e8c\u91cd\u964d\u4e0b\u306e\u5b58\u5728\u3092\u5b9f\u8a3c\u3057\u3001\u305d\u306e\u30e1\u30ab\u30cb\u30ba\u30e0\u3092\u89e3\u6790\u3002 / \u201c[1812.11118] Reconciling modern machine learning practice and the bias-v\u2026\u201d https://t.co/xWN4b3QK4p"}, "1081636625375989761": {"followers": "336", "datetime": "2019-01-05 19:40:41", "author": "@TheLeanAcademic", "content_summary": "RT @roydanroy: Slow down for the rest of us! (Another paper for my stacks.) https://t.co/xJhOvCrYCd https://t.co/Gg6IBupLpr"}, "1165546681686839296": {"followers": "54", "datetime": "2019-08-25 08:49:18", "author": "@SThanombun", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1207034961850720256": {"followers": "38", "datetime": "2019-12-17 20:28:55", "author": "@AntonySagayara6", "content_summary": "@PreetumNakkiran Reminds me of https://t.co/F2cQYbcPcc Perhaps data points & parameters are more interchangeable/connected than we think https://t.co/CswcXKPgRi"}, "1168368954483462144": {"followers": "624", "datetime": "2019-09-02 03:44:00", "author": "@Eseshinpu", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166204171478945792": {"followers": "514", "datetime": "2019-08-27 04:21:56", "author": "@mkt_kwn", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166199436818731009": {"followers": "8,290", "datetime": "2019-08-27 04:03:07", "author": "@SantchiWeb", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180800515057184768": {"followers": "163", "datetime": "2019-10-06 11:02:35", "author": "@yokotatsuya", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165727992762503169": {"followers": "1,306", "datetime": "2019-08-25 20:49:46", "author": "@chriswolfvision", "content_summary": "Bias-Variance revisited for high-capacity deep models: increasing model complexity first increases overfit, but beyond the interpolation threshold it can increase generalization again. Belkin et al., PNAS, https://t.co/nDOwWEh8Es https://t.co/5XRS7eHh1s"}, "1165625318855430145": {"followers": "824", "datetime": "2019-08-25 14:01:46", "author": "@morioka", "content_summary": "RT @nyker_goto: Deep \u306f\u53e4\u5178\u7684\u306a\u30d0\u30a4\u30a2\u30b9\u30d0\u30ea\u30a2\u30f3\u30b9\u306e\u8b70\u8ad6\u304c\u901a\u3058\u306a\u3044\u3063\u3066\u3044\u3046\u306e\u306f\u8074\u3044\u305f\u3053\u3068\u3042\u3063\u305f\u3051\u3069\u3001\u305d\u308c\u4ee5\u5916\u306e\u30e2\u30c7\u30eb\u3001\u4f8b\u3048\u3070\u8ad6\u6587\u4e2d\u306a\u3089RandomForest\u3067\u3082 Over Parameterized \u306a\u30e2\u30c7\u30eb\u306e\u307b\u3046\u304c\u6027\u80fd\u826f\u304f\u306a\u308b\u30dd\u30a4\u30f3\u30c8\u304c\u3042\u308b\u306e\u3001\u304a\u3082\u308d\u3044\u306a\u2026"}, "1165326401555197952": {"followers": "847", "datetime": "2019-08-24 18:13:59", "author": "@orcinus_orca", "content_summary": "\u3053\u308c\u306f\u3082\u3063\u3068\u77e5\u3089\u308c\u308b\u3079\u304d\u8ad6\u6587 https://t.co/Tkhbx3bF7z"}, "1166617240596340737": {"followers": "29", "datetime": "2019-08-28 07:43:19", "author": "@chenlailin", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165917311963938816": {"followers": "39", "datetime": "2019-08-26 09:22:03", "author": "@firstmn59", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1180903687268388864": {"followers": "1,203", "datetime": "2019-10-06 17:52:33", "author": "@F_Vaggi", "content_summary": "@SeanTrende In a very large data regime, you need domain knowledge, but, you really need a deep understanding of methods/maths/technology stack as well. For example - overfitting is completely different once you enter the big data/big model regime: https:"}, "1166231818888073216": {"followers": "394", "datetime": "2019-08-27 06:11:47", "author": "@hanetsuki_y", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165442036876500997": {"followers": "129", "datetime": "2019-08-25 01:53:29", "author": "@RndWalk", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1166406608286552067": {"followers": "89", "datetime": "2019-08-27 17:46:20", "author": "@mgrankin", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180750881072959493": {"followers": "194", "datetime": "2019-10-06 07:45:21", "author": "@laboage777", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165684139670069249": {"followers": "304", "datetime": "2019-08-25 17:55:30", "author": "@TradingEnigma", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166199649234874371": {"followers": "888", "datetime": "2019-08-27 04:03:57", "author": "@canchou", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165544057831116800": {"followers": "4", "datetime": "2019-08-25 08:38:52", "author": "@Wenlin__Chen", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165185792567853056": {"followers": "31", "datetime": "2019-08-24 08:55:15", "author": "@partm0r", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165299300613722112": {"followers": "290", "datetime": "2019-08-24 16:26:18", "author": "@itsrainingdata", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202816613789122560": {"followers": "41,033", "datetime": "2019-12-06 05:06:42", "author": "@amuellerml", "content_summary": "@jeremyphoward @reachtarunhere @OpenAI a theoretical explanation is given by y colleague Daniel Hsu here: https://t.co/PQHSZYrQH1"}, "1180999370096832513": {"followers": "128", "datetime": "2019-10-07 00:12:46", "author": "@mshinoda88", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1177344813932470277": {"followers": "570", "datetime": "2019-09-26 22:10:52", "author": "@uvmmathstats", "content_summary": "RT @KameronDHarris: Check out this paper: \"Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off\" by Mikha\u2026"}, "1166161433966460929": {"followers": "705", "datetime": "2019-08-27 01:32:06", "author": "@hilinker", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180714351000293376": {"followers": "113", "datetime": "2019-10-06 05:20:12", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj <4/4>This results in classical over-fitting as predicted by the bias-variance trade-off and prominently manifested at the peak of the curve, where the fit becomes exact. #nextAI https://t.co/0s7DIvb62c"}, "1165415361556037632": {"followers": "107", "datetime": "2019-08-25 00:07:29", "author": "@merajatgupta", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165121501592338434": {"followers": "444", "datetime": "2019-08-24 04:39:47", "author": "@k1monfared", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165398341586317313": {"followers": "98", "datetime": "2019-08-24 22:59:51", "author": "@rv1n0d85", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165397583554068480": {"followers": "84", "datetime": "2019-08-24 22:56:50", "author": "@RonnieDas11", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166161947961643010": {"followers": "364", "datetime": "2019-08-27 01:34:09", "author": "@tkym1220", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165268581812076545": {"followers": "182", "datetime": "2019-08-24 14:24:14", "author": "@doninred", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165302345120567297": {"followers": "66", "datetime": "2019-08-24 16:38:24", "author": "@diegovogeid", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202837800342753280": {"followers": "888", "datetime": "2019-12-06 06:30:53", "author": "@RichmanRonald", "content_summary": "RT @amuellerml: @jeremyphoward @reachtarunhere @OpenAI a theoretical explanation is given by y colleague Daniel Hsu here: https://t.co/PQHS\u2026"}, "1165475974999236608": {"followers": "63", "datetime": "2019-08-25 04:08:20", "author": "@saqibns", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1079606070140723201": {"followers": "193", "datetime": "2018-12-31 05:11:59", "author": "@arXiv_stat_ML", "content_summary": "https://t.co/AnoBlstjfL M Belkin et. al. Reconciling modern machine learning and the bias-variance trade-off https://t.co/lN8ql5YOIe"}, "1166298426696290304": {"followers": "817", "datetime": "2019-08-27 10:36:28", "author": "@JayroEfren", "content_summary": "RT @orestistsinalis: Very interesting paper with empirical observations of \"double descent\"/two-regime behaviour in test performance of com\u2026"}, "1258501808416317447": {"followers": "1,942", "datetime": "2020-05-07 20:59:47", "author": "@GiorgioPatrini", "content_summary": "ML Twitter: is the the \"double descent\" phenomenon widely confirmed when training deep neural nets? Did anyone prove that extremely large models with perfect training fit increase generalisation in practice? https://t.co/U1fgYRrndh https://t.co/D4b7nDASMo"}, "1180861071743078400": {"followers": "99", "datetime": "2019-10-06 15:03:13", "author": "@treasured_write", "content_summary": "RT @hillbig: The bias-variance tradeoff shows that a model with appropriate complexity can generalize. Recent \"double descent\" indicates th\u2026"}, "1166405761653780480": {"followers": "45", "datetime": "2019-08-27 17:42:59", "author": "@artuskg", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1180740512598249473": {"followers": "787", "datetime": "2019-10-06 07:04:09", "author": "@thatsdone", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166176119185297408": {"followers": "354", "datetime": "2019-08-27 02:30:27", "author": "@hrnbskgc", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1224728607001542663": {"followers": "7,061", "datetime": "2020-02-04 16:17:08", "author": "@tomordonez", "content_summary": "Reconciling modern machine learning practice and the bias-variance trade-off https://t.co/sMZ9qUSper"}, "1180695371577561088": {"followers": "235", "datetime": "2019-10-06 04:04:47", "author": "@bamboo4031", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166181416368951296": {"followers": "963", "datetime": "2019-08-27 02:51:30", "author": "@ashiato45", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166723395540701184": {"followers": "1,636", "datetime": "2019-08-28 14:45:08", "author": "@ProfStefanNagel", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1259626930774716418": {"followers": "7,444", "datetime": "2020-05-10 23:30:37", "author": "@o_guest", "content_summary": "@ChelseaParlett @BertieArbon Kinda scary how it works! https://t.co/BrG6aljKhG"}, "1167763894686953472": {"followers": "56,127", "datetime": "2019-08-31 11:39:43", "author": "@IntelligenceTV", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165365421610012673": {"followers": "204", "datetime": "2019-08-24 20:49:02", "author": "@Juho_Salminen", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165598212419477505": {"followers": "28", "datetime": "2019-08-25 12:14:04", "author": "@BhattDvijesh", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168891666083778561": {"followers": "28,195", "datetime": "2019-09-03 14:21:04", "author": "@halvarflake", "content_summary": "Stats/ML followers: This paper https://t.co/GqSUd4gJWX argues that the risk curve when overparametrizing models is \"w\"-shaped vs u-shaped for many models. They provide some evidence from DNN and RFs. A fascinating claim; will need to mull the paper a bit."}, "1166225207184388096": {"followers": "350", "datetime": "2019-08-27 05:45:31", "author": "@vochicong", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166159668428734464": {"followers": "43", "datetime": "2019-08-27 01:25:05", "author": "@oseose_11", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165439900491091968": {"followers": "440", "datetime": "2019-08-25 01:44:59", "author": "@alveuz", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165216334889668608": {"followers": "218", "datetime": "2019-08-24 10:56:37", "author": "@AssistedEvolve", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165424374901563392": {"followers": "174", "datetime": "2019-08-25 00:43:18", "author": "@ljvmiranda921", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166177155404812291": {"followers": "231", "datetime": "2019-08-27 02:34:35", "author": "@aiskoaskosd", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1168894953357025281": {"followers": "841", "datetime": "2019-09-03 14:34:08", "author": "@sm0b0t", "content_summary": "RT @halvarflake: Stats/ML followers: This paper https://t.co/GqSUd4gJWX argues that the risk curve when overparametrizing models is \"w\"-sha\u2026"}, "1166403984568901632": {"followers": "109", "datetime": "2019-08-27 17:35:55", "author": "@sotsogprinciple", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165317431155286017": {"followers": "6,719", "datetime": "2019-08-24 17:38:20", "author": "@chidambara09", "content_summary": "RT @BigData_Fr: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning an\u2026"}, "1166190580054937600": {"followers": "119", "datetime": "2019-08-27 03:27:55", "author": "@Mufei_Li", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1180748421067526151": {"followers": "819", "datetime": "2019-10-06 07:35:35", "author": "@saiyuki1919", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1180773238042812417": {"followers": "498", "datetime": "2019-10-06 09:14:12", "author": "@maguroIsland", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1166476645290643456": {"followers": "736", "datetime": "2019-08-27 22:24:38", "author": "@kokoichiro", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165231047753248769": {"followers": "95", "datetime": "2019-08-24 11:55:05", "author": "@ddehueck", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165565978463412224": {"followers": "4,249", "datetime": "2019-08-25 10:05:59", "author": "@SilverVVulpes", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165684297900154880": {"followers": "175", "datetime": "2019-08-25 17:56:08", "author": "@EnigmaData", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1164902860406087686": {"followers": "6,118", "datetime": "2019-08-23 14:10:59", "author": "@glouppe", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165092236813467648": {"followers": "404", "datetime": "2019-08-24 02:43:30", "author": "@kevoniano", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166344105795837953": {"followers": "1,477", "datetime": "2019-08-27 13:37:59", "author": "@yamato", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166156309034520576": {"followers": "2,532", "datetime": "2019-08-27 01:11:44", "author": "@kusano_k", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1166195132292419584": {"followers": "1,152", "datetime": "2019-08-27 03:46:01", "author": "@jd_mashiro", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1176684313284247552": {"followers": "95", "datetime": "2019-09-25 02:26:16", "author": "@latinostats", "content_summary": "@fchollet what you think about this paper...https://t.co/puGJe1VydO .. I am really interested in your opinion."}, "1166293684096122882": {"followers": "548", "datetime": "2019-08-27 10:17:37", "author": "@keno_ss", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165215109599367168": {"followers": "599", "datetime": "2019-08-24 10:51:45", "author": "@pierrechoffe", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165056795322269696": {"followers": "1,431", "datetime": "2019-08-24 00:22:40", "author": "@vievararosel", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166163198359330817": {"followers": "113", "datetime": "2019-08-27 01:39:07", "author": "@_moto86", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165312517180051457": {"followers": "4", "datetime": "2019-08-24 17:18:49", "author": "@om_cha72", "content_summary": "RT @NandoDF: I agree. This was a phenomenal paper. I\u2019m hoping it will inspire researchers to probe further. https://t.co/sea9atR0Qy"}, "1167044243329835009": {"followers": "4,599", "datetime": "2019-08-29 12:00:04", "author": "@TheCuriousLuke", "content_summary": "RT @Matchable_io: Interesting paper of the question of generalization in ML. How can the classical understanding of generalization can be r\u2026"}, "1180710666241376256": {"followers": "113", "datetime": "2019-10-06 05:05:34", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj In Figure 2, we show the test risk of the predictors learned using HN on a subset of the popular data set of handwritten digits called MNIST. #nextAI https://t.co/voYy58oOm2"}, "1166309769293881344": {"followers": "238", "datetime": "2019-08-27 11:21:32", "author": "@yudoufu_k", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1180715900434911232": {"followers": "113", "datetime": "2019-10-06 05:26:21", "author": "@SHIMOMURATakuji", "content_summary": "https://t.co/FFXHsebuhj This suboptimal behavior can lead to high variability in both the training and test risks that masks the double descent curve. #nextAI"}, "1180819298622689285": {"followers": "542", "datetime": "2019-10-06 12:17:14", "author": "@1789aorhow", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1195760947970732032": {"followers": "45", "datetime": "2019-11-16 17:50:00", "author": "@Anvesh50905036", "content_summary": "RT @glouppe: Do you know of anyone who reproduced the double-U generalization curve of over-parameterized networks? https://t.co/3AfsBQpmBL\u2026"}, "1166198562931138560": {"followers": "285", "datetime": "2019-08-27 03:59:38", "author": "@saya_hakuren", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1081604226382475266": {"followers": "126", "datetime": "2019-01-05 17:31:57", "author": "@deltakam", "content_summary": "!!! https://t.co/6ICnu9HX8U https://t.co/cC7mp5uOcn"}, "1166519597668786177": {"followers": "7", "datetime": "2019-08-28 01:15:19", "author": "@ZhaoDeli", "content_summary": "RT @OriolVinyalsML: The paper \"Understanding deep learning requires rethinking generalization\" mostly asked questions. Glad to see some ans\u2026"}, "1165562440769253381": {"followers": "47", "datetime": "2019-08-25 09:51:55", "author": "@abstract_datum", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1180655862441889792": {"followers": "449", "datetime": "2019-10-06 01:27:47", "author": "@shunitami", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1168897840384544773": {"followers": "85", "datetime": "2019-09-03 14:45:36", "author": "@ReversingWithMe", "content_summary": "RT @halvarflake: Stats/ML followers: This paper https://t.co/GqSUd4gJWX argues that the risk curve when overparametrizing models is \"w\"-sha\u2026"}, "1166562684067811330": {"followers": "1,461", "datetime": "2019-08-28 04:06:32", "author": "@rfrsarmiento", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1165464931837177856": {"followers": "133", "datetime": "2019-08-25 03:24:27", "author": "@AjayDubey1111", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1202652933067870211": {"followers": "52", "datetime": "2019-12-05 18:16:18", "author": "@bjornivart", "content_summary": "The effect is also described here https://t.co/1CDKURWIRz"}, "1165952281134731264": {"followers": "32", "datetime": "2019-08-26 11:41:00", "author": "@va13rik", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1167830068158025728": {"followers": "289", "datetime": "2019-08-31 16:02:40", "author": "@yoshiharuharada", "content_summary": "RT @dai0125mfs: @ML_deep \u3053\u308c\u3067\u306f\u306a\u3044\u3067\u3057\u3087\u3046\u304b\uff1f\uff1f https://t.co/38p4YdGeiW"}, "1180975178982907904": {"followers": "14", "datetime": "2019-10-06 22:36:38", "author": "@TsuguoMogami", "content_summary": "RT @hillbig: \u5f93\u6765\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u8003\u3048\u3067\u306f\u904e\u5b66\u7fd2\u3057\u306a\u3044\u9069\u5ea6\u306a\u5927\u304d\u3055\u306e\u30e2\u30c7\u30eb\u304c\u6700\u9069\u3060\u304c\u3001\u3042\u308b\u6761\u4ef6\u4e0b\u3067\u306f\u8a13\u7df4\u8aa4\u5dee\u30bc\u30ed\u304b\u3089\u3055\u3089\u306b\u30e2\u30c7\u30eb\u3092\u5927\u304d\u304f\u3057\u305f\u307b\u3046\u304c\u30c6\u30b9\u30c8\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u308b\u4e8c\u91cd\u964d\u4e0b\u73fe\u8c61\u304c\u8d77\u304d\u308b\u3002NN\u4ee5\u5916\u306e\u4ed6\u306e\u591a\u304f\u306e\u30e2\u30c7\u30eb\u3067\u3082\u8d77\u304d\u308b https://t.co/mWq1R4mA\u2026"}, "1165341602438615040": {"followers": "888", "datetime": "2019-08-24 19:14:23", "author": "@RichmanRonald", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1166234470610919425": {"followers": "562", "datetime": "2019-08-27 06:22:20", "author": "@nazenazeboy", "content_summary": "RT @icoxfog417: \u904e\u5b66\u7fd2\u3092\u8d85\u3048\u305f\u5148\u306b\u3001\u6c4e\u5316\u6027\u80fd\u304c\u9006\u306b\u4e0b\u304c\u3063\u3066\u3044\u304f\u30a8\u30ea\u30a2\u304c\u5b58\u5728\u3059\u308b\u306e\u3067\u306f\u3068\u3044\u3046\u7814\u7a76\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3078\u5b8c\u5168\u306bFit\u3057\u3066\u3044\u3066\u3082\u6c4e\u5316\u6027\u80fd\u3092\u6301\u3064\u3068\u3044\u3046\u7d4c\u9a13\u5247\u3092\u57fa\u306b\u63d0\u5531\u3055\u308c\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u304c\u5341\u5206\u306a\u8907\u96d1\u6027(\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u6570\u306a\u3069)\u3092\u6301\u3064\u5834\u5408\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u9593\u306e\u88dc\u5b8c(\u30c7\u30fc\u30bf\u69cb\u9020\u2026"}, "1165468302333894657": {"followers": "1,314", "datetime": "2019-08-25 03:37:51", "author": "@Demilade__A", "content_summary": "RT @IanOsband: Looking back over the year, the one paper that gave me the best \"aha\" moment was... Reconciling Modern Machine Learning and\u2026"}, "1225490784360828933": {"followers": "8,240", "datetime": "2020-02-06 18:45:46", "author": "@vsbuffalo", "content_summary": "I quite like this figure (from this paper: https://t.co/dOb10eUQvC), which I think unites why both machine learning and parameter-rich Bayesian models are doing well across a variety of tasks (Murphy also makes this point in Chapter 17 of his book). https:"}}}