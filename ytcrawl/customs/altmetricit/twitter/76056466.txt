{"citation_id": "76056466", "queriedAt": "2020-05-09 13:57:11", "completed": "0", "twitter": {"1253803353378701313": {"followers": "35", "content_summary": "RT @tingchenai: Introducing SimCLR: a Simple framework for Contrastive Learning of Representations. SimCLR advances previous SOTA in self-s\u2026", "author": "@le_chn", "datetime": "2020-04-24 21:49:48"}, "1257345143788769282": {"followers": "49", "content_summary": "DNNs, trained using supervised learning have been very successful at many tasks. But learning from unlabeled data, or less data remains an issue. For that, contrastive learning has emerged recently. Example - SimCLR Paper - https://t.co/85DWNjvpQj Code -", "author": "@rohitpgarg", "datetime": "2020-05-04 16:23:37"}, "1257477664497000448": {"followers": "0", "content_summary": "RT @geoffreyhinton: Unsupervised learning of representations is beginning to work quite well without requiring reconstruction. https://t.co\u2026", "author": "@AIFrontier1", "datetime": "2020-05-05 01:10:12"}, "1249276888725565440": {"followers": "220", "content_summary": "[10/10] \ud83d\udcc8 - A Simple Framework for Contrastive Learning of Visual Representations - 496 \u2b50 - \ud83d\udcc4 https://t.co/5FIIovVgd7 - \ud83d\udd17 https://t.co/X2qW41muhC", "author": "@PapersTrending", "datetime": "2020-04-12 10:03:15"}}, "tab": "twitter"}