{"tab": "twitter", "completed": "1", "twitter": {"1098171385430638593": {"author": "@shubh_300595", "followers": "61", "datetime": "2019-02-20 10:43:55", "content_summary": "RT @arxiv_org: Regularizing Black-box Models for Improved Interpretability. https://t.co/Jx0zJzJcvU https://t.co/uZr2xT4nly"}, "1098051727855706112": {"author": "@BrundageBot", "followers": "3,697", "datetime": "2019-02-20 02:48:27", "content_summary": "Regularizing Black-box Models for Improved Interpretability. Gregory Plumb, Maruan Al-Shedivat, Eric Xing, and Ameet Talwalkar https://t.co/73dzPOusEM"}, "1099432388650848259": {"author": "@arxiv_in_review", "followers": "1,264", "datetime": "2019-02-23 22:14:42", "content_summary": "#ICML2019 Regularizing Black-box Models for Improved Interpretability. (arXiv:1902.06787v1 [cs\\.LG]) https://t.co/I2NH4TGurg"}, "1099529668418449408": {"author": "@ukyo_ho", "followers": "73", "datetime": "2019-02-24 04:41:15", "content_summary": "RT @arxiv_in_review: #ICML2019 Regularizing Black-box Models for Improved Interpretability. (arXiv:1902.06787v1 [cs\\.LG]) https://t.co/I2NH\u2026"}, "1136881362164682752": {"author": "@Equiv_Exchange", "followers": "25", "datetime": "2019-06-07 06:23:33", "content_summary": "\u6a5f\u68b0\u5b66\u7fd2\u306e\u30d6\u30e9\u30c3\u30af\u30fb\u30dc\u30c3\u30af\u30b9\u6027\u306b\u95a2\u3057\u3066\u30ea\u30f3\u30af\u5148\u306e2\u3064\u306e\u8ad6\u6587\u3092\u767a\u898b\u3057\u305f\u3002\u6642\u9593\u3092\u4f5c\u3063\u3066\u8aad\u307f\u305f\u3044: https://t.co/tllwGceoW9\u3000\u3000https://t.co/TDAtdlSTKn"}, "1098061264868253696": {"author": "@yapp1e", "followers": "33", "datetime": "2019-02-20 03:26:21", "content_summary": "Regularizing Black-box Models for Improved Interpretability. (arXiv:1902.06787v1 [cs.LG]) https://t.co/2T3QWgEA8y Most work on interpretability in machine learning has focused on designing either inherently interpretable models, that typically trade-off i"}, "1098158830410579968": {"author": "@FujitaAtsunori", "followers": "1,119", "datetime": "2019-02-20 09:54:02", "content_summary": "RT @arxiv_org: Regularizing Black-box Models for Improved Interpretability. https://t.co/Jx0zJzJcvU https://t.co/uZr2xT4nly"}, "1098130032415858693": {"author": "@arxiv_org", "followers": "11,816", "datetime": "2019-02-20 07:59:36", "content_summary": "Regularizing Black-box Models for Improved Interpretability. https://t.co/Jx0zJzJcvU https://t.co/uZr2xT4nly"}, "1098118034324115456": {"author": "@arxivml", "followers": "665", "datetime": "2019-02-20 07:11:56", "content_summary": "\"Regularizing Black-box Models for Improved Interpretability\", Gregory Plumb, Maruan Al-Shedivat, Eric Xing, Ameet \u2026 https://t.co/UIyi97bTs4"}, "1098037286556577792": {"author": "@StatMLPapers", "followers": "9,199", "datetime": "2019-02-20 01:51:04", "content_summary": "Regularizing Black-box Models for Improved Interpretability. (arXiv:1902.06787v1 [cs.LG]) https://t.co/cU8ZkvaLOZ"}, "1098137329099829249": {"author": "@mvaldenegro", "followers": "926", "datetime": "2019-02-20 08:28:36", "content_summary": "RT @arxiv_org: Regularizing Black-box Models for Improved Interpretability. https://t.co/Jx0zJzJcvU https://t.co/uZr2xT4nly"}, "1098517573153415168": {"author": "@esXFdfOJxiGBFLx", "followers": "1,497", "datetime": "2019-02-21 09:39:33", "content_summary": "RT @arxiv_org: Regularizing Black-box Models for Improved Interpretability. https://t.co/Jx0zJzJcvU https://t.co/uZr2xT4nly"}}, "citation_id": "55775637", "queriedAt": "2020-06-03 23:46:30"}