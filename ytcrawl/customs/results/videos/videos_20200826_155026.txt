[{"idx_paper": "10.1109/TVCG.2017.2744518", "q": "ieeexplore.ieee.org/document/8017635", "items": [{"id": "YGU0uN_RAIo", "snippet": {"channelId": "UCvehvv6Pe8121DLiAtRSfTA", "title": "Of Catastrophes and Rescues: Making the Invisible Visible", "publishedAt": "2019-03-05T17:03:24Z", "tags": ["molecular visualization", "molecules", "microtubules", "biology", "cell", "education", "opengl", "real-time rendering", "dynamic instability", "microtubules explained", "microtubules animation", "microtubules structure and function", "procedural", "animation", "microtubule"], "channelTitle": "Too Dope for Microscope", "description": "Microtubules are long, hollow tubes present in each of your cells. They help to maintain the shape of the cell, and they form rails along which material is transported throughout the cell. They even help with the cell division. In this video, we show you how microtubules assemble from molecules of proteins randomly scattered throughout every cell.\n\nThe video has been rendered with a real-time molecular visualization engine Marion and real-time composition library Vj made by nanographics.\n\nhttps://nanographics.at\n\nMusic:\nTajnosnubn\u00fd Rastlina - Molecules\nhttps://soundcloud.com/tajnosnubn-rastlina/molecules\n\nSources:\n\nMicrotubule dynamics:\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4244961/\nhttp://essays.biochemistry.org/content/early/2018/10/02/EBC20180035\n\nModel of the Tubulin dimer:\nhttps://www.rcsb.org/structure/1tub\n\nMicrotubule growth and shortening rates:\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC2172968/\n\nDynamic Instability microscopy data:\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3032800/\n\nMarion (the real-time rendering engine we used):\nhttps://ieeexplore.ieee.org/document/8017635\n\nProcedural generator of the intercellular environment:\nhttps://ieeexplore.ieee.org/document/8019859", "defaultAudioLanguage": "en-GB"}, "statistics": {"likeCount": "23", "dislikeCount": "0", "viewCount": "771", "favoriteCount": "0", "commentCount": "0"}, "contentDetails": {"duration": "PT4M26S"}}]}, {"idx_paper": "10.1109/TVCG.2017.2744258", "q": "ieeexplore.ieee.org/document/8019859", "items": [{"id": "YGU0uN_RAIo", "snippet": {"channelId": "UCvehvv6Pe8121DLiAtRSfTA", "title": "Of Catastrophes and Rescues: Making the Invisible Visible", "publishedAt": "2019-03-05T17:03:24Z", "tags": ["molecular visualization", "molecules", "microtubules", "biology", "cell", "education", "opengl", "real-time rendering", "dynamic instability", "microtubules explained", "microtubules animation", "microtubules structure and function", "procedural", "animation", "microtubule"], "channelTitle": "Too Dope for Microscope", "description": "Microtubules are long, hollow tubes present in each of your cells. They help to maintain the shape of the cell, and they form rails along which material is transported throughout the cell. They even help with the cell division. In this video, we show you how microtubules assemble from molecules of proteins randomly scattered throughout every cell.\n\nThe video has been rendered with a real-time molecular visualization engine Marion and real-time composition library Vj made by nanographics.\n\nhttps://nanographics.at\n\nMusic:\nTajnosnubn\u00fd Rastlina - Molecules\nhttps://soundcloud.com/tajnosnubn-rastlina/molecules\n\nSources:\n\nMicrotubule dynamics:\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4244961/\nhttp://essays.biochemistry.org/content/early/2018/10/02/EBC20180035\n\nModel of the Tubulin dimer:\nhttps://www.rcsb.org/structure/1tub\n\nMicrotubule growth and shortening rates:\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC2172968/\n\nDynamic Instability microscopy data:\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3032800/\n\nMarion (the real-time rendering engine we used):\nhttps://ieeexplore.ieee.org/document/8017635\n\nProcedural generator of the intercellular environment:\nhttps://ieeexplore.ieee.org/document/8019859", "defaultAudioLanguage": "en-GB"}, "statistics": {"likeCount": "23", "dislikeCount": "0", "viewCount": "771", "favoriteCount": "0", "commentCount": "0"}, "contentDetails": {"duration": "PT4M26S"}}]}, {"idx_paper": "10.1109/TIP.2017.2760518", "q": "ieeexplore.ieee.org/document/8063957", "items": [{"id": "bvfMNa60f7o", "snippet": {"channelId": "UCYte5O0vH3TTX6k8Hzx6CqQ", "title": "\ub17c\ubb38\uc77d\ub294\ubc95(\ud6a8\uc728\uc801\uc73c\ub85c \uc5f0\uad6c\ub17c\ubb38 \uc77d\uae30)", "publishedAt": "2020-07-07T07:32:33Z", "channelTitle": "Sang-hyo Park", "description": "\uc601\uc0c1\uc5d0\uc11c \ub098\uc628 \ub17c\ubb38 \uc815\ubcf4\uc785\ub2c8\ub2e4.\n\n\ub17c\ubb38 1 \"Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment\"\nLink: https://ieeexplore.ieee.org/document/8063957\nCopyright: Under a Creative Commons License (https://creativecommons.org/licenses/by/3.0/)\n\n\ub17c\ubb38 2 \"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\"\nLink: https://ieeexplore.ieee.org/document/7803544\nCopyright: Under a Creative Commons License (https://creativecommons.org/licenses/by/3.0/)\n\n\ub17c\ubb38 3 \"Ensemble Neural Networks (ENN): A gradient-free stochastic method\"\nLink: https://www.sciencedirect.com/science/article/pii/S0893608018303319\nCopyright: Under a Creative Commons License (https://creativecommons.org/licenses/by-nc-nd/4.0/)\n\n\ub17c\ubb38 4 \"The connected-component labeling problem: A review of state-of-the-art algorithms\"\nLink: https://www.sciencedirect.com/science/article/pii/S0031320317301693\nCopyright: Under a Creative Commons License (https://creativecommons.org/licenses/by-nc-nd/4.0/)\n\n* \ubcf8 \uc601\uc0c1\uc740 Computer Science \ubd84\uc57c(\ud2b9\ud788 \uc601\uc0c1, \uc778\uacf5\uc9c0\ub2a5)\ub85c \ud55c\uc815\ud55c \uc81c \uc8fc\uad00\uc801\uc778 \ub17c\ubb38 \uc77d\ub294 \ubc29\ubc95\uc785\ub2c8\ub2e4. \uc5f0\uad6c \ubd84\uc57c\uc5d0 \ub530\ub77c \ub17c\ubb38 \uad6c\uc870\ub3c4 \ub2e4\ub974\uace0 \uc131\uaca9\ub3c4 \ub2e4\ub97c \uc218 \uc788\uc74c\uc744 \uc54c\ub824\ub4dc\ub9bd\ub2c8\ub2e4.\n* \ubcf8 \uc601\uc0c1\uc5d0\uc11c \ub098\uc628 \ub17c\ubb38\uc740 \ubaa8\ub450 Creative Commons License\uc5d0 \ub530\ub974\ub294 \uc800\uc791\ubb3c\uc784\uc744 \uc54c\ub9bd\ub2c8\ub2e4.", "defaultAudioLanguage": "ko"}, "statistics": {"likeCount": "1", "dislikeCount": "0", "viewCount": "48", "favoriteCount": "0", "commentCount": "0"}, "contentDetails": {"duration": "PT13M45S"}}]}, {"idx_paper": "10.1109/JSAC.2017.2774702", "q": "ieeexplore.ieee.org/document/8113454", "items": [{"id": "UOhXExKNNdw", "snippet": {"channelId": "UChrPLvfp7NgcVBoZCSGZTzw", "title": "IoUT - Internet of Underwater Things", "publishedAt": "2017-11-19T10:51:36Z", "tags": ["IoT", "IoUT", "Internet of Thinghs", "Pro4", "VideoRay", "Optical modem", "Underwater communication", "ROV", "AUV", "Internet of Things", "Internet of Underwater Things"], "channelTitle": "David Scaradozzi", "description": "Full-Fledged 10Base-T Ethernet Underwater Optical Wireless Communication System\nhttp://ieeexplore.ieee.org/document/8113454/", "defaultLanguage": "en"}, "statistics": {"likeCount": "0", "dislikeCount": "0", "viewCount": "75", "favoriteCount": "0", "commentCount": "0"}, "contentDetails": {"duration": "PT17S"}}]}, {"idx_paper": "10.1109/MSP.2017.2765202", "q": "ieeexplore.ieee.org/document/8253599", "items": [{"id": "y8LGAhzCOxQ", "snippet": {"channelId": "UCP9YJJ24w6g38VMVMm6Thtg", "title": "Deep Learning 35: (2) Wasserstein Generative Adversarial Network (WGAN):   Wasserstein metric", "publishedAt": "2019-04-22T06:50:22Z", "tags": ["wasserstein", "wasserstein gan", "wasserstein distance", "wasserstein metric", "wasserstein autoencoder", "wasserstein generative adversarial networks", "Earth mover", "Kl divergence", "Gan pytorch", "Movidius", "Adversarial training", "Generative model", "Wgan", "Geoffrey hinton", "Yoshua benjio", "Andrej kaparthy", "Andrew ng", "Ian goodfellow", "Convolution", "Self driving cars", "Yann lecunn", "Computerphile"], "channelTitle": "Ahlad Kumar", "description": "In this lecture a detailed discussion on Wasserstein metric is carried out.\n\n(1) https://ieeexplore.ieee.org/abstract/document/8253599\n\n\n#wasserstein#generative#GAN", "defaultAudioLanguage": "en-GB", "defaultLanguage": "en-GB"}, "statistics": {"likeCount": "151", "dislikeCount": "4", "viewCount": "6986", "favoriteCount": "0", "commentCount": "18"}, "contentDetails": {"duration": "PT29M46S"}}]}, {"idx_paper": "10.1109/MSP.2017.2765202", "q": "ieeexplore.ieee.org/document/8253599", "items": [{"id": "Cb8v0C8ZbXU", "snippet": {"channelId": "UCZYTClx2T1of7BRZ86-8fow", "title": "How Close Are We to the Perfect Deepfake?", "publishedAt": "2020-01-13T22:00:00Z", "tags": ["SciShow", "science", "Hank", "Green", "education", "learn", "How Close Are We to the Perfect Deepfake?", "deepfake", "CGI", "videogames", "graphics", "future", "technology", "video", "footage", "generative adversarial networks", "GANs", "neural network", "AI", "generative network", "discriminative network", "reality", "audio", "metadata", "GPS", "media literacy"], "channelTitle": "SciShow", "description": "Thanks to deepfakes, CGI can be more realistic and even amateurs can easily create some fun footage. But there are also sinister uses out there.\n\nHosted by: Hank Green \n\nJordan Peele's fakedeep Obama video: https://www.youtube.com/watch?v=cQ54GDm1eL0\n\nSciShow has a spinoff podcast! It's called SciShow Tangents. Check it out at http://www.scishowtangents.org\n----------\nSupport SciShow by becoming a patron on Patreon: https://www.patreon.com/scishow\n----------\nHuge thanks go to the following Patreon supporters for helping us keep SciShow free for everyone forever:\n\nKevin Carpentier, Eric Jensen, Matt Curls, Sam Buck, Christopher R Boucher, Avi Yashchin, Adam Brainard, Greg, Alex Hackman, Sam Lutfi, D.A. Noe, Piya Shedden, KatieMarie Magnone, Scott Satovsky Jr, Charles Southerland, Patrick D. Ashmore, charles george, Kevin Bealer, Chris Peters\n----------\nLooking for SciShow elsewhere on the internet?\nFacebook: http://www.facebook.com/scishow\nTwitter: http://www.twitter.com/scishow\nTumblr: http://scishow.tumblr.com\nInstagram: http://instagram.com/thescishow\n----------\nSources:\nhttps://www.wired.com/story/prepare-deepfake-era-web-video/\nhttps://www.bbc.co.uk/news/technology-49961089\nhttps://www.youtube.com/watch?v=g5wLaJYBAm4\nhttps://www.youtube.com/watch?v=8LhI-e2B8Lg\nhttps://www.ft.com/content/4bf4277c-f527-11e9-a79c-bc9acae3b654\nhttps://ieeexplore.ieee.org/abstract/document/8253599\nhttps://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf\nhttps://arxiv.org/abs/1701.00160\nhttps://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/\nhttps://www.wired.com/video/watch/researcher-explains-deepfake-videos\nhttps://thenextweb.com/insights/2018/01/22/i-trained-an-ai-to-copy-my-voice-and-scared-myself-silly/\nhttps://arxiv.org/abs/1910.06711\n\nImage Sources: \nhttps://www.istockphoto.com/photo/online-movie-stream-with-mobile-device-gm880861434-245318394\nhttps://commons.wikimedia.org/w/index.php?sort=relevance&search=generative+adversarial+networks&title=Special:Search&profile=advanced&fulltext=1&advancedSearch-current=%7B%7D&ns0=1&ns6=1&ns12=1&ns14=1&ns100=1&ns106=1#/media/File:Woman_4.jpg\nhttps://commons.wikimedia.org/wiki/File:Boy_1.jpg\nhttps://commons.wikimedia.org/wiki/File:Man_2.jpg\nhttps://commons.wikimedia.org/wiki/File:Woman_1.jpg\nhttps://www.istockphoto.com/photo/technology-abstract-gm1148091793-309936308\nhttps://www.videoblocks.com/video/fashion-vlogger-recording-on-mobile-video-camera-r-9sdu_tnju7waot5", "defaultAudioLanguage": "en", "defaultLanguage": "en"}, "statistics": {"likeCount": "7343", "dislikeCount": "115", "viewCount": "185467", "favoriteCount": "0", "commentCount": "583"}, "contentDetails": {"duration": "PT6M3S"}}]}, {"idx_paper": "10.1002/rob.21774", "q": "onlinelibrary.wiley.com/doi/abs/10.1002/rob.21774", "items": [{"id": "FLunb5Y-USI", "snippet": {"channelId": "UCvZxz1EAMogr3sU1GaGqVXQ", "title": "NVIDIA Jetson AGX Xavier Developer Day Talk - GTC DC 2018 - Shreyas Skandan", "publishedAt": "2018-10-23T16:35:43Z", "tags": ["shreyas", "skandan", "shivakumar", "nvidia", "gtc", "dc", "jetson", "xavier", "developer", "day", "washington", "darpa", "FLA", "upenn", "vijay", "kumar", "camillo", "jose", "taylor", "artificical", "intelligence", "deep", "learning", "embedded", "robotics", "drones", "uav", "guest", "speaker", "semantic", "segmentation", "state", "estimation", "planning"], "channelTitle": "Shreyas Skandan", "description": "Some of the discussed tools/software:\n\nFast Lightweight Autonomy project:\nhttps://www.darpa.mil/news-events/2018-07-18\n\nAssociated Papers:\nhttps://ieeexplore.ieee.org/abstract/document/7839930\nhttps://onlinelibrary.wiley.com/doi/full/10.1002/rob.21774\nhttps://ieeexplore.ieee.org/abstract/document/8206119\nhttps://arxiv.org/abs/1806.07053\nhttps://arxiv.org/abs/1809.07677\n\nThe Open Vision Computer - Morgan Quigley et. al\nOSRF Website: https://www.openrobotics.org/\nWebsite: http://open.vision.computer\nPaper: https://arxiv.org/abs/1809.07674\n\nRobust Stereo Visual Inertial Odometry for Fast\nAutonomous Flight - Ke Sun et. al.\nPaper: https://arxiv.org/pdf/1712.00036.pdf\nCode: https://github.com/KumarRobotics/msckf_vio\n\nEvent Camera work - Alex Zhu et. al\nPaper: https://arxiv.org/abs/1801.10202\nPaper: https://arxiv.org/abs/1802.06898\nCode: https://github.com/daniilidis-group/EV-FlowNet \n\nSemantic Segmentation ROS Package:\nCode: https://github.com/ShreyasSkandanS/ss_segmentation\n\nFeel free to contact me with any other questions."}, "statistics": {"likeCount": "1", "dislikeCount": "0", "viewCount": "254", "favoriteCount": "0", "commentCount": "0"}, "contentDetails": {"duration": "PT18M6S"}}]}, {"idx_paper": "10.1111/mice.12298", "q": "onlinelibrary.wiley.com/doi/abs/10.1111/mice.12298", "items": [{"id": "B2ZF2UAHGc4", "snippet": {"channelId": "UC9awMC5PyMZNHls3ZGFppkg", "title": "Como buscar Refer\u00eancias Bibliogr\u00e1ficas de qualidade (Parte 1 - Artigos cient\u00edficos)", "publishedAt": "2020-01-14T02:24:10Z", "tags": ["artigos", "sci hub", "sci-hub", "refer\u00eancias", "bibliograficas", "bibliografia", "referencial", "te\u00f3rico", "qu\u00edmica", "ci\u00eancia", "trabalho", "tese", "disserta\u00e7\u00e3o", "revista", "cient\u00edfica", "laborat\u00f3rio", "references", "journal", "paper", "divulga\u00e7\u00e3o", "trabalhos", "mestrado", "doutorado", "experimento", "experi\u00eancia", "peri\u00f3dico", "peri\u00f3dicos", "capes", "portal"], "channelTitle": "Canal Qu\u00edmica Experimental", "description": "Apresentamos nesse primeiro v\u00eddeo sobre refer\u00eancias bibliogr\u00e1ficas sugest\u00f5es para a busca de artigos cient\u00edficos pois sabemos da dificuldade em se encontrar material s\u00e9rio para se amparar na escrita de materiais de qualidade.\n\nComo fiz a grava\u00e7\u00e3o foi em tempo real, a narra\u00e7\u00e3o foi feita de um modo informal, ent\u00e3o pe\u00e7o que relevem os erros de portugu\u00eas do v\u00eddeo.\n\nLinks:\n\nweb of science (acessar pelo portal de peri\u00f3dicos da capes)\nhttps://www.ncbi.nlm.nih.gov (principalmente de ci\u00eancias da sa\u00fade)\nhttps://onlinelibrary.wiley.com (da Editora Wiley Interscience)\nhttps://www.reaxys.com (necess\u00e1rio cadastro al\u00e9m de estar em computador de uma IFES)\nhttps://www.scopus.com (da editora Elsevier)\nhttps://scifinder.cas.org (necess\u00e1rio cadastro al\u00e9m de estar em computador de uma IFES)\nhttps://scholar.google.com.br\nhttps://www.scielo.org (conte\u00fado em portugu\u00eas)\nhttps://www.ieee.org (material de engenharia)\nhttps://sci-hub.tw/ (ou https://sci-hub.se/ )\nhttps://www.sciencedirect.com/ (da editora Elsevier - apenas artigos)\nhttps://www.rsc.org/ (Royal Society of Chemistry)\n\nM\u00fasicas:\n\nJourney in the New World de Twin Musicom est\u00e1 licenciada sob uma licen\u00e7a Creative Commons Attribution (https://creativecommons.org/licenses/...)\nOrigem: http://www.twinmusicom.org/song/258/j...\nArtista: http://www.twinmusicom.org\n\nRefer\u00eancias Bibliogr\u00e1ficas\n\nBALHARA, Y. P. S., Indexed journal: What does it mean? Lung India 29(2):193, 2012. (Dispon\u00edvel em: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3354504/ )\n\nDUDO, A.; Scientists, the Media, and the Public Communication of Science. Sociology Compass, 9(9), 761\u2013775, 2015. (Dispon\u00edvel em: https://onlinelibrary.wiley.com/doi/abs/10.1111/soc4.12298 )", "defaultLanguage": "pt"}, "statistics": {"likeCount": "51", "dislikeCount": "0", "viewCount": "309", "favoriteCount": "0", "commentCount": "8"}, "contentDetails": {"duration": "PT30M52S"}}]}, {"idx_paper": "10.1016/j.cma.2017.08.030", "q": "sciencedirect.com/science/article/pii/S0045782517306096", "items": [{"id": "95Fr8Tz_e2I", "snippet": {"publishedAt": "2017-07-31T10:37:20Z", "channelTitle": "Archana Arbind", "description": "http://www.sciencedirect.com/science/article/pii/S0045782517306096", "channelId": "UCxBDz8hOL1UAh34v5IHOGGQ", "title": "One-dimensional theory of shell"}, "statistics": {"likeCount": "3", "dislikeCount": "0", "viewCount": "256", "favoriteCount": "0", "commentCount": "0"}, "contentDetails": {"duration": "PT5S"}}]}, {"idx_paper": "10.1016/j.cma.2017.08.030", "q": "sciencedirect.com/science/article/pii/S0045782517306096", "items": [{"id": "GnyESiynJ5w", "snippet": {"channelId": "UCxBDz8hOL1UAh34v5IHOGGQ", "title": "Pinched cylinder with fixed end by 1-D theory of shell", "publishedAt": "2017-07-31T10:37:52Z", "tags": ["Shell theory", "1-D theory"], "channelTitle": "Archana Arbind", "description": "http://www.sciencedirect.com/science/article/pii/S0045782517306096"}, "statistics": {"likeCount": "2", "dislikeCount": "0", "viewCount": "178", "favoriteCount": "0", "commentCount": "1"}, "contentDetails": {"duration": "PT7S"}}]}, {"idx_paper": "10.1016/j.trc.2017.10.024", "q": "sciencedirect.com/science/article/pii/S0968090X17302978", "items": [{"id": "tPa-ShiY2p4", "snippet": {"publishedAt": "2019-05-13T20:31:15Z", "channelTitle": "Shlomi Hacohen", "description": "We propose a new model for formulating the dynamics of the interaction between drivers and pedestrians at congested conflict spots. In this type of spots, characterized by heavy traffic, the interactions between the pedestrians and the vehicles is very close, often requiring aggressive maneuvers to avoid rashes. The model is based on the Probabilistic Navigation Function (PNF) that enables estimating the collision risks along a continuous trajectory. According to the model, drivers and pedestrians in congested environments select their trajectories based on their perceived probability map that is defined by the probability of collision with each other. Most accidents that involve collisions between cars and pedestrians can be interpreted in terms of the proposed model. The two major reasons of collisions according to the model are either initially incorrect cognitive \"probability map\" by one or more agents, or, despite proper estimating of risks, wrong choice of collision avoidance trajectory of at least one agent. \nThe development of the model follows an extensive theoretical and experimental investigation of pedestrian/vehicle interactions at crosswalks, as part of the development of an Agent-Based simulation of car-pedestrian interactions at road spot. The model is implement in a new agent based simulation system for pedestrian/drives interaction, and is validated using video clips taken at several congested road spots. The model can be used for analysing the effect of changes in spots' architecture and traffic regulations for reducing the danger of traffic accidents. It can also serve as a standard tool for assessing accident risks at urban crossroads before they are constructed or re-constructed. \n\nfor more information see:  https://www.sciencedirect.com/science/article/pii/S0968090X17302978", "channelId": "UCQX7_yyW_hyhyIopRZSDhvQ", "title": "Dynamic Model for Pedestrian Crossing using  PNF"}, "statistics": {"likeCount": "0", "dislikeCount": "0", "viewCount": "16", "favoriteCount": "0", "commentCount": "0"}, "contentDetails": {"duration": "PT43S"}}]}]