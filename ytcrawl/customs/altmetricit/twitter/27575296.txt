{"citation_id": "27575296", "completed": "1", "queriedAt": "2020-05-14 12:32:25", "tab": "twitter", "twitter": {"920608284591185921": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "24", "datetime": "2017-10-18 11:11:33", "author": "@healthonrails"}, "921065085715566592": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "599", "datetime": "2017-10-19 17:26:43", "author": "@gerasimoss"}, "1249531677358960643": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "3,633", "datetime": "2020-04-13 02:55:41", "author": "@HirokatuKataoka"}, "921364491022999552": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,250", "datetime": "2017-10-20 13:16:27", "author": "@side_tana"}, "1249219298838474752": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "46", "datetime": "2020-04-12 06:14:24", "author": "@kakikukeko996"}, "1247822099101683712": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "118", "datetime": "2020-04-08 09:42:26", "author": "@matthewopala"}, "920659671727226880": {"content_summary": "Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u5be7\u3055\u300d\u3082\u611f\u3058\u3089\u308c\u308b\uff09 https://t.co/Zkiou7D2Rh", "followers": "2,671", "datetime": "2017-10-18 14:35:45", "author": "@mosko_mule"}, "921322734788919297": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "318", "datetime": "2017-10-20 10:30:31", "author": "@rad0717"}, "921236934092980224": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "457", "datetime": "2017-10-20 04:49:35", "author": "@kouki_outstand"}, "920620481677586432": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "5,016", "datetime": "2017-10-18 12:00:01", "author": "@Clive_G_Brown"}, "921619871531638784": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "626", "datetime": "2017-10-21 06:11:14", "author": "@Alisher_ai_ML"}, "923728362865967105": {"content_summary": "Proposals of new activation functions are quite in fashion. Swish https://t.co/IFHZZZtWa8 ISRLU https://t.co/a8eqgoFcG0 #iclr2018", "followers": "3,223", "datetime": "2017-10-27 01:49:38", "author": "@MelodyGuan"}, "920636070953304065": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "4,946", "datetime": "2017-10-18 13:01:58", "author": "@micahstubbs"}, "921247942006026242": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "841", "datetime": "2017-10-20 05:33:19", "author": "@a2uky"}, "921235358171275264": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "903", "datetime": "2017-10-20 04:43:19", "author": "@kyogoku_meta"}, "972293463315288066": {"content_summary": "31 https://t.co/h8eWECkmep", "followers": "2", "datetime": "2018-03-10 02:10:00", "author": "@yartrick"}, "921214510211383296": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,454", "datetime": "2017-10-20 03:20:29", "author": "@mandel59"}, "921654220234801152": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "879", "datetime": "2017-10-21 08:27:44", "author": "@kusanominal"}, "921207138478825473": {"content_summary": "\u8a66\u3057\u3066\u307f\u305f\u3089\u666e\u901a\u306b\u7cbe\u5ea6\u4e0a\u304c\u3063\u305f\uff57 https://t.co/JJ2z5hrNBI", "followers": "347", "datetime": "2017-10-20 02:51:11", "author": "@Gin04tw"}, "1247754839733325824": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "8", "datetime": "2020-04-08 05:15:10", "author": "@Zhanghanchu1"}, "921902568355258368": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "3", "datetime": "2017-10-22 00:54:35", "author": "@FromNowOnOnline"}, "920639547586867200": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "38", "datetime": "2017-10-18 13:15:47", "author": "@gauravp3005"}, "920544351410892801": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "206", "datetime": "2017-10-18 06:57:30", "author": "@chode_modules"}, "922011630719795201": {"content_summary": "RT @datasci_blogs: \u3010\u7dd1\u8336\u601d\u8003\u30d6\u30ed\u30b0\u3011 https://t.co/i1KBIfqdD7 Swish\u3092CIFAR10\u3067\u8a66\u3057\u3066\u307f\u308b Swish: a Self-Gated Activation Function https://t.co/CW5UIFSWAj\u2026", "followers": "433", "datetime": "2017-10-22 08:07:57", "author": "@hs_heddy"}, "921065844880355329": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "819", "datetime": "2017-10-19 17:29:44", "author": "@ErmiaBivatan"}, "921223310045732866": {"content_summary": "RT:machinelearnbot: RT Weenkus: It seems like there is a new activation function every day - Swish! https://t.co/TTcqr2Zx9G #DataScience #\u2026", "followers": "3,314", "datetime": "2017-10-20 03:55:27", "author": "@AndySugs"}, "921662213609238528": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "868", "datetime": "2017-10-21 08:59:30", "author": "@SING_A_WELL"}, "921281505741062145": {"content_summary": "#\u6211\u7684\u5370\u8c61\u7b14\u8bb0 https://t.co/8E7iZuhqKb", "followers": "221", "datetime": "2017-10-20 07:46:42", "author": "@ScriptShade"}, "921329240104042498": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "143", "datetime": "2017-10-20 10:56:22", "author": "@yuzutyaya"}, "920988497556545537": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "155", "datetime": "2017-10-19 12:22:23", "author": "@Trtd6Trtd"}, "920619142956302336": {"content_summary": "RT @_Ryobot: Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co\u2026", "followers": "451", "datetime": "2017-10-18 11:54:42", "author": "@cobwebkanamachi"}, "921186444776845312": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,031", "datetime": "2017-10-20 01:28:57", "author": "@tomoya52215710"}, "920891415743283201": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "66", "datetime": "2017-10-19 05:56:37", "author": "@iamtpb"}, "921217567254966272": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "610", "datetime": "2017-10-20 03:32:38", "author": "@gendaibushi"}, "920642081994940417": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "698", "datetime": "2017-10-18 13:25:51", "author": "@michaelconlin"}, "920880446614904832": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "24", "datetime": "2017-10-19 05:13:02", "author": "@EliBenMichael"}, "921300681411108864": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "3,005", "datetime": "2017-10-20 09:02:54", "author": "@hakumai_no_tomo"}, "920697583491837953": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/iZ1eRgqBJN #datascience #startups", "followers": "113", "datetime": "2017-10-18 17:06:24", "author": "@GrwthUnion"}, "921127776345821184": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "52", "datetime": "2017-10-19 21:35:50", "author": "@HengjianJia"}, "921217091054612480": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "407", "datetime": "2017-10-20 03:30:44", "author": "@mwtndmik"}, "921590069974069248": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "585", "datetime": "2017-10-21 04:12:49", "author": "@e10dokup"}, "921222706414084096": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "10,129", "datetime": "2017-10-20 03:53:03", "author": "@sylvan5"}, "1249210026092310538": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "291", "datetime": "2020-04-12 05:37:34", "author": "@ZQ875328"}, "920543223713542145": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "574", "datetime": "2017-10-18 06:53:02", "author": "@LucaAmb"}, "920924730097483776": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "28", "datetime": "2017-10-19 08:09:00", "author": "@Swaraj_Kumar_"}, "920518033520709632": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "51", "datetime": "2017-10-18 05:12:56", "author": "@DataScienceToni"}, "921371816614092800": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "186", "datetime": "2017-10-20 13:45:33", "author": "@erk_subasi"}, "1229517732279877632": {"content_summary": "SWISH is looking to be a better activation function than LeakyReLU (pdf) https://t.co/7Gl0dCc8I6 #MachineLearning #neuralnetworks", "followers": "332", "datetime": "2020-02-17 21:27:25", "author": "@myoneuralnet"}, "921272768838037505": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "4,531", "datetime": "2017-10-20 07:11:59", "author": "@yoshizaki_kkgk"}, "920705021603471360": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "214", "datetime": "2017-10-18 17:35:57", "author": "@mauriciociprian"}, "921196575681941504": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "1,137", "datetime": "2017-10-20 02:09:13", "author": "@NaNkotsukan"}, "920660109805592576": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "331", "datetime": "2017-10-18 14:37:29", "author": "@Rohitpatil5"}, "922689780311363586": {"content_summary": "RT @segal_eran: Swish: A new activation function for deep neural network claimed to work better than the good old Relu https://t.co/H6RBauA\u2026", "followers": "317", "datetime": "2017-10-24 05:02:41", "author": "@yaronhadad"}, "1021669358630653952": {"content_summary": "swish\u4f7f\u3063\u305f\u3053\u3068\u306a\u3044\u3051\u3069\u3001ReLU\u306b\u5168\u52dd\u3063\u3066\u3053\u3068\u3067\u4f7f\u3063\u3066\u307f\u3088\u3046\u304b\u306a\u3002 \u3067\u3082\u53ce\u675f\u306f\u9045\u305d\u3046\uff1f https://t.co/aQbPk0TvYh", "followers": "1", "datetime": "2018-07-24 08:12:11", "author": "@gucci11919846"}, "920586084320464896": {"content_summary": "RT @AMVA4NP: Swish activation function f(x) = x \u22c5 \u03c3 (x) outperforms ReLUs in a bunch of benchmarks https://t.co/7z3tBb2xmB #DeepLearning ht\u2026", "followers": "325", "datetime": "2017-10-18 09:43:20", "author": "@pablodecm"}, "921272693575491584": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,508", "datetime": "2017-10-20 07:11:41", "author": "@FatAndRound"}, "921355856498720768": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "155", "datetime": "2017-10-20 12:42:08", "author": "@Trtd6Trtd"}, "920955945282400256": {"content_summary": "RT @aureliengeron: The swish activation function, f(x) = x sigmoid(x). Yet another ReLU variant that seems to outperform it (https://t.co/R\u2026", "followers": "165", "datetime": "2017-10-19 10:13:02", "author": "@giovenko"}, "921231707142885377": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "134", "datetime": "2017-10-20 04:28:49", "author": "@TOx2RO"}, "921323121960820736": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "133", "datetime": "2017-10-20 10:32:04", "author": "@soratobi96"}, "920548222631841792": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "293", "datetime": "2017-10-18 07:12:53", "author": "@RickGalbo"}, "921343591129137152": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "642", "datetime": "2017-10-20 11:53:24", "author": "@mohammedari"}, "921622709775118336": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "218", "datetime": "2017-10-21 06:22:31", "author": "@yocchaz"}, "921049628233031680": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "160", "datetime": "2017-10-19 16:25:18", "author": "@wilkatorrico"}, "920568330347597825": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "76", "datetime": "2017-10-18 08:32:47", "author": "@undo76"}, "1247829417612607488": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "53", "datetime": "2020-04-08 10:11:31", "author": "@hrituraj1997"}, "920721604514123777": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/TuPlBhuVCb", "followers": "4,100", "datetime": "2017-10-18 18:41:51", "author": "@arxiv_cscv"}, "920510007204081665": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,159", "datetime": "2017-10-18 04:41:02", "author": "@R4_Unit"}, "921319586212884481": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "867", "datetime": "2017-10-20 10:18:01", "author": "@YasunoriGoto1"}, "1085038790220107776": {"content_summary": "RT @ajixander: https://t.co/fEP66YQEHT using machine learning to do machine learning research", "followers": "8,291", "datetime": "2019-01-15 04:59:41", "author": "@SantchiWeb"}, "920504379362471937": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "216", "datetime": "2017-10-18 04:18:40", "author": "@e0en"}, "921344083875962880": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "380", "datetime": "2017-10-20 11:55:21", "author": "@oigami013"}, "920696125690204160": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "190", "datetime": "2017-10-18 17:00:36", "author": "@Harssh_Seth"}, "921283922075324417": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,158", "datetime": "2017-10-20 07:56:18", "author": "@tacchan_soccer"}, "921048615346458625": {"content_summary": "Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a PR to @PyTorch now. https://t.co/xc0qeKzXmD", "followers": "622", "datetime": "2017-10-19 16:21:16", "author": "@AiAiHealthcare"}, "921279814715064321": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "847", "datetime": "2017-10-20 07:39:59", "author": "@itoooon"}, "1247828468399607808": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "425", "datetime": "2020-04-08 10:07:45", "author": "@iamknighton"}, "921402765552762886": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,015", "datetime": "2017-10-20 15:48:32", "author": "@tarchan"}, "921085923319828481": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "157", "datetime": "2017-10-19 18:49:31", "author": "@Nbring"}, "920522093179146241": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,938", "datetime": "2017-10-18 05:29:04", "author": "@EldarSilver"}, "920720070044782593": {"content_summary": "Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/eVaiQiXw2H #AI #ML https://t.co/yZAL6b46Ts", "followers": "747", "datetime": "2017-10-18 18:35:45", "author": "@topbotsnews"}, "921024220250935296": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "313", "datetime": "2017-10-19 14:44:20", "author": "@Scott_Frye"}, "921854514973626368": {"content_summary": "RT @appliedAIbook: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/\u2026", "followers": "440", "datetime": "2017-10-21 21:43:38", "author": "@krishnalaghari1"}, "921349029534908417": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "109", "datetime": "2017-10-20 12:15:01", "author": "@Tapacchi_okm"}, "920509303487893504": {"content_summary": "Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co/52gwjXqEBA https://t.co/Tc4dz6bvP2", "followers": "12,924", "datetime": "2017-10-18 04:38:14", "author": "@deliprao"}, "920499567967330304": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "2,043", "datetime": "2017-10-18 03:59:33", "author": "@dosei_sanga"}, "920812126263844864": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,536", "datetime": "2017-10-19 00:41:33", "author": "@rizaudo"}, "921069797353254912": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "161", "datetime": "2017-10-19 17:45:26", "author": "@argv_sat184"}, "921225734479167491": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "247", "datetime": "2017-10-20 04:05:05", "author": "@kogeda92"}, "921337543198515200": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "3,965", "datetime": "2017-10-20 11:29:22", "author": "@hi_saito"}, "921397218380103680": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "136", "datetime": "2017-10-20 15:26:30", "author": "@pencilrocketman"}, "920565709813379072": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "162", "datetime": "2017-10-18 08:22:23", "author": "@greentecq"}, "920706183819821056": {"content_summary": "RT @GrwthUnion: Swish: a Self-Gated Activation Function https://t.co/iZ1eRgqBJN #datascience #startups", "followers": "3,133", "datetime": "2017-10-18 17:40:34", "author": "@AdaptiveToolbox"}, "1249233458716696576": {"content_summary": "\u30b7\u30f3\u30ae\u30e5\u30e9\u308b", "followers": "266", "datetime": "2020-04-12 07:10:40", "author": "@RumojiD"}, "920786664410169344": {"content_summary": "RT @thinkmariya: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/nU\u2026", "followers": "456", "datetime": "2017-10-18 23:00:22", "author": "@PerthMLGroup"}, "921275846760980480": {"content_summary": "Everyone seems to keep arguing about how nonmonotonicity helps the training faster and better with this SWISH\u2193 https://t.co/Q0JrnxTYqz", "followers": "273", "datetime": "2017-10-20 07:24:13", "author": "@faisal_putra"}, "921317984253050880": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "756", "datetime": "2017-10-20 10:11:39", "author": "@yoshihoka"}, "1247866309372784641": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "493", "datetime": "2020-04-08 12:38:07", "author": "@smahate"}, "920759838535274496": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "600", "datetime": "2017-10-18 21:13:47", "author": "@John_Idol"}, "921087841568022528": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "108", "datetime": "2017-10-19 18:57:09", "author": "@kbjorklu"}, "925254914363727872": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "14,222", "datetime": "2017-10-31 06:55:36", "author": "@upura0"}, "920519288678731776": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "299", "datetime": "2017-10-18 05:17:55", "author": "@westis96"}, "921172865860255745": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/EMdou481zm #ai #deeplearning #nlp via @thinkmariya", "followers": "2,286", "datetime": "2017-10-20 00:35:00", "author": "@future_of_AI"}, "922029238718316551": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "3,210", "datetime": "2017-10-22 09:17:55", "author": "@hika_ruriruri"}, "921345393568501760": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,160", "datetime": "2017-10-20 12:00:34", "author": "@_ambodi"}, "920522125156417537": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "291", "datetime": "2017-10-18 05:29:11", "author": "@pierre_paci"}, "920696470331973633": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/iMjvewCBq4", "followers": "2,352", "datetime": "2017-10-18 17:01:58", "author": "@programmingncr"}, "1249383696257318913": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "71", "datetime": "2020-04-12 17:07:40", "author": "@semiinvariant"}, "921330328408440832": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "386", "datetime": "2017-10-20 11:00:42", "author": "@tellusium"}, "921567394903891968": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,093", "datetime": "2017-10-21 02:42:43", "author": "@Xe_no"}, "972293343995719681": {"content_summary": "https://t.co/uC5EgpyiJk An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling", "followers": "2", "datetime": "2018-03-10 02:09:32", "author": "@yartrick"}, "921544853204361217": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "339", "datetime": "2017-10-21 01:13:09", "author": "@ttomoakii"}, "921322935209533441": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "257", "datetime": "2017-10-20 10:31:19", "author": "@osker_jn"}, "1166397573709496321": {"content_summary": "swish\u95a2\u6570\u767a\u898b\u306e\u8ad6\u6587\u306b\u3088\u308b\u3068\u3001softplus\u3082\u7d50\u69cb\u826f\u3044\u3089\u3057\u3044 \u3084\u3063\u3071\u308a\u8a08\u7b97\u30b3\u30b9\u30c8\u304c\u554f\u984c\u306a\u306e\u304b https://t.co/emyyRsJih6", "followers": "633", "datetime": "2019-08-27 17:10:26", "author": "@ChagallBlau"}, "920534164381847552": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "608", "datetime": "2017-10-18 06:17:02", "author": "@qmalvido"}, "920761687283851264": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "110", "datetime": "2017-10-18 21:21:07", "author": "@rguignar"}, "920772099387437056": {"content_summary": "RT @arxiv_flying: #ICLR2018 Swish: a Self-Gated Activation Function. (arXiv:1710.05941v1 [cs.NE]) https://t.co/uoKw4ms5yU", "followers": "783", "datetime": "2017-10-18 22:02:30", "author": "@muktabh"}, "921069518100852748": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "1,335", "datetime": "2017-10-19 17:44:20", "author": "@Sugarsteroni"}, "921213159880323072": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "345", "datetime": "2017-10-20 03:15:07", "author": "@yuukikey"}, "921210918628769792": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "248", "datetime": "2017-10-20 03:06:12", "author": "@arrow_elpis"}, "922629267250331649": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "12", "datetime": "2017-10-24 01:02:13", "author": "@Masashi_Ueda"}, "920662527234621440": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "491", "datetime": "2017-10-18 14:47:06", "author": "@shamidreza"}, "925547696051576835": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "511", "datetime": "2017-11-01 02:19:01", "author": "@tmasada"}, "1249210518293921792": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "463", "datetime": "2020-04-12 05:39:31", "author": "@8kazu3"}, "920776747716558848": {"content_summary": "RT @arxiv_cscv: Swish: a Self-Gated Activation Function https://t.co/TuPlBhuVCb", "followers": "68", "datetime": "2017-10-18 22:20:58", "author": "@shinryu_rk"}, "921216179024289793": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,290", "datetime": "2017-10-20 03:27:07", "author": "@machinery81"}, "921423959173644290": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "134", "datetime": "2017-10-20 17:12:45", "author": "@gjhdvhd"}, "920508950692483073": {"content_summary": "RT @awjuliani: Love it. https://t.co/nfXRZv9mnz", "followers": "113", "datetime": "2017-10-18 04:36:50", "author": "@isaiahtaguibao"}, "1249270284269408257": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "174", "datetime": "2020-04-12 09:37:00", "author": "@n_u_l_l_p_o"}, "921408626312462336": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "158", "datetime": "2017-10-20 16:11:50", "author": "@curlune"}, "921337863941242881": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "128", "datetime": "2017-10-20 11:30:39", "author": "@mshinoda88"}, "921409721747193863": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "420", "datetime": "2017-10-20 16:16:11", "author": "@habatafuture"}, "920501760761958400": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "427", "datetime": "2017-10-18 04:08:16", "author": "@jp_axs4ll"}, "921323491227344896": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "433", "datetime": "2017-10-20 10:33:32", "author": "@ruimo"}, "922689834623340544": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "9", "datetime": "2017-10-24 05:02:53", "author": "@Ltee_0and4th"}, "921290201770606593": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "4", "datetime": "2017-10-20 08:21:15", "author": "@yasacurry"}, "921284695878377472": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "82", "datetime": "2017-10-20 07:59:22", "author": "@RyoHWS"}, "1249203569905020928": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "63", "datetime": "2020-04-12 05:11:54", "author": "@dentoman05"}, "920697442605158400": {"content_summary": "Title: Swish: a Self-Gated Activation Function https://t.co/qLdo9aHNyj #datascience #analytics", "followers": "666", "datetime": "2017-10-18 17:05:50", "author": "@thiakx"}, "921530661453815809": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "357", "datetime": "2017-10-21 00:16:45", "author": "@nukinukinuki555"}, "920632493182615552": {"content_summary": "Interesting approach for an activation function ! When 1% improvement is hard work - https://t.co/O5Ny0uXTYp", "followers": "21", "datetime": "2017-10-18 12:47:45", "author": "@souravch2014"}, "1061463255263014912": {"content_summary": "RT @AI_Frontiers: #AutoML is capable of searching optimized network architecture for your #AI problem, @quocleix et al have found a new act\u2026", "followers": "26", "datetime": "2018-11-11 03:38:55", "author": "@ReedRoof"}, "920603105896599552": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "189", "datetime": "2017-10-18 10:50:59", "author": "@shahrukh_athar"}, "921654817264517120": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "186", "datetime": "2017-10-21 08:30:06", "author": "@genksn4"}, "920528719776796672": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "7,133", "datetime": "2017-10-18 05:55:24", "author": "@anshulkundaje"}, "921350344730320897": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "448", "datetime": "2017-10-20 12:20:14", "author": "@iftianjiar"}, "921216323392114690": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "136", "datetime": "2017-10-20 03:27:41", "author": "@spike_fairway"}, "921328956514607104": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "190", "datetime": "2017-10-20 10:55:15", "author": "@sation25000"}, "920524725243273216": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "39", "datetime": "2017-10-18 05:39:31", "author": "@Christyjacob126"}, "920503037071974400": {"content_summary": "Yet another activation function. Don't trick me like SELU again. All those experiments with false hopes. Lol. https://t.co/g46tBcVzko", "followers": "817", "datetime": "2017-10-18 04:13:20", "author": "@ark_aung"}, "921126981873348608": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "604", "datetime": "2017-10-19 21:32:40", "author": "@JustinTimesUK"}, "922667405612015617": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "543", "datetime": "2017-10-24 03:33:46", "author": "@wsuzume"}, "924935947170598912": {"content_summary": "@poolio An update of the paper: https://t.co/MNJtl5YdpZ New experiments and \"swish\" is now x*sigmoid(beta*x). To be grumpy: no comparison to GLU \ud83d\ude09", "followers": "2,781", "datetime": "2017-10-30 09:48:08", "author": "@jmtomczak"}, "921534262918103040": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "68", "datetime": "2017-10-21 00:31:04", "author": "@misoh_009"}, "921216976222953478": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "827", "datetime": "2017-10-20 03:30:17", "author": "@morioka"}, "1249214707338272768": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "201", "datetime": "2020-04-12 05:56:10", "author": "@Singularity_43"}, "920696317726167040": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "854", "datetime": "2017-10-18 17:01:22", "author": "@mbeissinger"}, "921342040738115584": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "211", "datetime": "2017-10-20 11:47:14", "author": "@wamiria"}, "920504454004334592": {"content_summary": "[1710.05941] Swish: a Self-Gated Activation Function https://t.co/hTj5WD5SJU ReLU\u3088\u308a\u826f\u3044\u3088\u3001\u3068\u3044\u3046Swish\u6d3b\u6027\u5316\u95a2\u6570 f(x) = x\u30fb\u03c3(x) = x/{1+exp(-x)}\u3002", "followers": "5,118", "datetime": "2017-10-18 04:18:58", "author": "@tonets"}, "921212805973393408": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,279", "datetime": "2017-10-20 03:13:42", "author": "@yitabashi"}, "920782505577406464": {"content_summary": "RT @mosko_mule: Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u2026", "followers": "2,290", "datetime": "2017-10-18 22:43:51", "author": "@fronori"}, "920458262788448256": {"content_summary": "Swish: a Self-Gated Activation Function. https://t.co/RBABgVZ5uc", "followers": "613", "datetime": "2017-10-18 01:15:25", "author": "@ComputerPapers"}, "1249280207170596868": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "530", "datetime": "2020-04-12 10:16:26", "author": "@bana_cell"}, "920518255114059782": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "25,260", "datetime": "2017-10-18 05:13:49", "author": "@alexjc"}, "921211280509173763": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "384", "datetime": "2017-10-20 03:07:39", "author": "@SVOdoriko"}, "920693132454498304": {"content_summary": "Swish, swish, bish https://t.co/xeWml9WcuJ", "followers": "441", "datetime": "2017-10-18 16:48:43", "author": "@shivam13verma"}, "924803097334968320": {"content_summary": "Searching for Activation Functions. (arXiv:1710.05941v2 [cs.NE] UPDATED) https://t.co/cp7M0oX6hv The choice of activation functions in deep", "followers": "757", "datetime": "2017-10-30 01:00:15", "author": "@M157q_News_RSS"}, "921212166727901184": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "339", "datetime": "2017-10-20 03:11:10", "author": "@Links_1008"}, "920718774805786624": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "25,311", "datetime": "2017-10-18 18:30:36", "author": "@deeplearning4j"}, "921186674389823488": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "325", "datetime": "2017-10-20 01:29:52", "author": "@k_yagisan9"}, "1249221200233943040": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "422", "datetime": "2020-04-12 06:21:58", "author": "@KH201110"}, "920633836597157888": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "2,813", "datetime": "2017-10-18 12:53:05", "author": "@CSProfKGD"}, "1259995543675080704": {"content_summary": "RT @jaguring1: AutoML\u5206\u91ce\u306e\u4e8b\u4f8b https://t.co/wHxLDEZLld", "followers": "133", "datetime": "2020-05-11 23:55:21", "author": "@shinichi_natori"}, "920804608892592128": {"content_summary": "RT @mosko_mule: Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u2026", "followers": "325", "datetime": "2017-10-19 00:11:41", "author": "@ichi5c2"}, "920582719691685889": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "7,210", "datetime": "2017-10-18 09:29:58", "author": "@fastml_extra"}, "921357354871922689": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "437", "datetime": "2017-10-20 12:48:06", "author": "@tomisuker"}, "920599105293955072": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "43", "datetime": "2017-10-18 10:35:05", "author": "@frabarbuto"}, "921828082809438213": {"content_summary": "RT @topbotsnews: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/eV\u2026", "followers": "96", "datetime": "2017-10-21 19:58:36", "author": "@kellyscientist"}, "920540870037901312": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "4,891", "datetime": "2017-10-18 06:43:40", "author": "@IgorCarron"}, "920890165547159553": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "28,418", "datetime": "2017-10-19 05:51:39", "author": "@ogrisel"}, "920506777552203776": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "753", "datetime": "2017-10-18 04:28:12", "author": "@suneelmarthi"}, "920563741934067712": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "558", "datetime": "2017-10-18 08:14:33", "author": "@ocaokgbu"}, "920609644510359552": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "823", "datetime": "2017-10-18 11:16:58", "author": "@CarldeBoerPhD"}, "920605560164241408": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "7,190", "datetime": "2017-10-18 11:00:44", "author": "@gigasquid"}, "920500257355530241": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "19,132", "datetime": "2017-10-18 04:02:18", "author": "@petewarden"}, "921307792035549184": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "356", "datetime": "2017-10-20 09:31:09", "author": "@ryors_k"}, "921340520898682881": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "287", "datetime": "2017-10-20 11:41:12", "author": "@nekomaguro"}, "920555374175928320": {"content_summary": "RT @_Ryobot: Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co\u2026", "followers": "2,043", "datetime": "2017-10-18 07:41:18", "author": "@dosei_sanga"}, "921064057070907394": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "1,417", "datetime": "2017-10-19 17:22:38", "author": "@seanmylaw"}, "921323580515692544": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "300", "datetime": "2017-10-20 10:33:53", "author": "@wing_tail"}, "920720058472529920": {"content_summary": "RT @thinkmariya: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/nU\u2026", "followers": "0", "datetime": "2017-10-18 18:35:42", "author": "@BurgdorfOssie"}, "921197007833829378": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "15,143", "datetime": "2017-10-20 02:10:56", "author": "@alevergara78"}, "1247833675539996674": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "13", "datetime": "2020-04-08 10:28:26", "author": "@EricKuy"}, "920666141525098497": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,838", "datetime": "2017-10-18 15:01:27", "author": "@gringene_bio"}, "921229595986104321": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "816", "datetime": "2017-10-20 04:20:25", "author": "@Zygote2501"}, "921304007229845505": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "679", "datetime": "2017-10-20 09:16:06", "author": "@yousui_t_ken"}, "1249210554725662720": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "279", "datetime": "2020-04-12 05:39:40", "author": "@shigesan43"}, "921603826305654784": {"content_summary": "\u3010\u7dd1\u8336\u601d\u8003\u30d6\u30ed\u30b0\u3011 https://t.co/i1KBIfqdD7 Swish\u3092CIFAR10\u3067\u8a66\u3057\u3066\u307f\u308b Swish: a Self-Gated Activation Function https://t.co/CW5UIFSWAj ReLU\u306e\u4ee3\u308f\u308a\u306b\u306a\u308b\u6d3b\u6027\u5316\u95a2\u6570\u2026", "followers": "3,136", "datetime": "2017-10-21 05:07:29", "author": "@datasci_blogs"}, "921390860142391297": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "835", "datetime": "2017-10-20 15:01:14", "author": "@yukky_saito"}, "920692080866816000": {"content_summary": "Really interesting stuff! Either matches or outperforms relu on all the benchmarks they did https://t.co/yTA1yrncQQ", "followers": "190", "datetime": "2017-10-18 16:44:32", "author": "@lizardlucas42"}, "921334979233169408": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "14", "datetime": "2017-10-20 11:19:11", "author": "@onsh_"}, "921713874642063360": {"content_summary": "A new Swish activation function to replace #RELU in #DeepNeturalNets! https://t.co/LdLRTJNRVM", "followers": "665", "datetime": "2017-10-21 12:24:46", "author": "@jeffreynsk"}, "920676539716505604": {"content_summary": "RT @Miles_Brundage: \"Swish: a Self-Gated Activation Function,\" Ramachandran et al.: https://t.co/bRa2xOCugx", "followers": "4,636", "datetime": "2017-10-18 15:42:47", "author": "@mohitban47"}, "921394036333625344": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "21,147", "datetime": "2017-10-20 15:13:51", "author": "@kurubushi_rm"}, "921338755339902977": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,071", "datetime": "2017-10-20 11:34:11", "author": "@amasawa_seiji"}, "1249228254717685760": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "4", "datetime": "2020-04-12 06:50:00", "author": "@florest92842252"}, "920529954290524160": {"content_summary": "What really matters is that now we get a real good understanding of why deep nets work.. oh wait jk, just +.x% on some ad hoc benchmark smh https://t.co/C7Uhx0hQmS", "followers": "27,773", "datetime": "2017-10-18 06:00:18", "author": "@jabawack"}, "921552623903285248": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "398", "datetime": "2017-10-21 01:44:01", "author": "@naitoh"}, "953057833989255168": {"content_summary": "RT @carlcarrie: Activation functions in Deep Learning compared - paper Rectified Linear Unit (ReLU) vs Swish (based on Sigmoid) https://t\u2026", "followers": "56", "datetime": "2018-01-16 00:14:29", "author": "@AllenGan"}, "924994578096246784": {"content_summary": "Searching for Activation Functions https://t.co/TuPlBhuVCb", "followers": "4,100", "datetime": "2017-10-30 13:41:07", "author": "@arxiv_cscv"}, "920949003436613633": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "155", "datetime": "2017-10-19 09:45:27", "author": "@samuelcharron"}, "1249313394575867909": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "196", "datetime": "2020-04-12 12:28:19", "author": "@ml15min"}, "921190487104528384": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "44", "datetime": "2017-10-20 01:45:01", "author": "@CharaBentoPapa"}, "922536352364691456": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "240", "datetime": "2017-10-23 18:53:00", "author": "@malcgreaves"}, "920690242209886208": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "564", "datetime": "2017-10-18 16:37:13", "author": "@DrSamirBhatt"}, "921028493223194624": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "129", "datetime": "2017-10-19 15:01:19", "author": "@SupreethManyam"}, "921239719547039744": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "425", "datetime": "2017-10-20 05:00:39", "author": "@0x1FC0"}, "920800920115351552": {"content_summary": "RT @mosko_mule: Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u2026", "followers": "1,667", "datetime": "2017-10-18 23:57:01", "author": "@Scaled_Wurm"}, "920620701899542529": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "179,069", "datetime": "2017-10-18 12:00:54", "author": "@Montreal_AI"}, "920720072947224576": {"content_summary": "Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/YwmTnr7oSo #AI #ML https://t.co/5q8bp5gIEn", "followers": "207", "datetime": "2017-10-18 18:35:46", "author": "@deepdrinkingnet"}, "920676096147951616": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "83", "datetime": "2017-10-18 15:41:01", "author": "@lucaruzzola"}, "921313156797906944": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "50", "datetime": "2017-10-20 09:52:28", "author": "@ito436"}, "920514149012164609": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,576", "datetime": "2017-10-18 04:57:30", "author": "@nyker_goto"}, "920496622433374210": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "37", "datetime": "2017-10-18 03:47:51", "author": "@RishaanPatel"}, "920691866080817153": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "343", "datetime": "2017-10-18 16:43:41", "author": "@TebanDeSade"}, "920546612203741185": {"content_summary": "RT @beenharsh: Cool! This has been incorporated in #Tensorflow; tf.nn.swish(x). Folks can now just substitute ReLU w/ this and see how much\u2026", "followers": "15,143", "datetime": "2017-10-18 07:06:29", "author": "@alevergara78"}, "921225754695819267": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,048", "datetime": "2017-10-20 04:05:10", "author": "@tackson5"}, "920709826841264128": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/DMT5nwRIpu", "followers": "102", "datetime": "2017-10-18 17:55:03", "author": "@msbicoe"}, "921039361688424449": {"content_summary": "RT @evolvingstuff: Swish: a Self-Gated Activation Function https://t.co/uOuAKypyKP #GoogleBrain https://t.co/SB1H85ymsU", "followers": "142", "datetime": "2017-10-19 15:44:30", "author": "@goulagman"}, "1249342774995865602": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "706", "datetime": "2020-04-12 14:25:03", "author": "@AstarADIEU"}, "920782611336765440": {"content_summary": "RT @thinkmariya: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/nU\u2026", "followers": "217", "datetime": "2017-10-18 22:44:16", "author": "@AssistedEvolve"}, "921723480046952448": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "401", "datetime": "2017-10-21 13:02:57", "author": "@m00y00m"}, "1249209968101916674": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "558", "datetime": "2020-04-12 05:37:20", "author": "@i4mwh4ti4m"}, "940839929315282944": {"content_summary": "[1710.05941] Searching for Activation Functions: https://t.co/8Ki874IDof", "followers": "1,409", "datetime": "2017-12-13 07:04:53", "author": "@Ryosuke0624"}, "920585555775238144": {"content_summary": "Swish activation function f(x) = x \u22c5 \u03c3 (x) outperforms ReLUs in a bunch of benchmarks https://t.co/7z3tBb2xmB #DeepLearning https://t.co/qXNgi01xSh", "followers": "197", "datetime": "2017-10-18 09:41:14", "author": "@AMVA4NP"}, "921446729144090624": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,673", "datetime": "2017-10-20 18:43:14", "author": "@bear_Rits_Conan"}, "920565005065621509": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "103", "datetime": "2017-10-18 08:19:35", "author": "@jongen87"}, "920892665201287168": {"content_summary": "@VishwajitSasi https://t.co/GrilDdizQe", "followers": "63", "datetime": "2017-10-19 06:01:35", "author": "@saxenauts"}, "922521876878053378": {"content_summary": "Swish: A new activation function for deep neural network claimed to work better than the good old Relu https://t.co/H6RBauANef", "followers": "8,731", "datetime": "2017-10-23 17:55:29", "author": "@segal_eran"}, "920936585797005313": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "103", "datetime": "2017-10-19 08:56:06", "author": "@avmoldovan"}, "920511108053643264": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "9,482", "datetime": "2017-10-18 04:45:25", "author": "@Atrix256"}, "923418759829757952": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "5", "datetime": "2017-10-26 05:19:23", "author": "@enoch1ai"}, "921363562848817153": {"content_summary": "Gotta be one of the best 'plucks' of low-hanging fruit in ML. Good thinking! #swish https://t.co/TPGSmdSAfc", "followers": "385", "datetime": "2017-10-20 13:12:46", "author": "@adantro"}, "921391635836973056": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "345", "datetime": "2017-10-20 15:04:19", "author": "@p20_7"}, "1249490696098263041": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "316", "datetime": "2020-04-13 00:12:51", "author": "@DiegoEduk"}, "921207990329344000": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "252", "datetime": "2017-10-20 02:54:34", "author": "@AshitaHamatsuri"}, "920570070153043968": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "3,020", "datetime": "2017-10-18 08:39:42", "author": "@NataliaDiazRodr"}, "920731863492251648": {"content_summary": "RT @deepdrinkingnet: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.c\u2026", "followers": "96", "datetime": "2017-10-18 19:22:37", "author": "@kellyscientist"}, "921772233013518337": {"content_summary": "RT @mariushelf: Swish swish! A new activation function for #deeplearning. TLDR: x*sigmoid(x). Curious to try it on Monday https://t.co/38WI\u2026", "followers": "82", "datetime": "2017-10-21 16:16:40", "author": "@LittleNonsuch"}, "920660496621203463": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/EMdou4pCXW #ai #deeplearning #nlp via @Miles_Brundage", "followers": "2,286", "datetime": "2017-10-18 14:39:02", "author": "@future_of_AI"}, "920509729226534912": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "2,600", "datetime": "2017-10-18 04:39:56", "author": "@AdamMarblestone"}, "920619274724450305": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "363", "datetime": "2017-10-18 11:55:14", "author": "@superneo77"}, "921616528650285056": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "98", "datetime": "2017-10-21 05:57:57", "author": "@drumichiro"}, "925025196154806272": {"content_summary": "[1710.05941v2] Searching for Activation Functions Swish\u306e\u6587\u732e\u304c\u3044\u3064\u306e\u9593\u306b\u304b\u6052\u4f8b\u306eRNN\u3067\u69cb\u9020\u63a2\u7d22\u3059\u308b\u3084\u3064\u306b\u306a\u3063\u3066\u305f\u3002\u305d\u3057\u3066switch\u3060\u3068\u601d\u3063\u3066\u305f\u3002\u3002\u3002 https://t.co/FAauBO6CFg", "followers": "564", "datetime": "2017-10-30 15:42:47", "author": "@asam9891"}, "920667495324946432": {"content_summary": "[1710.05941] Swish: a Self-Gated Activation Function - https://t.co/9D1COPolYq https://t.co/YHQr6w2mMz", "followers": "195", "datetime": "2017-10-18 15:06:50", "author": "@hereticreader"}, "920511370289909761": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "629", "datetime": "2017-10-18 04:46:27", "author": "@oshtim"}, "1249291683281260544": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "30", "datetime": "2020-04-12 11:02:02", "author": "@Xx3IHqpXFXIFj7E"}, "920735963097305088": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "34", "datetime": "2017-10-18 19:38:54", "author": "@vuly16"}, "920511258847215616": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "569", "datetime": "2017-10-18 04:46:01", "author": "@nlehuen"}, "1247774191199244288": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "93", "datetime": "2020-04-08 06:32:04", "author": "@0xhexhex"}, "921225967628034055": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "15,645", "datetime": "2017-10-20 04:06:00", "author": "@pmedina"}, "921380084916748290": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "311", "datetime": "2017-10-20 14:18:25", "author": "@prprhyt"}, "921024727933648896": {"content_summary": "'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/ng6thXfPxL #Deep... by #alevergara78 https://t.co/qrIZ9LSdh5", "followers": "3,917", "datetime": "2017-10-19 14:46:21", "author": "@digr_io"}, "921129427873992705": {"content_summary": "Using ReLU as your activation function? Check out Swish: https://t.co/cIs6rM1XMF", "followers": "10", "datetime": "2017-10-19 21:42:24", "author": "@adrian_spataru"}, "921220600126849025": {"content_summary": "RT @Weenkus: It seems like there is a new activation function every day - Swish! https://t.co/6cTgZ9rgU9 #DataScience #AI #ML #DL #DeepLear\u2026", "followers": "15,143", "datetime": "2017-10-20 03:44:41", "author": "@alevergara78"}, "920719022429229056": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "269", "datetime": "2017-10-18 18:31:35", "author": "@semih_korkmaz_"}, "921317353937190912": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "748", "datetime": "2017-10-20 10:09:09", "author": "@kichi_robo"}, "921276182623948800": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "642", "datetime": "2017-10-20 07:25:33", "author": "@Jd183189381D"}, "920514754552229888": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "934", "datetime": "2017-10-18 04:59:54", "author": "@pavelkordik"}, "920575788767956992": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "294", "datetime": "2017-10-18 09:02:26", "author": "@vedranfranke"}, "921032405648941056": {"content_summary": "RT @chezou: \u6d3b\u6027\u5316\u95a2\u6570\u3092 f(x)=x\u00b7\u03c3(x)\u306b\u3057\u305f\u3089ReLU\u7cfb\u3088\u308a\u826f\u304f\u306a\u3063\u305f\u3068\u3044\u3046\u8a71\u3002\u305d\u308c\u3067\u826f\u3044\u306e\u304b... / \u201c[1710.05941] Swish: a Self-Gated Activation Function\u201d https://t.co/oG0dMGz\u2026", "followers": "52", "datetime": "2017-10-19 15:16:52", "author": "@haru__256"}, "920449828345270273": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/TuPlBhuVCb", "followers": "4,100", "datetime": "2017-10-18 00:41:54", "author": "@arxiv_cscv"}, "920531576915726336": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "1,168", "datetime": "2017-10-18 06:06:45", "author": "@ApacheOpennlp"}, "1249830425763037184": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "21", "datetime": "2020-04-13 22:42:48", "author": "@Gatchan_dayo"}, "1249280114098991105": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "12,763", "datetime": "2020-04-12 10:16:04", "author": "@jaguring1"}, "920501852613103616": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "322", "datetime": "2017-10-18 04:08:38", "author": "@letranger14"}, "920664266973233153": {"content_summary": "\u6d3b\u6027\u5316\u95a2\u6570\u3092 f(x)=x\u00b7\u03c3(x)\u306b\u3057\u305f\u3089ReLU\u7cfb\u3088\u308a\u826f\u304f\u306a\u3063\u305f\u3068\u3044\u3046\u8a71\u3002\u305d\u308c\u3067\u826f\u3044\u306e\u304b... / \u201c[1710.05941] Swish: a Self-Gated Activation Function\u201d https://t.co/oG0dMGzTYK", "followers": "4,054", "datetime": "2017-10-18 14:54:01", "author": "@chezou"}, "1249217431970574336": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,071", "datetime": "2020-04-12 06:06:59", "author": "@amasawa_seiji"}, "921160795609817089": {"content_summary": "RT @mosko_mule: Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u2026", "followers": "2,451", "datetime": "2017-10-19 23:47:02", "author": "@jinbeizame007"}, "920572669715730432": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,705", "datetime": "2017-10-18 08:50:02", "author": "@pulsebase"}, "921229595474411522": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "1,280", "datetime": "2017-10-20 04:20:25", "author": "@__DaLong"}, "921473392393404416": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,832", "datetime": "2017-10-20 20:29:11", "author": "@_Dr_ASA"}, "921105510853697536": {"content_summary": "RT @lizardlucas42: Really interesting stuff! Either matches or outperforms relu on all the benchmarks they did https://t.co/yTA1yrncQQ", "followers": "68", "datetime": "2017-10-19 20:07:21", "author": "@hussam_ashab"}, "921341773296758787": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "719", "datetime": "2017-10-20 11:46:11", "author": "@jin1016"}, "1249218120041902082": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "354", "datetime": "2020-04-12 06:09:43", "author": "@yunie564"}, "1249202822756864003": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "76", "datetime": "2020-04-12 05:08:56", "author": "@dill2307"}, "920690632804274176": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "141", "datetime": "2017-10-18 16:38:47", "author": "@vinh0105"}, "922160892460007425": {"content_summary": "RT @exocert: Hot #swish activation function beats #ReLU in existing #deeplearning architectures. https://t.co/xHf5fLbVtu https://t.co/39Rt\u2026", "followers": "19,048", "datetime": "2017-10-22 18:01:04", "author": "@ham_gretsky"}, "921193606811041792": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "73", "datetime": "2017-10-20 01:57:25", "author": "@uc7xe5t"}, "920543098505220097": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "268", "datetime": "2017-10-18 06:52:32", "author": "@corbyjerez"}, "1258791102879985665": {"content_summary": "@hokudai_meiyo2 \u305d\u3046\u3067\u3059\u306d\u3001\u30b7\u30b0\u30e2\u30a4\u30c9\u3060\u3068\u5fae\u5206\u5024\u304c\u57fa\u672c\u7684\u306b1\u672a\u6e80\u306e\u70ba\u3001\u30c1\u30a7\u30a4\u30f3\u30eb\u30fc\u30eb\u3067\u5f8c\u65b9\u306b\u884c\u304f\u306b\u3064\u308c\u3066\u60c5\u5831\u304c\u7121\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u304b\u3089\u2026\u2026 \u3068\u306f\u8a00\u3048relu\u3082relu\u3067\u554f\u984c\u304c\u3042\u308b\u306e\u3067\u6700\u8fd1\u3067\u306fswish\u95a2\u6570\u306a\u3069\u304c\u4f7f\u308f\u308c\u305f\u308a\u3057\u3066\u3044\u3066\u3001\u30d0\u30a4\u30c8\u3067\u3082swish\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u5b9f\u88c5\u3055\u305b\u3089\u308c\u305f\u308a\u3057\u307e\u3059\u306d\u2026 https://t.co/uO0zruWD47 https://t.co/eWkleNJ82o", "followers": "208", "datetime": "2020-05-08 16:09:20", "author": "@Sapmed_IML"}, "921350030421663744": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,451", "datetime": "2017-10-20 12:18:59", "author": "@wraikny_"}, "922781180839084033": {"content_summary": "RT @segal_eran: Swish: A new activation function for deep neural network claimed to work better than the good old Relu https://t.co/H6RBauA\u2026", "followers": "87", "datetime": "2017-10-24 11:05:52", "author": "@suzhixi"}, "1249374574338166791": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "91", "datetime": "2020-04-12 16:31:25", "author": "@namatameuraura"}, "953996770899648515": {"content_summary": "Which activation function you use in your NN models? ReLU? Google's paper present you a new possibly better one called Swish: https://t.co/8zzhnYpBRl #DataScience", "followers": "586", "datetime": "2018-01-18 14:25:29", "author": "@apachaves"}, "921491703294582785": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "54", "datetime": "2017-10-20 21:41:57", "author": "@boo_aboutme"}, "920510277799510016": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "16,813", "datetime": "2017-10-18 04:42:07", "author": "@octonion"}, "1249259330769022976": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "2,681", "datetime": "2020-04-12 08:53:29", "author": "@tacmasi"}, "920586380065026048": {"content_summary": "RT @AMVA4NP: Swish activation function f(x) = x \u22c5 \u03c3 (x) outperforms ReLUs in a bunch of benchmarks https://t.co/7z3tBb2xmB #DeepLearning ht\u2026", "followers": "317", "datetime": "2017-10-18 09:44:31", "author": "@amaheedhar"}, "920495982831288321": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "99,930", "datetime": "2017-10-18 03:45:18", "author": "@jeremyphoward"}, "920550856608514048": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "407", "datetime": "2017-10-18 07:23:21", "author": "@nishantiam"}, "920545769190514688": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "556", "datetime": "2017-10-18 07:03:08", "author": "@tagoma_tech"}, "920660602296692736": {"content_summary": "RT @future_of_AI: Swish: a Self-Gated Activation Function https://t.co/EMdou4pCXW #ai #deeplearning #nlp via @Miles_Brundage", "followers": "15,143", "datetime": "2017-10-18 14:39:27", "author": "@alevergara78"}, "921214296775786496": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,823", "datetime": "2017-10-20 03:19:38", "author": "@trinity_site"}, "921238019360747520": {"content_summary": "Swish: a Self-Gated Activation Function, outperforms ReLU in several tasks https://t.co/mPFp2SSBfO", "followers": "3", "datetime": "2017-10-20 04:53:54", "author": "@curto487"}, "946121427647807488": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "958", "datetime": "2017-12-27 20:51:41", "author": "@nishinojunji"}, "921394104222695425": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "526", "datetime": "2017-10-20 15:14:07", "author": "@kbyk_01"}, "921597379647647745": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "235", "datetime": "2017-10-21 04:41:52", "author": "@quantumbtc"}, "921217595658743808": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "6,053", "datetime": "2017-10-20 03:32:44", "author": "@hsjoihs"}, "920778267300417537": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/EMdou4pCXW #ai #deeplearning #nlp via @Miles_Brundage", "followers": "2,286", "datetime": "2017-10-18 22:27:00", "author": "@future_of_AI"}, "1249486502020571137": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "519", "datetime": "2020-04-12 23:56:11", "author": "@_nxgx_"}, "1249252910778597377": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "554", "datetime": "2020-04-12 08:27:58", "author": "@FBWM8888"}, "920664589821394944": {"content_summary": "RT @chezou: \u6d3b\u6027\u5316\u95a2\u6570\u3092 f(x)=x\u00b7\u03c3(x)\u306b\u3057\u305f\u3089ReLU\u7cfb\u3088\u308a\u826f\u304f\u306a\u3063\u305f\u3068\u3044\u3046\u8a71\u3002\u305d\u308c\u3067\u826f\u3044\u306e\u304b... / \u201c[1710.05941] Swish: a Self-Gated Activation Function\u201d https://t.co/oG0dMGz\u2026", "followers": "1,667", "datetime": "2017-10-18 14:55:17", "author": "@Scaled_Wurm"}, "920541740112760832": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "145", "datetime": "2017-10-18 06:47:08", "author": "@esvhd"}, "920804196038750208": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "72", "datetime": "2017-10-19 00:10:02", "author": "@MackT_uCF"}, "920545697719468032": {"content_summary": "RT @_Ryobot: Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co\u2026", "followers": "12,763", "datetime": "2017-10-18 07:02:51", "author": "@jaguring1"}, "920514924673200129": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "222", "datetime": "2017-10-18 05:00:35", "author": "@parresianz"}, "921157150415704067": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "1,448", "datetime": "2017-10-19 23:32:33", "author": "@dicekicker"}, "920646111710404609": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/TuPlBhuVCb", "followers": "4,100", "datetime": "2017-10-18 13:41:52", "author": "@arxiv_cscv"}, "920980546137686016": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "179", "datetime": "2017-10-19 11:50:47", "author": "@Gabi_illo"}, "921217497059115014": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "6,053", "datetime": "2017-10-20 03:32:21", "author": "@hsjoihs"}, "920606987057995776": {"content_summary": "RT @_Ryobot: Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co\u2026", "followers": "155", "datetime": "2017-10-18 11:06:24", "author": "@Trtd6Trtd"}, "922376028122738688": {"content_summary": "RT @exocert: Hot #swish activation function beats #ReLU in existing #deeplearning architectures. https://t.co/xHf5fLbVtu https://t.co/39Rt\u2026", "followers": "1,938", "datetime": "2017-10-23 08:15:56", "author": "@EldarSilver"}, "1249211406597185536": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "182", "datetime": "2020-04-12 05:43:03", "author": "@japanAmi2015"}, "920720303826898950": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "313", "datetime": "2017-10-18 18:36:41", "author": "@ThomasNiebler"}, "924496784587497472": {"content_summary": "Swish: a Self-Gated Activation Function \u5358\u8abf\u3067\u306a\u3044\u95a2\u6570\u3092\u4f7f\u3046\u3053\u3068\u3067\u591a\u5cf0\u6027\u304c\u751f\u307e\u308c\u308b\u3002\u5927\u5c40\u7684\u6700\u9069\u5316\u304c\u56f0\u96e3\u306b\u306a\u308b\u306e\u3067\u306f\uff1f https://t.co/17kYW2aEBi", "followers": "0", "datetime": "2017-10-29 04:43:04", "author": "@yshry1"}, "920547035316711424": {"content_summary": "RT @PabloDoval: Reading about Swish (https://t.co/f6H3JnMjw5) on my way to LHR, a selfgated activation function (x\u22c5sigmoid(x)) to replace R\u2026", "followers": "1,446", "datetime": "2017-10-18 07:08:10", "author": "@_unaizc_"}, "1249336590192664576": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "190", "datetime": "2020-04-12 14:00:29", "author": "@nskm_m"}, "921338337956265984": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "155", "datetime": "2017-10-20 11:32:32", "author": "@vimovimo29"}, "920825156297248768": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "61", "datetime": "2017-10-19 01:33:20", "author": "@albelwu"}, "922160812617355265": {"content_summary": "RT @exocert: Hot #swish activation function beats #ReLU in existing #deeplearning architectures. https://t.co/xHf5fLbVtu https://t.co/39Rt\u2026", "followers": "4,056", "datetime": "2017-10-22 18:00:45", "author": "@scottbot_17"}, "920564396664991744": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "5,407", "datetime": "2017-10-18 08:17:10", "author": "@TechNowOrNever"}, "921006603876278272": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "154", "datetime": "2017-10-19 13:34:20", "author": "@philipskokoh"}, "920997049646149632": {"content_summary": "RT @aureliengeron: The swish activation function, f(x) = x sigmoid(x). Yet another ReLU variant that seems to outperform it (https://t.co/R\u2026", "followers": "273", "datetime": "2017-10-19 12:56:22", "author": "@denfromufa"}, "952728270243540993": {"content_summary": "RT @carlcarrie: Activation functions in Deep Learning compared - paper Rectified Linear Unit (ReLU) vs Swish (based on Sigmoid) https://t\u2026", "followers": "2,283", "datetime": "2018-01-15 02:24:55", "author": "@AdaptToReality"}, "921227448217346051": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "228", "datetime": "2017-10-20 04:11:53", "author": "@hengcherkeng"}, "920856297360130048": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "664", "datetime": "2017-10-19 03:37:04", "author": "@crude2refined"}, "920613861245509632": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,023", "datetime": "2017-10-18 11:33:43", "author": "@desertnaut"}, "920719475221172227": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "154", "datetime": "2017-10-18 18:33:23", "author": "@108pravi"}, "921234470518190081": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,667", "datetime": "2017-10-20 04:39:48", "author": "@Scaled_Wurm"}, "920699549290700800": {"content_summary": "May we need AutoActivationFunction ... https://t.co/1v4OVlT9A9", "followers": "135,925", "datetime": "2017-10-18 17:14:12", "author": "@hiconcep"}, "1247800587527180293": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "128", "datetime": "2020-04-08 08:16:57", "author": "@shimopino"}, "1249241251687231488": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "151", "datetime": "2020-04-12 07:41:38", "author": "@take_gattcha"}, "925152780842450944": {"content_summary": "\u3053\u308c\u306f\u6050\u308b\u3079\u304d\u76f8\u8ee2\u79fb https://t.co/OL4r0iC9Fv Swish: a Self-Gated Activation Func.v1/Mon, 16 Oct 2017 Searching for Activation Func.v2/Fri, 27 Oct 2017", "followers": "2,671", "datetime": "2017-10-31 00:09:46", "author": "@mosko_mule"}, "920720060653719554": {"content_summary": "Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/PzemjONOQf #AI #ML https://t.co/ND5Owc5Efs", "followers": "1,075", "datetime": "2017-10-18 18:35:43", "author": "@appliedAIbook"}, "921221186494783488": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "818", "datetime": "2017-10-20 03:47:00", "author": "@pinmarch_t"}, "1249202396418490370": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,126", "datetime": "2020-04-12 05:07:15", "author": "@innocent_zero"}, "920543368458878976": {"content_summary": "Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co/T67VO6N6De", "followers": "4,386", "datetime": "2017-10-18 06:53:36", "author": "@_Ryobot"}, "920642907173982208": {"content_summary": "RT @Miles_Brundage: \"Swish: a Self-Gated Activation Function,\" Ramachandran et al.: https://t.co/bRa2xOCugx", "followers": "427", "datetime": "2017-10-18 13:29:08", "author": "@david_schles"}, "920520282728738817": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "2,043", "datetime": "2017-10-18 05:21:52", "author": "@dosei_sanga"}, "921734824745869312": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,455", "datetime": "2017-10-21 13:48:01", "author": "@miz_oka"}, "922451945251520512": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,829", "datetime": "2017-10-23 13:17:36", "author": "@hogehogehogege"}, "922839422625751040": {"content_summary": "Swish [f(x)=x\u22c5sigmoid(x)] is a new activation function which tends to work better than ReLU on deeper models https://t.co/TA1G4XAMRa", "followers": "40", "datetime": "2017-10-24 14:57:18", "author": "@CobaltAI"}, "921221680592125953": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "3,128", "datetime": "2017-10-20 03:48:58", "author": "@uint256_t"}, "921256894873792512": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "791", "datetime": "2017-10-20 06:08:54", "author": "@0xb5951"}, "920919477046296577": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "103", "datetime": "2017-10-19 07:48:07", "author": "@shreya_malani"}, "920640951936102400": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "4,946", "datetime": "2017-10-18 13:21:22", "author": "@micahstubbs"}, "921364048721018880": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "43", "datetime": "2017-10-20 13:14:41", "author": "@freedial_dev"}, "921021486269284353": {"content_summary": "RT @mosko_mule: Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u2026", "followers": "2,530", "datetime": "2017-10-19 14:33:28", "author": "@_329_"}, "1249630311014490112": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "14", "datetime": "2020-04-13 09:27:37", "author": "@milai_tk"}, "920589076851576832": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "767", "datetime": "2017-10-18 09:55:14", "author": "@johndburger"}, "921600700475478016": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "15,143", "datetime": "2017-10-21 04:55:04", "author": "@alevergara78"}, "1218458074697961472": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/VEAMtY4qlI (Popularity:12.0) #Neural_and_Evolutionary_Computing #Computer_Vision_and_Pattern_Recognition #Machine_Learning", "followers": "38", "datetime": "2020-01-18 09:00:17", "author": "@poqaa_cv"}, "1259044907198578690": {"content_summary": "RT @jaguring1: AutoML\u5206\u91ce\u306e\u4e8b\u4f8b https://t.co/wHxLDEZLld", "followers": "554", "datetime": "2020-05-09 08:57:52", "author": "@FBWM8888"}, "920498728649113600": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "19,132", "datetime": "2017-10-18 03:56:13", "author": "@petewarden"}, "921209492284391424": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "347", "datetime": "2017-10-20 03:00:32", "author": "@Gin04tw"}, "1259010544377319424": {"content_summary": "AutoML\u5206\u91ce\u306e\u4e8b\u4f8b https://t.co/wHxLDEZLld", "followers": "12,763", "datetime": "2020-05-09 06:41:19", "author": "@jaguring1"}, "921058439672971264": {"content_summary": "Not sure I understand the hype around Swish. It's literally relu with a bump. Tiny performance boost. https://t.co/sicoAhGIdB #deeplearning", "followers": "1,188", "datetime": "2017-10-19 17:00:19", "author": "@joeddav"}, "921827489122476032": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "296", "datetime": "2017-10-21 19:56:14", "author": "@moto_josyu_K"}, "940840018863673350": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,409", "datetime": "2017-12-13 07:05:15", "author": "@Ryosuke0624"}, "920519859930320896": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "340", "datetime": "2017-10-18 05:20:11", "author": "@bgmartins"}, "1249237257770291202": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "389", "datetime": "2020-04-12 07:25:46", "author": "@hangartalk_zero"}, "1249220835820179461": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "4,189", "datetime": "2020-04-12 06:20:31", "author": "@tkuTokyo"}, "921496971914833922": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "794", "datetime": "2017-10-20 22:02:53", "author": "@shkoga"}, "920888622835843072": {"content_summary": "Footnote (page 3) has the real answer to where the inspiration for this activation function came from. Brute force! https://t.co/KmEFBqh6O1 https://t.co/cx0CUIL1wW", "followers": "1,336", "datetime": "2017-10-19 05:45:31", "author": "@jigarkdoshi"}, "921337905703829505": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "4,407", "datetime": "2017-10-20 11:30:49", "author": "@7shi"}, "924798333566291969": {"content_summary": "Searching for Activation Functions https://t.co/TuPlBhuVCb", "followers": "4,100", "datetime": "2017-10-30 00:41:19", "author": "@arxiv_cscv"}, "1218190700497469440": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/tFH4EZjLcc", "followers": "1,262", "datetime": "2020-01-17 15:17:50", "author": "@fratmelhylmaz"}, "1248041511268134912": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "2", "datetime": "2020-04-09 00:14:18", "author": "@hoboroots"}, "920692856691482624": {"content_summary": "link to the swish (self-gated activations) paper https://t.co/ob9gLNcGhA", "followers": "913", "datetime": "2017-10-18 16:47:37", "author": "@SpaceAnubis"}, "1249204056293281799": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "173", "datetime": "2020-04-12 05:13:50", "author": "@AzuriteCm"}, "921098792933437440": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "6", "datetime": "2017-10-19 19:40:40", "author": "@dev_juice"}, "1249342564710268928": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "96", "datetime": "2020-04-12 14:24:13", "author": "@hamage9"}, "1247779878419628033": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "44", "datetime": "2020-04-08 06:54:40", "author": "@jetjodh"}, "1088254945877360640": {"content_summary": "RT @mosko_mule: \u3053\u308c\u306f\u6050\u308b\u3079\u304d\u76f8\u8ee2\u79fb https://t.co/OL4r0iC9Fv Swish: a Self-Gated Activation Func.v1/Mon, 16 Oct 2017 Searching for Activation Func.v2\u2026", "followers": "2", "datetime": "2019-01-24 01:59:32", "author": "@ttt00479239"}, "921332854621028352": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,861", "datetime": "2017-10-20 11:10:44", "author": "@Tarpon_red2"}, "920921006583304192": {"content_summary": "RT @thinkmariya: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/nU\u2026", "followers": "968", "datetime": "2017-10-19 07:54:12", "author": "@ThomasSpura"}, "921216995214860290": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "827", "datetime": "2017-10-20 03:30:21", "author": "@morioka"}, "920804231996571649": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "72", "datetime": "2017-10-19 00:10:11", "author": "@MackT_uCF"}, "920527900033585152": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "17,768", "datetime": "2017-10-18 05:52:08", "author": "@ericjang11"}, "920571313160306688": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "217", "datetime": "2017-10-18 08:44:39", "author": "@AssistedEvolve"}, "920660544381632512": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "255", "datetime": "2017-10-18 14:39:13", "author": "@guntaguntario"}, "921305081277857792": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "642", "datetime": "2017-10-20 09:20:23", "author": "@Jd183189381D"}, "920650046114226176": {"content_summary": "RT @_Ryobot: Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co\u2026", "followers": "157", "datetime": "2017-10-18 13:57:30", "author": "@NCC1701R"}, "921255405233233920": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "40", "datetime": "2017-10-20 06:02:59", "author": "@kappa1989"}, "921231815829893120": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "286", "datetime": "2017-10-20 04:29:15", "author": "@t_tkd3a"}, "922624848039354368": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "1,457", "datetime": "2017-10-24 00:44:39", "author": "@St_Hakky"}, "920626205237313536": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "478", "datetime": "2017-10-18 12:22:46", "author": "@SELUAppendix"}, "920500414436360192": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "4,327", "datetime": "2017-10-18 04:02:55", "author": "@jekbradbury"}, "1249203054743863296": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,850", "datetime": "2020-04-12 05:09:51", "author": "@penmmd"}, "920649536867102720": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "3,416", "datetime": "2017-10-18 13:55:29", "author": "@alxndrkalinin"}, "921220411332759553": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "748", "datetime": "2017-10-20 03:43:56", "author": "@Ningensei848"}, "920582237837516801": {"content_summary": "RT @PabloDoval: Reading about Swish (https://t.co/f6H3JnMjw5) on my way to LHR, a selfgated activation function (x\u22c5sigmoid(x)) to replace R\u2026", "followers": "828", "datetime": "2017-10-18 09:28:03", "author": "@mrcabellom"}, "1247753150846529538": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "1,627", "datetime": "2020-04-08 05:08:27", "author": "@chris_brockett"}, "920646133096923136": {"content_summary": "RT @seaandsailor: Have you folks started swishing your models yet? https://t.co/eiGeVRiLdR", "followers": "245", "datetime": "2017-10-18 13:41:57", "author": "@__jm"}, "921097318631378954": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "193", "datetime": "2017-10-19 19:34:48", "author": "@alexhock"}, "921224283312947201": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "380", "datetime": "2017-10-20 03:59:19", "author": "@harujoh"}, "921373057544994817": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "614", "datetime": "2017-10-20 13:50:29", "author": "@stepney141"}, "921008145979211776": {"content_summary": "RT @awjuliani: Love it. https://t.co/nfXRZv9mnz", "followers": "53", "datetime": "2017-10-19 13:40:28", "author": "@vb_tri"}, "921379000122982400": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "704", "datetime": "2017-10-20 14:14:06", "author": "@uet1"}, "920711233048928257": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "30", "datetime": "2017-10-18 18:00:38", "author": "@Wrinkled_time"}, "920704436481048577": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "264", "datetime": "2017-10-18 17:33:38", "author": "@hellorahulk"}, "920500788312576000": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "3,003", "datetime": "2017-10-18 04:04:24", "author": "@syoyo"}, "921268218798338048": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "4,136", "datetime": "2017-10-20 06:53:54", "author": "@hanaken_n"}, "1249217216060383233": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "540", "datetime": "2020-04-12 06:06:08", "author": "@mamantick"}, "921133111617863680": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "1,058", "datetime": "2017-10-19 21:57:02", "author": "@BigsnarfDude"}, "920613840936677376": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "232", "datetime": "2017-10-18 11:33:38", "author": "@bf_imagination"}, "921277405699833856": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,198", "datetime": "2017-10-20 07:30:24", "author": "@nikq"}, "920797632699629569": {"content_summary": "RT @mosko_mule: Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u2026", "followers": "485", "datetime": "2017-10-18 23:43:57", "author": "@eve_yk"}, "920740510679076864": {"content_summary": "#ICLR2018 Swish: a Self-Gated Activation Function. (arXiv:1710.05941v1 [cs.NE]) https://t.co/uoKw4ms5yU", "followers": "1,308", "datetime": "2017-10-18 19:56:58", "author": "@arxiv_flying"}, "920631939618439168": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "837", "datetime": "2017-10-18 12:45:33", "author": "@m_albunni1"}, "921536345427755009": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "91", "datetime": "2017-10-21 00:39:20", "author": "@Rigel_Mc"}, "921384772412235776": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "216", "datetime": "2017-10-20 14:37:02", "author": "@KSKSKSKS2"}, "920642968536666113": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "427", "datetime": "2017-10-18 13:29:23", "author": "@david_schles"}, "922684983130468354": {"content_summary": "https://t.co/ffuoV9Tf30 Interesting!", "followers": "428", "datetime": "2017-10-24 04:43:37", "author": "@gopi1410"}, "922591375316668417": {"content_summary": "RT @deepdrinkingnet: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.c\u2026", "followers": "93", "datetime": "2017-10-23 22:31:39", "author": "@marinakuz22"}, "920499598246006784": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "4,017", "datetime": "2017-10-18 03:59:40", "author": "@ballforest"}, "921377209876492288": {"content_summary": "https://t.co/CRulTJAkhX Swish \u8aad\u3093\u3060\u3002 ReLU \u304b\u3089 x*sigmoid(x) \u306b\u7f6e\u304d\u63db\u3048\u308b\u3068\u7cbe\u5ea6\u4e0a\u304c\u308b\u305e\u3001\u3068\u3044\u3046\u8a71\u3002\u6a5f\u68b0\u7ffb\u8a33\u542b\u3081\u305f\u5404\u7a2e\u30bf\u30b9\u30af\u3084\u30e2\u30c7\u30eb\u3092\u5e73\u5747\u7684\u306b\u898b\u308b\u3068\u307e\u3042\u78ba\u304b\u306b\u826f\u3044\u304b\u306a\u3001\u3068\u3044\u3046\u611f\u3058\u3002\u3082\u3046\u5c11\u3057\u8272\u3005\u8b70\u8ad6\u304c\u3042\u308b\u306e\u304b\u3068\u671f\u5f85\u3057\u3066\u3044\u305f\u3002", "followers": "1,703", "datetime": "2017-10-20 14:06:59", "author": "@yohei_kikuta"}, "920890888938770432": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "185", "datetime": "2017-10-19 05:54:31", "author": "@pilusocrespo"}, "922091324752281600": {"content_summary": "Swish: a Self-Gated Activation Function. (arXiv:1710.05941v1 [cs.NE]) https://t.co/3uGUeOgo2y", "followers": "873", "datetime": "2017-10-22 13:24:38", "author": "@ciela"}, "920523468222947333": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "1,938", "datetime": "2017-10-18 05:34:31", "author": "@EldarSilver"}, "921145111110709250": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "76", "datetime": "2017-10-19 22:44:43", "author": "@ec_larson"}, "920795856369999873": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "146", "datetime": "2017-10-18 23:36:54", "author": "@ellisvalentiner"}, "921597742303997952": {"content_summary": "https://t.co/sL82oqNi8y", "followers": "1,092", "datetime": "2017-10-21 04:43:18", "author": "@takuzoo3868"}, "920647225885241344": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "243", "datetime": "2017-10-18 13:46:18", "author": "@diazandr3s"}, "921357777364180992": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "198", "datetime": "2017-10-20 12:49:46", "author": "@fukuroder"}, "920539274164006912": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "2,372", "datetime": "2017-10-18 06:37:20", "author": "@FranGallegoBR"}, "921340534865539073": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "398", "datetime": "2017-10-20 11:41:15", "author": "@marchuq"}, "920542470571806721": {"content_summary": "Reading about Swish (https://t.co/f6H3JnMjw5) on my way to LHR, a selfgated activation function (x\u22c5sigmoid(x)) to replace RELUs,via @SoyGema", "followers": "978", "datetime": "2017-10-18 06:50:02", "author": "@PabloDoval"}, "920697986765778944": {"content_summary": "Swish: a Self-Gated Activation Function #DataTau #DataScience https://t.co/cqHtQILxNC", "followers": "73", "datetime": "2017-10-18 17:08:00", "author": "@DataAnalyticsGH"}, "921216543957987328": {"content_summary": "\u5727\u52dd\u306f\u8a00\u3044\u904e\u304e\u306a\u3093\u3058\u3083\u306a\u3044\u304b\u306a\u30fc \u00bb [1710.05941] Swish: a Self-Gated Activation Function https://t.co/NbaF0L2xbp", "followers": "1,823", "datetime": "2017-10-20 03:28:34", "author": "@trinity_site"}, "920618253495312390": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "179", "datetime": "2017-10-18 11:51:10", "author": "@Gabi_illo"}, "921305263574999041": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "196", "datetime": "2017-10-20 09:21:06", "author": "@HunterKonoha"}, "923503206289891328": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "52", "datetime": "2017-10-26 10:54:56", "author": "@hakanardo"}, "920455653826555905": {"content_summary": "Swish: a Self-Gated Activation Function. (arXiv:1710.05941v1 [cs.NE]) https://t.co/9izHSmKIy0", "followers": "1,087", "datetime": "2017-10-18 01:05:03", "author": "@ai_papers"}, "920548382141308928": {"content_summary": "RT @Miles_Brundage: \"Swish: a Self-Gated Activation Function,\" Ramachandran et al.: https://t.co/bRa2xOCugx", "followers": "315", "datetime": "2017-10-18 07:13:31", "author": "@_yayan24"}, "921236819232006144": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "356", "datetime": "2017-10-20 04:49:08", "author": "@gorogoroyasu"}, "920562028095340544": {"content_summary": "So this is a thing now? https://t.co/FktwOArQ33", "followers": "291", "datetime": "2017-10-18 08:07:45", "author": "@lpag_ai"}, "921215666547408899": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "714", "datetime": "2017-10-20 03:25:04", "author": "@ghost_orange"}, "921264586031996928": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "119", "datetime": "2017-10-20 06:39:28", "author": "@toto_toilet"}, "921301895087398912": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "991", "datetime": "2017-10-20 09:07:43", "author": "@arika_nashika"}, "920681689193598976": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "117", "datetime": "2017-10-18 16:03:14", "author": "@SchulteRoman"}, "920618359871356928": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,317", "datetime": "2017-10-18 11:51:35", "author": "@KageKirin"}, "922181513516548096": {"content_summary": "The replacement of the ReLU activation function maybe here: Swish: a Self-Gated Activation Function https://t.co/TdfhDo1Ft6", "followers": "15", "datetime": "2017-10-22 19:23:00", "author": "@_bossenbroek_"}, "1249202202461290502": {"content_summary": "\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 https://t.co/awxfXo1Thu \u640d\u5931\u95a2\u6570 https://t.co/5CNG7y0v2d \u307b\u307c\u30bc\u30ed\u304b\u3089\u5b66\u7fd2\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u767a\u898b https://t.co/fdyHbuyIqX", "followers": "12,763", "datetime": "2020-04-12 05:06:28", "author": "@jaguring1"}, "1249321279858982912": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "202", "datetime": "2020-04-12 12:59:39", "author": "@fakesaibaba"}, "921319914220040192": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "545", "datetime": "2017-10-20 10:19:19", "author": "@d_gfx"}, "920545198278565888": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "25", "datetime": "2017-10-18 07:00:52", "author": "@jiahui_du"}, "920531326448619520": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "301", "datetime": "2017-10-18 06:05:45", "author": "@Spriteware"}, "922024730705530880": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "780", "datetime": "2017-10-22 09:00:00", "author": "@onojimaF"}, "920540458249416704": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "94", "datetime": "2017-10-18 06:42:02", "author": "@garethseneque"}, "1249538053267320832": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "54", "datetime": "2020-04-13 03:21:01", "author": "@ainewsantenna"}, "920534462626136064": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "671", "datetime": "2017-10-18 06:18:13", "author": "@erwtokritos"}, "920706683764031494": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "4,222", "datetime": "2017-10-18 17:42:33", "author": "@tuntuku_sy"}, "920630226589188096": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "3,013", "datetime": "2017-10-18 12:38:45", "author": "@sarahbadr"}, "920872711018156032": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "649", "datetime": "2017-10-19 04:42:17", "author": "@Cortexelation"}, "1249279716290375680": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "27", "datetime": "2020-04-12 10:14:29", "author": "@uskC"}, "921120672331415553": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "2,628", "datetime": "2017-10-19 21:07:36", "author": "@Juxi"}, "925154262753034240": {"content_summary": "RT @mosko_mule: \u3053\u308c\u306f\u6050\u308b\u3079\u304d\u76f8\u8ee2\u79fb https://t.co/OL4r0iC9Fv Swish: a Self-Gated Activation Func.v1/Mon, 16 Oct 2017 Searching for Activation Func.v2\u2026", "followers": "150", "datetime": "2017-10-31 00:15:39", "author": "@y_yammt"}, "921218793631711233": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "271", "datetime": "2017-10-20 03:37:30", "author": "@weapom923"}, "921393450871693319": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "358", "datetime": "2017-10-20 15:11:32", "author": "@_nhayato"}, "921654744363311104": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "402", "datetime": "2017-10-21 08:29:49", "author": "@ntnt4174"}, "921558805976006656": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "104", "datetime": "2017-10-21 02:08:35", "author": "@MeemTona"}, "1249310314740379648": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "120", "datetime": "2020-04-12 12:16:04", "author": "@neuralinker"}, "952728189230571526": {"content_summary": "Activation functions in Deep Learning compared - paper Rectified Linear Unit (ReLU) vs Swish (based on Sigmoid) https://t.co/i5lZRFCfPH", "followers": "6,021", "datetime": "2018-01-15 02:24:35", "author": "@carlcarrie"}, "920652202678644737": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "431", "datetime": "2017-10-18 14:06:04", "author": "@blauigris"}, "920999445650726912": {"content_summary": "RT @Keva161: Swish: a Self-Gated Activation Function https://t.co/OI0fwdXorO #datascience #dataanalysis #bigdata", "followers": "1,616", "datetime": "2017-10-19 13:05:53", "author": "@ThugMetrics"}, "920533820444631040": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,203", "datetime": "2017-10-18 06:15:40", "author": "@F_Vaggi"}, "920608791497932802": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,417", "datetime": "2017-10-18 11:13:34", "author": "@seanmylaw"}, "1249217302748254209": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "607", "datetime": "2020-04-12 06:06:28", "author": "@kukanjohoclub"}, "920534442749210624": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "913", "datetime": "2017-10-18 06:18:08", "author": "@SpaceAnubis"}, "920497194305650688": {"content_summary": "RT @Miles_Brundage: \"Swish: a Self-Gated Activation Function,\" Ramachandran et al.: https://t.co/bRa2xOCugx", "followers": "1,627", "datetime": "2017-10-18 03:50:07", "author": "@chris_brockett"}, "921222361969389568": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "364", "datetime": "2017-10-20 03:51:41", "author": "@tkym1220"}, "920704983800188929": {"content_summary": "Not surprised it works better, ReLU is a horrible space bender. ReLU is still more computationally efficient thought. #MachineLearning https://t.co/6NqV6klZWA", "followers": "210", "datetime": "2017-10-18 17:35:48", "author": "@TariqDaouda"}, "924976883342516224": {"content_summary": "Swish\u306e\u8ad6\u6587\u66f4\u65b0\u3055\u308c\u3066\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u03b2\u304c\u5c0e\u5165\u3055\u308c\u3066\u308b https://t.co/HpvE5RlSUt https://t.co/pUE4NdSmtN", "followers": "1,031", "datetime": "2017-10-30 12:30:48", "author": "@tomoya52215710"}, "920756848348708865": {"content_summary": "Swish: f(x) = x sigma(x) #DeepLearning https://t.co/8m2eCaKjqb https://t.co/476somr5mQ", "followers": "322", "datetime": "2017-10-18 21:01:54", "author": "@CalcCon"}, "920497126169124864": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "1,117", "datetime": "2017-10-18 03:49:51", "author": "@nheagy"}, "1249229756991549442": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "52", "datetime": "2020-04-12 06:55:58", "author": "@haru_256"}, "921371181168676865": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "4,298", "datetime": "2017-10-20 13:43:02", "author": "@transhumanbob"}, "921618667250393088": {"content_summary": "RT @datasci_blogs: \u3010\u7dd1\u8336\u601d\u8003\u30d6\u30ed\u30b0\u3011 https://t.co/i1KBIfqdD7 Swish\u3092CIFAR10\u3067\u8a66\u3057\u3066\u307f\u308b Swish: a Self-Gated Activation Function https://t.co/CW5UIFSWAj\u2026", "followers": "4,531", "datetime": "2017-10-21 06:06:27", "author": "@yoshizaki_kkgk"}, "921349823009243136": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "11", "datetime": "2017-10-20 12:18:10", "author": "@kure556crc"}, "920689346599985153": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "432", "datetime": "2017-10-18 16:33:40", "author": "@bhargavbardipur"}, "921273570369482752": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "511", "datetime": "2017-10-20 07:15:10", "author": "@tmasada"}, "920719854310535168": {"content_summary": "Swish, Google Brain's new activation function: f(x) = x * sigmoid(x) https://t.co/5EuVU3rjXt", "followers": "197", "datetime": "2017-10-18 18:34:54", "author": "@yusdisaliman"}, "920673812538150913": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "556", "datetime": "2017-10-18 15:31:56", "author": "@tagoma_tech"}, "920622206152929281": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "119", "datetime": "2017-10-18 12:06:52", "author": "@ladidinesh"}, "921307502444085249": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "573", "datetime": "2017-10-20 09:30:00", "author": "@zlrc0m"}, "920502931656495105": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "359", "datetime": "2017-10-18 04:12:55", "author": "@mundoplano"}, "921596509761630208": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "221", "datetime": "2017-10-21 04:38:25", "author": "@UEDAYUJI"}, "920782594714693632": {"content_summary": "RT @_Ryobot: Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co\u2026", "followers": "2,290", "datetime": "2017-10-18 22:44:12", "author": "@fronori"}, "1247930908188893186": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "56", "datetime": "2020-04-08 16:54:48", "author": "@aptr322"}, "921352653375807488": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,529", "datetime": "2017-10-20 12:29:25", "author": "@Ymgn_Bass"}, "1249273120101289986": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "165", "datetime": "2020-04-12 09:48:16", "author": "@samurairodeo"}, "920644520626327552": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "75", "datetime": "2017-10-18 13:35:33", "author": "@adityachivu"}, "921299771574296576": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "3,541", "datetime": "2017-10-20 08:59:17", "author": "@tankazunori0914"}, "921635415701864448": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "827", "datetime": "2017-10-21 07:13:00", "author": "@yumetodo"}, "920587830753193984": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "497", "datetime": "2017-10-18 09:50:17", "author": "@SpectralFilter"}, "920533078434631680": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "753", "datetime": "2017-10-18 06:12:43", "author": "@suneelmarthi"}, "921125893799645186": {"content_summary": "@SAlsaif7 https://t.co/iITDSvl9xH", "followers": "1,029", "datetime": "2017-10-19 21:28:21", "author": "@malsobay"}, "921326131516604416": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "327", "datetime": "2017-10-20 10:44:01", "author": "@oxycaster"}, "921357274072805376": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "719", "datetime": "2017-10-20 12:47:46", "author": "@kawachi"}, "920484005702639617": {"content_summary": "RT @Miles_Brundage: \"Swish: a Self-Gated Activation Function,\" Ramachandran et al.: https://t.co/bRa2xOCugx", "followers": "256", "datetime": "2017-10-18 02:57:43", "author": "@guguchi_yama"}, "920668811505885184": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "37", "datetime": "2017-10-18 15:12:04", "author": "@manuelschmidt90"}, "920504322282188800": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,302", "datetime": "2017-10-18 04:18:27", "author": "@crocodoyle"}, "1247753387606605824": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "1,433", "datetime": "2020-04-08 05:09:24", "author": "@damianborth"}, "920684548681355264": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "182", "datetime": "2017-10-18 16:14:36", "author": "@drdeanjones"}, "921243884079824896": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "275", "datetime": "2017-10-20 05:17:12", "author": "@22114w"}, "921197772908371968": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "422", "datetime": "2017-10-20 02:13:58", "author": "@wakaba130"}, "920956551233490944": {"content_summary": "RT @aureliengeron: The swish activation function, f(x) = x sigmoid(x). Yet another ReLU variant that seems to outperform it (https://t.co/R\u2026", "followers": "102", "datetime": "2017-10-19 10:15:27", "author": "@MisterFreire"}, "920590604039438338": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "334", "datetime": "2017-10-18 10:01:18", "author": "@nel215"}, "1042874144025534464": {"content_summary": "Learning about activation functions - want to improve performance on ImageNet by 0.9%? \ud83d\udd25 Swap out your ReLu's for Swift's https://t.co/cug35aD8R9 #MachineLearning #DeepLearning", "followers": "24", "datetime": "2018-09-20 20:32:26", "author": "@tom__quirk"}, "921246878137597952": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "62", "datetime": "2017-10-20 05:29:06", "author": "@panpu333"}, "1240349700466921477": {"content_summary": "If you want to geek out on the hard-swish activation function, check out: \ud83d\udc49Paper on the Swish activation function and how it compare with Rectified Linear Unit (ReLU) https://t.co/9MGdJZNTQm \ud83d\udc49MobileNet V3 & computationally efficient hard-swish https:/", "followers": "3,902", "datetime": "2020-03-18 18:49:47", "author": "@hoitab"}, "920791917222281216": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "571", "datetime": "2017-10-18 23:21:15", "author": "@sagashin"}, "921318689143537666": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "142", "datetime": "2017-10-20 10:14:27", "author": "@ritzs2u"}, "1249216947771682823": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "65", "datetime": "2020-04-12 06:05:04", "author": "@yukachi022"}, "920754555666817031": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "76", "datetime": "2017-10-18 20:52:47", "author": "@alapite"}, "920825042186903553": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "15,224", "datetime": "2017-10-19 01:32:52", "author": "@lmthang"}, "920619586378067968": {"content_summary": "@nntaleb https://t.co/Hb3iihR4bF", "followers": "317", "datetime": "2017-10-18 11:56:28", "author": "@hegemonetics"}, "921562145715654657": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "70", "datetime": "2017-10-21 02:21:51", "author": "@Gokuraku104robo"}, "920510342618370049": {"content_summary": "No love for the Heaviside function. https://t.co/302q0KBzxz", "followers": "2,345", "datetime": "2017-10-18 04:42:22", "author": "@JonAMichaels"}, "921353210840752128": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "256", "datetime": "2017-10-20 12:31:38", "author": "@dizzy_my_future"}, "920499757918732288": {"content_summary": "Love it. https://t.co/nfXRZv9mnz", "followers": "6,355", "datetime": "2017-10-18 04:00:19", "author": "@awjuliani"}, "921303256541798400": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "993", "datetime": "2017-10-20 09:13:08", "author": "@taniokah"}, "921361484961038336": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "76", "datetime": "2017-10-20 13:04:30", "author": "@LS_for_LP"}, "922005030487519232": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,151", "datetime": "2017-10-22 07:41:43", "author": "@jd_mashiro"}, "921216748149358593": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "68", "datetime": "2017-10-20 03:29:22", "author": "@shinryu_rk"}, "920761288980094976": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/mAkYdYwc1v", "followers": "41", "datetime": "2017-10-18 21:19:32", "author": "@BigDataSpace"}, "920593412071362561": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "26", "datetime": "2017-10-18 10:12:27", "author": "@ReedRoof"}, "921190250772176897": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "4,017", "datetime": "2017-10-20 01:44:05", "author": "@ballforest"}, "921052826775715845": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/EMdou4pCXW #ai #deeplearning #nlp via @alexjc", "followers": "2,286", "datetime": "2017-10-19 16:38:00", "author": "@future_of_AI"}, "921511659352367105": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "44", "datetime": "2017-10-20 23:01:15", "author": "@ma2n0hit04"}, "925357828742701056": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "835", "datetime": "2017-10-31 13:44:33", "author": "@yukky_saito"}, "921532414299553792": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "4,878", "datetime": "2017-10-21 00:23:43", "author": "@mohzeki222"}, "921216828554092544": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,593", "datetime": "2017-10-20 03:29:41", "author": "@tmiya_"}, "921161254118526981": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "857", "datetime": "2017-10-19 23:48:51", "author": "@kyogok"}, "1249343634937384962": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "399", "datetime": "2020-04-12 14:28:28", "author": "@xmhrkx"}, "923878815646015488": {"content_summary": "RT @deepdrinkingnet: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.c\u2026", "followers": "440", "datetime": "2017-10-27 11:47:29", "author": "@krishnalaghari1"}, "920565481051967488": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "206", "datetime": "2017-10-18 08:21:28", "author": "@chode_modules"}, "920776158744113152": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "52", "datetime": "2017-10-18 22:18:38", "author": "@hoangcuong0605"}, "921215980188999680": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,328", "datetime": "2017-10-20 03:26:19", "author": "@azaika_"}, "954014423131320320": {"content_summary": "RT @apachaves: Which activation function you use in your NN models? ReLU? Google's paper present you a new possibly better one called Swish\u2026", "followers": "36,944", "datetime": "2018-01-18 15:35:37", "author": "@entwistletx"}, "921350471368896512": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "525", "datetime": "2017-10-20 12:20:44", "author": "@kazuhiloyagi"}, "920494890252779525": {"content_summary": "TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "7,580", "datetime": "2017-10-18 03:40:58", "author": "@poolio"}, "920619856906588160": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "357", "datetime": "2017-10-18 11:57:32", "author": "@_florianmai"}, "920705706273230849": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "129", "datetime": "2017-10-18 17:38:40", "author": "@goloskokovic"}, "920564921586286592": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "455", "datetime": "2017-10-18 08:19:15", "author": "@skaslev"}, "1249536806766309378": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "59", "datetime": "2020-04-13 03:16:04", "author": "@mirum00"}, "921139922970476547": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "564", "datetime": "2017-10-19 22:24:06", "author": "@gazay"}, "920892625682513920": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "63", "datetime": "2017-10-19 06:01:25", "author": "@saxenauts"}, "921299887366590464": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "4,056", "datetime": "2017-10-20 08:59:44", "author": "@scottbot_17"}, "921607034629373952": {"content_summary": "RT @datasci_blogs: \u3010\u7dd1\u8336\u601d\u8003\u30d6\u30ed\u30b0\u3011 https://t.co/i1KBIfqdD7 Swish\u3092CIFAR10\u3067\u8a66\u3057\u3066\u307f\u308b Swish: a Self-Gated Activation Function https://t.co/CW5UIFSWAj\u2026", "followers": "261", "datetime": "2017-10-21 05:20:14", "author": "@ka10ryu1"}, "1249331680722092033": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "176", "datetime": "2020-04-12 13:40:58", "author": "@taroimo1013"}, "920671966582915074": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "739", "datetime": "2017-10-18 15:24:36", "author": "@ajinkyakale"}, "1247776125545115650": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "362", "datetime": "2020-04-08 06:39:45", "author": "@atulskulkarni"}, "921396126602878976": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "177", "datetime": "2017-10-20 15:22:09", "author": "@suzumikasumi"}, "922782551898492928": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "8", "datetime": "2017-10-24 11:11:19", "author": "@2013sasha"}, "1247794900914941958": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "4,891", "datetime": "2020-04-08 07:54:21", "author": "@IgorCarron"}, "921245872859398144": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,199", "datetime": "2017-10-20 05:25:06", "author": "@uts45"}, "920612933893312514": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "12", "datetime": "2017-10-18 11:30:02", "author": "@sheetalparade"}, "921348427497095168": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "659", "datetime": "2017-10-20 12:12:37", "author": "@BPK_t"}, "921024313603522560": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "15,143", "datetime": "2017-10-19 14:44:42", "author": "@alevergara78"}, "920803500744876033": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "45", "datetime": "2017-10-19 00:07:16", "author": "@beopst"}, "921415215715143680": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/EMdou4pCXW #ai #deeplearning #nlp via @ogrisel", "followers": "2,286", "datetime": "2017-10-20 16:38:01", "author": "@future_of_AI"}, "920884904719613953": {"content_summary": "RT @lizardlucas42: Really interesting stuff! Either matches or outperforms relu on all the benchmarks they did https://t.co/yTA1yrncQQ", "followers": "270", "datetime": "2017-10-19 05:30:45", "author": "@kotti_sasikanth"}, "921246474867965952": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "137", "datetime": "2017-10-20 05:27:30", "author": "@phykar"}, "920625061945597952": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "698", "datetime": "2017-10-18 12:18:13", "author": "@dvazquezcv"}, "921024631104065536": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "313", "datetime": "2017-10-19 14:45:58", "author": "@Scott_Frye"}, "921395103314280450": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "352", "datetime": "2017-10-20 15:18:05", "author": "@clclclclc1"}, "920687686549045250": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "436", "datetime": "2017-10-18 16:27:04", "author": "@noop_noob"}, "921215218817961984": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "207", "datetime": "2017-10-20 03:23:18", "author": "@vitafa"}, "921394182685474817": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "817", "datetime": "2017-10-20 15:14:26", "author": "@Capabilitist"}, "921196936551473152": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "760", "datetime": "2017-10-20 02:10:39", "author": "@jun0inoue"}, "921191757190017024": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,444", "datetime": "2017-10-20 01:50:04", "author": "@_yukinoi"}, "920628499181948928": {"content_summary": "How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but who cares\"? https://t.co/O6N8UEdGau", "followers": "19,607", "datetime": "2017-10-18 12:31:53", "author": "@samim"}, "1248623238659244032": {"content_summary": "Swish\u6d3b\u6027\u5316\u95a2\u6570 ReLU\u95a2\u6570\u3088\u308a\u7cbe\u5ea6\u304c\u5411\u4e0a\u3059\u308b\u3068\u304b\u306a\u3093\u3068\u304b \u3068\u308a\u3042\u3048\u305a\u753b\u50cf\u306f\u5fae\u5206\u3057\u305f\u3084\u3064 Prajit Ramachandran, Barret Zoph, Quoc V. Le: Searching for Activation Functions https://t.co/hH9xps14az https://t.co/ivB6lDQbh1", "followers": "766", "datetime": "2020-04-10 14:45:53", "author": "@wagasa2"}, "924046774267887616": {"content_summary": "[1710.05941v1] Swish: a Self-Gated Activation Function \u3061\u3087\u3063\u3068\u524d\u306b\u8a71\u984c\u306b\u306a\u3063\u305f\u6587\u732e\u3002\u6d3b\u6027\u5316\u95a2\u6570\u3092x\u2022sigmoid(x)\u306b\u3059\u308b\u3068relu-like\u3067\u9023\u7d9a\u3060\u304b\u3089\u826f\u3044\u3088\u306d https://t.co/VirzVCV3xC", "followers": "564", "datetime": "2017-10-27 22:54:53", "author": "@asam9891"}, "920668895228260352": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "739", "datetime": "2017-10-18 15:12:24", "author": "@ajinkyakale"}, "921778804288135169": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "147", "datetime": "2017-10-21 16:42:47", "author": "@zib1996"}, "921277662638751744": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "248", "datetime": "2017-10-20 07:31:25", "author": "@norikitta"}, "921196046893465601": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "338", "datetime": "2017-10-20 02:07:07", "author": "@ikuro_s"}, "920564129483710464": {"content_summary": "'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning #MachineLearning https://t.co/ezNksBryrw", "followers": "4,255", "datetime": "2017-10-18 08:16:06", "author": "@weballergy"}, "921277495390781440": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "7,503", "datetime": "2017-10-20 07:30:46", "author": "@HigeponJa"}, "1247752725137248256": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "357", "datetime": "2020-04-08 05:06:46", "author": "@JFernandoGRE"}, "920795785079373824": {"content_summary": "RT @nilakshdas: f(x) = x sigmoid(x), a self gated activation function: https://t.co/bnUm5iIDEP Apparently performs a bit better than ReLU\u2026", "followers": "1,308", "datetime": "2017-10-18 23:36:37", "author": "@sahildua2305"}, "920951524347600897": {"content_summary": "RT @aureliengeron: The swish activation function, f(x) = x sigmoid(x). Yet another ReLU variant that seems to outperform it (https://t.co/R\u2026", "followers": "24", "datetime": "2017-10-19 09:55:28", "author": "@malekcellier"}, "921315339001987072": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "104", "datetime": "2017-10-20 10:01:08", "author": "@nadu_festival"}, "921051648742514689": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "717", "datetime": "2017-10-19 16:33:20", "author": "@malai_san"}, "1249204592321101825": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "596", "datetime": "2020-04-12 05:15:58", "author": "@moffattwt"}, "1249217711306977280": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "927", "datetime": "2020-04-12 06:08:06", "author": "@take_cheeze"}, "921604920184266753": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "338", "datetime": "2017-10-21 05:11:50", "author": "@hikosans"}, "920668079658622977": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "360", "datetime": "2017-10-18 15:09:10", "author": "@andrewssobral"}, "925363550486278145": {"content_summary": "\u63a8\u6e2c\u3067\u66f8\u304b\u308c\u3066\u3044\u305f\u3068\u3053\u308d\u304c\u524a\u9664\u3055\u308c\u3066\u3044\u308b https://t.co/Jn4klXrLPH", "followers": "225", "datetime": "2017-10-31 14:07:17", "author": "@ElectronNest"}, "925239926026788865": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "62", "datetime": "2017-10-31 05:56:03", "author": "@panpu333"}, "921300536674066437": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,072", "datetime": "2017-10-20 09:02:19", "author": "@enmTurtle"}, "921320269657935873": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "157", "datetime": "2017-10-20 10:20:44", "author": "@NCC1701R"}, "921223891632058368": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "26", "datetime": "2017-10-20 03:57:45", "author": "@tokoton01"}, "921301518468333568": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,346", "datetime": "2017-10-20 09:06:13", "author": "@iruka3"}, "920696730487808001": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/X38y1XJEUw", "followers": "234", "datetime": "2017-10-18 17:03:00", "author": "@hadoop_pro"}, "921723637794619392": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,406", "datetime": "2017-10-21 13:03:34", "author": "@KawakatsuM"}, "921379792041029632": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,350", "datetime": "2017-10-20 14:17:15", "author": "@kikuchy"}, "921271853561159681": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "118", "datetime": "2017-10-20 07:08:20", "author": "@D05E1"}, "920790862170267649": {"content_summary": "Tables 2,3 report median performance over 5 runs; not mean w/ stdev; not statistically significant improvement? @ramprajit @barret_zoph #dl https://t.co/AI9wNcPm5n", "followers": "798", "datetime": "2017-10-18 23:17:03", "author": "@schaumberg_a"}, "1249493847450648578": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "64", "datetime": "2020-04-13 00:25:22", "author": "@gpu_eater"}, "920615175396515841": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "159,742", "datetime": "2017-10-18 11:38:56", "author": "@Montreal_IA"}, "1248119545442770946": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "208", "datetime": "2020-04-09 05:24:23", "author": "@Don_Rubiel"}, "921273507861880832": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "3,493", "datetime": "2017-10-20 07:14:55", "author": "@uupaa"}, "921329560808955906": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "169", "datetime": "2017-10-20 10:57:39", "author": "@mint_0_rook"}, "920707899508211712": {"content_summary": "A new activation function for deep learning: https://t.co/Zbe4JpY0VY \u2014 the heuristic of \u201cwatching what everyone benchmarks against and use that\u201d with this paper makes a case for ReLU.", "followers": "9,219", "datetime": "2017-10-18 17:47:23", "author": "@posco"}, "921273546415865856": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,961", "datetime": "2017-10-20 07:15:04", "author": "@yu__ya4"}, "921190642562121728": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "3,100", "datetime": "2017-10-20 01:45:38", "author": "@takeda25"}, "921519078447001600": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "289", "datetime": "2017-10-20 23:30:43", "author": "@fresh_homepie"}, "1249280223637471233": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,550", "datetime": "2020-04-12 10:16:30", "author": "@kyorohiro"}, "921331445322342400": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,403", "datetime": "2017-10-20 11:05:08", "author": "@numpad0"}, "921272877831221249": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "964", "datetime": "2017-10-20 07:12:25", "author": "@antimon2"}, "921322551426539522": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "21,804", "datetime": "2017-10-20 10:29:48", "author": "@vaaaaanquish"}, "921093956548550656": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "322", "datetime": "2017-10-19 19:21:26", "author": "@letranger14"}, "925202868889559040": {"content_summary": "Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "606", "datetime": "2017-10-31 03:28:48", "author": "@musyokudon"}, "1247817304517292033": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "626", "datetime": "2020-04-08 09:23:23", "author": "@alisher_ai"}, "921597731532976129": {"content_summary": "@teppeikanayama https://t.co/ApALM8YWOo", "followers": "4,963", "datetime": "2017-10-21 04:43:16", "author": "@m_nishiba"}, "1183803044972105728": {"content_summary": "@phillypoopskins @jeremyphoward @fastdotai And swish: https://t.co/A6QyDbe1yk", "followers": "275", "datetime": "2019-10-14 17:53:34", "author": "@javifreemind"}, "921689462655954946": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "963", "datetime": "2017-10-21 10:47:46", "author": "@snuffkin"}, "920698067573239809": {"content_summary": "RT @samim: How much % of current machine learning is science driven and how much just \"lets try stuff, if it works great, unclear why but w\u2026", "followers": "1,258", "datetime": "2017-10-18 17:08:19", "author": "@dmn_comms"}, "920591971990642688": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "99", "datetime": "2017-10-18 10:06:44", "author": "@treasured_write"}, "952731659773890561": {"content_summary": "RT @carlcarrie: Activation functions in Deep Learning compared - paper Rectified Linear Unit (ReLU) vs Swish (based on Sigmoid) https://t\u2026", "followers": "1,254", "datetime": "2018-01-15 02:38:23", "author": "@_sbr1"}, "920727269026467841": {"content_summary": "RT @agrimsingh: .@goswish https://t.co/auU6bWkFbm", "followers": "2,294", "datetime": "2017-10-18 19:04:21", "author": "@goswish"}, "921225707044290562": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "1,474", "datetime": "2017-10-20 04:04:58", "author": "@sycx"}, "921195577550848000": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "211", "datetime": "2017-10-20 02:05:15", "author": "@BK21561088"}, "921220306647126016": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "61", "datetime": "2017-10-20 03:43:31", "author": "@jjjjjjjjjjjj31"}, "921341925566824448": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "296", "datetime": "2017-10-20 11:46:47", "author": "@MikazukiFuyuno"}, "920623382974132226": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "88", "datetime": "2017-10-18 12:11:33", "author": "@guilhermefickel"}, "921319378175475712": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "12,763", "datetime": "2017-10-20 10:17:11", "author": "@jaguring1"}, "921189415673782272": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "75", "datetime": "2017-10-20 01:40:46", "author": "@RyutaroYamauchi"}, "921223651579404288": {"content_summary": "RT @Weenkus: It seems like there is a new activation function every day - Swish! https://t.co/6cTgZ9rgU9 #DataScience #AI #ML #DL #DeepLear\u2026", "followers": "171", "datetime": "2017-10-20 03:56:48", "author": "@luisafercald"}, "921214543061172224": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,145", "datetime": "2017-10-20 03:20:37", "author": "@niku9Tenhou"}, "920801666005217280": {"content_summary": "RT @golbin: ReLU\ub97c \ub6f0\uc5b4\ub118\ub294(\ub2e4\uace0 \uc8fc\uc7a5\ud558\ub294) \ud65c\uc131\ud654 \ud568\uc218 Swish!! \uc218\uc2dd\ub3c4 f(x) = x \u22c5 sigmoid(x) \ub85c \uac04\ub2e8\ud558\ub2e4. \ud83d\ude32 https://t.co/eH0DtCIc2V", "followers": "525", "datetime": "2017-10-18 23:59:59", "author": "@LineRoh"}, "920653615227736064": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "783", "datetime": "2017-10-18 14:11:41", "author": "@muktabh"}, "921602446358704128": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "2,448", "datetime": "2017-10-21 05:02:00", "author": "@Angelinux3000"}, "922011108407259136": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "526", "datetime": "2017-10-22 08:05:53", "author": "@uzimith"}, "920603304790503424": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "60", "datetime": "2017-10-18 10:51:46", "author": "@DataMarques"}, "1259046297350205440": {"content_summary": "RT @jaguring1: AutoML\u5206\u91ce\u306e\u4e8b\u4f8b https://t.co/wHxLDEZLld", "followers": "1,879", "datetime": "2020-05-09 09:03:23", "author": "@sesquipedale"}, "921267913738223616": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "325", "datetime": "2017-10-20 06:52:41", "author": "@ichi5c2"}, "920608728809988099": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "284", "datetime": "2017-10-18 11:13:19", "author": "@MaxVico"}, "920524957788106753": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,168", "datetime": "2017-10-18 05:40:27", "author": "@ApacheOpennlp"}, "920804144201400321": {"content_summary": "New activation functions are important https://t.co/gpdP7vNhQ1, but can't help but hear Geoffrey Hinton's voice being critical of such incremental progress while reading this article. Science being science?", "followers": "76", "datetime": "2017-10-19 00:09:50", "author": "@SlugocM"}, "921221651504627712": {"content_summary": "RT @Weenkus: It seems like there is a new activation function every day - Swish! https://t.co/6cTgZ9rgU9 #DataScience #AI #ML #DL #DeepLear\u2026", "followers": "79,099", "datetime": "2017-10-20 03:48:51", "author": "@machinelearnbot"}, "921569730879635456": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "243", "datetime": "2017-10-21 02:52:00", "author": "@A_I_AEG"}, "920546802075623425": {"content_summary": "RT @beenharsh: Cool! This has been incorporated in #Tensorflow; tf.nn.swish(x). Folks can now just substitute ReLU w/ this and see how much\u2026", "followers": "79,099", "datetime": "2017-10-18 07:07:15", "author": "@machinelearnbot"}, "920546441252052992": {"content_summary": "Cool! This has been incorporated in #Tensorflow; tf.nn.swish(x). Folks can now just substitute ReLU w/ this and see how much it improves. https://t.co/lAWOB5pKI3", "followers": "317", "datetime": "2017-10-18 07:05:49", "author": "@beenharsh"}, "923759680802795520": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "94", "datetime": "2017-10-27 03:54:05", "author": "@Pengkai_Ru"}, "921338642106159104": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "623", "datetime": "2017-10-20 11:33:44", "author": "@yam_cpp"}, "1247752303857172480": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "65", "datetime": "2020-04-08 05:05:06", "author": "@dave_co_dev"}, "949492315755724800": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "530", "datetime": "2018-01-06 04:06:23", "author": "@albertstartup"}, "920522829967384576": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "1,200", "datetime": "2017-10-18 05:31:59", "author": "@hurrycane"}, "920608599469985792": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "4,615", "datetime": "2017-10-18 11:12:48", "author": "@HITStales"}, "920643508767096832": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "2,671", "datetime": "2017-10-18 13:31:31", "author": "@ayirpelle"}, "920557283360243712": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "210", "datetime": "2017-10-18 07:48:54", "author": "@MihaelFeldman"}, "921210362078281729": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "248", "datetime": "2017-10-20 03:04:00", "author": "@arrow_elpis"}, "1249285854024978432": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "716", "datetime": "2020-04-12 10:38:52", "author": "@inoque"}, "920632292661432320": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "179", "datetime": "2017-10-18 12:46:57", "author": "@ziky90"}, "921215374963519488": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "193", "datetime": "2017-10-20 03:23:55", "author": "@laboage777"}, "921282418438316033": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "433", "datetime": "2017-10-20 07:50:19", "author": "@hs_heddy"}, "920554645361176578": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "59", "datetime": "2017-10-18 07:38:25", "author": "@damianoazzolini"}, "921719480593584128": {"content_summary": "Swish swish! A new activation function for #deeplearning. TLDR: x*sigmoid(x). Curious to try it on Monday https://t.co/38WIRo0wRR https://t.co/b9gUJCvr5k", "followers": "159", "datetime": "2017-10-21 12:47:03", "author": "@mariushelf"}, "921278171508457472": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "353", "datetime": "2017-10-20 07:33:27", "author": "@hrnbskgc"}, "921214538636132352": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "1,823", "datetime": "2017-10-20 03:20:36", "author": "@trinity_site"}, "1249208807043092480": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "688", "datetime": "2020-04-12 05:32:43", "author": "@BCH29760395"}, "921327804964204544": {"content_summary": "\u3053\u308c\u307e\u3058\uff1f\u3048\u3048\u3084\u3093| Swish: a Self-Gated Activation Function https://t.co/tiUuo7yhNX", "followers": "214", "datetime": "2017-10-20 10:50:40", "author": "@ryo6036"}, "920623018568642561": {"content_summary": "RT @Miles_Brundage: \"Swish: a Self-Gated Activation Function,\" Ramachandran et al.: https://t.co/bRa2xOCugx", "followers": "77", "datetime": "2017-10-18 12:10:06", "author": "@savinay1986"}, "1249347342861398020": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,020", "datetime": "2020-04-12 14:43:12", "author": "@nishizawa"}, "920525904048246785": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "54", "datetime": "2017-10-18 05:44:12", "author": "@tszk96"}, "921350206507032578": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "846", "datetime": "2017-10-20 12:19:41", "author": "@pavlov469"}, "922557153386393600": {"content_summary": "RT @thinkmariya: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/nU\u2026", "followers": "96", "datetime": "2017-10-23 20:15:40", "author": "@kellyscientist"}, "920525028537626624": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "106", "datetime": "2017-10-18 05:40:43", "author": "@simplystupid1"}, "921457771156877312": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "50", "datetime": "2017-10-20 19:27:07", "author": "@takuya_araki"}, "1249523827425460224": {"content_summary": "https://t.co/5O1VZOYlTW AutoML\u3067\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30ec\u30a4\u30e4\u69cb\u9020\u3084\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3057\u3088\u3046\u3068\u3044\u3046\u8a66\u307f\u3067\u3001\u6d3b\u6027\u95a2\u6570\u30fb\u640d\u5931\u95a2\u6570\u304b\u3089\u5b66\u7fd2\u30eb\u30fc\u30eb\u30fb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020\u304b\u3089\u3064\u3044\u306b\u30bc\u30ed\u304b\u3089\u5b66\u7fd2\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4f5c\u308a\u4e0a\u3052\u308b\u307e\u3067\u306b\u81f3\u3063\u305f\u3068\u3044\u3046\u6d41\u308c\u3001\u6050\u308d\u3057\u3044\u3067\u3059\u306d", "followers": "64", "datetime": "2020-04-13 02:24:30", "author": "@gpu_eater"}, "921337754365050880": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,337", "datetime": "2017-10-20 11:30:12", "author": "@yagami_360"}, "921193007457562624": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "113", "datetime": "2017-10-20 01:55:02", "author": "@maxuil"}, "921290862612459520": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "433", "datetime": "2017-10-20 08:23:53", "author": "@hs_heddy"}, "921186807328358400": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,022", "datetime": "2017-10-20 01:30:24", "author": "@hironow"}, "920608647696097280": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "4,615", "datetime": "2017-10-18 11:13:00", "author": "@HITStales"}, "925059043764391937": {"content_summary": "Swish: A Self-Gated Activation Function https://t.co/zlhYtHm1gi", "followers": "861", "datetime": "2017-10-30 17:57:17", "author": "@ryf_feed"}, "920809141785935873": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "322", "datetime": "2017-10-19 00:29:41", "author": "@letranger14"}, "920498848870600704": {"content_summary": "f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUcRU", "followers": "81,490", "datetime": "2017-10-18 03:56:42", "author": "@hardmaru"}, "921783360296382465": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "2,671", "datetime": "2017-10-21 17:00:53", "author": "@ayirpelle"}, "921333268523261952": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "548", "datetime": "2017-10-20 11:12:23", "author": "@CreatorQsF"}, "920602388540674048": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "399", "datetime": "2017-10-18 10:48:08", "author": "@kamilsindi"}, "920585638096916481": {"content_summary": "RT @AMVA4NP: Swish activation function f(x) = x \u22c5 \u03c3 (x) outperforms ReLUs in a bunch of benchmarks https://t.co/7z3tBb2xmB #DeepLearning ht\u2026", "followers": "15,143", "datetime": "2017-10-18 09:41:34", "author": "@alevergara78"}, "1241391581854228483": {"content_summary": "RT @hoitab: If you want to geek out on the hard-swish activation function, check out: \ud83d\udc49Paper on the Swish activation function and how it c\u2026", "followers": "2,944", "datetime": "2020-03-21 15:49:51", "author": "@hurutoriya"}, "921266480682897408": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,736", "datetime": "2017-10-20 06:46:59", "author": "@cota_nabe"}, "1249361575594455047": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "193", "datetime": "2020-04-12 15:39:46", "author": "@laboage777"}, "921407716664393729": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,636", "datetime": "2017-10-20 16:08:13", "author": "@teruteru128"}, "920540525731762176": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "640", "datetime": "2017-10-18 06:42:18", "author": "@bll_krtl"}, "920499799010500608": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "568", "datetime": "2017-10-18 04:00:28", "author": "@cxhrndz"}, "1251424247232319490": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "43", "datetime": "2020-04-18 08:16:05", "author": "@AronCiroTeo"}, "921315124618473473": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "345", "datetime": "2017-10-20 10:00:17", "author": "@blockahead"}, "922140215095029762": {"content_summary": "New, easily trainable activation function by the Google Brain team. Beats RELU, SELU and others: https://t.co/T6zSNUgGbZ", "followers": "97", "datetime": "2017-10-22 16:38:54", "author": "@karlsonp"}, "1249309775130746880": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "30", "datetime": "2020-04-12 12:13:56", "author": "@Kashu82171388"}, "920673760327491585": {"content_summary": "#Swish (just f(x) = x * sigmoid(x)) as an activation function over ReLU makes some image-processing more accurate https://t.co/hXgQ4Cb2U0 https://t.co/uTsAlbVH3I", "followers": "576", "datetime": "2017-10-18 15:31:44", "author": "@MatthewMcAteer0"}, "921329967102697473": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "517", "datetime": "2017-10-20 10:59:16", "author": "@ImagingSolAkira"}, "920675849594007553": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "527", "datetime": "2017-10-18 15:40:02", "author": "@christianramsey"}, "920523141650239490": {"content_summary": "Must be a fan of #KatyPerry https://t.co/v5Ia4ZZo8u", "followers": "99", "datetime": "2017-10-18 05:33:14", "author": "@greed2411"}, "920466072041676802": {"content_summary": "Swish: a Self-Gated Activation Function - Prajit Ramachandran https://t.co/EZWEscKIK2", "followers": "858", "datetime": "2017-10-18 01:46:27", "author": "@deep_rl"}, "922523474601660416": {"content_summary": "RT @segal_eran: Swish: A new activation function for deep neural network claimed to work better than the good old Relu https://t.co/H6RBauA\u2026", "followers": "304", "datetime": "2017-10-23 18:01:50", "author": "@tae_hwang"}, "1247751933915353092": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "134", "datetime": "2020-04-08 05:03:37", "author": "@vish_cse11"}, "920501276919681024": {"content_summary": "activation function\u3001\u307e\u3060\u51fa\u3066\u304f\u308b\u306e\u2026\u2026 https://t.co/gxNzo7PDsd", "followers": "1,948", "datetime": "2017-10-18 04:06:21", "author": "@yag_ays"}, "921505847402024961": {"content_summary": "RT @Weenkus: It seems like there is a new activation function every day - Swish! https://t.co/6cTgZ9rgU9 #DataScience #AI #ML #DL #DeepLear\u2026", "followers": "470", "datetime": "2017-10-20 22:38:09", "author": "@zerothworld"}, "921282776891932672": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,684", "datetime": "2017-10-20 07:51:45", "author": "@rf0444"}, "921380855053828096": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "3,175", "datetime": "2017-10-20 14:21:28", "author": "@tjmlab"}, "921066321726595072": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "207", "datetime": "2017-10-19 17:31:38", "author": "@eram1205"}, "921285229926522880": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,034", "datetime": "2017-10-20 08:01:30", "author": "@yasu_919"}, "1249283799856435207": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,306", "datetime": "2020-04-12 10:30:43", "author": "@ororons"}, "920586153346195462": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "1,987", "datetime": "2017-10-18 09:43:37", "author": "@DeepLearningFTW"}, "920520295919779840": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "2,043", "datetime": "2017-10-18 05:21:55", "author": "@dosei_sanga"}, "929026102789595137": {"content_summary": "RT @aureliengeron: The swish activation function, f(x) = x sigmoid(x). Yet another ReLU variant that seems to outperform it (https://t.co/R\u2026", "followers": "19", "datetime": "2017-11-10 16:40:58", "author": "@ML_Coni"}, "925237435948154880": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "8,954", "datetime": "2017-10-31 05:46:09", "author": "@nardtree"}, "921021533589565440": {"content_summary": "Nice https://t.co/EeDUXkdBsJ", "followers": "13", "datetime": "2017-10-19 14:33:40", "author": "@pasarilacom"}, "921064554125189120": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "81,490", "datetime": "2017-10-19 17:24:36", "author": "@hardmaru"}, "920656646891888640": {"content_summary": "Swish: a Self-Gated Activation Function - https://t.co/RePA7qfYpI", "followers": "344", "datetime": "2017-10-18 14:23:44", "author": "@jefkine"}, "920902870823768064": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "6,144", "datetime": "2017-10-19 06:42:08", "author": "@flipper83"}, "921303095061102592": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "583", "datetime": "2017-10-20 09:12:29", "author": "@LazyMii"}, "920641558453481473": {"content_summary": "Swish: a Self-Gated Activation Function. https://t.co/GCN9BTVrhs https://t.co/KKlOSk7DTQ", "followers": "12,724", "datetime": "2017-10-18 13:23:46", "author": "@arxiv_org"}, "920510302411722758": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "106", "datetime": "2017-10-18 04:42:13", "author": "@simplystupid1"}, "921211204315463680": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,684", "datetime": "2017-10-20 03:07:21", "author": "@TATEXH"}, "922160672309465093": {"content_summary": "Hot #swish activation function beats #ReLU in existing #deeplearning architectures. https://t.co/xHf5fLbVtu https://t.co/39RtVkhj3Q", "followers": "1,443", "datetime": "2017-10-22 18:00:11", "author": "@exocert"}, "920518245035249664": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "25,260", "datetime": "2017-10-18 05:13:46", "author": "@alexjc"}, "920508730072031232": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "63", "datetime": "2017-10-18 04:35:58", "author": "@saxenauts"}, "925235227034652672": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "1,667", "datetime": "2017-10-31 05:37:22", "author": "@Scaled_Wurm"}, "925227037572325376": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "4,017", "datetime": "2017-10-31 05:04:50", "author": "@ballforest"}, "920712366358118405": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/AFf1552VtG", "followers": "3,687", "datetime": "2017-10-18 18:05:08", "author": "@IIoTML"}, "1249551151273402368": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "72", "datetime": "2020-04-13 04:13:04", "author": "@tsuchiyayoshio"}, "921346958555353088": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "21", "datetime": "2017-10-20 12:06:47", "author": "@ryo_takata"}, "920924189598547968": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "292", "datetime": "2017-10-19 08:06:51", "author": "@BitABit5"}, "1249560202447163392": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "31", "datetime": "2020-04-13 04:49:02", "author": "@otya_is"}, "923593826052313089": {"content_summary": "RT @appliedAIbook: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/\u2026", "followers": "96", "datetime": "2017-10-26 16:55:02", "author": "@kellyscientist"}, "921290715497340930": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "25", "datetime": "2017-10-20 08:23:17", "author": "@LouiS940616"}, "922561862738198534": {"content_summary": "New NN Activation Function - Swish https://t.co/KV8cAv8T2P", "followers": "1,584", "datetime": "2017-10-23 20:34:23", "author": "@aneesha"}, "920549684753649665": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "5,214", "datetime": "2017-10-18 07:18:42", "author": "@AlisonBLowndes"}, "920820276136259584": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "425", "datetime": "2017-10-19 01:13:56", "author": "@iamknighton"}, "920618105096822784": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "401", "datetime": "2017-10-18 11:50:35", "author": "@SgtLennon"}, "921618910020956160": {"content_summary": "RT @datasci_blogs: \u3010\u7dd1\u8336\u601d\u8003\u30d6\u30ed\u30b0\u3011 https://t.co/i1KBIfqdD7 Swish\u3092CIFAR10\u3067\u8a66\u3057\u3066\u307f\u308b Swish: a Self-Gated Activation Function https://t.co/CW5UIFSWAj\u2026", "followers": "1,031", "datetime": "2017-10-21 06:07:25", "author": "@tomoya52215710"}, "921381564621119489": {"content_summary": "RT @yohei_kikuta: https://t.co/CRulTJAkhX Swish \u8aad\u3093\u3060\u3002 ReLU \u304b\u3089 x*sigmoid(x) \u306b\u7f6e\u304d\u63db\u3048\u308b\u3068\u7cbe\u5ea6\u4e0a\u304c\u308b\u305e\u3001\u3068\u3044\u3046\u8a71\u3002\u6a5f\u68b0\u7ffb\u8a33\u542b\u3081\u305f\u5404\u7a2e\u30bf\u30b9\u30af\u3084\u30e2\u30c7\u30eb\u3092\u5e73\u5747\u7684\u306b\u898b\u308b\u3068\u307e\u3042\u78ba\u304b\u306b\u826f\u3044\u304b\u306a\u3001\u3068\u3044\u3046\u611f\u3058\u3002\u3082\u3046\u5c11\u3057\u8272\u2026", "followers": "597", "datetime": "2017-10-20 14:24:18", "author": "@hyper_pigeon"}, "920995698702725120": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/OI0fwdXorO #datascience #dataanalysis #bigdata", "followers": "582", "datetime": "2017-10-19 12:51:00", "author": "@Keva161"}, "1249216902632624128": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,279", "datetime": "2020-04-12 06:04:53", "author": "@yitabashi"}, "925293170614616064": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "1,039", "datetime": "2017-10-31 09:27:37", "author": "@s_w_d_"}, "920601822124916739": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "356", "datetime": "2017-10-18 10:45:53", "author": "@saruftw"}, "928093159296397312": {"content_summary": "\u3042\u308c\u3001 Swish \u306e\u8ad6\u6587 v2 \u3067\u30bf\u30a4\u30c8\u30eb\u5909\u308f\u3063\u305f\u306e\u304b https://t.co/YQqibuaimM", "followers": "873", "datetime": "2017-11-08 02:53:46", "author": "@ciela"}, "1247759265839771648": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "54", "datetime": "2020-04-08 05:32:45", "author": "@ttnam93"}, "920720052827115522": {"content_summary": "Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/nU8PrBLtbq #AI #ML https://t.co/AaOiiXDssQ", "followers": "28,529", "datetime": "2017-10-18 18:35:41", "author": "@thinkmariya"}, "1247751655929425922": {"content_summary": "Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules https://t.co/7UrjVgN2SW \u2022 better data augmentation https://t.co/2zRPSY2fdz \u2022 better loss functions https://t.co/JxFG4e2Dps &", "followers": "81,490", "datetime": "2020-04-08 05:02:31", "author": "@hardmaru"}, "921317157882839041": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,957", "datetime": "2017-10-20 10:08:22", "author": "@ysuga"}, "1249532610797330433": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "0", "datetime": "2020-04-13 02:59:24", "author": "@Sam09lol"}, "920537979747155968": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "39,503", "datetime": "2017-10-18 06:32:11", "author": "@TJO_datasci"}, "920502067927674880": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "602", "datetime": "2017-10-18 04:09:29", "author": "@fjsosah"}, "921069858736947200": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "161", "datetime": "2017-10-19 17:45:41", "author": "@argv_sat184"}, "921217522266914817": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "997", "datetime": "2017-10-20 03:32:27", "author": "@AkiraIsaka88"}, "920800523069952000": {"content_summary": "RT @mosko_mule: Swish\uff08x * sigmoid(x): https://t.co/gJH5625MLi \uff09\u306e\u7c21\u5358\u3055\u306f\u7b2c\u4e8c\u6b21\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30d6\u30fc\u30e0\u6642\u4ee3\u306b\u63d0\u6848\u3055\u308c\u3066\u3044\u305d\u3046\u306a\u611f\u3058\u304c\u3042\u308b\uff0e\uff08Google\u767a\u306a\u306e\u3067\u5404\u7a2e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067ImageNet\u5b9f\u9a13\u3092\u884c\u3063\u3066\u3044\u3066\u300c\u4e01\u2026", "followers": "8,954", "datetime": "2017-10-18 23:55:27", "author": "@nardtree"}, "921186401554644993": {"content_summary": "ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u3057ReLU\u306b\u5168\u52dd\u3057\u305f\u3068\u3044\u3046\u3002 https://t.co/rUOCYoggUx", "followers": "11,462", "datetime": "2017-10-20 01:28:47", "author": "@icoxfog417"}, "921499860259373056": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "375", "datetime": "2017-10-20 22:14:21", "author": "@tomohitoy"}, "921120695525896192": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "2,628", "datetime": "2017-10-19 21:07:42", "author": "@Juxi"}, "920687321929805824": {"content_summary": "Swish:f(x) =x\u00b7sigmoid(x) works better than ReLU on imagenet improving top-1 classif accuracy by 0.9% https://t.co/mF30qu2tWt #DeepLearning", "followers": "90", "datetime": "2017-10-18 16:25:37", "author": "@abhi_kumar07"}, "921338319484502016": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "9", "datetime": "2017-10-20 11:32:27", "author": "@heating_smoke"}, "920515231700439040": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,971", "datetime": "2017-10-18 05:01:48", "author": "@IrwanBello"}, "920528133937422338": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "7,133", "datetime": "2017-10-18 05:53:04", "author": "@anshulkundaje"}, "921571003704139776": {"content_summary": "RT @AI_m_lab: \u7406\u89e3\u3092\u6df1\u3081\u308b\u4e0a\u3067\u3082\u8aad\u3093\u3067\u304a\u304d\u305f\u3044\u8a18\u4e8b\u3067\u3059\u306d \u25bc[1710.05941] Swish: a Self-Gated Activation Function https://t.co/qUDef7Rz5j #deeplearning", "followers": "433", "datetime": "2017-10-21 02:57:03", "author": "@hs_heddy"}, "921337554422468608": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "116", "datetime": "2017-10-20 11:29:25", "author": "@embasm"}, "921095286260490241": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "130", "datetime": "2017-10-19 19:26:44", "author": "@aitorbak"}, "921708915141763072": {"content_summary": "RT @datasci_blogs: \u3010\u7dd1\u8336\u601d\u8003\u30d6\u30ed\u30b0\u3011 https://t.co/i1KBIfqdD7 Swish\u3092CIFAR10\u3067\u8a66\u3057\u3066\u307f\u308b Swish: a Self-Gated Activation Function https://t.co/CW5UIFSWAj\u2026", "followers": "4,977", "datetime": "2017-10-21 12:05:04", "author": "@ishiid"}, "921541060655849472": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,500", "datetime": "2017-10-21 00:58:04", "author": "@NaOHaq"}, "921342934124859393": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "4,075", "datetime": "2017-10-20 11:50:47", "author": "@YSRKEN"}, "952798055803301889": {"content_summary": "RT @carlcarrie: Activation functions in Deep Learning compared - paper Rectified Linear Unit (ReLU) vs Swish (based on Sigmoid) https://t\u2026", "followers": "205", "datetime": "2018-01-15 07:02:13", "author": "@oliverjlee"}, "921381868188049409": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "576", "datetime": "2017-10-20 14:25:30", "author": "@sumio_tym"}, "1247766629431136259": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "75", "datetime": "2020-04-08 06:02:01", "author": "@MozejkoMarcin"}, "921591369595891712": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "350", "datetime": "2017-10-21 04:17:59", "author": "@goahead1216"}, "921600640240967680": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "779", "datetime": "2017-10-21 04:54:49", "author": "@kuromunori"}, "1249294586230394883": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "299", "datetime": "2020-04-12 11:13:34", "author": "@knuo"}, "920566353706205184": {"content_summary": "SWISH: A self-gated activation function that outperforms ReLU. f(x) = x * sigmoid(x) https://t.co/RsKjkRLAA7 https://t.co/rXcrT3QPuY", "followers": "329", "datetime": "2017-10-18 08:24:56", "author": "@danielmartinezf"}, "920625078584430593": {"content_summary": "Have you folks started swishing your models yet? https://t.co/eiGeVRiLdR", "followers": "1,593", "datetime": "2017-10-18 12:18:17", "author": "@seaandsailor"}, "921335982254800896": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "674", "datetime": "2017-10-20 11:23:10", "author": "@horimotz"}, "921279140573016064": {"content_summary": "[1710.05941] Swish: a Self-Gated Activation Function https://t.co/uEAy9Dk38a", "followers": "731", "datetime": "2017-10-20 07:37:18", "author": "@aohsato"}, "1249220833173594112": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "79", "datetime": "2020-04-12 06:20:30", "author": "@Rart_Gin"}, "920500379116326913": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "14,647", "datetime": "2017-10-18 04:02:47", "author": "@iScienceLuvr"}, "920618154992205824": {"content_summary": "Goodbye ReLU! Swish is unbounded above and bounded below but, unlike you, it is also non-monotonic and smooth. #AI #ML #DL #DeepLearning https://t.co/BJFnp80jMR", "followers": "5,992", "datetime": "2017-10-18 11:50:47", "author": "@dmonett"}, "1249206567582523393": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "42", "datetime": "2020-04-12 05:23:49", "author": "@tupupapa"}, "921233195185586176": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "346", "datetime": "2017-10-20 04:34:44", "author": "@xxpodxx"}, "920740101474230273": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "482", "datetime": "2017-10-18 19:55:21", "author": "@P_tan"}, "920509749476642816": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "459", "datetime": "2017-10-18 04:40:01", "author": "@dolhani"}, "920606708111515649": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "69", "datetime": "2017-10-18 11:05:17", "author": "@ku21fan"}, "922005752549580800": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "993", "datetime": "2017-10-22 07:44:36", "author": "@EnsekiTT"}, "922205010687025152": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "56", "datetime": "2017-10-22 20:56:22", "author": "@fenildoshi009"}, "920487551777099776": {"content_summary": "\"Swish: a Self-Gated Activation Function\", Prajit Ramachandran, Barret Zoph, Quoc V\uff0e Le https://t.co/VAHGMZFQgD", "followers": "773", "datetime": "2017-10-18 03:11:48", "author": "@arxivml"}, "921604584505622528": {"content_summary": "RT @datasci_blogs: \u3010\u7dd1\u8336\u601d\u8003\u30d6\u30ed\u30b0\u3011 https://t.co/i1KBIfqdD7 Swish\u3092CIFAR10\u3067\u8a66\u3057\u3066\u307f\u308b Swish: a Self-Gated Activation Function https://t.co/CW5UIFSWAj\u2026", "followers": "1,667", "datetime": "2017-10-21 05:10:30", "author": "@Scaled_Wurm"}, "920811563501494272": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "11,766", "datetime": "2017-10-19 00:39:19", "author": "@yutakashino"}, "920832736159502337": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "25", "datetime": "2017-10-19 02:03:27", "author": "@harsha_091"}, "1247854314585862145": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "30", "datetime": "2020-04-08 11:50:27", "author": "@DesaiDjd"}, "921600612977876997": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "779", "datetime": "2017-10-21 04:54:43", "author": "@kuromunori"}, "921349390765252608": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "353", "datetime": "2017-10-20 12:16:27", "author": "@shikihuton"}, "1247877774850830339": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "92", "datetime": "2020-04-08 13:23:40", "author": "@SentimOfficial"}, "921345600250978306": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "9,287", "datetime": "2017-10-20 12:01:23", "author": "@biikame"}, "921307226895089664": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "162", "datetime": "2017-10-20 09:28:54", "author": "@tuxi_dashimaki"}, "923308850186420224": {"content_summary": "RT @topbotsnews: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/eV\u2026", "followers": "440", "datetime": "2017-10-25 22:02:38", "author": "@krishnalaghari1"}, "921332539683254274": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,221", "datetime": "2017-10-20 11:09:29", "author": "@D_Plius"}, "920623064513052672": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "77", "datetime": "2017-10-18 12:10:17", "author": "@savinay1986"}, "921121856324820992": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "165", "datetime": "2017-10-19 21:12:18", "author": "@herchu"}, "921367782976921602": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "268", "datetime": "2017-10-20 13:29:32", "author": "@sol_ursus"}, "924005029660442624": {"content_summary": "RT @MelodyGuan: Proposals of new activation functions are quite in fashion. Swish https://t.co/IFHZZZtWa8 ISRLU https://t.co/a8eqgoFcG0\u2026", "followers": "783", "datetime": "2017-10-27 20:09:00", "author": "@muktabh"}, "924858717270458368": {"content_summary": "Searching for Activation Functions https://t.co/TuPlBhMwtJ", "followers": "4,100", "datetime": "2017-10-30 04:41:15", "author": "@arxiv_cscv"}, "920664536486694912": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "49", "datetime": "2017-10-18 14:55:05", "author": "@amjad_aburmileh"}, "1249468566664929280": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "323", "datetime": "2020-04-12 22:44:54", "author": "@24math_tech"}, "920556648992718849": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/uOuAKypyKP #GoogleBrain https://t.co/SB1H85ymsU", "followers": "2,927", "datetime": "2017-10-18 07:46:22", "author": "@evolvingstuff"}, "1247752067852034049": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "14", "datetime": "2020-04-08 05:04:09", "author": "@ProjectDomani"}, "921535975192268800": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,477", "datetime": "2017-10-21 00:37:52", "author": "@yoko8ma"}, "921302421434806273": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "476", "datetime": "2017-10-20 09:09:48", "author": "@TypelessType"}, "920534259558944769": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "561", "datetime": "2017-10-18 06:17:24", "author": "@menace_"}, "921260426926612481": {"content_summary": "A beautiful looking activation function. Sounds better to say \u2018Swish\u2019 than \u2018ReLU\u2019 \ud83d\ude1d https://t.co/zN2YjeJATx #ML #AI #MachineLearning #Swish", "followers": "13", "datetime": "2017-10-20 06:22:56", "author": "@_aidude"}, "921341605721751552": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "203", "datetime": "2017-10-20 11:45:31", "author": "@toshi_pp"}, "921409481757548544": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "196", "datetime": "2017-10-20 16:15:14", "author": "@unnohideyuki"}, "1249280067458351105": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "96", "datetime": "2020-04-12 10:15:53", "author": "@garlic55"}, "921345777401655298": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "617", "datetime": "2017-10-20 12:02:05", "author": "@DMiyamo3"}, "920518074721341442": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "8,954", "datetime": "2017-10-18 05:13:06", "author": "@nardtree"}, "1249258793331904512": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "966", "datetime": "2020-04-12 08:51:21", "author": "@ryozo18"}, "921476597617537024": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,058", "datetime": "2017-10-20 20:41:55", "author": "@BigsnarfDude"}, "921272622192541697": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "4,531", "datetime": "2017-10-20 07:11:24", "author": "@yoshizaki_kkgk"}, "920629390182150145": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,018", "datetime": "2017-10-18 12:35:25", "author": "@deCustine"}, "921295657318494208": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,169", "datetime": "2017-10-20 08:42:56", "author": "@zaoriku0"}, "1247798343343853569": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "0", "datetime": "2020-04-08 08:08:02", "author": "@Sam09lol"}, "920729946523406336": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "684", "datetime": "2017-10-18 19:15:00", "author": "@mmmgaber"}, "1249262017308815360": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,879", "datetime": "2020-04-12 09:04:09", "author": "@sesquipedale"}, "930013187142909952": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "533", "datetime": "2017-11-13 10:03:17", "author": "@ddragon"}, "922452050901794817": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,174", "datetime": "2017-10-23 13:18:01", "author": "@yonedadesk4"}, "921678742614708224": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,983", "datetime": "2017-10-21 10:05:10", "author": "@Rauziii"}, "925043468770066432": {"content_summary": "RT @asam9891: [1710.05941v2] Searching for Activation Functions Swish\u306e\u6587\u732e\u304c\u3044\u3064\u306e\u9593\u306b\u304b\u6052\u4f8b\u306eRNN\u3067\u69cb\u9020\u63a2\u7d22\u3059\u308b\u3084\u3064\u306b\u306a\u3063\u3066\u305f\u3002\u305d\u3057\u3066switch\u3060\u3068\u601d\u3063\u3066\u305f\u3002\u3002\u3002 https://t.co/FAauBO6\u2026", "followers": "2,043", "datetime": "2017-10-30 16:55:24", "author": "@dosei_sanga"}, "920645945766875137": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "215", "datetime": "2017-10-18 13:41:12", "author": "@uapatira"}, "920779991960506369": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "32", "datetime": "2017-10-18 22:33:52", "author": "@__Yevgeniy"}, "920550339933364224": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "217", "datetime": "2017-10-18 07:21:18", "author": "@mrhctr"}, "921220368177668096": {"content_summary": "It seems like there is a new activation function every day - Swish! https://t.co/6cTgZ9rgU9 #DataScience #AI #ML #DL #DeepLearning", "followers": "207", "datetime": "2017-10-20 03:43:45", "author": "@Weenkus"}, "921338490930978816": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "666", "datetime": "2017-10-20 11:33:08", "author": "@Taizo_Ayase"}, "921186698725277696": {"content_summary": "RT @AiAiHealthcare: Tried #Swish \ud83d\ude0d, and works much better than ReLU on our model! ReLU was beating everything else incl SELU. Submitting a\u2026", "followers": "216", "datetime": "2017-10-20 01:29:58", "author": "@e0en"}, "920724064389382144": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "412", "datetime": "2017-10-18 18:51:37", "author": "@deanofthewebb"}, "920903393014530049": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "323", "datetime": "2017-10-19 06:44:13", "author": "@xpearhead"}, "920523133261615104": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,377", "datetime": "2017-10-18 05:33:12", "author": "@kaineko"}, "920668450300813312": {"content_summary": "RT @arxiv_cscv: Swish: a Self-Gated Activation Function https://t.co/TuPlBhuVCb", "followers": "37", "datetime": "2017-10-18 15:10:38", "author": "@manuelschmidt90"}, "1249216827999191041": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "840", "datetime": "2020-04-12 06:04:35", "author": "@CTsuchinoko"}, "922524882394431488": {"content_summary": "RT @exocert: Hot #swish activation function beats #ReLU in existing #deeplearning architectures. https://t.co/xHf5fLbVtu https://t.co/39Rt\u2026", "followers": "903", "datetime": "2017-10-23 18:07:26", "author": "@wk77"}, "920598431260962816": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "202", "datetime": "2017-10-18 10:32:24", "author": "@gnperdue"}, "1249535896694620160": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "1,318", "datetime": "2020-04-13 03:12:27", "author": "@fujitahajime"}, "920536231200538624": {"content_summary": "Yet another non-linearity: Swish - self-gated activation function - f(x)=x\u22c5sigmoid(x) https://t.co/a187ORCy6s", "followers": "913", "datetime": "2017-10-18 06:25:14", "author": "@SpaceAnubis"}, "920655031577317377": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "313", "datetime": "2017-10-18 14:17:19", "author": "@jrbtaylor"}, "925155784832323585": {"content_summary": "RT @mosko_mule: \u3053\u308c\u306f\u6050\u308b\u3079\u304d\u76f8\u8ee2\u79fb https://t.co/OL4r0iC9Fv Swish: a Self-Gated Activation Func.v1/Mon, 16 Oct 2017 Searching for Activation Func.v2\u2026", "followers": "62", "datetime": "2017-10-31 00:21:42", "author": "@panpu333"}, "920652159015899143": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "381", "datetime": "2017-10-18 14:05:54", "author": "@anantzoid"}, "924826191458177024": {"content_summary": "Swish inspired me to search for activation functions and now here is \"Searching for activations functions\" https://t.co/6Ye7TtVBwj", "followers": "817", "datetime": "2017-10-30 02:32:01", "author": "@ark_aung"}, "920786775047512064": {"content_summary": "RT @poolio: TL;DR: use x * sigmoid(x) for neural net activations. Multiplicative interactions strike again! https://t.co/wOZB3Ck9oJ", "followers": "456", "datetime": "2017-10-18 23:00:49", "author": "@PerthMLGroup"}, "920621289429184512": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "208", "datetime": "2017-10-18 12:03:14", "author": "@AdrianoCarmezim"}, "920921225379147777": {"content_summary": "The swish activation function, f(x) = x sigmoid(x). Yet another ReLU variant that seems to outperform it (https://t.co/R5SrEqeWM1). https://t.co/m9DfpgdRjy", "followers": "13,638", "datetime": "2017-10-19 07:55:04", "author": "@aureliengeron"}, "920668487198093314": {"content_summary": "f(x) = x sigmoid(x), a self gated activation function: https://t.co/bnUm5iIDEP Apparently performs a bit better than ReLU with no other changes to the network at all. https://t.co/B3SQ7KImyQ", "followers": "332", "datetime": "2017-10-18 15:10:47", "author": "@nilakshdas"}, "921252841649344512": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "266", "datetime": "2017-10-20 05:52:48", "author": "@hiroakichan"}, "920608550652583939": {"content_summary": "RT @_Ryobot: Swish: f(x) = x * sigmoid(x) \u3092\u30d7\u30ed\u30c3\u30c8\uff0eGated Linear Unit \u306e\u6d3b\u6027\u5316\u95a2\u6570\u7248\u3068\u3044\u3046\u611f\u3058\uff0e\u6700\u8fd1\u306f\u81ea\u5df1\u6ce8\u610f\u3084\u81ea\u5df1\u30b2\u30fc\u30c6\u30a3\u30f3\u30b0\u306b\u52e2\u3044\u3092\u611f\u3058\u308b https://t.co/uprwQXCu63 https://t.co\u2026", "followers": "4,615", "datetime": "2017-10-18 11:12:37", "author": "@HITStales"}, "921588555465363456": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,224", "datetime": "2017-10-21 04:06:48", "author": "@takemioIO"}, "920782658363211776": {"content_summary": "RT @golbin: ReLU\ub97c \ub6f0\uc5b4\ub118\ub294(\ub2e4\uace0 \uc8fc\uc7a5\ud558\ub294) \ud65c\uc131\ud654 \ud568\uc218 Swish!! \uc218\uc2dd\ub3c4 f(x) = x \u22c5 sigmoid(x) \ub85c \uac04\ub2e8\ud558\ub2e4. \ud83d\ude32 https://t.co/eH0DtCIc2V", "followers": "335", "datetime": "2017-10-18 22:44:27", "author": "@kobi78"}, "920562051566657536": {"content_summary": ".@goswish https://t.co/auU6bWkFbm", "followers": "1,214", "datetime": "2017-10-18 08:07:50", "author": "@agrimsingh"}, "920499660183269378": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "2,530", "datetime": "2017-10-18 03:59:55", "author": "@_329_"}, "925154403073507328": {"content_summary": "RT @asam9891: [1710.05941v2] Searching for Activation Functions Swish\u306e\u6587\u732e\u304c\u3044\u3064\u306e\u9593\u306b\u304b\u6052\u4f8b\u306eRNN\u3067\u69cb\u9020\u63a2\u7d22\u3059\u308b\u3084\u3064\u306b\u306a\u3063\u3066\u305f\u3002\u305d\u3057\u3066switch\u3060\u3068\u601d\u3063\u3066\u305f\u3002\u3002\u3002 https://t.co/FAauBO6\u2026", "followers": "150", "datetime": "2017-10-31 00:16:12", "author": "@y_yammt"}, "1249308226106970112": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "158", "datetime": "2020-04-12 12:07:46", "author": "@_xwas0ux"}, "925229399934300160": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "1,766", "datetime": "2017-10-31 05:14:13", "author": "@jaialkdanel"}, "920547690240495616": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "374", "datetime": "2017-10-18 07:10:46", "author": "@8B_EC"}, "920530189527941120": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "5,521", "datetime": "2017-10-18 06:01:14", "author": "@SoyGema"}, "921245221798625280": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "358", "datetime": "2017-10-20 05:22:31", "author": "@inabe49"}, "921222652978593792": {"content_summary": "@stealthinu FYI: https://t.co/DgzHaYFOb4 RT\u3067\u6d41\u308c\u3066\u304d\u305f\u30d6\u30c4", "followers": "301", "datetime": "2017-10-20 03:52:50", "author": "@ktz_alias"}, "921346358518300673": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "354", "datetime": "2017-10-20 12:04:24", "author": "@akimitsuy"}, "920630460828434432": {"content_summary": "https://t.co/f90Yw1lLgh", "followers": "613", "datetime": "2017-10-18 12:39:41", "author": "@piroyoung"}, "930014468096057344": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "3,211", "datetime": "2017-11-13 10:08:22", "author": "@chartersazevedo"}, "921133745561677824": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "1,058", "datetime": "2017-10-19 21:59:33", "author": "@BigsnarfDude"}, "920796835698040832": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/TuPlBhMwtJ", "followers": "4,100", "datetime": "2017-10-18 23:40:47", "author": "@arxiv_cscv"}, "921419882809323520": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "44", "datetime": "2017-10-20 16:56:33", "author": "@Ng_Thanh_Chinh"}, "1249300254245015558": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "9", "datetime": "2020-04-12 11:36:06", "author": "@jr5CWDnQTY76XAE"}, "1085038709064396800": {"content_summary": "https://t.co/fEP66YQEHT using machine learning to do machine learning research", "followers": "119", "datetime": "2019-01-15 04:59:21", "author": "@ajixander"}, "927184507324772353": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/VfVyo3PjBU", "followers": "254", "datetime": "2017-11-05 14:43:07", "author": "@SenteticSense"}, "920760063438086145": {"content_summary": "RT @thinkmariya: Is Swish the new ReLU? New activation function outperforms previous ones in network training & performance https://t.co/nU\u2026", "followers": "409", "datetime": "2017-10-18 21:14:40", "author": "@AmirSaffari"}, "920897911214415873": {"content_summary": "RT @deliprao: Newly proposed activation \"Swish\" outperforms ReLU and many other activation functions on multiple models/tasks. https://t.co\u2026", "followers": "30", "datetime": "2017-10-19 06:22:26", "author": "@dave_hirschfeld"}, "921198405610651648": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "173", "datetime": "2017-10-20 02:16:29", "author": "@morishii"}, "921188866404560896": {"content_summary": "Swish: a Self-Gated Activation Function https://t.co/2N9FL2XmS9 https://t.co/ZLOuhNogNY", "followers": "846", "datetime": "2017-10-20 01:38:35", "author": "@inte11igence"}, "921192723167641600": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "2,451", "datetime": "2017-10-20 01:53:54", "author": "@jinbeizame007"}, "925292430131322880": {"content_summary": "RT @musyokudon: Swish\u8ad6\u6587\u304c\u66f4\u65b0\u3055\u308c\u3066\u9032\u5316\u3057\u3066\u305f Searching for Activation Functions https://t.co/LyibFpgkv5", "followers": "200", "datetime": "2017-10-31 09:24:41", "author": "@shin2ro_o"}, "920469684222418945": {"content_summary": "\"Swish: a Self-Gated Activation Function,\" Ramachandran et al.: https://t.co/bRa2xOCugx", "followers": "25,578", "datetime": "2017-10-18 02:00:48", "author": "@Miles_Brundage"}, "921215873708199937": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,039", "datetime": "2017-10-20 03:25:54", "author": "@s_w_d_"}, "920875539447066624": {"content_summary": "New #deeplearning paper https://t.co/zjysswktfH https://t.co/9oNiqzuoNN", "followers": "98", "datetime": "2017-10-19 04:53:32", "author": "@DeepLearningNow"}, "920807883842863104": {"content_summary": "The last time I played with functions like this, we found some curious connections with functional analysis. https://t.co/epsKB1S98u https://t.co/OfXE7D8Jx8", "followers": "245", "datetime": "2017-10-19 00:24:41", "author": "@seanforscience"}, "922718918791196672": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "64", "datetime": "2017-10-24 06:58:28", "author": "@2raru"}, "921406426538319872": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "99", "datetime": "2017-10-20 16:03:05", "author": "@yascriptor"}, "921446700337610754": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "1,673", "datetime": "2017-10-20 18:43:07", "author": "@bear_Rits_Conan"}, "1247775621175902210": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "42", "datetime": "2020-04-08 06:37:45", "author": "@MishakinSergey"}, "920619793119670273": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "29", "datetime": "2017-10-18 11:57:17", "author": "@jbuck594"}, "922242850493837312": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "256", "datetime": "2017-10-22 23:26:44", "author": "@jcchinhui"}, "921345304904966145": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "158", "datetime": "2017-10-20 12:00:13", "author": "@charlesryo"}, "921591953552154625": {"content_summary": "RT @weballergy: 'Swish: a Self-Gated Activation Function': a replacement for RELU-s? By Google Brain. https://t.co/CEsxPVgRGy #DeepLearning\u2026", "followers": "1,091", "datetime": "2017-10-21 04:20:18", "author": "@tatatrade"}, "920876932484423680": {"content_summary": "https://t.co/K2s17LeOdp\u0e08\u0e30\u0e15\u0e34\u0e14 computation bottleneck \u0e21\u0e31\u0e49\u0e22\u0e19\u0e30", "followers": "311", "datetime": "2017-10-19 04:59:04", "author": "@ssakares"}, "1184771419701424129": {"content_summary": "[7/10] \ud83d\udcc8 - Searching for Activation Functions - 305 \u2b50 - \ud83d\udcc4 https://t.co/YQ9LcJ6JVc - \ud83d\udd17 https://t.co/uZsEWfdr8M", "followers": "221", "datetime": "2019-10-17 10:01:33", "author": "@PapersTrending"}, "920733345998360577": {"content_summary": "RT @hardmaru: f(x) = x\uff0esigmoid(x) They call it the Swish, a self-gated activation function. Seems to outperform Relu. https://t.co/J4tyCbUc\u2026", "followers": "586", "datetime": "2017-10-18 19:28:30", "author": "@chaoticneural"}, "1247862922044456960": {"content_summary": "RT @hardmaru: Papers excluding first (NAS) and last point: \u2022 better activation functions https://t.co/J4tyCcbNJs \u2022 better learning rules\u2026", "followers": "3", "datetime": "2020-04-08 12:24:39", "author": "@mgp3334"}, "920596609687347200": {"content_summary": "Swish: A Self-Gated Activation Function https://t.co/xD8hmaGQGz", "followers": "861", "datetime": "2017-10-18 10:25:10", "author": "@ryf_feed"}, "922841145750650883": {"content_summary": "RT @CobaltAI: Swish [f(x)=x\u22c5sigmoid(x)] is a new activation function which tends to work better than ReLU on deeper models https://t.co/TA1\u2026", "followers": "549", "datetime": "2017-10-24 15:04:09", "author": "@ScmMishra"}, "921259352828264448": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "1,673", "datetime": "2017-10-20 06:18:40", "author": "@keigohtr"}, "921601873311756289": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "794", "datetime": "2017-10-21 04:59:43", "author": "@lpha_z"}, "1249420642442555392": {"content_summary": "RT @jaguring1: \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u6539\u5584\u3059\u3089\u81ea\u52d5\u5316\u3059\u308b\u8a66\u307f \u30cd\u30c3\u30c8\u69cb\u9020 https://t.co/FpihsoSZCy \u6d3b\u6027\u5316\u95a2\u6570 https://t.co/Fd8H5yOCyP \u5b66\u7fd2\u30eb\u30fc\u30eb https://t.co/LaHxJ0hRO6 \u30c7\u30fc\u30bf\u62e1\u5f35 ht\u2026", "followers": "142", "datetime": "2020-04-12 19:34:28", "author": "@n_kats_"}, "920676529524187137": {"content_summary": "ReLU\ub97c \ub6f0\uc5b4\ub118\ub294(\ub2e4\uace0 \uc8fc\uc7a5\ud558\ub294) \ud65c\uc131\ud654 \ud568\uc218 Swish!! \uc218\uc2dd\ub3c4 f(x) = x \u22c5 sigmoid(x) \ub85c \uac04\ub2e8\ud558\ub2e4. \ud83d\ude32 https://t.co/eH0DtCIc2V", "followers": "10,282", "datetime": "2017-10-18 15:42:44", "author": "@golbin"}, "921245088977526784": {"content_summary": "RT @icoxfog417: ReLU\u3092\u8d85\u3048\u308b\u30b7\u30f3\u30d7\u30eb\u304b\u3064\u5f37\u529b\u306a\u6d3b\u6027\u95a2\u6570\u3092\u767a\u660e\u3059\u3079\u304f\u751f\u307f\u51fa\u3055\u308c\u305fSwish\u306e\u7d39\u4ecb\u3002\u305d\u306e\u5f0f\u306ff(x) = x\u30fb\u03c3(x)\u3068\u3044\u3046\u3053\u306e\u4e0a\u306a\u304f\u5358\u7d14\u306a\u3082\u306e\u3067\u3001\u8ad6\u6587\u306e\u540d\u306e\u901a\u308aSelf-Gated\u306a\u5f62\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u753b\u50cf\u8a8d\u8b58\u3001\u7ffb\u8a33\u306e\u5404\u30e2\u30c7\u30eb\u30fb\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u691c\u8a3c\u2026", "followers": "35", "datetime": "2017-10-20 05:21:59", "author": "@nakasuke_a"}}}