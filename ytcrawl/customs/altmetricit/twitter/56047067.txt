{"citation_id": "56047067", "tab": "twitter", "twitter": {"1100225801197375488": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-26 02:47:26", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/BKmIOuDxNR Pretraining-Based Natural Language Generation for Text Summarization. (arXiv:1902.09243v1 [https://t.co/HHSAgzbrV2])"}, "1132137589891260416": {"author": "@ryo_masumura", "followers": "427", "datetime": "2019-05-25 04:13:30", "content_summary": "RT @kyoun: Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u2026"}, "1149408494145007616": {"author": "@RexDouglass", "followers": "1,409", "datetime": "2019-07-11 20:01:54", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization https://t.co/IVeqqAkmlp"}, "1121204913524994048": {"author": "@dyama1813", "followers": "38", "datetime": "2019-04-25 00:10:57", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1132144095411879936": {"author": "@semiinvariant", "followers": "74", "datetime": "2019-05-25 04:39:21", "content_summary": "RT @kyoun: Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u2026"}, "1132283922744659968": {"author": "@gbiwer", "followers": "28", "datetime": "2019-05-25 13:54:58", "content_summary": "RT @kyoun: Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u2026"}, "1132052915491729408": {"author": "@kyoun", "followers": "2,439", "datetime": "2019-05-24 22:37:02", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u306eEnc\u306bBERT\u3092\u4f7f\u3063\u3066draft\u751f\u6210\uff0e\u3082\u3046\u4e00\u3064\u306eDec(Stage2)\u3067BERT\u3092\u4f7f\u3044\uff0cLeft-to-right\u3067\u306f\u306a\u304fDraft\u3092editing\u3059\u308b\u30a4\u30e1\u30fc\u30b8\u3067\u751f\u6210\uff0eCNNDM\u3068NYT\u3067SOTA\uff0e https://t.co/vzk5skECyT"}, "1100222395917500416": {"author": "@BrundageBot", "followers": "3,906", "datetime": "2019-02-26 02:33:54", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization. Haoyu Zhang, Yeyun Gong, Yu Yan, Nan Duan, Jianjun Xu, Ji Wang, Ming Gong, and Ming Zhou https://t.co/ZksxOweJxj"}, "1117591727647408128": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-04-15 00:53:26", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/Z8HgjV7LjN Pretraining-Based Natural Language Generation for Text Summarization. (arXiv:1902.09243v2 [https://t.co/HHSAgzbrV2] UPDATED)"}, "1132080898344488960": {"author": "@rose_miura", "followers": "297", "datetime": "2019-05-25 00:28:13", "content_summary": "RT @kyoun: Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u2026"}, "1100471151451623425": {"author": "@arxivml", "followers": "782", "datetime": "2019-02-26 19:02:22", "content_summary": "\"Pretraining-Based Natural Language Generation for Text Summarization\", Haoyu Zhang, Yeyun Gong, Yu Yan, Nan Duan, \u2026 https://t.co/KPXsvTYOuk"}, "1120902989705728001": {"author": "@pinmarch_t", "followers": "820", "datetime": "2019-04-24 04:11:12", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1117892523333046272": {"author": "@katsuhitosudoh", "followers": "1,865", "datetime": "2019-04-15 20:48:41", "content_summary": "RT @rtanaka_lab: BERT\u3092\u6587\u751f\u6210\u306b\u4f7f\u3046\u3088\u3046\u306b\u306a\u3063\u305f\u306e\u304b https://t.co/hXGlIudb0n"}, "1118081212814225410": {"author": "@watchdog20xx", "followers": "78", "datetime": "2019-04-16 09:18:28", "content_summary": "RT @rtanaka_lab: BERT\u3092\u6587\u751f\u6210\u306b\u4f7f\u3046\u3088\u3046\u306b\u306a\u3063\u305f\u306e\u304b https://t.co/hXGlIudb0n"}, "1117875490490990592": {"author": "@arxiv_cscl", "followers": "3,531", "datetime": "2019-04-15 19:41:00", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6sQllH"}, "1117961340100829185": {"author": "@akf", "followers": "813", "datetime": "2019-04-16 01:22:08", "content_summary": "RT @arxiv_cscl: Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6t7WKh"}, "1120912882424668160": {"author": "@kdaira_", "followers": "321", "datetime": "2019-04-24 04:50:31", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1117808675786113029": {"author": "@rtanaka_lab", "followers": "146", "datetime": "2019-04-15 15:15:30", "content_summary": "BERT\u3092\u6587\u751f\u6210\u306b\u4f7f\u3046\u3088\u3046\u306b\u306a\u3063\u305f\u306e\u304b"}, "1117603782668558336": {"author": "@arxiv_cscl", "followers": "3,531", "datetime": "2019-04-15 01:41:20", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6t7WKh"}, "1100413853601488903": {"author": "@arxiv_in_review", "followers": "1,317", "datetime": "2019-02-26 15:14:42", "content_summary": "#IJCAI19 Pretraining-Based Natural Language Generation for Text Summarization. (arXiv:1902.09243v1 [cs\\.CL]) https://t.co/SGJmwwT4B1"}, "1117996044661350400": {"author": "@jaguring1", "followers": "13,476", "datetime": "2019-04-16 03:40:03", "content_summary": "RT @rtanaka_lab: BERT\u3092\u6587\u751f\u6210\u306b\u4f7f\u3046\u3088\u3046\u306b\u306a\u3063\u305f\u306e\u304b https://t.co/hXGlIudb0n"}, "1132061953323556864": {"author": "@KSKSKSKS2", "followers": "216", "datetime": "2019-05-24 23:12:57", "content_summary": "RT @kyoun: Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u2026"}, "1117986633427472384": {"author": "@ttt00479239", "followers": "2", "datetime": "2019-04-16 03:02:39", "content_summary": "RT @arxiv_cscl: Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6t7WKh"}, "1120994064831143936": {"author": "@asa9no640511", "followers": "189", "datetime": "2019-04-24 10:13:06", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1117591929892556807": {"author": "@helioRocha_", "followers": "631", "datetime": "2019-04-15 00:54:14", "content_summary": "\"Pretraining-Based Natural Language Generation for Text Summarization. (arXiv:1902.09243v2 [https://t.co/CE87fflQud] UPDATED)\" #arXiv https://t.co/x81U60b61O"}, "1100239322987577345": {"author": "@arxiv_cscl", "followers": "3,531", "datetime": "2019-02-26 03:41:10", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6t7WKh"}, "1120904184193175552": {"author": "@jaguring1", "followers": "13,476", "datetime": "2019-04-24 04:15:57", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1118113595881996290": {"author": "@jojonki", "followers": "1,157", "datetime": "2019-04-16 11:27:09", "content_summary": "RT @arxiv_cscl: Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6t7WKh"}, "1132053863920328704": {"author": "@jaguring1", "followers": "13,476", "datetime": "2019-05-24 22:40:48", "content_summary": "RT @kyoun: Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u2026"}, "1120902353324896261": {"author": "@icoxfog417", "followers": "11,547", "datetime": "2019-04-24 04:08:41", "content_summary": "BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u88dc\u5b8c=>\u88dc\u5b8c\u6587\u3068\u5165\u529b\u3092\u5143\u306b\u518d\u4f5c\u6210\u3001\u30682\u6bb5\u968e\u3067\u751f\u6210\u3057\u3066\u3044\u308b https://t.co/WPPg2pzvtn"}, "1100225390868680706": {"author": "@arxiv_cs_cl", "followers": "4,217", "datetime": "2019-02-26 02:45:49", "content_summary": "https://t.co/C2cijdDELL Pretraining-Based Natural Language Generation for Text Summarization. (arXiv:1902.09243v1 [https://t.co/HW5RVw4UkE]) #NLProc"}, "1120959810613026816": {"author": "@kz_lil_fox", "followers": "150", "datetime": "2019-04-24 07:56:59", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1121093889455058945": {"author": "@MaftraQ", "followers": "329", "datetime": "2019-04-24 16:49:46", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1117799901721714690": {"author": "@arxiv_cscl", "followers": "3,531", "datetime": "2019-04-15 14:40:38", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6t7WKh"}, "1132053017996300288": {"author": "@esXFdfOJxiGBFLx", "followers": "1,793", "datetime": "2019-05-24 22:37:26", "content_summary": "RT @kyoun: Pretraining-Based Natural Language Generation for Text Summarization (\u56fd\u9632\u79d1\u6280\u5927) https://t.co/i3sefbSjXP BERT\u3092\u8981\u7d04\u751f\u6210\u306b\u5229\u7528\uff0eEncDec(Stage1)\u2026"}, "1120914036223123456": {"author": "@morioka", "followers": "822", "datetime": "2019-04-24 04:55:06", "content_summary": "RT @icoxfog417: BERT\u3092\u4f7f\u3063\u305f\u62bd\u8c61\u578b(Abstractive)\u8981\u7d04\u306e\u7814\u7a76\u3002BERT\u306f\u30de\u30b9\u30af\u3055\u308c\u305f\u7b87\u6240\u3092\u4e88\u6e2c\u3059\u308b\u5f62\u3067\u5b66\u7fd2\u3059\u308b\u305f\u3081\u3001\u305d\u306e\u307e\u307e\u3067\u306f\u6587\u751f\u6210\u306b\u4f7f\u3048\u306a\u3044\u3002\u3053\u306e\u305f\u3081\u3001\u4e00\u65e6Transformer\u30d9\u30fc\u30b9\u306e\u30e2\u30c7\u30eb\u3067\u6587(\u30c9\u30e9\u30d5\u30c8)\u3092\u4f5c\u6210=>Mask\u3092\u304b\u3051\u3066BERT\u3067\u2026"}, "1100226641266176003": {"author": "@helioRocha_", "followers": "631", "datetime": "2019-02-26 02:50:47", "content_summary": "\"Pretraining-Based Natural Language Generation for Text Summarization. (arXiv:1902.09243v1 [https://t.co/CE87fflQud])\" #arXiv https://t.co/x81U60b61O"}, "1149415601124892672": {"author": "@albsantosdel", "followers": "265", "datetime": "2019-07-11 20:30:09", "content_summary": "RT @RexDouglass: Pretraining-Based Natural Language Generation for Text Summarization https://t.co/IVeqqAkmlp"}, "1117590181169827840": {"author": "@arxiv_cs_cl", "followers": "4,217", "datetime": "2019-04-15 00:47:17", "content_summary": "https://t.co/9RSsfEKCZ0 Pretraining-Based Natural Language Generation for Text Summarization. (arXiv:1902.09243v2 [https://t.co/HW5RVw4UkE] UPDATED) #NLProc"}, "1117943625789218816": {"author": "@nskm_m", "followers": "190", "datetime": "2019-04-16 00:11:45", "content_summary": "RT @rtanaka_lab: BERT\u3092\u6587\u751f\u6210\u306b\u4f7f\u3046\u3088\u3046\u306b\u306a\u3063\u305f\u306e\u304b https://t.co/hXGlIudb0n"}, "1100435585427271680": {"author": "@arxiv_cscl", "followers": "3,531", "datetime": "2019-02-26 16:41:03", "content_summary": "Pretraining-Based Natural Language Generation for Text Summarization https://t.co/4NRt6t7WKh"}}, "completed": "1", "queriedAt": "2020-06-03 01:36:44"}