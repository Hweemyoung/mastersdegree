{"twitter": {"1172364346275459072": {"author": "@heghbalz", "datetime": "2019-09-13 04:20:16", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "1,303"}, "1090507041188139008": {"author": "@ComputerPapers", "datetime": "2019-01-30 07:08:33", "content_summary": "An Investigation into Neural Net Optimization via Hessian Eigenvalue Density. https://t.co/KlzNXX0Qxh", "followers": "613"}, "1172368368214503426": {"author": "@NickGeneva", "datetime": "2019-09-13 04:36:15", "content_summary": "A really well thought out thread on batch norm that's worth the read.", "followers": "14"}, "1164323444269260800": {"author": "@ChrSzegedy", "datetime": "2019-08-21 23:48:35", "content_summary": "@dcpage3 Sergey pointed me to this paper, coming lately from his group: https://t.co/YFV9gIzups They came to similar conclusions regarding the Hessian.", "followers": "4,531"}, "1171080794917494784": {"author": "@dcpage3", "datetime": "2019-09-09 15:19:53", "content_summary": "@TheGregYang @kobai19 @yoavgo @srush_nlp @philipmlong This was discovered in the original BN paper; made quantitative in terms of the conditioning of the Hessian in https://t.co/OpwgQOXwzj; and the mechanism is elucidated and related to fixing of layer dis", "followers": "2,420"}, "1223336402412130304": {"author": "@jeremyphoward", "datetime": "2020-01-31 20:05:01", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "100,162"}, "1172062987932327942": {"author": "@aeroengineer91", "datetime": "2019-09-12 08:22:46", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "24"}, "1239070905038323714": {"author": "@ShinobuKinjo1", "datetime": "2020-03-15 06:08:19", "content_summary": "https://t.co/gyolJdGDGd The Hessian contains few outliers which are orders of magnitudes smaller than rest of eigenvalues. The negative eigenvalues at the end of training are orders of magnitude smaller than positive ones. W/O BN, outliers grow much larger", "followers": "18"}, "1164495147532529670": {"author": "@heghbalz", "datetime": "2019-08-22 11:10:53", "content_summary": "RT @ChrSzegedy: @dcpage3 Sergey pointed me to this paper, coming lately from his group: https://t.co/YFV9gIzups They came to similar conclu\u2026", "followers": "1,303"}, "1152168892585979904": {"author": "@DrSamirBhatt", "datetime": "2019-07-19 10:50:44", "content_summary": "I thought this paper was fascinating https://t.co/FmiljBbHDE . Looking at the Eigen density as deep nets are optimised. The effect of batchnorm concentrating the distribution towards zero with few large outliers is the most convincing explanation to date o", "followers": "564"}, "1172352606699585536": {"author": "@WaleAkinfaderin", "datetime": "2019-09-13 03:33:37", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "3,087"}, "1090441871502049282": {"author": "@deep_rl", "datetime": "2019-01-30 02:49:36", "content_summary": "An Investigation into Neural Net Optimization via Hessian Eigenvalue Density - Behrooz Ghorbani https://t.co/xfOEGOocjH", "followers": "858"}, "1170969761670414336": {"author": "@dcpage3", "datetime": "2019-09-09 07:58:41", "content_summary": "@yoavgo @TheGregYang @yoavgo in the practical regime (shallow/skip connects; nonlinear) BN aids training via better condn of the loss Hessn. This is almost a tautology! Here is the experimental res from Stanford/Google https://t.co/OpwgQOXwzj. My work clar", "followers": "2,420"}, "1223353750250614784": {"author": "@iugoaoj", "datetime": "2020-01-31 21:13:57", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "363"}, "1172168213599281154": {"author": "@stalhabukhari", "datetime": "2019-09-12 15:20:54", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "39"}, "1171946715672244224": {"author": "@ayirpelle", "datetime": "2019-09-12 00:40:45", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "2,675"}, "1142225185229156352": {"author": "@vishnu_lsvsr", "datetime": "2019-06-22 00:18:00", "content_summary": "Problem: Compute the eigenvalues of Hessian of the loss function in deep networks. Practically infeasible because of millions of parameters. Solution: Compute the eigenvalue density with Lanczos method which just uses Hessian-Vector products https://t.co/", "followers": "67"}, "1171867643336376320": {"author": "@dcpage3", "datetime": "2019-09-11 19:26:33", "content_summary": "Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ, https://t.co/Wbk3sSbIbr (Papyan) https://t.co/l4QcB85nir. (@_ghorbani et al) https://t.co/VUxknF5QkM compare what happens with", "followers": "2,420"}, "1172027887450492928": {"author": "@JunMa_11", "datetime": "2019-09-12 06:03:18", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "71"}, "1170993547320930305": {"author": "@yoavgo", "datetime": "2019-09-09 09:33:12", "content_summary": "RT @dcpage3: @yoavgo @TheGregYang @yoavgo in the practical regime (shallow/skip connects; nonlinear) BN aids training via better condn of t\u2026", "followers": "13,790"}, "1172249976472256512": {"author": "@dr_levan", "datetime": "2019-09-12 20:45:48", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "169"}, "1171996069577797632": {"author": "@EldarSilver", "datetime": "2019-09-12 03:56:52", "content_summary": "RT @dcpage3: Recent papers have studied the Hessian of the loss for deep nets experimentally: (@leventsagun et al) https://t.co/JNJKeqZyvZ,\u2026", "followers": "1,942"}, "1090448027213545478": {"author": "@arxiv_cs_LG", "datetime": "2019-01-30 03:14:03", "content_summary": "An Investigation into Neural Net Optimization via Hessian Eigenvalue Density. Behrooz Ghorbani, Shankar Krishnan, and Ying Xiao https://t.co/hLn9GCtmPG", "followers": "318"}, "1171008295957487616": {"author": "@ChrSzegedy", "datetime": "2019-09-09 10:31:48", "content_summary": "RT @dcpage3: @yoavgo @TheGregYang @yoavgo in the practical regime (shallow/skip connects; nonlinear) BN aids training via better condn of t\u2026", "followers": "4,531"}, "1090445623990669312": {"author": "@BrundageBot", "datetime": "2019-01-30 03:04:30", "content_summary": "An Investigation into Neural Net Optimization via Hessian Eigenvalue Density. Behrooz Ghorbani, Shankar Krishnan, and Ying Xiao https://t.co/E0XaJCVi8w", "followers": "3,890"}}, "queriedAt": "2020-05-21 20:36:18", "completed": "1", "citation_id": "54680163", "tab": "twitter"}