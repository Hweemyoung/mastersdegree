{"tab": "twitter", "completed": "1", "twitter": {"1105632639548116992": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-03-13 00:52:17", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/HwxIjuIsrq Communication-efficient distributed SGD with Sketching. (arXiv:1903.04488v1 [cs.LG])"}, "1106321726286245888": {"author": "@EnayatUllah", "followers": "69", "datetime": "2019-03-14 22:30:28", "content_summary": "Our new paper is up on arXiv."}, "1105669161244639239": {"author": "@yapp1e", "followers": "48", "datetime": "2019-03-13 03:17:25", "content_summary": "Communication-efficient distributed SGD with Sketching. (arXiv:1903.04488v1 [cs.LG]) https://t.co/lzv0ePSEEp Large-scale distributed training of neural networks is often limited by network bandwidth, wherein the communication time overwhelms the local com"}, "1106724782572257280": {"author": "@Rosenchild", "followers": "11,988", "datetime": "2019-03-16 01:12:04", "content_summary": "RT @arxiv_org: Communication-efficient distributed SGD with Sketching. https://t.co/kEK2J8SKz5 https://t.co/ied8DhsjfI"}, "1105705054491676672": {"author": "@ai_papers", "followers": "1,106", "datetime": "2019-03-13 05:40:02", "content_summary": "Communication-efficient distributed SGD with Sketching. (arXiv:1903.04488v1 [cs.LG]) https://t.co/b1Zpuz8bJ3"}, "1105827683714375683": {"author": "@arxiv_cs_LG", "followers": "322", "datetime": "2019-03-13 13:47:19", "content_summary": "Communication-efficient distributed SGD with Sketching. Nikita Ivkin, Daniel Rothchild, Enayat Ullah, Vladimir Braverman, Ion Stoica, and Raman Arora https://t.co/t0aQfj8k7b"}, "1105745622198562816": {"author": "@gastronomy", "followers": "1,394", "datetime": "2019-03-13 08:21:14", "content_summary": "[arXiv] Communication-efficient distributed SGD with Sketching. (arXiv:1903.04488v1 [cs.LG]) --> Large-scale distributed training of neural networks is often limited by network bandwidth, wherein the communication time overwhelms the local computation"}, "1105632907845165056": {"author": "@StatMLPapers", "followers": "9,764", "datetime": "2019-03-13 00:53:21", "content_summary": "Communication-efficient distributed SGD with Sketching. (arXiv:1903.04488v1 [cs.LG]) https://t.co/sHwrBRSzNC"}, "1105784604244340736": {"author": "@arxiv_org", "followers": "12,794", "datetime": "2019-03-13 10:56:08", "content_summary": "Communication-efficient distributed SGD with Sketching. https://t.co/kEK2J8SKz5 https://t.co/ied8DhsjfI"}, "1169265476611923970": {"author": "@EnayatUllah", "followers": "69", "datetime": "2019-09-04 15:06:28", "content_summary": "Our paper on distributed SGD is accepted at NeurIPS 2019! Link - https://t.co/QmOrVctymJ"}, "1105633006742577153": {"author": "@helioRocha_", "followers": "630", "datetime": "2019-03-13 00:53:45", "content_summary": "\"Communication-efficient distributed SGD with Sketching. (arXiv:1903.04488v1 [cs.LG])\" #arXiv https://t.co/dhKhBXiEFy"}, "1105646899376340992": {"author": "@BrundageBot", "followers": "3,913", "datetime": "2019-03-13 01:48:57", "content_summary": "Communication-efficient distributed SGD with Sketching. Nikita Ivkin, Daniel Rothchild, Enayat Ullah, Vladimir Braverman, Ion Stoica, and Raman Arora https://t.co/7NxOLuEBL4"}, "1109664507100622849": {"author": "@Rosenchild", "followers": "11,988", "datetime": "2019-03-24 03:53:29", "content_summary": "RT @HubBucket: Communication-efficient distributed SGD with Sketching Large-scale distributed training of #NeuralNetworks is often limited\u2026"}, "1108154810673459200": {"author": "@ElectronNest", "followers": "231", "datetime": "2019-03-19 23:54:30", "content_summary": "\"Communication-efficient distributed SGD with Sketching\" https://t.co/E2U3pwiFNo"}, "1106619210539646977": {"author": "@HubBucket", "followers": "5,319", "datetime": "2019-03-15 18:12:34", "content_summary": "RT @HubBucket: Communication-efficient distributed SGD with Sketching Large-scale distributed training of #NeuralNetworks is often limited\u2026"}, "1105835017203150848": {"author": "@subhobrata1", "followers": "310", "datetime": "2019-03-13 14:16:28", "content_summary": "RT @arxiv_org: Communication-efficient distributed SGD with Sketching. https://t.co/kEK2J8SKz5 https://t.co/ied8DhsjfI"}, "1106423894200721408": {"author": "@pmianjy", "followers": "74", "datetime": "2019-03-15 05:16:27", "content_summary": "RT @EnayatUllah: Our new paper is up on arXiv. https://t.co/tbN24e8ZHd"}, "1106098044301393920": {"author": "@HubBucket", "followers": "5,319", "datetime": "2019-03-14 07:41:38", "content_summary": "Communication-efficient distributed SGD with Sketching Large-scale distributed training of #NeuralNetworks is often limited by network bandwidth, wherein the communication time overwhelms the local computation time. \ud83d\udda5\ufe0fhttps://t.co/0IlDCr7sHP #MachineLe"}}, "citation_id": "56928940", "queriedAt": "2020-06-04 00:25:56"}