{"twitter": {"1089035482430955520": {"author": "@arXiv__ml", "datetime": "2019-01-26 05:41:06", "content_summary": "#arXiv #machinelearning [cs.LG] Hypergraph Convolution and Hypergraph Attention. (arXiv:1901.08150v1 [cs.LG]) https://t.co/XQxclLzdox Recently, graph neural networks have attracted great attention and achieved prominent performance in various research fie", "followers": "1,743"}, "1088625326312357889": {"author": "@yapp1e", "datetime": "2019-01-25 02:31:18", "content_summary": "Hypergraph Convolution and Hypergraph Attention. (arXiv:1901.08150v1 [cs.LG]) https://t.co/M92XkNJBPS Recently, graph neural networks have attracted great attention and achieved prominent performance in various research fields. Most of those algorithms ha", "followers": "49"}, "1088642762206048256": {"author": "@arxiv_cscv", "datetime": "2019-01-25 03:40:35", "content_summary": "Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "4,105"}, "1103816249400680449": {"author": "@asam9891", "datetime": "2019-03-08 00:34:36", "content_summary": "Hypergraph Convolution and Hypergraph Attention \u5f93\u6765\u306egraph conv\u306f\u96a3\u63a5\u884c\u5217\u3092\u4f7f\u3046\u305f\u3081pairwise \u306a\u95a2\u4fc2\u3057\u304b\u6271\u3048\u306a\u304b\u3063\u305f\u3002\u3053\u308c\u3092hypergraph\u3092\u5c0e\u5165\u3059\u308b\u3053\u3068\u3067\u3088\u308a\u9ad8\u6b21\u306e\u95a2\u4fc2\u3082\u6271\u3048\u308b\u3088\u3046\u306b\u3059\u308b\u3002\u307e\u305f\u3001hypergraph\u3092\u81ea\u52d5\u7684\u306b\u6c42\u3081\u308bhypergraph attention \u3082\u63d0\u6848\u3002 https://t.co/bvgrQ2l3ry", "followers": "564"}, "1104008250674970624": {"author": "@antiplastics", "datetime": "2019-03-08 13:17:33", "content_summary": "RT @asam9891: Hypergraph Convolution and Hypergraph Attention \u5f93\u6765\u306egraph conv\u306f\u96a3\u63a5\u884c\u5217\u3092\u4f7f\u3046\u305f\u3081pairwise \u306a\u95a2\u4fc2\u3057\u304b\u6271\u3048\u306a\u304b\u3063\u305f\u3002\u3053\u308c\u3092hypergraph\u3092\u5c0e\u5165\u3059\u308b\u3053\u3068\u3067\u3088\u308a\u9ad8\u6b21\u306e\u95a2\u4fc2\u3082\u6271\u3048\u308b\u3088\u2026", "followers": "1,188"}, "1088629640997031937": {"author": "@BrundageBot", "datetime": "2019-01-25 02:48:26", "content_summary": "Hypergraph Convolution and Hypergraph Attention. Song Bai, Feihu Zhang, and Philip H. S. Torr https://t.co/G0D4yUj1jx", "followers": "3,890"}, "1088755440371027969": {"author": "@rdzeniu", "datetime": "2019-01-25 11:08:19", "content_summary": "RT @arxiv_cscv: Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "1,116"}, "1088824030780706816": {"author": "@arxiv_cscv", "datetime": "2019-01-25 15:40:52", "content_summary": "Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "4,105"}, "1088627760707321856": {"author": "@arxiv_cscv", "datetime": "2019-01-25 02:40:58", "content_summary": "Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "4,105"}, "1088625131272978432": {"author": "@deep_rl", "datetime": "2019-01-25 02:30:31", "content_summary": "Hypergraph Convolution and Hypergraph Attention - Song Bai https://t.co/mUxUAlPvvw", "followers": "858"}, "1089020287696470017": {"author": "@arxiv_cscv", "datetime": "2019-01-26 04:40:44", "content_summary": "Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "4,105"}, "1104176446208073728": {"author": "@morioka", "datetime": "2019-03-09 00:25:54", "content_summary": "RT @asam9891: Hypergraph Convolution and Hypergraph Attention \u5f93\u6765\u306egraph conv\u306f\u96a3\u63a5\u884c\u5217\u3092\u4f7f\u3046\u305f\u3081pairwise \u306a\u95a2\u4fc2\u3057\u304b\u6271\u3048\u306a\u304b\u3063\u305f\u3002\u3053\u308c\u3092hypergraph\u3092\u5c0e\u5165\u3059\u308b\u3053\u3068\u3067\u3088\u308a\u9ad8\u6b21\u306e\u95a2\u4fc2\u3082\u6271\u3048\u308b\u3088\u2026", "followers": "828"}, "1088761354440323072": {"author": "@arxivml", "datetime": "2019-01-25 11:31:49", "content_summary": "\"Hypergraph Convolution and Hypergraph Attention\", Song Bai, Feihu Zhang, Philip H\uff0eS\uff0e Torr https://t.co/XSpjKbHlx1", "followers": "779"}, "1088615885487648768": {"author": "@StatMLPapers", "datetime": "2019-01-25 01:53:47", "content_summary": "Hypergraph Convolution and Hypergraph Attention. (arXiv:1901.08150v1 [cs.LG]) https://t.co/diHSNXQwJv", "followers": "9,706"}, "1259645773916049420": {"author": "@cottascience", "datetime": "2020-05-11 00:45:30", "content_summary": "@BahareFatemi @chrsmrrs @IJCAIconf @dvazquezcv @davpoole Sorry, I guess it expired :( There are some other GNNs for Hypergraphs as well: https://t.co/24d34ECLx1 https://t.co/dpIRT3xvrI", "followers": "117"}, "1089000593060974592": {"author": "@mlmemoirs", "datetime": "2019-01-26 03:22:28", "content_summary": "#arXiv #machinelearning [cs.LG] Hypergraph Convolution and Hypergraph Attention. (arXiv:1901.08150v1 [cs.LG]) https://t.co/omZgqZqFTX Recently, graph neural networks have attracted great attention and achieved prominent performance in various research fie", "followers": "1,260"}, "1104375450757931008": {"author": "@RyoHWS", "datetime": "2019-03-09 13:36:40", "content_summary": "RT @asam9891: Hypergraph Convolution and Hypergraph Attention \u5f93\u6765\u306egraph conv\u306f\u96a3\u63a5\u884c\u5217\u3092\u4f7f\u3046\u305f\u3081pairwise \u306a\u95a2\u4fc2\u3057\u304b\u6271\u3048\u306a\u304b\u3063\u305f\u3002\u3053\u308c\u3092hypergraph\u3092\u5c0e\u5165\u3059\u308b\u3053\u3068\u3067\u3088\u308a\u9ad8\u6b21\u306e\u95a2\u4fc2\u3082\u6271\u3048\u308b\u3088\u2026", "followers": "82"}, "1088656430754918400": {"author": "@MLandDL_papers", "datetime": "2019-01-25 04:34:54", "content_summary": "Hypergraph Convolution and Hypergraph Attention. (arXiv:1901.08150v1 [cs.LG]) https://t.co/kwXPfepO49", "followers": "380"}, "1104007253466574848": {"author": "@rkakamilan", "datetime": "2019-03-08 13:13:35", "content_summary": "RT @asam9891: Hypergraph Convolution and Hypergraph Attention \u5f93\u6765\u306egraph conv\u306f\u96a3\u63a5\u884c\u5217\u3092\u4f7f\u3046\u305f\u3081pairwise \u306a\u95a2\u4fc2\u3057\u304b\u6271\u3048\u306a\u304b\u3063\u305f\u3002\u3053\u308c\u3092hypergraph\u3092\u5c0e\u5165\u3059\u308b\u3053\u3068\u3067\u3088\u308a\u9ad8\u6b21\u306e\u95a2\u4fc2\u3082\u6271\u3048\u308b\u3088\u2026", "followers": "637"}, "1088923142586810373": {"author": "@arxiv_in_review", "datetime": "2019-01-25 22:14:43", "content_summary": "#ICML2019 Hypergraph Convolution and Hypergraph Attention. (arXiv:1901.08150v1 [cs\\.LG]) https://t.co/sQeo9eNt6B", "followers": "1,310"}, "1089578988434018304": {"author": "@arxiv_cscv", "datetime": "2019-01-27 17:40:48", "content_summary": "Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "4,105"}, "1089216498588151808": {"author": "@arxiv_cscv", "datetime": "2019-01-26 17:40:24", "content_summary": "Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "4,105"}, "1089397779569496066": {"author": "@arxiv_cscv", "datetime": "2019-01-27 05:40:45", "content_summary": "Hypergraph Convolution and Hypergraph Attention https://t.co/Oij3Gsw7fD", "followers": "4,105"}}, "queriedAt": "2020-05-21 19:56:38", "completed": "1", "citation_id": "54456003", "tab": "twitter"}