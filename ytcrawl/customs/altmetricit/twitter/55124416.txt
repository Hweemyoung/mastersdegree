{"citation_id": "55124416", "tab": "twitter", "twitter": {"1094166758452330496": {"author": "@Rosenchild", "followers": "11,913", "datetime": "2019-02-09 09:30:58", "content_summary": "RT @arxiv_org: Global Explanations of Neural Networks: Mapping the Landscape of Predictions. https://t.co/Wo876Vbk1M https://t.co/VbA3uuM3xC"}, "1093714391407706117": {"author": "@yapp1e", "followers": "45", "datetime": "2019-02-08 03:33:25", "content_summary": "Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG]) https://t.co/hJP6jFPCc1 A barrier to the wider adoption of neural networks is their lack of interpretability. While local explanation methods exist"}, "1094410284909752321": {"author": "@owltrainlab", "followers": "42", "datetime": "2019-02-10 01:38:39", "content_summary": "Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG]) https://t.co/pucO1JaIlL #papers- ai #ml #feedly"}, "1093703028136386560": {"author": "@BrundageBot", "followers": "3,828", "datetime": "2019-02-08 02:48:16", "content_summary": "Global Explanations of Neural Networks: Mapping the Landscape of Predictions. Mark Ibrahim, Melissa Louie, Ceena Modarres, and John Paisley https://t.co/8wSWzq3KoV"}, "1094682312686686208": {"author": "@udmrzn", "followers": "1,350", "datetime": "2019-02-10 19:39:36", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02\u2026"}, "1093792218387599360": {"author": "@arxiv_org", "followers": "12,586", "datetime": "2019-02-08 08:42:41", "content_summary": "Global Explanations of Neural Networks: Mapping the Landscape of Predictions. https://t.co/Wo876Vbk1M https://t.co/VbA3uuM3xC"}, "1093689229224349699": {"author": "@StatMLPapers", "followers": "9,594", "datetime": "2019-02-08 01:53:26", "content_summary": "Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG]) https://t.co/eUyaQpEUjn"}, "1095000419854704645": {"author": "@ryanjgallag", "followers": "2,041", "datetime": "2019-02-11 16:43:38", "content_summary": "\"Global Explanations of Neural Networks: Mapping the Landscape of Predictions\" https://t.co/IAFUktRZrN \"We present an approach for generating global attributions called GAM, which explains the landscape of neural network predictions across subpopulations."}, "1093697317155295232": {"author": "@udmrzn", "followers": "1,350", "datetime": "2019-02-08 02:25:34", "content_summary": "RT @StatMLPapers: Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG]) https://t.co/e\u2026"}, "1093797068290822144": {"author": "@gastronomy", "followers": "1,386", "datetime": "2019-02-08 09:01:57", "content_summary": "[arXiv] Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG]) --> A barrier to the wider adoption of neural networks is their lack of interpretability. While local explanation methods exist for one p"}, "1094428044461330432": {"author": "@arXiv__ml", "followers": "1,613", "datetime": "2019-02-10 02:49:13", "content_summary": "#arXiv #machinelearning [cs.LG] Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG]) https://t.co/mxQTqMcgHk A barrier to the wider adoption of neural networks is their lack of interpretability. While"}, "1094424998046035969": {"author": "@mlmemoirs", "followers": "1,218", "datetime": "2019-02-10 02:37:07", "content_summary": "#arXiv #machinelearning [cs.LG] Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG]) https://t.co/gq1luU7lyt A barrier to the wider adoption of neural networks is their lack of interpretability. While"}, "1093764206938206209": {"author": "@arxivml", "followers": "763", "datetime": "2019-02-08 06:51:22", "content_summary": "\"Global Explanations of Neural Networks: Mapping the Landscape of Predictions\", Mark Ibrahim, Melissa Louie, Ceena \u2026 https://t.co/bLlUpF5Kcg"}, "1094429046837071878": {"author": "@HumansAnalytics", "followers": "3,237", "datetime": "2019-02-10 02:53:12", "content_summary": "RT @mlmemoirs: #arXiv #machinelearning [cs.LG] Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02\u2026"}, "1093689026060734464": {"author": "@helioRocha_", "followers": "619", "datetime": "2019-02-08 01:52:38", "content_summary": "\"Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG])\" #arXiv https://t.co/XK1iZpS9nA"}, "1093689084701298688": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-08 01:52:52", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/K99M8vuGzd Global Explanations of Neural Networks: Mapping the Landscape of Predictions. (arXiv:1902.02384v1 [cs.LG])"}, "1095024099393454080": {"author": "@compstorylab", "followers": "2,435", "datetime": "2019-02-11 18:17:44", "content_summary": "New paper from Story Lab alum Mark Ibrahim \"Global Explanations of Neural Networks: Mapping the Landscape of Predictions\" https://t.co/fFTxWKL0xt"}}, "completed": "1", "queriedAt": "2020-06-03 00:55:12"}