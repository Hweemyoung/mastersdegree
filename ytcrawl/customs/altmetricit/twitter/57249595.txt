{"tab": "twitter", "queriedAt": "2020-05-21 20:31:22", "citation_id": "57249595", "twitter": {"1107937417938567168": {"datetime": "2019-03-19 09:30:39", "followers": "1,570", "author": "@arXiv__ml", "content_summary": "#arXiv #machinelearning [cs.LG] DSPG: Decentralized Simultaneous Perturbations Gradient Descent Scheme. (arXiv:1903.07050v1 [math.OC]) https://t.co/na7rS9B5kN In this paper, we present an asynchronous approximate gradient method that is easy to implement"}, "1108010702378278913": {"datetime": "2019-03-19 14:21:51", "followers": "750", "author": "@arxivml", "content_summary": "\"DSPG: Decentralized Simultaneous Perturbations Gradient Descent Scheme\", Arunselvan Ramaswamy https://t.co/sNiEspaHGx"}, "1107818183661019136": {"datetime": "2019-03-19 01:36:51", "followers": "478", "author": "@mathOCb", "content_summary": "Arunselvan Ramaswamy : DSPG: Decentralized Simultaneous Perturbations Gradient Descent Scheme https://t.co/7kgGCaU96h https://t.co/uUEu2ByT9Z"}, "1107812866520944640": {"datetime": "2019-03-19 01:15:44", "followers": "9,558", "author": "@StatMLPapers", "content_summary": "DSPG: Decentralized Simultaneous Perturbations Gradient Descent Scheme. (arXiv:1903.07050v1 [math.OC]) https://t.co/JWKUuwNKTJ"}, "1107962756634955783": {"datetime": "2019-03-19 11:11:20", "followers": "1,186", "author": "@mlmemoirs", "content_summary": "#arXiv #machinelearning [cs.LG] DSPG: Decentralized Simultaneous Perturbations Gradient Descent Scheme. (arXiv:1903.07050v1 [math.OC]) https://t.co/tCJbdJ42ZA In this paper, we present an asynchronous approximate gradient method that is easy to implement"}}, "completed": "1"}