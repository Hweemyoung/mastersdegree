{"tab": "twitter", "completed": "1", "twitter": {"1095951246576488448": {"author": "@arxivml", "followers": "785", "datetime": "2019-02-14 07:41:53", "content_summary": "\"Towards moderate overparameterization: global convergence guarantees for training shallow neural networks\", Samet \u2026 https://t.co/WHC7pb23Ey"}, "1095864393106157569": {"author": "@StatMLPapers", "followers": "9,746", "datetime": "2019-02-14 01:56:46", "content_summary": "Towards moderate overparameterization: global convergence guarantees for training shallow neural networks. (arXiv:1902.04674v1 [cs.LG]) https://t.co/OErlf9n74a"}}, "citation_id": "55431294", "queriedAt": "2020-06-03 23:17:53"}