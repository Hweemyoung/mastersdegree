{"tab": "twitter", "completed": "1", "twitter": {"1099870588137545728": {"author": "@arxiv_cs_LG", "followers": "318", "datetime": "2019-02-25 03:15:57", "content_summary": "Multi-Armed Bandit Strategies for Non-Stationary Reward Distributions and Delayed Feedback Processes. Larkin Liu, Richard Downe, and Joshua Reid https://t.co/KVr3aU7tJE"}, "1099876977488449538": {"author": "@arxivml", "followers": "780", "datetime": "2019-02-25 03:41:20", "content_summary": "\"Multi-Armed Bandit Strategies for Non-Stationary Reward Distributions and Delayed Feedback Processes\", Larkin Liu,\u2026 https://t.co/uj9m96fhIO"}, "1099907820391034880": {"author": "@StatsPapers", "followers": "5,454", "datetime": "2019-02-25 05:43:54", "content_summary": "Multi-Armed Bandit Strategies for Non-Stationary Reward Distributions and Delayed Feedback Processes. https://t.co/R64Ln4BEQ7"}}, "citation_id": "56004095", "queriedAt": "2020-06-04 00:15:27"}