{"completed": "1", "queriedAt": "2020-06-03 16:09:30", "tab": "twitter", "twitter": {"1092740240232591361": {"followers": "768", "datetime": "2019-02-05 11:02:30", "content_summary": "\"On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning\", Jian Li, Xuanyuan Luo, Mingda Q\u2026 https://t.co/Nus9UHZwWA", "author": "@arxivml"}, "1094504318370234368": {"followers": "735", "datetime": "2019-02-10 07:52:19", "content_summary": "RT @roydanroy: And another (likely COLT) submission, https://t.co/8aJC9l1xDj, proving generalization bounds for \"noisy\" gradient methods li\u2026", "author": "@unsorsodicorda"}, "1092626008811945985": {"followers": "307", "datetime": "2019-02-05 03:28:35", "content_summary": "On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning. Jian Li, Xuanyuan Luo, and Mingda Qiao https://t.co/5Vy3OQ9X3F", "author": "@arxiv_cs_LG"}, "1094227443760664577": {"followers": "14,702", "datetime": "2019-02-09 13:32:07", "content_summary": "And another (likely COLT) submission, https://t.co/8aJC9l1xDj, proving generalization bounds for \"noisy\" gradient methods like SGLD. Some of the statements about Rademacher complexity (a la Zhang et al.) are surprising to read in a COLT paper.", "author": "@roydanroy"}, "1092616062095540226": {"followers": "3,856", "datetime": "2019-02-05 02:49:03", "content_summary": "On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning. Jian Li, Xuanyuan Luo, and Mingda Qiao https://t.co/fRgezEcLJH", "author": "@BrundageBot"}, "1092607333740539906": {"followers": "9,658", "datetime": "2019-02-05 02:14:22", "content_summary": "On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning. (arXiv:1902.00621v1 [cs.LG]) https://t.co/t9EnD7GPhS", "author": "@StatMLPapers"}}, "citation_id": "54960952"}