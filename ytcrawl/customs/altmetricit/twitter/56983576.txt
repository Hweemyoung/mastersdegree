{"citation_id": "56983576", "tab": "twitter", "twitter": {"1106067620208537601": {"author": "@arxiv_cscl", "followers": "3,370", "datetime": "2019-03-14 05:40:45", "content_summary": "Adversarial attacks against Fact Extraction and VERification https://t.co/ath579S5M3"}, "1106201893355880448": {"author": "@j6mes", "followers": "505", "datetime": "2019-03-14 14:34:18", "content_summary": "RT @reckel: Paper from @Cambridge_Uni researchers @j6mes @vlachos_nlp Adversarial attacks against Fact Extraction and VERification #FEVER\u2026"}, "1106179365711368192": {"author": "@vlachos_nlp", "followers": "2,827", "datetime": "2019-03-14 13:04:47", "content_summary": "RT @reckel: Paper from @Cambridge_Uni researchers @j6mes @vlachos_nlp Adversarial attacks against Fact Extraction and VERification #FEVER\u2026"}, "1109150630248103936": {"author": "@Tuhin66978276", "followers": "402", "datetime": "2019-03-22 17:51:31", "content_summary": "RT @reckel: Paper from @Cambridge_Uni researchers @j6mes @vlachos_nlp Adversarial attacks against Fact Extraction and VERification #FEVER\u2026"}, "1106005246252322817": {"author": "@BrundageBot", "followers": "3,811", "datetime": "2019-03-14 01:32:53", "content_summary": "Adversarial attacks against Fact Extraction and VERification. James Thorne and Andreas Vlachos https://t.co/f2x0Nw59RE"}, "1106263814339772418": {"author": "@arxiv_cscl", "followers": "3,370", "datetime": "2019-03-14 18:40:21", "content_summary": "Adversarial attacks against Fact Extraction and VERification https://t.co/ath579S5M3"}, "1105997907004743681": {"author": "@helioRocha_", "followers": "615", "datetime": "2019-03-14 01:03:44", "content_summary": "\"Adversarial attacks against Fact Extraction and VERification. (arXiv:1903.05543v1 [https://t.co/CE87fflQud])\" #arXiv https://t.co/ppF3dpXzIb"}, "1106177236409946112": {"author": "@reckel", "followers": "2,322", "datetime": "2019-03-14 12:56:19", "content_summary": "Paper from @Cambridge_Uni researchers @j6mes @vlachos_nlp Adversarial attacks against Fact Extraction and VERification #FEVER https://t.co/2TIOgGn94R @IamArpitMittal @c_christodoulop"}, "1106441279703900160": {"author": "@Epsilon_Lee", "followers": "84", "datetime": "2019-03-15 06:25:32", "content_summary": "#adversarial in NLP, fact adversarials"}, "1109137893119930368": {"author": "@daniilmagpie", "followers": "899", "datetime": "2019-03-22 17:00:55", "content_summary": "I am sure you were eager to see how our fact checking system from last year #fever shared task fails miserably \ud83d\udc47 #NLProc"}, "1106359303965999104": {"author": "@PhyIis", "followers": "4,813", "datetime": "2019-03-15 00:59:47", "content_summary": "RT @SciFi: Adversarial attacks against Fact Extraction and VERification. https://t.co/0mKWio2oy1"}, "1106007281261576193": {"author": "@arxiv_cscl", "followers": "3,370", "datetime": "2019-03-14 01:40:59", "content_summary": "Adversarial attacks against Fact Extraction and VERification https://t.co/ath579S5M3"}, "1116628474720948224": {"author": "@j6mes", "followers": "505", "datetime": "2019-04-12 09:05:48", "content_summary": "@vlachos_nlp We've made it super simple for people to make adversarial instances that we can test against the state-of-the-art systems. Adversarial generation don't have to be complicated, even tweeking existing instances with regular expressions does the"}, "1107010677636513792": {"author": "@IamArpitMittal", "followers": "147", "datetime": "2019-03-16 20:08:07", "content_summary": "RT @reckel: Paper from @Cambridge_Uni researchers @j6mes @vlachos_nlp Adversarial attacks against Fact Extraction and VERification #FEVER\u2026"}, "1105997754554302465": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-03-14 01:03:07", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/w1fqnRyVqT Adversarial attacks against Fact Extraction and VERification. (arXiv:1903.05543v1 [https://t.co/HHSAgzbrV2])"}, "1105996796256575488": {"author": "@arxiv_cs_cl", "followers": "4,135", "datetime": "2019-03-14 00:59:19", "content_summary": "https://t.co/vkIZPYDgGn Adversarial attacks against Fact Extraction and VERification. (arXiv:1903.05543v1 [https://t.co/HW5RVw4UkE]) #NLProc"}, "1106150812466716672": {"author": "@arxivml", "followers": "754", "datetime": "2019-03-14 11:11:19", "content_summary": "\"Adversarial attacks against Fact Extraction and VERification\", James Thorne, Andreas Vlachos https://t.co/y3ndVMx6FE"}, "1106016234577879040": {"author": "@sigitpurnomo", "followers": "2,663", "datetime": "2019-03-14 02:16:33", "content_summary": "RT @arxiv_cs_cl: https://t.co/vkIZPYDgGn Adversarial attacks against Fact Extraction and VERification. (arXiv:1903.05543v1 [https://t.co/HW\u2026"}}, "completed": "1", "queriedAt": "2020-06-03 02:30:42"}