{"twitter": {"1139652795945115649": {"author": "@ceobillionaire", "datetime": "2019-06-14 21:56:14", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "163,744"}, "1140041182795272192": {"author": "@natashajaques", "datetime": "2019-06-15 23:39:33", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "10,576"}, "1090429037707780098": {"author": "@StatMLPapers", "datetime": "2019-01-30 01:58:36", "content_summary": "Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs.LG]) https://t.co/doOvPr4Pxp", "followers": "9,706"}, "1090474699853750272": {"author": "@MelroLeandro", "datetime": "2019-01-30 05:00:03", "content_summary": "Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs.LG]) https://t.co/c0LNKmBjmZ", "followers": "57"}, "1095501883945480193": {"author": "@helioRocha_", "datetime": "2019-02-13 01:56:17", "content_summary": "\"Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v2 [cs.LG] UPDATED)\" #arXiv https://t.co/IzRQ14OJiZ", "followers": "627"}, "1139720005719744512": {"author": "@avijit9d", "datetime": "2019-06-15 02:23:18", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "179"}, "1090525133394100226": {"author": "@gastronomy", "datetime": "2019-01-30 08:20:27", "content_summary": "[arXiv] Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs.LG]) --> We study continuous action reinforcement learning problems in which it is crucial that the agent interacts with the environment only through {\\em s", "followers": "1,389"}, "1090445728336490496": {"author": "@BrundageBot", "datetime": "2019-01-30 03:04:55", "content_summary": "Lyapunov-based Safe Policy Optimization for Continuous Control. Yinlam Chow, Ofir Nachum, Aleksandra Faust, Mohammad Ghavamzadeh, and Edgar Duenez-Guzman https://t.co/PEVaDKMhqB", "followers": "3,890"}, "1090745966116982784": {"author": "@mmmgaber", "datetime": "2019-01-30 22:57:58", "content_summary": "RT @arxiv_org: Lyapunov-based Safe Policy Optimization for Continuous Control. https://t.co/uixwyz6JvZ https://t.co/vyWBd1wrdM", "followers": "684"}, "1139621546178351106": {"author": "@brandondamos", "datetime": "2019-06-14 19:52:04", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "7,572"}, "1090428496915169285": {"author": "@SoEngineering", "datetime": "2019-01-30 01:56:27", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/NrCDvKPR7o Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs.LG])", "followers": "61"}, "1139612142502440960": {"author": "@ofirnachum", "datetime": "2019-06-14 19:14:42", "content_summary": "Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "1,409"}, "1091897742476173312": {"author": "@arxiv_in_review", "datetime": "2019-02-03 03:14:42", "content_summary": "#ICML2019 Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs\\.LG]) https://t.co/aHb84Gi1KU", "followers": "1,310"}, "1140093686228934656": {"author": "@leonofthewired", "datetime": "2019-06-16 03:08:11", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "77"}, "1139865180618334208": {"author": "@mphogo_dinorego", "datetime": "2019-06-15 12:00:11", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "82"}, "1139635570534039553": {"author": "@jachiam0", "datetime": "2019-06-14 20:47:48", "content_summary": "Congrats to you and your collaborators! It's great to see work on constrained RL getting visibility, we need it for safe and reliable RL! :)", "followers": "2,969"}, "1139766765863354370": {"author": "@yen_chen_lin", "datetime": "2019-06-15 05:29:07", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "294"}, "1095721778591162372": {"author": "@Deep_In_Depth", "datetime": "2019-02-13 16:30:04", "content_summary": "Lyapunov-based Safe Policy Optimization for Continuous Control https://t.co/Z8GxJkLoRd #DeepLearning #MachineLearning #AI #DataScience #NeuralNetworks #CNN #Reinforcement #Learning #DeepRL #GPU #TensorFlow #Keras #Caffe #Pytorch #Python #HPC #Robotics #Aut", "followers": "9,014"}, "1139924546545307648": {"author": "@marcgbellemare", "datetime": "2019-06-15 15:56:05", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "5,831"}, "1140257449003216896": {"author": "@ayirpelle", "datetime": "2019-06-16 13:58:55", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "2,675"}, "1090742646459445249": {"author": "@arxiv_org", "datetime": "2019-01-30 22:44:46", "content_summary": "Lyapunov-based Safe Policy Optimization for Continuous Control. https://t.co/uixwyz6JvZ https://t.co/vyWBd1wrdM", "followers": "12,757"}, "1139914746553982976": {"author": "@jiaodaxiaozi1", "datetime": "2019-06-15 15:17:08", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "152"}, "1090557563320573952": {"author": "@arXiv__ml", "datetime": "2019-01-30 10:29:19", "content_summary": "#arXiv #machinelearning [cs.LG] Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs.LG]) https://t.co/gyZibpHdlH We study continuous action reinforcement learning problems in which it is crucial that the agent interacts", "followers": "1,743"}, "1090573480276512768": {"author": "@mlmemoirs", "datetime": "2019-01-30 11:32:34", "content_summary": "#arXiv #machinelearning [cs.LG] Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs.LG]) https://t.co/vZNd9acBHB We study continuous action reinforcement learning problems in which it is crucial that the agent interacts", "followers": "1,260"}, "1140098194644144133": {"author": "@realhuawei", "datetime": "2019-06-16 03:26:06", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "9"}, "1139807883464331264": {"author": "@sandraorion", "datetime": "2019-06-15 08:12:30", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "362"}, "1095502214561443840": {"author": "@SoEngineering", "datetime": "2019-02-13 01:57:36", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/NrCDvKPR7o Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v2 [cs.LG] UPDATED)", "followers": "61"}, "1090428750192361472": {"author": "@helioRocha_", "datetime": "2019-01-30 01:57:27", "content_summary": "\"Lyapunov-based Safe Policy Optimization for Continuous Control. (arXiv:1901.10031v1 [cs.LG])\" #arXiv https://t.co/IzRQ14OJiZ", "followers": "627"}, "1140155461771153408": {"author": "@MehdiBenKhadija", "datetime": "2019-06-16 07:13:39", "content_summary": "RT @ofirnachum: Our submission won best paper at the RL4RL workshop at ICML! https://t.co/NoesEIKFrI https://t.co/o8N1Jpaj5p", "followers": "282"}}, "queriedAt": "2020-05-21 20:33:15", "completed": "1", "citation_id": "54678750", "tab": "twitter"}