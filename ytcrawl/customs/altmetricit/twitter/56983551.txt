{"tab": "twitter", "completed": "1", "twitter": {"1106017649069297666": {"author": "@yapp1e", "followers": "42", "datetime": "2019-03-14 02:22:11", "content_summary": "A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction. (arXiv:1903.05133v1 [cs.LG]) https://t.co/Gs209pbgBQ Reducing communication overhead is a big challenge for large-scale distributed training. To address this issue, we present a hierar"}, "1108154345982287872": {"author": "@ElectronNest", "followers": "211", "datetime": "2019-03-19 23:52:39", "content_summary": "\"A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction\" https://t.co/i3gVbXbY1v"}, "1106077831698808832": {"author": "@arxivml", "followers": "742", "datetime": "2019-03-14 06:21:19", "content_summary": "\"A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction\", Fan Zhou, Guojing Cong https://t.co/7KkQzN16e9"}, "1105996566710706183": {"author": "@StatMLPapers", "followers": "9,517", "datetime": "2019-03-14 00:58:24", "content_summary": "A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction. (arXiv:1903.05133v1 [cs.LG]) https://t.co/40nNgUTBgL"}, "1105999375111618562": {"author": "@StatsPapers", "followers": "5,426", "datetime": "2019-03-14 01:09:34", "content_summary": "A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction. https://t.co/bpJRhtSICH"}, "1106003800534515712": {"author": "@deep_rl", "followers": "832", "datetime": "2019-03-14 01:27:09", "content_summary": "A Distributed Hierarchical SGD Algorithm with Sparse Global Reduction - Fan Zhou https://t.co/9kH5MBJZLW"}}, "citation_id": "56983551", "queriedAt": "2020-06-04 00:34:30"}