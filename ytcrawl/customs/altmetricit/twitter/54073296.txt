{"twitter": {"1097961935507783680": {"author": "@eeevgen", "datetime": "2019-02-19 20:51:39", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "84"}, "1147509003909566464": {"author": "@nichalin0", "datetime": "2019-07-06 14:14:00", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "4"}, "1086589706509434880": {"author": "@talkdatatomee", "datetime": "2019-01-19 11:42:28", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "369"}, "1086511525462978560": {"author": "@indy9000", "datetime": "2019-01-19 06:31:48", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "354"}, "1087157835530526720": {"author": "@and_papers", "datetime": "2019-01-21 01:20:01", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "18"}, "1124966135114424320": {"author": "@indy9000", "datetime": "2019-05-05 09:16:42", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "354"}, "1086458364945588226": {"author": "@NickFlows", "datetime": "2019-01-19 03:00:34", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "131"}, "1086347208998481920": {"author": "@AdaptToReality", "datetime": "2019-01-18 19:38:52", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2,285"}, "1128155940409069568": {"author": "@surangasms01", "datetime": "2019-05-14 04:31:50", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "186"}, "1086356286466412545": {"author": "@stephenrra", "datetime": "2019-01-18 20:14:56", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "676"}, "1087281217328893953": {"author": "@Deep_In_Depth", "datetime": "2019-01-21 09:30:17", "content_summary": "Attentive Neural Processes https://t.co/gP7HEEht3V #DeepLearning #MachineLearning #AI #DataScience #NeuralNetworks #CNN #Reinforcement #Learning #DeepRL #GPU #TensorFlow #Keras #Caffe #Pytorch #Python #HPC #Robotics #AutonomousCar #Quant", "followers": "8,977"}, "1086405857431044096": {"author": "@oliviastartrip", "datetime": "2019-01-18 23:31:55", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "12"}, "1086339354992279554": {"author": "@DeepComms", "datetime": "2019-01-18 19:07:40", "content_summary": "Attentive Neural Processes: https://t.co/ZVIcwhCvMo", "followers": "11"}, "1086391276835090432": {"author": "@twiecki", "datetime": "2019-01-18 22:33:59", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "14,938"}, "1125072608154783744": {"author": "@arkitus", "datetime": "2019-05-05 16:19:47", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "4,889"}, "1086687252598538240": {"author": "@sidbrahma", "datetime": "2019-01-19 18:10:05", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "179"}, "1125040251226005505": {"author": "@IntelligenceTV", "datetime": "2019-05-05 14:11:12", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "56,127"}, "1086598511053946880": {"author": "@MarklDouthwaite", "datetime": "2019-01-19 12:17:27", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "837"}, "1086329054096052224": {"author": "@Synced_Global", "datetime": "2019-01-18 18:26:44", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2,949"}, "1086601350870454273": {"author": "@SorishaPragyan", "datetime": "2019-01-19 12:28:44", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "3,924"}, "1086524506649358336": {"author": "@AlexGuoHan", "datetime": "2019-01-19 07:23:23", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "392"}, "1086321548930228227": {"author": "@Akanksha_Ahuja9", "datetime": "2019-01-18 17:56:54", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "700"}, "1086719900763049985": {"author": "@tudor_jacob", "datetime": "2019-01-19 20:19:49", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "21"}, "1126626398813270016": {"author": "@desertnaut", "datetime": "2019-05-09 23:13:59", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "1,025"}, "1086118835650998272": {"author": "@arxivml", "datetime": "2019-01-18 04:31:24", "content_summary": "\"Attentive Neural Processes\", Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum,\u2026 https://t.co/R6z18XVpCJ", "followers": "774"}, "1088039635735871489": {"author": "@ekusoyt", "datetime": "2019-01-23 11:43:58", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "1,213"}, "1086393146253168640": {"author": "@rkarrimov", "datetime": "2019-01-18 22:41:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "16"}, "1086304870011940864": {"author": "@heghbalz", "datetime": "2019-01-18 16:50:38", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "1,303"}, "1086555024988106752": {"author": "@tak_yamm", "datetime": "2019-01-19 09:24:39", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,295"}, "1086412747980496896": {"author": "@khmlpy", "datetime": "2019-01-18 23:59:18", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "199"}, "1125031972248674306": {"author": "@yeewhye", "datetime": "2019-05-05 13:38:18", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "13,524"}, "1086277689571340289": {"author": "@ceobillionaire", "datetime": "2019-01-18 15:02:37", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "163,809"}, "1086634842916294656": {"author": "@Korex_F", "datetime": "2019-01-19 14:41:49", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "548"}, "1086277417256214528": {"author": "@emidup", "datetime": "2019-01-18 15:01:32", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "673"}, "1087852453922402304": {"author": "@carpedm20", "datetime": "2019-01-22 23:20:10", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "2,515"}, "1086320569962975237": {"author": "@alanwil337", "datetime": "2019-01-18 17:53:01", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "690"}, "1086534706265509888": {"author": "@JayChance5", "datetime": "2019-01-19 08:03:55", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "559"}, "1086362197586980864": {"author": "@isaiahtaguibao", "datetime": "2019-01-18 20:38:26", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "113"}, "1125138609374486528": {"author": "@jvmancuso", "datetime": "2019-05-05 20:42:03", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "648"}, "1087474246777856000": {"author": "@ysaito8015", "datetime": "2019-01-21 22:17:19", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,048"}, "1086715511021424642": {"author": "@NGRColosimo", "datetime": "2019-01-19 20:02:22", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "563"}, "1092805512582840328": {"author": "@hayashiyus", "datetime": "2019-02-05 15:21:52", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "4,200"}, "1086582932649709568": {"author": "@goloskokovic", "datetime": "2019-01-19 11:15:33", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "128"}, "1125014652084076545": {"author": "@KouroshMeshgi", "datetime": "2019-05-05 12:29:29", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "618"}, "1086727196230774785": {"author": "@HaoTan5", "datetime": "2019-01-19 20:48:48", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "198"}, "1086325347728195586": {"author": "@Mehdi_A_Bennani", "datetime": "2019-01-18 18:12:00", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "187"}, "1086400706855272450": {"author": "@Albert_Hanser", "datetime": "2019-01-18 23:11:27", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "379"}, "1086580806901002241": {"author": "@danrsm", "datetime": "2019-01-19 11:07:06", "content_summary": "Nice results using Neural Processes with attention!", "followers": "153"}, "1086923320325558273": {"author": "@airesearchcom", "datetime": "2019-01-20 09:48:08", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "6,955"}, "1086419306714406912": {"author": "@ManbinderSingh", "datetime": "2019-01-19 00:25:22", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "721"}, "1087099116138708992": {"author": "@FumingGuo", "datetime": "2019-01-20 21:26:41", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "6"}, "1086478868523991040": {"author": "@cosmicBboy", "datetime": "2019-01-19 04:22:02", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "156"}, "1086391148204171264": {"author": "@diegovogeid", "datetime": "2019-01-18 22:33:28", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "69"}, "1128155441475784709": {"author": "@brandondamos", "datetime": "2019-05-14 04:29:52", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "7,556"}, "1086331792829730817": {"author": "@StevieOlowe", "datetime": "2019-01-18 18:37:37", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "51"}, "1086546994359746560": {"author": "@himanshumisra", "datetime": "2019-01-19 08:52:45", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "91"}, "1088700172627050496": {"author": "@shyamal_chandra", "datetime": "2019-01-25 07:28:42", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "381"}, "1086557669429788672": {"author": "@puneethmishra", "datetime": "2019-01-19 09:35:10", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "556"}, "1087339591546400768": {"author": "@EldarSilver", "datetime": "2019-01-21 13:22:15", "content_summary": "RT @schwarzjn_: Our new paper shows how to fix some of the underfitting issues we observed with Neural Processes. +cool new image inpaintin\u2026", "followers": "1,942"}, "1086486916436942848": {"author": "@Manju1505", "datetime": "2019-01-19 04:54:01", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "12"}, "1086499424556208128": {"author": "@StephenCoxZA", "datetime": "2019-01-19 05:43:43", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "44"}, "1086327658332340226": {"author": "@charlinelelan", "datetime": "2019-01-18 18:21:11", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "143"}, "1086463027724079104": {"author": "@TerencePlizga", "datetime": "2019-01-19 03:19:05", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "255"}, "1086467227308699649": {"author": "@johnnyprothero", "datetime": "2019-01-19 03:35:47", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "184"}, "1086526362305716225": {"author": "@Planning203", "datetime": "2019-01-19 07:30:46", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "166"}, "1086403996624084992": {"author": "@adamajm", "datetime": "2019-01-18 23:24:31", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "145"}, "1126112772226314240": {"author": "@PerthMLGroup", "datetime": "2019-05-08 13:13:01", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "456"}, "1099006612725891072": {"author": "@cghosh_", "datetime": "2019-02-22 18:02:49", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "276"}, "1125122582196432896": {"author": "@JackIVaughan", "datetime": "2019-05-05 19:38:22", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "371"}, "1086536840968957952": {"author": "@ImrulJubair", "datetime": "2019-01-19 08:12:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "10"}, "1086325419425570819": {"author": "@twigwam", "datetime": "2019-01-18 18:12:17", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,656"}, "1086538047091466241": {"author": "@SharanVishnu7", "datetime": "2019-01-19 08:17:11", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "56"}, "1086331803672076288": {"author": "@500zainraza", "datetime": "2019-01-18 18:37:39", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "299"}, "1086681878654943233": {"author": "@kakrafoon2", "datetime": "2019-01-19 17:48:44", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "17"}, "1125021708841357313": {"author": "@ErmiaBivatan", "datetime": "2019-05-05 12:57:31", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "817"}, "1086320211706417152": {"author": "@agispof", "datetime": "2019-01-18 17:51:35", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "107"}, "1086825524121554945": {"author": "@tianshi5940", "datetime": "2019-01-20 03:19:31", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "35"}, "1086608006316507138": {"author": "@luckflow", "datetime": "2019-01-19 12:55:11", "content_summary": "RT DeepMindAI: Attentive Neural Processes: https://t.co/iMvwx7mBgI", "followers": "196"}, "1086321237310300161": {"author": "@luckflow", "datetime": "2019-01-18 17:55:40", "content_summary": "Attentive Neural Processes: https://t.co/iMvwx7mBgI", "followers": "196"}, "1097899034478407681": {"author": "@__tmats__", "datetime": "2019-02-19 16:41:42", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "795"}, "1086778439279927297": {"author": "@chen_guozhang", "datetime": "2019-01-20 00:12:25", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "33"}, "1086357898224119808": {"author": "@TimesandTech", "datetime": "2019-01-18 20:21:21", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "3,107"}, "1086334767195402240": {"author": "@estes_rickey", "datetime": "2019-01-18 18:49:26", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "803"}, "1086275894572834819": {"author": "@jinxu06", "datetime": "2019-01-18 14:55:29", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "89"}, "1086435466780372994": {"author": "@MOTOGRILL", "datetime": "2019-01-19 01:29:34", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "79"}, "1131828837787013121": {"author": "@Rosenchild", "datetime": "2019-05-24 07:46:37", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "11,933"}, "1086319677557653509": {"author": "@georg_gauss", "datetime": "2019-01-18 17:49:28", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2,331"}, "1125048925218574341": {"author": "@MyPassion_M9T", "datetime": "2019-05-05 14:45:40", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "15"}, "1086526566568472576": {"author": "@MannyDePresso", "datetime": "2019-01-19 07:31:34", "content_summary": "Attentive Neural Processes. (arXiv:1901.05761v1 [cs.LG]) https://t.co/1L50CIjuGe", "followers": "273"}, "1098406734752669696": {"author": "@daewonyoon", "datetime": "2019-02-21 02:19:07", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "129"}, "1086319819647930368": {"author": "@russell_lliu", "datetime": "2019-01-18 17:50:02", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "65"}, "1086328173451653120": {"author": "@ZachBessinger", "datetime": "2019-01-18 18:23:14", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "164"}, "1125142239892725761": {"author": "@pavelkordik", "datetime": "2019-05-05 20:56:28", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "934"}, "1086557203161440256": {"author": "@AssistedEvolve", "datetime": "2019-01-19 09:33:19", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "218"}, "1086634704973905920": {"author": "@thruthebckdr", "datetime": "2019-01-19 14:41:17", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "516"}, "1124959450064932864": {"author": "@heghbalz", "datetime": "2019-05-05 08:50:08", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "1,303"}, "1086508710288125952": {"author": "@BesanHalwa", "datetime": "2019-01-19 06:20:37", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "13"}, "1086518190463692800": {"author": "@BodyachavlQuest", "datetime": "2019-01-19 06:58:17", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1"}, "1086575364879441920": {"author": "@jadhavamitb", "datetime": "2019-01-19 10:45:29", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "361"}, "1125124370681098240": {"author": "@adamajm", "datetime": "2019-05-05 19:45:28", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "145"}, "1086344634492698624": {"author": "@meltemataynsnt", "datetime": "2019-01-18 19:28:38", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,882"}, "1099555847506665472": {"author": "@alfo_512", "datetime": "2019-02-24 06:25:17", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "104"}, "1086663243714592768": {"author": "@fengsterooni", "datetime": "2019-01-19 16:34:41", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "113"}, "1086345612977553408": {"author": "@jinbeizame007", "datetime": "2019-01-18 19:32:32", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2,456"}, "1086649808545333250": {"author": "@data_hpz", "datetime": "2019-01-19 15:41:17", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "11,002"}, "1086554730648629248": {"author": "@morioka", "datetime": "2019-01-19 09:23:29", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "826"}, "1086374790401789952": {"author": "@MTogxi", "datetime": "2019-01-18 21:28:28", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2,451"}, "1098114247567921152": {"author": "@kolu_nsquare", "datetime": "2019-02-20 06:56:53", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "250"}, "1086524408926105600": {"author": "@hereticreader", "datetime": "2019-01-19 07:23:00", "content_summary": "Attentive Neural Processes - https://t.co/9D1COPFWPY https://t.co/rYYaJCDmvD", "followers": "195"}, "1086336503243042818": {"author": "@GabrieLcR7ATL", "datetime": "2019-01-18 18:56:20", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2"}, "1086230333132099589": {"author": "@hyunjik11", "datetime": "2019-01-18 11:54:27", "content_summary": "\u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, the same model (with same weights) can do both stochastic bottom-half prediction and super-resolution. To appear @iclr2019. https://t.", "followers": "441"}, "1088016420858982401": {"author": "@alsombra7", "datetime": "2019-01-23 10:11:43", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "111"}, "1089544076788228096": {"author": "@JCHarper13", "datetime": "2019-01-27 15:22:05", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "997"}, "1086397926820192256": {"author": "@ceobillionaire", "datetime": "2019-01-18 23:00:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "163,809"}, "1086817847852945408": {"author": "@_pradeep_reddy", "datetime": "2019-01-20 02:49:01", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "11"}, "1181139954103009281": {"author": "@ekusoyt", "datetime": "2019-10-07 09:31:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,213"}, "1086472987467902977": {"author": "@hoangcuong0605", "datetime": "2019-01-19 03:58:40", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "52"}, "1086424319083724800": {"author": "@keylinker", "datetime": "2019-01-19 00:45:17", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "155"}, "1086393302042198019": {"author": "@Bear_Bees", "datetime": "2019-01-18 22:42:02", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "7"}, "1086471039985451008": {"author": "@derekchen14", "datetime": "2019-01-19 03:50:56", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "249"}, "1125115454316367872": {"author": "@vsinghalus", "datetime": "2019-05-05 19:10:02", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "332"}, "1086426348027953152": {"author": "@ekusoyt", "datetime": "2019-01-19 00:53:20", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,213"}, "1086408887320768512": {"author": "@moe_moe_moegi", "datetime": "2019-01-18 23:43:57", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "731"}, "1086313799576100864": {"author": "@arkosiorek", "datetime": "2019-01-18 17:26:07", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "4,069"}, "1086460351397285888": {"author": "@arun_kejariwal", "datetime": "2019-01-19 03:08:27", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "574"}, "1086265448210022400": {"author": "@kasparmartens", "datetime": "2019-01-18 14:13:59", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "860"}, "1125048023090900992": {"author": "@Montreal_IA", "datetime": "2019-05-05 14:42:05", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "159,742"}, "1126110701330653184": {"author": "@shubh_300595", "datetime": "2019-05-08 13:04:47", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "66"}, "1086740336515473409": {"author": "@luisfredgs", "datetime": "2019-01-19 21:41:01", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "74"}, "1086627681200943104": {"author": "@mrtnoshad", "datetime": "2019-01-19 14:13:22", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "76"}, "1086321960982859779": {"author": "@collectedview", "datetime": "2019-01-18 17:58:33", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "218"}, "1086415472705191936": {"author": "@pumpikano", "datetime": "2019-01-19 00:10:07", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "102"}, "1086281602940981248": {"author": "@Montreal_AI", "datetime": "2019-01-18 15:18:10", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "177,405"}, "1086321652667899904": {"author": "@makoFALAR1229", "datetime": "2019-01-18 17:57:19", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,091"}, "1086269786189905922": {"author": "@l3robot", "datetime": "2019-01-18 14:31:13", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "57"}, "1086560273056571392": {"author": "@JeanMarcJAzzi", "datetime": "2019-01-19 09:45:31", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "365"}, "1086169042849677312": {"author": "@ekusoyt", "datetime": "2019-01-18 07:50:54", "content_summary": "RT @arxivml: \"Attentive Neural Processes\", Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum,\u2026 https://t\u2026", "followers": "1,213"}, "1086342554407264257": {"author": "@spencerplee", "datetime": "2019-01-18 19:20:22", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "189"}, "1087867089858158592": {"author": "@treasured_write", "datetime": "2019-01-23 00:18:20", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "99"}, "1098050520302972928": {"author": "@ionekr", "datetime": "2019-02-20 02:43:39", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "1,019"}, "1086926113241251840": {"author": "@rolibran", "datetime": "2019-01-20 09:59:14", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "53"}, "1086319417590464513": {"author": "@DeepLearningYou", "datetime": "2019-01-18 17:48:26", "content_summary": "DeepMindAI: Attentive Neural Processes: https://t.co/mLaWEg5tFM", "followers": "67"}, "1086328344415629313": {"author": "@MatRazor", "datetime": "2019-01-18 18:23:54", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "35"}, "1086441371433648129": {"author": "@mbenhamdtw", "datetime": "2019-01-19 01:53:02", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "9"}, "1086319855521931264": {"author": "@mlmemoirs", "datetime": "2019-01-18 17:50:11", "content_summary": "#arXiv #machinelearning [cs.LG] Attentive Neural Processes. (arXiv:1901.05761v1 [cs.LG]) https://t.co/wQjXjwxSHe Neural Processes (NPs) (Garnelo et al 2018a;b) approach regression by learning to map a context set of observed input-output pairs to a distri", "followers": "1,260"}, "1087361469681872896": {"author": "@ShaliniAnanda1", "datetime": "2019-01-21 14:49:11", "content_summary": "RT @schwarzjn_: Our new paper shows how to fix some of the underfitting issues we observed with Neural Processes. +cool new image inpaintin\u2026", "followers": "541"}, "1086446159554584576": {"author": "@aglooka", "datetime": "2019-01-19 02:12:04", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "323"}, "1097952803849469952": {"author": "@mfigurnov", "datetime": "2019-02-19 20:15:22", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "2,677"}, "1086551939049877504": {"author": "@kacky24", "datetime": "2019-01-19 09:12:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "21"}, "1098886723000360965": {"author": "@kabunoyoichi", "datetime": "2019-02-22 10:06:25", "content_summary": "RT @learn_learning3: ICLR2019\u306e\u63a1\u629e\u8ad6\u6587\"Attentive Neural Processes\"(https://t.co/mKsGwqMY8A)\uff0cDeepMind\u306e\u8457\u8005\u306b\u3088\u308bJupyter Notebook\u30d9\u30fc\u30b9\u5b9f\u88c5\u304c\u516c\u958b\u3055\u308c\u3066\u305f https://\u2026", "followers": "56"}, "1086777993140322304": {"author": "@wilderrodrigues", "datetime": "2019-01-20 00:10:39", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "448"}, "1087890206156500992": {"author": "@idgmatrix", "datetime": "2019-01-23 01:50:11", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "4,473"}, "1086411091742281728": {"author": "@alexdaviscmu", "datetime": "2019-01-18 23:52:43", "content_summary": "@kristencallen", "followers": "708"}, "1086589743901671424": {"author": "@deeplearningldn", "datetime": "2019-01-19 11:42:37", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "18,735"}, "1125033949137448960": {"author": "@At7788546", "datetime": "2019-05-05 13:46:10", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "32"}, "1086927651636432896": {"author": "@unelmaplatforms", "datetime": "2019-01-20 10:05:20", "content_summary": "Attentive Neural Processes: https://t.co/fz8iUU2qWA", "followers": "145"}, "1087452545579008000": {"author": "@DrGenM1", "datetime": "2019-01-21 20:51:05", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "0"}, "1125378844515430400": {"author": "@nulllnil", "datetime": "2019-05-06 12:36:39", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "129"}, "1086323685730934784": {"author": "@iamknighton", "datetime": "2019-01-18 18:05:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "425"}, "1086366385830354944": {"author": "@ralexander6", "datetime": "2019-01-18 20:55:04", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "173"}, "1086918400272527361": {"author": "@__MLT__", "datetime": "2019-01-20 09:28:35", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "5,618"}, "1126473128228429824": {"author": "@MiranShahine", "datetime": "2019-05-09 13:04:57", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "17"}, "1086354361872252930": {"author": "@AntoMon", "datetime": "2019-01-18 20:07:18", "content_summary": "Attentive Neural Processes Neural Processes approach regression by learning to map a context set of observed input-output pairs to a distribution over regression functions #ArtificialIntelligence #Technology https://t.co/8Tucqf0dNS", "followers": "627"}, "1086372426278039552": {"author": "@0xhexhex", "datetime": "2019-01-18 21:19:04", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "93"}, "1086513701648257024": {"author": "@heghbalz", "datetime": "2019-01-19 06:40:27", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,303"}, "1125035848565698562": {"author": "@adn_twitts", "datetime": "2019-05-05 13:53:43", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "73"}, "1086817717733093376": {"author": "@gabeibagon", "datetime": "2019-01-20 02:48:30", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "72"}, "1086326134915108864": {"author": "@PeterOwanAgida", "datetime": "2019-01-18 18:15:08", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "39"}, "1086262616320888833": {"author": "@indy9000", "datetime": "2019-01-18 14:02:44", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "354"}, "1124943947422367744": {"author": "@schwarzjn_", "datetime": "2019-05-05 07:48:32", "content_summary": "Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr) at the #iclr2019 main conference and on meta-learning for sequential decision making (https://t.co/uPQeVPZCow) at the SPiRL workshop.", "followers": "2,035"}, "1086244931415560192": {"author": "@yeewhye", "datetime": "2019-01-18 12:52:27", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "13,524"}, "1125359718908567552": {"author": "@AssistedEvolve", "datetime": "2019-05-06 11:20:39", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "218"}, "1086576231112355846": {"author": "@tchaye59", "datetime": "2019-01-19 10:48:55", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "8"}, "1097892810525687808": {"author": "@hyunjik11", "datetime": "2019-02-19 16:16:58", "content_summary": "An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (https://t.co/0HiNz3KEss). Try running the code on your browser (or phone) at: https://t.co/GsbcmPCgvd https://t.co/lr2ZQaBFwV", "followers": "441"}, "1086266432504049665": {"author": "@the_onederful", "datetime": "2019-01-18 14:17:54", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "141"}, "1097916126544179202": {"author": "@emidup", "datetime": "2019-02-19 17:49:37", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "673"}, "1086404533486477312": {"author": "@jnhwkim", "datetime": "2019-01-18 23:26:39", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "962"}, "1086927098621673472": {"author": "@SileyeBaba", "datetime": "2019-01-20 10:03:09", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "418"}, "1087886688091697152": {"author": "@minxdragon", "datetime": "2019-01-23 01:36:13", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "3,030"}, "1086576869498126338": {"author": "@Weenkus", "datetime": "2019-01-19 10:51:27", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "207"}, "1125683636961890305": {"author": "@MarkTan57229491", "datetime": "2019-05-07 08:47:47", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "246"}, "1086366353248870400": {"author": "@deeplearning4j", "datetime": "2019-01-18 20:54:56", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "25,311"}, "1125147175531323392": {"author": "@ceobillionaire", "datetime": "2019-05-05 21:16:05", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "163,809"}, "1125094960812793856": {"author": "@Assaultarmor", "datetime": "2019-05-05 17:48:36", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "91"}, "1158338861526896640": {"author": "@ceobillionaire", "datetime": "2019-08-05 11:28:00", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "163,809"}, "1086362648122281984": {"author": "@aavella77", "datetime": "2019-01-18 20:40:13", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "196"}, "1086324696835067905": {"author": "@arXiv__ml", "datetime": "2019-01-18 18:09:25", "content_summary": "#arXiv #machinelearning [cs.LG] Attentive Neural Processes. (arXiv:1901.05761v1 [cs.LG]) https://t.co/uCkU2ijSmv Neural Processes (NPs) (Garnelo et al 2018a;b) approach regression by learning to map a context set of observed input-output pairs to a distri", "followers": "1,723"}, "1086114629317648385": {"author": "@muktabh", "datetime": "2019-01-18 04:14:41", "content_summary": "RT @arxiv_cs_LG: Attentive Neural Processes. Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum, Oriol Vi\u2026", "followers": "779"}, "1158539921268891649": {"author": "@Montreal_AI", "datetime": "2019-08-06 00:46:56", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "177,405"}, "1086597086798213120": {"author": "@vishwa_jha", "datetime": "2019-01-19 12:11:48", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "267"}, "1086319350989111296": {"author": "@DeepMindAI", "datetime": "2019-01-18 17:48:10", "content_summary": "Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "295,998"}, "1086291541617004545": {"author": "@whyboris", "datetime": "2019-01-18 15:57:40", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "765"}, "1086319967157579776": {"author": "@alfo_512", "datetime": "2019-01-18 17:50:37", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "104"}, "1087148681516568576": {"author": "@jie_song", "datetime": "2019-01-21 00:43:38", "content_summary": "RT @danrsm: Nice results using Neural Processes with attention! https://t.co/Oi63fWK9gq", "followers": "14"}, "1097932952267313152": {"author": "@CasperKaae", "datetime": "2019-02-19 18:56:29", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "273"}, "1086323630571704322": {"author": "@stephenrra", "datetime": "2019-01-18 18:05:11", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "676"}, "1086368524434636803": {"author": "@mertyuksekgonul", "datetime": "2019-01-18 21:03:34", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "396"}, "1086092874087829509": {"author": "@BrundageBot", "datetime": "2019-01-18 02:48:14", "content_summary": "Attentive Neural Processes. Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum, Oriol Vinyals, and Yee Whye Teh https://t.co/mDnwuuMf5y", "followers": "3,887"}, "1086322731413630976": {"author": "@huazi08", "datetime": "2019-01-18 18:01:36", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "95"}, "1086798455786299392": {"author": "@Illmatist", "datetime": "2019-01-20 01:31:58", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "31"}, "1110777502673317888": {"author": "@gmorison", "datetime": "2019-03-27 05:36:08", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "278"}, "1086639754085629952": {"author": "@alirg1", "datetime": "2019-01-19 15:01:20", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "152"}, "1097966072647557121": {"author": "@permutans", "datetime": "2019-02-19 21:08:05", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "1,105"}, "1086319464608608257": {"author": "@TechAggreg", "datetime": "2019-01-18 17:48:37", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "295"}, "1158387151622553600": {"author": "@Quebec_AI", "datetime": "2019-08-05 14:39:53", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "160,790"}, "1088515794135384066": {"author": "@Zommiommy", "datetime": "2019-01-24 19:16:03", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "57"}, "1093551917949628416": {"author": "@sappy_and_sappy", "datetime": "2019-02-07 16:47:49", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "175"}, "1086387171609755649": {"author": "@KavehHassani", "datetime": "2019-01-18 22:17:40", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "161"}, "1086445096596234240": {"author": "@koburouze845", "datetime": "2019-01-19 02:07:50", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,136"}, "1086514644242522112": {"author": "@Miles_Brundage", "datetime": "2019-01-19 06:44:12", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "25,741"}, "1086597132101083136": {"author": "@biarne_a", "datetime": "2019-01-19 12:11:58", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "39"}, "1086616819820085250": {"author": "@Honipsdigitals", "datetime": "2019-01-19 13:30:12", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,504"}, "1086398429499219971": {"author": "@Montreal_AI", "datetime": "2019-01-18 23:02:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "177,405"}, "1087104283802103808": {"author": "@AIOptify", "datetime": "2019-01-20 21:47:13", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "72"}, "1086342593066221568": {"author": "@ThingsReallyR", "datetime": "2019-01-18 19:20:32", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "48"}, "1086327376294797313": {"author": "@TheCuriousLuke", "datetime": "2019-01-18 18:20:04", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Attentive Neural Processes. (arXiv:1901.05761v1 [cs.LG]) https://t.co/uCkU2ijSmv Neural Pro\u2026", "followers": "4,626"}, "1086563128169586688": {"author": "@PerthMLGroup", "datetime": "2019-01-19 09:56:51", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "456"}, "1086307383872233476": {"author": "@dimadamen", "datetime": "2019-01-18 17:00:37", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "1,161"}, "1086272921507643392": {"author": "@IntuitMachine", "datetime": "2019-01-18 14:43:41", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "4,815"}, "1086083492838924294": {"author": "@mxwlj", "datetime": "2019-01-18 02:10:57", "content_summary": "RT @StatMLPapers: Attentive Neural Processes. (arXiv:1901.05761v1 [cs.LG]) https://t.co/N6Dm61vHHg", "followers": "1,223"}, "1086647130419163136": {"author": "@howardmeng", "datetime": "2019-01-19 15:30:39", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "44"}, "1086357810525302784": {"author": "@KrishaMehta2", "datetime": "2019-01-18 20:21:00", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "131"}, "1086561837779484673": {"author": "@desertnaut", "datetime": "2019-01-19 09:51:44", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1,025"}, "1125264872361451520": {"author": "@panchovie", "datetime": "2019-05-06 05:03:46", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "66"}, "1087879939364249602": {"author": "@plsang", "datetime": "2019-01-23 01:09:24", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "165"}, "1098920209015033856": {"author": "@Nonparametrics", "datetime": "2019-02-22 12:19:29", "content_summary": "RT @learn_learning3: ICLR2019\u306e\u63a1\u629e\u8ad6\u6587\"Attentive Neural Processes\"(https://t.co/mKsGwqMY8A)\uff0cDeepMind\u306e\u8457\u8005\u306b\u3088\u308bJupyter Notebook\u30d9\u30fc\u30b9\u5b9f\u88c5\u304c\u516c\u958b\u3055\u308c\u3066\u305f https://\u2026", "followers": "523"}, "1086352319497887745": {"author": "@kevespresso", "datetime": "2019-01-18 19:59:11", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "307"}, "1086955515115114497": {"author": "@xmah_mood", "datetime": "2019-01-20 11:56:04", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "39"}, "1086078083092799488": {"author": "@StatMLPapers", "datetime": "2019-01-18 01:49:28", "content_summary": "Attentive Neural Processes. (arXiv:1901.05761v1 [cs.LG]) https://t.co/N6Dm61vHHg", "followers": "9,695"}, "1088482926810013696": {"author": "@eldracote", "datetime": "2019-01-24 17:05:27", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "3,368"}, "1088366102244196353": {"author": "@d_kangin", "datetime": "2019-01-24 09:21:14", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "118"}, "1128156550449643521": {"author": "@gabeibagon", "datetime": "2019-05-14 04:34:16", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "72"}, "1086345302448193536": {"author": "@Communicate_AI", "datetime": "2019-01-18 19:31:18", "content_summary": "RT DeepMindAI: Attentive Neural Processes: https://t.co/ow07ECHRba", "followers": "56"}, "1086339102633390080": {"author": "@PJ_Muncaster", "datetime": "2019-01-18 19:06:39", "content_summary": "\" incorporating attention into NPs,... greatly improves the accuracy of predictions, results in noticeably faster training, and expands the range of functions that can be modelled.\" #deeplearning", "followers": "1,977"}, "1086322857624260608": {"author": "@MrBrutti", "datetime": "2019-01-18 18:02:06", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "535"}, "1086405311269789696": {"author": "@kurt_koo", "datetime": "2019-01-18 23:29:45", "content_summary": "DeepMind ICLR2019 paper it showed improved context prediction accuracy using attention with faster training time compared to Neural Processes 2018. https://t.co/gfQOmOYmdN #SchoolofAI #DeepMind #Attention #NeuralProcess https://t.co/5IQgp15hyF", "followers": "473"}, "1086569995470098432": {"author": "@hasaanprince33", "datetime": "2019-01-19 10:24:09", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "18"}, "1087055768367652864": {"author": "@Appanacca", "datetime": "2019-01-20 18:34:26", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "95"}, "1087853245869961216": {"author": "@jcchinhui", "datetime": "2019-01-22 23:23:19", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "256"}, "1086980060580626433": {"author": "@T_Rugby_H", "datetime": "2019-01-20 13:33:36", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "100"}, "1086431931498037248": {"author": "@KelliBuckreus", "datetime": "2019-01-19 01:15:32", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "205"}, "1086377715551195136": {"author": "@SythonUK", "datetime": "2019-01-18 21:40:05", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "691"}, "1125071429718953985": {"author": "@DevHunterYZ", "datetime": "2019-05-05 16:15:06", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "87"}, "1086092536509353986": {"author": "@arxiv_cs_LG", "datetime": "2019-01-18 02:46:53", "content_summary": "Attentive Neural Processes. Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum, Oriol Vinyals, and Yee Whye Teh https://t.co/fi9DWtLr1c", "followers": "314"}, "1087333897745154048": {"author": "@schwarzjn_", "datetime": "2019-01-21 12:59:37", "content_summary": "Our new paper shows how to fix some of the underfitting issues we observed with Neural Processes. +cool new image inpainting results. Work lead by @hyunjik11", "followers": "2,035"}, "1128174486912753664": {"author": "@gupta__abhay", "datetime": "2019-05-14 05:45:32", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "73"}, "1086322248426967040": {"author": "@LenzBelzner", "datetime": "2019-01-18 17:59:41", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "107"}, "1086449019566452736": {"author": "@hayashiyus", "datetime": "2019-01-19 02:23:26", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "4,200"}, "1132043843363381248": {"author": "@HubBucket", "datetime": "2019-05-24 22:00:59", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "5,315"}, "1086367223839633410": {"author": "@jeandut14000", "datetime": "2019-01-18 20:58:24", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "43"}, "1086383354100965381": {"author": "@yizhongwyz", "datetime": "2019-01-18 22:02:30", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "193"}, "1086630388385013760": {"author": "@Akari87800456", "datetime": "2019-01-19 14:24:07", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1"}, "1098016766884745218": {"author": "@indy9000", "datetime": "2019-02-20 00:29:32", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "354"}, "1128028488164884481": {"author": "@AdaptiveAgents", "datetime": "2019-05-13 20:05:23", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "2,163"}, "1086609840435331072": {"author": "@vct_sartor", "datetime": "2019-01-19 13:02:28", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "1"}, "1086371939407613953": {"author": "@mr_ubik", "datetime": "2019-01-18 21:17:08", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "330"}, "1086328483263860736": {"author": "@mogwaicoin", "datetime": "2019-01-18 18:24:28", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2,732"}, "1086562714778890240": {"author": "@PerthMLGroup", "datetime": "2019-01-19 09:55:13", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "456"}, "1087218259370209280": {"author": "@overleo", "datetime": "2019-01-21 05:20:07", "content_summary": "[1901.05761] Attentive Neural Processes: Abstract: Neural Processes (NPs) (Garnelo et al 2018a;b) approach regression by learning to map a context set of observed input-output pairs to a distribution over regression functions. Each function models\u2026 https:/", "followers": "200"}, "1086556941453651968": {"author": "@AssistedEvolve", "datetime": "2019-01-19 09:32:16", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "218"}, "1158541809477402626": {"author": "@TusharJain_007", "datetime": "2019-08-06 00:54:26", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "122"}, "1086354128807309312": {"author": "@joyenergynews", "datetime": "2019-01-18 20:06:22", "content_summary": "Attentive Neural Processes Neural Processes approach regression by learning to map a context set of observed input-output pairs to a distribution over regression functions #ArtificialIntelligence #Technology https://t.co/NAhwKFt0eA", "followers": "135"}, "1086556843323863040": {"author": "@Alexhein", "datetime": "2019-01-19 09:31:53", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "80"}, "1086341538249027585": {"author": "@rndmcnlly", "datetime": "2019-01-18 19:16:20", "content_summary": "I like that this technique offers a clear story for how neural systems can work with an unbounded memory of past experience, distinguishing short term learning (recording specific new experiences) from long-term learning (reinterpreting past experiences in", "followers": "1,473"}, "1097910374265954305": {"author": "@adam_golinski", "datetime": "2019-02-19 17:26:46", "content_summary": "RT @hyunjik11: An iPython notebook for Attentive Neural Processes (https://t.co/3kFQ8IbuKN) are out! A special case are Neural Processes (h\u2026", "followers": "1,065"}, "1086243795233136640": {"author": "@arkitus", "datetime": "2019-01-18 12:47:56", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "4,889"}, "1086248410007719937": {"author": "@albelwu", "datetime": "2019-01-18 13:06:17", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "62"}, "1086876065199321088": {"author": "@erik_nijkamp", "datetime": "2019-01-20 06:40:21", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "219"}, "1086335541321187328": {"author": "@hoangcuong0605", "datetime": "2019-01-18 18:52:30", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "52"}, "1086567719758118912": {"author": "@zsozdemir", "datetime": "2019-01-19 10:15:06", "content_summary": "\ud83c\udf89", "followers": "2,232"}, "1087336517461250050": {"author": "@FeryalMP", "datetime": "2019-01-21 13:10:02", "content_summary": "RT @schwarzjn_: Our new paper shows how to fix some of the underfitting issues we observed with Neural Processes. +cool new image inpaintin\u2026", "followers": "5,225"}, "1087950598224384010": {"author": "@youks95", "datetime": "2019-01-23 05:50:10", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "79"}, "1086653260679675905": {"author": "@ayirpelle", "datetime": "2019-01-19 15:55:01", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "2,675"}, "1124958974170804224": {"author": "@FeryalMP", "datetime": "2019-05-05 08:48:14", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "5,225"}, "1086554395796398082": {"author": "@ballforest", "datetime": "2019-01-19 09:22:09", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "4,031"}, "1088024091695538182": {"author": "@hiconcep", "datetime": "2019-01-23 10:42:12", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "135,428"}, "1125237934062546944": {"author": "@danrsm", "datetime": "2019-05-06 03:16:44", "content_summary": "RT @schwarzjn_: Check out our work on Attentive Neural Processes (https://t.co/YFR1aPNNdg) and KL-regularized RL (https://t.co/0qRxYshgJr)\u2026", "followers": "153"}, "1086382377348280322": {"author": "@ber24", "datetime": "2019-01-18 21:58:37", "content_summary": "RT @DeepMindAI: Attentive Neural Processes: https://t.co/GCSXGYyvEz", "followers": "402"}, "1086607270262132736": {"author": "@himanshumisra", "datetime": "2019-01-19 12:52:16", "content_summary": "Attentive Neural Processes - DeepMind Paper: https://t.co/555ZZNteAd Prereq: https://t.co/dwSK57uYBk \"NPs have the benefit of fitting observed data efficiently with linear complexity in the number of context input-output pairs, and can learn a wide famil\u2026", "followers": "91"}, "1086251719410024449": {"author": "@diegovogeid", "datetime": "2019-01-18 13:19:26", "content_summary": "RT @hyunjik11: \u2018Attentive Neural Processes\u2019 is live! We learn stochastic processes using deep architectures, and once trained on images, th\u2026", "followers": "69"}}, "queriedAt": "2020-05-21 19:38:47", "completed": "1", "citation_id": "54073296", "tab": "twitter"}