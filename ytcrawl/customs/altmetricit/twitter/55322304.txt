{"citation_id": "55322304", "tab": "twitter", "twitter": {"1095347014580269056": {"author": "@arxiv_cscv", "followers": "4,134", "datetime": "2019-02-12 15:40:53", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/qG9kY3EMBk"}, "1267021680997777409": {"author": "@arxiv_in_review", "followers": "1,344", "datetime": "2020-05-31 09:14:43", "content_summary": "#ICLR2020 Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v2 [cs\\.LG] UPDATED) https://t.co/Vqrmuf6KcX"}, "1095149170145587200": {"author": "@deep_rl", "followers": "866", "datetime": "2019-02-12 02:34:43", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning - Ruqi Zhang https://t.co/I6sB2FBLcI"}, "1096204643279851520": {"author": "@__tameiki__", "followers": "274", "datetime": "2019-02-15 00:28:48", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095430052215369728": {"author": "@letranger14", "followers": "329", "datetime": "2019-02-12 21:10:51", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095390806096125952": {"author": "@NoguerMiquel", "followers": "335", "datetime": "2019-02-12 18:34:54", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095467147889860608": {"author": "@izumism3", "followers": "424", "datetime": "2019-02-12 23:38:15", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095227224515588097": {"author": "@ThomasNiebler", "followers": "313", "datetime": "2019-02-12 07:44:53", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095685782516359168": {"author": "@owltrainlab", "followers": "45", "datetime": "2019-02-13 14:07:02", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v1 [cs.LG]) https://t.co/nkKGRb4chd #papers- ai #ml #feedly"}, "1095670908889362437": {"author": "@hs_heddy", "followers": "431", "datetime": "2019-02-13 13:07:55", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1107984316427051013": {"author": "@TDataScience", "followers": "40,775", "datetime": "2019-03-19 12:37:01", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. https://t.co/t2iwqkSrGi \ud83d\udd8aby Ruqi Zhang @ChunyuanLi Jianyi Zhang, Changyou Chen @andrewgwils @arxiv #DeepLearning #TDSPick \u2728"}, "1096166927876145152": {"author": "@fastml_extra", "followers": "7,219", "datetime": "2019-02-14 21:58:56", "content_summary": "https://t.co/2ObN5KoHTA"}, "1095349912584237062": {"author": "@ogrisel", "followers": "28,532", "datetime": "2019-02-12 15:52:24", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095506927121920000": {"author": "@nassyemon", "followers": "1,055", "datetime": "2019-02-13 02:16:19", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095538589251690497": {"author": "@dmarthal", "followers": "502", "datetime": "2019-02-13 04:22:08", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095368808053772288": {"author": "@andresmasegosa", "followers": "39", "datetime": "2019-02-12 17:07:29", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095453733008207872": {"author": "@389jan", "followers": "1,202", "datetime": "2019-02-12 22:44:57", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095152835648458753": {"author": "@BrundageBot", "followers": "3,913", "datetime": "2019-02-12 02:49:17", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson https://t.co/VLl5BX3P1I"}, "1095466538662936579": {"author": "@ML_deep", "followers": "4,738", "datetime": "2019-02-12 23:35:50", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095287899594010624": {"author": "@AssistedEvolve", "followers": "216", "datetime": "2019-02-12 11:45:59", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1097679680054784000": {"author": "@Khattiy74899201", "followers": "1,318", "datetime": "2019-02-19 02:10:04", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095189405063700480": {"author": "@MervinFansler", "followers": "167", "datetime": "2019-02-12 05:14:36", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095143513979830272": {"author": "@SoEngineering", "followers": "61", "datetime": "2019-02-12 02:12:15", "content_summary": "#NewPaper: #arXiv https://t.co/8kHVi9UcuF https://t.co/Wv0dRzpZBe Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v1 [cs.LG])"}, "1095357325714567168": {"author": "@AINewsFeed", "followers": "6,453", "datetime": "2019-02-12 16:21:51", "content_summary": "[1902.03932] Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/1twOtpr9Pf #ai #ml #dl"}, "1095357161302048768": {"author": "@DataSciNews", "followers": "21,501", "datetime": "2019-02-12 16:21:12", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095178793168310273": {"author": "@Pavel_Izmailov", "followers": "604", "datetime": "2019-02-12 04:32:26", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095503959777697792": {"author": "@tkazusa", "followers": "415", "datetime": "2019-02-13 02:04:32", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095181160098029568": {"author": "@jie_song", "followers": "14", "datetime": "2019-02-12 04:41:50", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095466240271765504": {"author": "@yukinagae", "followers": "1,069", "datetime": "2019-02-12 23:34:39", "content_summary": "\u3042\u3068\u3067\u8aad\u3082\u3046(\uff40\u30fb\u03c9\u30fb\u00b4)"}, "1155475108900700160": {"author": "@SiavashSakhavi", "followers": "188", "datetime": "2019-07-28 13:48:28", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1097297670983409664": {"author": "@koshian2", "followers": "2,718", "datetime": "2019-02-18 00:52:06", "content_summary": "RT @arxiv_pop: 2019/02/11 \u6295\u7a3f 1\u4f4d LG(Machine Learning) Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/gWPd2c660b 1\u2026"}, "1095731959588900869": {"author": "@Atabey_Kaygun", "followers": "1,088", "datetime": "2019-02-13 17:10:31", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095151959487795202": {"author": "@arxiv_cs_LG", "followers": "322", "datetime": "2019-02-12 02:45:48", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson https://t.co/ftav633B5l"}, "1096797252784476161": {"author": "@KokkasKostas", "followers": "182", "datetime": "2019-02-16 15:43:37", "content_summary": "Weekend reading of research on 'Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning' https://t.co/kRGa0l36xo #DataScience #DeepLearning #MachineLearning"}, "1095387773387837441": {"author": "@ThomasBoquet", "followers": "413", "datetime": "2019-02-12 18:22:51", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095324717081395200": {"author": "@jayeshmthakur", "followers": "2,071", "datetime": "2019-02-12 14:12:17", "content_summary": "RT @razoralign: cSG-MCMC: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning: https://t.co/UM1esl7J8U https://t.co/dzRtn4Ev5J"}, "1095136675162918914": {"author": "@brandondamos", "followers": "7,659", "datetime": "2019-02-12 01:45:04", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095592187314823170": {"author": "@octonion", "followers": "16,965", "datetime": "2019-02-13 07:55:07", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095439468159557632": {"author": "@anitayorker", "followers": "950", "datetime": "2019-02-12 21:48:16", "content_summary": "'Kenreisman/machine-learning' Top: [1902.03932] Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/ws05a2tXZN, see more https://t.co/VAU8peuLvN"}, "1095304379408609282": {"author": "@01717257469", "followers": "309", "datetime": "2019-02-12 12:51:28", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095391597531983873": {"author": "@markbriers", "followers": "468", "datetime": "2019-02-12 18:38:02", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1260470351483539458": {"author": "@helioRocha_", "followers": "630", "datetime": "2020-05-13 07:22:04", "content_summary": "\"Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v2 [cs.LG] UPDATED)\" #arXiv https://t.co/2thc5Jrrtd"}, "1095512229644922881": {"author": "@Ziquan12", "followers": "8", "datetime": "2019-02-13 02:37:23", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095453518255644672": {"author": "@hayashiyus", "followers": "4,246", "datetime": "2019-02-12 22:44:05", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095399576586997760": {"author": "@Ghassen_ML", "followers": "177", "datetime": "2019-02-12 19:09:45", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1267056676282097664": {"author": "@tmasada", "followers": "514", "datetime": "2020-05-31 11:33:47", "content_summary": "[1902.03932] Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/8cL4EW02xk"}, "1095155187793174530": {"author": "@qiming82", "followers": "396", "datetime": "2019-02-12 02:58:38", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095188752891330560": {"author": "@arxivml", "followers": "787", "datetime": "2019-02-12 05:12:00", "content_summary": "\"Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning\", Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Che\u2026 https://t.co/gS2htxBgdm"}, "1095186293888143360": {"author": "@ChunyuanLi", "followers": "206", "datetime": "2019-02-12 05:02:14", "content_summary": "Cyclical scheduling of stepsizes for gradient-based MCMC."}, "1095169492576030720": {"author": "@hrksrkr", "followers": "446", "datetime": "2019-02-12 03:55:28", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1097107065707945984": {"author": "@arxiv_in_review", "followers": "1,344", "datetime": "2019-02-17 12:14:42", "content_summary": "#ICML2019 Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v1 [cs\\.LG]) https://t.co/Vqrmuf6KcX"}, "1095365359794864137": {"author": "@nunomgarcia", "followers": "542", "datetime": "2019-02-12 16:53:47", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095137102738665478": {"author": "@jbloom22", "followers": "1,274", "datetime": "2019-02-12 01:46:46", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095381789558874112": {"author": "@bayesian_stats", "followers": "2,434", "datetime": "2019-02-12 17:59:04", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095504138039771136": {"author": "@ballforest", "followers": "4,098", "datetime": "2019-02-13 02:05:14", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1096074143240355841": {"author": "@quantumbtc", "followers": "231", "datetime": "2019-02-14 15:50:14", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095358675617832961": {"author": "@renato_umeton", "followers": "3,398", "datetime": "2019-02-12 16:27:13", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095350052464353280": {"author": "@MaciekSzul", "followers": "695", "datetime": "2019-02-12 15:52:57", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095369257108598784": {"author": "@samsinai", "followers": "1,134", "datetime": "2019-02-12 17:09:16", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1098231705821822976": {"author": "@wooyoungahn", "followers": "528", "datetime": "2019-02-20 14:43:37", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095267484465315842": {"author": "@mattmcd", "followers": "612", "datetime": "2019-02-12 10:24:52", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1103276584885202944": {"author": "@ogrisel", "followers": "28,532", "datetime": "2019-03-06 12:50:10", "content_summary": "@F_Vaggi @eigenhector @sigfpe @PhDemetri @tqchenml @guestrin And also the SGLD and SGHMC variants with a cyclic stepsize scheduling that can explore much better highly multimodal or complex high dimensional posteriors: https://t.co/QtoQDESea8"}, "1095365463909912576": {"author": "@hereticreader", "followers": "195", "datetime": "2019-02-12 16:54:12", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning - https://t.co/9D1COPFWPY https://t.co/86U8v9zod0"}, "1095353247106326528": {"author": "@unsorsodicorda", "followers": "739", "datetime": "2019-02-12 16:05:39", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1097186032716525568": {"author": "@nicholasabad_ai", "followers": "18", "datetime": "2019-02-17 17:28:29", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095150748680314880": {"author": "@arxiv_cscv", "followers": "4,134", "datetime": "2019-02-12 02:41:00", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/qG9kY3EMBk"}, "1095170942932639745": {"author": "@KouroshMeshgi", "followers": "622", "datetime": "2019-02-12 04:01:14", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095239450660163584": {"author": "@pietrovischia", "followers": "531", "datetime": "2019-02-12 08:33:28", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1096228566843441153": {"author": "@ErmiaBivatan", "followers": "818", "datetime": "2019-02-15 02:03:51", "content_summary": "RT @fastml_extra: https://t.co/2ObN5KoHTA https://t.co/lqe2Gj1TQs"}, "1095153878406901760": {"author": "@_moto86", "followers": "112", "datetime": "2019-02-12 02:53:26", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1260380714115031040": {"author": "@arXiv_reaDer", "followers": "144", "datetime": "2020-05-13 01:25:53", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning \u30d9\u30a4\u30b8\u30a2\u30f3\u6df1\u5c64\u5b66\u7fd2\u306e\u305f\u3081\u306e\u5faa\u74b0\u78ba\u7387\u52fe\u914dMCMC 2020-05-11T20:49:28+00:00 arXiv: https://t.co/CbxbfvZvnB \u82f1/\u65e5\u30b5\u30de\u30ea\u2193 https://t.co/xuYdcXkuHI"}, "1095256819780472833": {"author": "@mrityunjay_99", "followers": "127", "datetime": "2019-02-12 09:42:29", "content_summary": "Interesting"}, "1095349069973676034": {"author": "@arowan_ml", "followers": "481", "datetime": "2019-02-12 15:49:03", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095333606610808832": {"author": "@jastner109", "followers": "194", "datetime": "2019-02-12 14:47:36", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095159597466247168": {"author": "@alexdaviscmu", "followers": "718", "datetime": "2019-02-12 03:16:09", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1260656205413797890": {"author": "@arxiv_cscv", "followers": "4,134", "datetime": "2020-05-13 19:40:35", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/qG9kY3WnsS"}, "1095304178304458752": {"author": "@Blood_Buff", "followers": "420", "datetime": "2019-02-12 12:50:40", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095241280588836864": {"author": "@natdsim", "followers": "326", "datetime": "2019-02-12 08:40:44", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095136470153732096": {"author": "@andrewgwils", "followers": "12,938", "datetime": "2019-02-12 01:44:15", "content_summary": "MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifically for efficiently sampling from the complex multimodal posteriors in modern Bayesian deep learning (with code!): https://t.co/o5NelK"}, "1108015796721254400": {"author": "@EldarSilver", "followers": "1,940", "datetime": "2019-03-19 14:42:06", "content_summary": "RT @TDataScience: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. https://t.co/t2iwqkSrGi \ud83d\udd8aby Ruqi Zhang @ChunyuanLi Jianyi Z\u2026"}, "1095144573419077635": {"author": "@helioRocha_", "followers": "630", "datetime": "2019-02-12 02:16:27", "content_summary": "\"Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v1 [cs.LG])\" #arXiv https://t.co/gaBZY5rFlW"}, "1104007308575678464": {"author": "@MAlqahdali", "followers": "1,315", "datetime": "2019-03-08 13:13:48", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095703492306616320": {"author": "@sksq96", "followers": "506", "datetime": "2019-02-13 15:17:24", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1097311141670219776": {"author": "@prototechno", "followers": "4,825", "datetime": "2019-02-18 01:45:37", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095543261303734272": {"author": "@tahmidmehdi", "followers": "82", "datetime": "2019-02-13 04:40:42", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1260384551660126214": {"author": "@arxiv_cscv", "followers": "4,134", "datetime": "2020-05-13 01:41:08", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/qG9kY3EMBk"}, "1095292450560708611": {"author": "@desertnaut", "followers": "1,031", "datetime": "2019-02-12 12:04:04", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095272957666979841": {"author": "@razoralign", "followers": "697", "datetime": "2019-02-12 10:46:36", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095410399950848001": {"author": "@zein_shahine", "followers": "201", "datetime": "2019-02-12 19:52:45", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095474534713454593": {"author": "@swamids1", "followers": "52", "datetime": "2019-02-13 00:07:36", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095156573876424704": {"author": "@diegovogeid", "followers": "69", "datetime": "2019-02-12 03:04:08", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095580597953724416": {"author": "@dahlemd", "followers": "197", "datetime": "2019-02-13 07:09:04", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1267056862060597248": {"author": "@BlkHwk0ps", "followers": "964", "datetime": "2020-05-31 11:34:31", "content_summary": "RT @tmasada: [1902.03932] Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/8cL4EW02xk"}, "1260565746045911043": {"author": "@arxiv_cscv", "followers": "4,134", "datetime": "2020-05-13 13:41:08", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/qG9kY3EMBk"}, "1095548317101117440": {"author": "@yarphs", "followers": "11", "datetime": "2019-02-13 05:00:47", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095594105067851776": {"author": "@jaialkdanel", "followers": "1,770", "datetime": "2019-02-13 08:02:44", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1107985369361010690": {"author": "@theChrisChua", "followers": "2,136", "datetime": "2019-03-19 12:41:12", "content_summary": "RT @TDataScience: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. https://t.co/t2iwqkSrGi \ud83d\udd8aby Ruqi Zhang @ChunyuanLi Jianyi Z\u2026"}, "1095280045419974658": {"author": "@akdm_bot", "followers": "1,778", "datetime": "2019-02-12 11:14:46", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1107985262217441280": {"author": "@_Artemisa_v", "followers": "74", "datetime": "2019-03-19 12:40:46", "content_summary": "RT @TDataScience: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. https://t.co/t2iwqkSrGi \ud83d\udd8aby Ruqi Zhang @ChunyuanLi Jianyi Z\u2026"}, "1095215466879037441": {"author": "@saltcube1925", "followers": "170", "datetime": "2019-02-12 06:58:10", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095292294767378434": {"author": "@PerthMLGroup", "followers": "456", "datetime": "2019-02-12 12:03:27", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095341211399798786": {"author": "@ArpitJ_", "followers": "150", "datetime": "2019-02-12 15:17:49", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1096203647241711616": {"author": "@quantrad", "followers": "1,375", "datetime": "2019-02-15 00:24:50", "content_summary": "This is cool, and I think applicable to radiology. @SIIM_Tweets #ACRDSI"}, "1095389799534551040": {"author": "@IgorCarron", "followers": "4,887", "datetime": "2019-02-12 18:30:54", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095245203294826496": {"author": "@heghbalz", "followers": "1,314", "datetime": "2019-02-12 08:56:19", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095222594364526593": {"author": "@agibsonccc", "followers": "3,511", "datetime": "2019-02-12 07:26:29", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1267030581046468608": {"author": "@thanhnguyentang", "followers": "130", "datetime": "2020-05-31 09:50:05", "content_summary": "RT @arxiv_in_review: #ICLR2020 Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v2 [cs\\.LG] UPDATED) https://\u2026"}, "1095231244152070144": {"author": "@ClOrmandy", "followers": "50", "datetime": "2019-02-12 08:00:51", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095149986021588992": {"author": "@tscholak", "followers": "990", "datetime": "2019-02-12 02:37:58", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095799856545914880": {"author": "@nicib83", "followers": "495", "datetime": "2019-02-13 21:40:19", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095390473332707329": {"author": "@rahuldave", "followers": "853", "datetime": "2019-02-12 18:33:34", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1097605001227259912": {"author": "@imSrGadich", "followers": "902", "datetime": "2019-02-18 21:13:19", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095158221361139712": {"author": "@cghosh_", "followers": "281", "datetime": "2019-02-12 03:10:41", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095154099987845121": {"author": "@joeddav", "followers": "1,774", "datetime": "2019-02-12 02:54:19", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095364593495560193": {"author": "@muktabh", "followers": "798", "datetime": "2019-02-12 16:50:44", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095391924922474496": {"author": "@ZachBessinger", "followers": "165", "datetime": "2019-02-12 18:39:20", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095432617300803584": {"author": "@cartalop", "followers": "532", "datetime": "2019-02-12 21:21:02", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095729707314630656": {"author": "@__nggih", "followers": "416", "datetime": "2019-02-13 17:01:34", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1096797436452974596": {"author": "@theChrisChua", "followers": "2,136", "datetime": "2019-02-16 15:44:21", "content_summary": "RT @KokkasKostas: Weekend reading of research on 'Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning' https://t.co/kRGa0l36xo #Da\u2026"}, "1097296516161593344": {"author": "@arxiv_pop", "followers": "714", "datetime": "2019-02-18 00:47:30", "content_summary": "2019/02/11 \u6295\u7a3f 1\u4f4d LG(Machine Learning) Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning https://t.co/gWPd2c660b 15 Tweets 88 Retweets 381 Favorites"}, "1095477522844663808": {"author": "@nagachika", "followers": "1,546", "datetime": "2019-02-13 00:19:29", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095594922940354560": {"author": "@yjkao", "followers": "200", "datetime": "2019-02-13 08:05:59", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095319926531899392": {"author": "@amarquand", "followers": "590", "datetime": "2019-02-12 13:53:15", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095317246619078657": {"author": "@andybaoxv", "followers": "16", "datetime": "2019-02-12 13:42:36", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095282639169175552": {"author": "@razoralign", "followers": "697", "datetime": "2019-02-12 11:25:05", "content_summary": "cSG-MCMC: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning: https://t.co/UM1esl7J8U https://t.co/dzRtn4Ev5J"}, "1095300012001570816": {"author": "@madsyair", "followers": "118", "datetime": "2019-02-12 12:34:07", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095639884155445248": {"author": "@owltrainlab", "followers": "45", "datetime": "2019-02-13 11:04:39", "content_summary": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning. (arXiv:1902.03932v1 [cs.LG]) https://t.co/nkKGRb4chd"}, "1095476308409233408": {"author": "@adamianou", "followers": "1,171", "datetime": "2019-02-13 00:14:39", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095270164948496384": {"author": "@amarotaylorw", "followers": "197", "datetime": "2019-02-12 10:35:31", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}, "1095598137245384706": {"author": "@EldarSilver", "followers": "1,940", "datetime": "2019-02-13 08:18:45", "content_summary": "RT @andrewgwils: MCMC was once the gold standard for inference with neural networks. In this new work, we develop stochastic MCMC specifica\u2026"}}, "completed": "1", "queriedAt": "2020-06-03 01:05:46"}