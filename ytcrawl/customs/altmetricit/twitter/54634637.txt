{"twitter": {"1139196546271141888": {"author": "@NotFakeBrendan", "datetime": "2019-06-13 15:43:16", "content_summary": "RT @abidlabs: A new way to do an old problem! Classical feature selection (FS) methods use L1 regularization (think: lasso). We\u2019re presen\u2026", "followers": "966"}, "1090198328288165888": {"author": "@arxivml", "datetime": "2019-01-29 10:41:51", "content_summary": "\"Concrete Autoencoders for Differentiable Feature Selection and Reconstruction\", Abubakar Abid, Muhammad Fatih Bali\u2026 https://t.co/xK16Xl2eDB", "followers": "756"}, "1122430487019053056": {"author": "@Andreasheenn", "datetime": "2019-04-28 09:20:56", "content_summary": "RT @abidlabs: You can use Autoencoders for discrete feature selection! (https://t.co/hxZicqMzF4). Here's an animation I made selecting the\u2026", "followers": "125"}, "1091355633255890945": {"author": "@sa501428", "datetime": "2019-02-01 15:20:34", "content_summary": "RT @abidlabs: You can use Autoencoders for discrete feature selection! (https://t.co/hxZicqMzF4). Here's an animation I made selecting the\u2026", "followers": "469"}, "1098771070537076737": {"author": "@stephenrra", "datetime": "2019-02-22 02:26:52", "content_summary": "Interesting paper from @abidlabs, Muhammad Fatih Balin, and James Zou: https://t.co/L06TaZTnyP; uses Concrete RVs to differentiate through recon. loss + select discrete features that min. loss. Recovers similar MSE to the 943 landmark genes in @LINCSProgra", "followers": "625"}, "1106648337472802817": {"author": "@MFatihBalin", "datetime": "2019-03-15 20:08:18", "content_summary": "RT @abidlabs: You can use Autoencoders for discrete feature selection! (https://t.co/hxZicqMzF4). Here's an animation I made selecting the\u2026", "followers": "3"}, "1091073167823536129": {"author": "@abidlabs", "datetime": "2019-01-31 20:38:09", "content_summary": "You can use Autoencoders for discrete feature selection! (https://t.co/hxZicqMzF4). Here's an animation I made selecting the 10 most informative global features in MNIST: https://t.co/yKhlgk45rb", "followers": "842"}, "1090568988076240896": {"author": "@arxiv_in_review", "datetime": "2019-01-30 11:14:43", "content_summary": "#ICML2019 Concrete Autoencoders for Differentiable Feature Selection and Reconstruction. (arXiv:1901.09346v1 [cs\\.LG]) https://t.co/t8PReTFeuf", "followers": "1,285"}, "1139195329486528512": {"author": "@abidlabs", "datetime": "2019-06-13 15:38:26", "content_summary": "A new way to do an old problem! Classical feature selection (FS) methods use L1 regularization (think: lasso). We\u2019re presenting today at #ICML2019 showing how new methods based on Concrete random variables do FS better & directly with backpropagation", "followers": "842"}, "1120466829762285572": {"author": "@abidlabs", "datetime": "2019-04-22 23:18:04", "content_summary": "Preprint of the paper here: https://t.co/hxZicr4b3E (\u201cConcrete Autoencoders for Differentiable Feature Selection and Reconstruction\u201d)", "followers": "842"}, "1106631279305519104": {"author": "@LINCSProgram", "datetime": "2019-03-15 19:00:31", "content_summary": "RT @stephenrra: Interesting paper from @abidlabs, Muhammad Fatih Balin, and James Zou: https://t.co/L06TaZTnyP; uses Concrete RVs to differ\u2026", "followers": "405"}, "1098806129163829248": {"author": "@abidlabs", "datetime": "2019-02-22 04:46:10", "content_summary": "RT @stephenrra: Interesting paper from @abidlabs, Muhammad Fatih Balin, and James Zou: https://t.co/L06TaZTnyP; uses Concrete RVs to differ\u2026", "followers": "842"}, "1090079702306484224": {"author": "@BrundageBot", "datetime": "2019-01-29 02:50:28", "content_summary": "Concrete Autoencoders for Differentiable Feature Selection and Reconstruction. Abubakar Abid, Muhammad Fatih Balin, and James Zou https://t.co/YnJmaxbz94", "followers": "3,813"}, "1124126868939071488": {"author": "@abidlabs", "datetime": "2019-05-03 01:41:45", "content_summary": "@decodyng How about: https://t.co/hxZicqMzF4 (appearing in ICML \u201819) Looking forward to reading it \u2014 it\u2019s always insightful to see how someone else presents your work \ud83d\ude03", "followers": "842"}, "1139489534964465664": {"author": "@chemphy123", "datetime": "2019-06-14 11:07:30", "content_summary": "RT @abidlabs: A new way to do an old problem! Classical feature selection (FS) methods use L1 regularization (think: lasso). We\u2019re presen\u2026", "followers": "41"}, "1120489403821039617": {"author": "@letranger14", "datetime": "2019-04-23 00:47:46", "content_summary": "RT @abidlabs: You can use Autoencoders for discrete feature selection! (https://t.co/hxZicqMzF4). Here's an animation I made selecting the\u2026", "followers": "324"}, "1139212273388576769": {"author": "@stephenrra", "datetime": "2019-06-13 16:45:46", "content_summary": "RT @abidlabs: A new way to do an old problem! Classical feature selection (FS) methods use L1 regularization (think: lasso). We\u2019re presen\u2026", "followers": "625"}, "1139204076145713154": {"author": "@unsorsodicorda", "datetime": "2019-06-13 16:13:11", "content_summary": "RT @abidlabs: A new way to do an old problem! Classical feature selection (FS) methods use L1 regularization (think: lasso). We\u2019re presen\u2026", "followers": "717"}}, "queriedAt": "2020-05-21 20:20:38", "completed": "1", "citation_id": "54634637", "tab": "twitter"}