{"citation_id": "44136598", "completed": "1", "queriedAt": "2020-05-14 13:38:51", "tab": "twitter", "twitter": {"1014844147973308416": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/4v0qVw9uCF YutaKoreeda \u3055\u3093\u306e\u767a\u8868 #tfug", "followers": "1,044", "datetime": "2018-07-05 12:11:14", "author": "@ysaito8015"}, "1011977450715164673": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "1,472", "datetime": "2018-06-27 14:20:00", "author": "@came1223pg"}, "1012040621912215556": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "278", "datetime": "2018-06-27 18:31:01", "author": "@dafil"}, "1012906078923776000": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "98", "datetime": "2018-06-30 03:50:02", "author": "@kgwmath"}, "1011615698617921536": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "385", "datetime": "2018-06-26 14:22:32", "author": "@Rian4083"}, "1011696671577665536": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "353", "datetime": "2018-06-26 19:44:17", "author": "@_AkshitArora"}, "1012545887191515136": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "282", "datetime": "2018-06-29 03:58:46", "author": "@vksbhandary"}, "1011713359228669952": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "54", "datetime": "2018-06-26 20:50:36", "author": "@sinatv52"}, "1011540920112562177": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,409", "datetime": "2018-06-26 09:25:23", "author": "@nicklovescode"}, "1013014391418056704": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "336", "datetime": "2018-06-30 11:00:26", "author": "@KoheiSakamoto88"}, "1012022519979696128": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "1,215", "datetime": "2018-06-27 17:19:05", "author": "@devnag"}, "1013156121803190273": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "9", "datetime": "2018-06-30 20:23:37", "author": "@TafBelles"}, "1011977494172446720": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "992", "datetime": "2018-06-27 14:20:10", "author": "@datahack_"}, "1012303999448608768": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "179,069", "datetime": "2018-06-28 11:57:35", "author": "@Montreal_AI"}, "1011771322114793472": {"content_summary": "Skynet will come soon.. https://t.co/IeFFjFWLam", "followers": "10,282", "datetime": "2018-06-27 00:40:55", "author": "@golbin"}, "1011959774001258496": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "190", "datetime": "2018-06-27 13:09:46", "author": "@nskm_m"}, "1012983584771063809": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "12", "datetime": "2018-06-30 08:58:01", "author": "@Masashi_Ueda"}, "1011905132613787648": {"content_summary": "Have already retweeted this, but can't emphasize how cool it is to simultenously update weights and softmax parts of the model architecture in a differentiable way. https://t.co/21xyQG6rS4", "followers": "360", "datetime": "2018-06-27 09:32:38", "author": "@NyatzAnger"}, "1011703877148774401": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "56", "datetime": "2018-06-26 20:12:55", "author": "@wulab"}, "1012969323403436032": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "438", "datetime": "2018-06-30 08:01:21", "author": "@yoto_3"}, "1012953663608885248": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "35", "datetime": "2018-06-30 06:59:07", "author": "@t_zoeller"}, "1011423890982174722": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/9FpoWDNN9I", "followers": "4,100", "datetime": "2018-06-26 01:40:21", "author": "@arxiv_cscv"}, "1120865158170124293": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/bvdTLm8GEe", "followers": "3,501", "datetime": "2019-04-24 01:40:53", "author": "@arxiv_cscl"}, "1012941561267712002": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "212", "datetime": "2018-06-30 06:11:02", "author": "@awaldock"}, "1012123496116375552": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "538", "datetime": "2018-06-28 00:00:20", "author": "@redmor11"}, "1011659823681867776": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "427", "datetime": "2018-06-26 17:17:52", "author": "@jp_axs4ll"}, "1013206021857206274": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "4,861", "datetime": "2018-06-30 23:41:54", "author": "@MachineLearn45"}, "1011877430070599680": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "395", "datetime": "2018-06-27 07:42:33", "author": "@salahuddin517"}, "1019247703950176256": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "230", "datetime": "2018-07-17 15:49:23", "author": "@ko_ash"}, "1012072122053742592": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "219", "datetime": "2018-06-27 20:36:11", "author": "@aitechleeds"}, "1011829051881807872": {"content_summary": "\ud83d\udc4f\ud83d\udc4f\ud83d\udc4f https://t.co/KPbq58AvBu", "followers": "5,219", "datetime": "2018-06-27 04:30:19", "author": "@omarsar0"}, "1011932337951596545": {"content_summary": "RT @hillbig: For efficient network architecture search with gradient information, they propose to use softmax relaxation to select the oper\u2026", "followers": "478", "datetime": "2018-06-27 11:20:44", "author": "@yasuokajihei"}, "1012231605547667458": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "11", "datetime": "2018-06-28 07:09:55", "author": "@ToKraTheSecond"}, "1011622527947292673": {"content_summary": "RT @kchonyc: very nice! https://t.co/J6aUQWly2s", "followers": "1,816", "datetime": "2018-06-26 14:49:40", "author": "@MikiBear_"}, "1011825645754699776": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "518", "datetime": "2018-06-27 04:16:47", "author": "@giannirg"}, "1012915892043370497": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "293", "datetime": "2018-06-30 04:29:02", "author": "@chachay"}, "1011637365738295296": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "211", "datetime": "2018-06-26 15:48:37", "author": "@tiulpin"}, "1012898178545225729": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "442", "datetime": "2018-06-30 03:18:39", "author": "@mattn_"}, "1012911071986888704": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4", "datetime": "2018-06-30 04:09:53", "author": "@ZilongZhong"}, "1011952966641872899": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "159,742", "datetime": "2018-06-27 12:42:43", "author": "@Montreal_IA"}, "1011764473198047232": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "1,877", "datetime": "2018-06-27 00:13:42", "author": "@masahiro_sakai"}, "1033820883062808576": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,392", "datetime": "2018-08-26 20:58:00", "author": "@ChuckBaggett"}, "1011654901812916225": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "141", "datetime": "2018-06-26 16:58:18", "author": "@the_onederful"}, "1011805469524967424": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "468", "datetime": "2018-06-27 02:56:37", "author": "@debidatta"}, "1011447038150496256": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "1,221", "datetime": "2018-06-26 03:12:20", "author": "@D_Plius"}, "1011467820457005057": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "486", "datetime": "2018-06-26 04:34:55", "author": "@nmygle"}, "1011715186712109057": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "48", "datetime": "2018-06-26 20:57:51", "author": "@unknowlake"}, "1011933758570692613": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "1,183", "datetime": "2018-06-27 11:26:23", "author": "@Khalid_nowaf"}, "1012955448285134848": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "475", "datetime": "2018-06-30 07:06:13", "author": "@marefa9cb8"}, "1011420855891423234": {"content_summary": "\"DARTS: Differentiable Architecture Search,\" Liu et al.: https://t.co/qixqxtY8BN", "followers": "25,578", "datetime": "2018-06-26 01:28:17", "author": "@Miles_Brundage"}, "1011702493489737729": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "956", "datetime": "2018-06-26 20:07:25", "author": "@Kingwulf"}, "1012928558774153217": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "178", "datetime": "2018-06-30 05:19:22", "author": "@KempNicklin"}, "1011728221702967296": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "168", "datetime": "2018-06-26 21:49:39", "author": "@dr_levan"}, "1011817433542414336": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,288", "datetime": "2018-06-27 03:44:09", "author": "@heghbalz"}, "1011423962348257280": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/bvdTLm8GEe", "followers": "3,501", "datetime": "2018-06-26 01:40:38", "author": "@arxiv_cscl"}, "1011700750806913025": {"content_summary": "Very cool approach for relaxing the categorical choice of operations. DARTS (https://t.co/wgWwQ9QRCe). https://t.co/ozKSxtllvv", "followers": "3,623", "datetime": "2018-06-26 20:00:30", "author": "@tarantulae"}, "1011787299963760640": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "16", "datetime": "2018-06-27 01:44:25", "author": "@andrexsol"}, "1011591234429673472": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "177", "datetime": "2018-06-26 12:45:19", "author": "@suzumikasumi"}, "1011901151858454528": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "302", "datetime": "2018-06-27 09:16:49", "author": "@mofumofu1729"}, "1012193714511364096": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "1,823", "datetime": "2018-06-28 04:39:21", "author": "@trinity_site"}, "1012021146147885057": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "57", "datetime": "2018-06-27 17:13:38", "author": "@kuttykousik"}, "1012047996752576512": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "553", "datetime": "2018-06-27 19:00:20", "author": "@folkstone"}, "1011751026519658497": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "7,590", "datetime": "2018-06-26 23:20:16", "author": "@graphific"}, "1011872068848082945": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "13", "datetime": "2018-06-27 07:21:15", "author": "@CvRocker_XuJian"}, "1012888746948112385": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,707", "datetime": "2018-06-30 02:41:10", "author": "@shiftsphere"}, "1012685881134608386": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "4", "datetime": "2018-06-29 13:15:03", "author": "@ajyg54"}, "1011883000856969216": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "954", "datetime": "2018-06-27 08:04:41", "author": "@sannykimchi"}, "1011574454789509120": {"content_summary": "very nice! https://t.co/J6aUQWly2s", "followers": "23,866", "datetime": "2018-06-26 11:38:38", "author": "@kchonyc"}, "1011971379439079428": {"content_summary": "RT @yutakashino: [1806.09055] DARTS: Differentiable Architecture Search https://t.co/H9WfxoS7BK \u3053\u308c\uff0c\u8aad\u3093\u3060\u3089\u9762\u767d\u304b\u3063\u305f\u3057\uff0cPyTorch\u5b9f\u88c5\u3082\u52d5\u304b\u3057\u3066\u76ee\u304b\u3089\u9c57\u7cfb\u306a\u306e\u3067\uff0c\u6a5f\u4f1a\u304c\u3042\u3063\u305f\u2026", "followers": "303", "datetime": "2018-06-27 13:55:53", "author": "@213R"}, "1192027039324180480": {"content_summary": "DARTS (Differentiable Architecture Search) summary. Interesting idea! https://t.co/8e3OUMnAkv https://t.co/bTDKFIIUaZ", "followers": "13", "datetime": "2019-11-06 10:32:47", "author": "@GiangTr24025714"}, "1011889329914896384": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "67", "datetime": "2018-06-27 08:29:50", "author": "@dksdc"}, "1012301882302324737": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "137", "datetime": "2018-06-28 11:49:11", "author": "@ralphbrooks"}, "1011683821492809728": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "13", "datetime": "2018-06-26 18:53:13", "author": "@monish_ma"}, "1011683058725027843": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "826", "datetime": "2018-06-26 18:50:12", "author": "@bryan_wisk"}, "1011762189537964032": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "150", "datetime": "2018-06-27 00:04:38", "author": "@y_yammt"}, "1011965338165153792": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "284", "datetime": "2018-06-27 13:31:52", "author": "@otroFama"}, "1011799757805613056": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "212", "datetime": "2018-06-27 02:33:55", "author": "@erik_nijkamp"}, "1011654608526172161": {"content_summary": "Now this is neat! https://t.co/2vEfkWXu2Y", "followers": "877", "datetime": "2018-06-26 16:57:08", "author": "@StevenNHart"}, "1011847008108335104": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "263", "datetime": "2018-06-27 05:41:40", "author": "@raphaelm_sicara"}, "1011894922776121344": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "28", "datetime": "2018-06-27 08:52:04", "author": "@Mouatez"}, "1013954491224412161": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,069", "datetime": "2018-07-03 01:16:03", "author": "@hernangraffe"}, "1011949093239902208": {"content_summary": "Main idea of an important new paper, abstracted and understandably summarized in one tweet! :-) #DeepLearning https://t.co/2Eg9z2R6AJ", "followers": "1,135", "datetime": "2018-06-27 12:27:19", "author": "@zkajdan"}, "1011740413902778369": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "446", "datetime": "2018-06-26 22:38:06", "author": "@IHaveSweaters"}, "1011684990541844488": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "625", "datetime": "2018-06-26 18:57:52", "author": "@nova77t"}, "1012695139192459265": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "115", "datetime": "2018-06-29 13:51:50", "author": "@million_color"}, "1011912536483155970": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "54", "datetime": "2018-06-27 10:02:03", "author": "@drorhilman"}, "1012293467538632704": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "19", "datetime": "2018-06-28 11:15:44", "author": "@expertosays"}, "1011632261253533697": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "19", "datetime": "2018-06-26 15:28:20", "author": "@AVSave"}, "1011738250149367808": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "65", "datetime": "2018-06-26 22:29:30", "author": "@kli_nlpr"}, "1011785447796822016": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "28", "datetime": "2018-06-27 01:37:03", "author": "@SentissiMedLarb"}, "1011887459221803008": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "78", "datetime": "2018-06-27 08:22:24", "author": "@Simply_Sukumar"}, "1011698885230759937": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,670", "datetime": "2018-06-26 19:53:05", "author": "@StuartReid1929"}, "1011851142463086593": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "304", "datetime": "2018-06-27 05:58:06", "author": "@flrgsr"}, "1011662389987762176": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "12,559", "datetime": "2018-06-26 17:28:04", "author": "@chessninja"}, "1016712940970487809": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,614", "datetime": "2018-07-10 15:57:09", "author": "@standupguyxxx"}, "1011730189573861377": {"content_summary": "dope https://t.co/DPq4kjlQDx", "followers": "379", "datetime": "2018-06-26 21:57:28", "author": "@conorheins"}, "1011656695305687040": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "225", "datetime": "2018-06-26 17:05:26", "author": "@marqoz"}, "1011765678775271425": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "2,454", "datetime": "2018-06-27 00:18:30", "author": "@mandel59"}, "1011660096638603264": {"content_summary": "Fully differential architecture for architecture search(CNN and LSTM support only). It's super efficient- it can run on single GPU. https://t.co/YZIT0RIJIp", "followers": "251", "datetime": "2018-06-26 17:18:57", "author": "@Tanaygahlot"}, "1011684924397670400": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "17", "datetime": "2018-06-26 18:57:36", "author": "@andybaoxv"}, "1012010859755855872": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,528", "datetime": "2018-06-27 16:32:45", "author": "@ilblackdragon"}, "1012590032710819840": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "12,765", "datetime": "2018-06-29 06:54:11", "author": "@jaguring1"}, "1011789680805806080": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "234", "datetime": "2018-06-27 01:53:52", "author": "@iamsiddhantsahu"}, "1014843893387485184": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "2", "datetime": "2018-07-05 12:10:13", "author": "@pohsienliu"}, "1011688324313026560": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "226", "datetime": "2018-06-26 19:11:07", "author": "@cetusparibus"}, "1012033430345920512": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "77", "datetime": "2018-06-27 18:02:27", "author": "@ossama_s_ahmed"}, "1011927625022009346": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "912", "datetime": "2018-06-27 11:02:01", "author": "@marianojavierd1"}, "1011673366174941184": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "371", "datetime": "2018-06-26 18:11:41", "author": "@hrmoaddeli"}, "1013025556374392832": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "132", "datetime": "2018-06-30 11:44:48", "author": "@Emran_Saleh"}, "1011875827347124226": {"content_summary": "RT @LiamFedus: Fully differentiable architecture search! Liu et al. compute a softmax over operators and setup an approx alternating gra\u2026", "followers": "673", "datetime": "2018-06-27 07:36:11", "author": "@saikrishna_gvs"}, "1011748077806505984": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "531", "datetime": "2018-06-26 23:08:33", "author": "@zapletal_martin"}, "1017814986347905024": {"content_summary": "DARTS: Differentiable architecture search for convolutional and recurrent networks https://t.co/EyZYgryP1H https://t.co/UDljyO1Tyh", "followers": "12,827", "datetime": "2018-07-13 16:56:17", "author": "@jedisct1"}, "1011800116129423360": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "47", "datetime": "2018-06-27 02:35:20", "author": "@corey0913"}, "1025035570253312000": {"content_summary": "RT @davilagrau: Interesting! Improving image classification, finding convolutional architectures with reinforcement learning https://t.co/N\u2026", "followers": "3,321", "datetime": "2018-08-02 15:08:18", "author": "@juantomas"}, "1011411352055963649": {"content_summary": "\"DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG])\" #arXiv https://t.co/z67lZnueEU", "followers": "627", "datetime": "2018-06-26 00:50:32", "author": "@helioRocha_"}, "1013270037103181825": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "30", "datetime": "2018-07-01 03:56:17", "author": "@yotaro8887"}, "1011682619543744512": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "642", "datetime": "2018-06-26 18:48:27", "author": "@_AntreasAntonio"}, "1012546414063128579": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "12,765", "datetime": "2018-06-29 04:00:51", "author": "@jaguring1"}, "1011802775527845893": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "183", "datetime": "2018-06-27 02:45:54", "author": "@dkastaniotis"}, "1011952309973200896": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "159,742", "datetime": "2018-06-27 12:40:06", "author": "@Montreal_IA"}, "1012131327506870272": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "7", "datetime": "2018-06-28 00:31:27", "author": "@Mani20734381"}, "1011770235290939392": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "342", "datetime": "2018-06-27 00:36:36", "author": "@dariocazzani"}, "1011714814979129345": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "350", "datetime": "2018-06-26 20:56:23", "author": "@dkislyuk"}, "1011619236710703105": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "19", "datetime": "2018-06-26 14:36:35", "author": "@lostinio"}, "1045952988974526464": {"content_summary": "RT @imenurok: SNAS: stochastic neural architecture search https://t.co/dfYL7C6ka7 DARTS\u306eLiu et al.\u306e\u5f8c\u7d9a\u7814\u7a76\u306e\u4e88\u611f\u304c\u3059\u308b\u3002 https://t.co/kTcrdwzH2u", "followers": "121", "datetime": "2018-09-29 08:26:40", "author": "@mktozk"}, "1013445370658074624": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "27", "datetime": "2018-07-01 15:32:59", "author": "@mahesh21aug"}, "1011898020399603713": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "186", "datetime": "2018-06-27 09:04:22", "author": "@skureta"}, "1011588682921283584": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "7,503", "datetime": "2018-06-26 12:35:11", "author": "@HigeponJa"}, "1011776323688148993": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "691", "datetime": "2018-06-27 01:00:48", "author": "@SythonUK"}, "1011569457355821056": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "1,667", "datetime": "2018-06-26 11:18:47", "author": "@Scaled_Wurm"}, "1012272882490019841": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "27", "datetime": "2018-06-28 09:53:56", "author": "@mahesh21aug"}, "1018826471081533441": {"content_summary": "RT @imenurok: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u63a2\u7d22\u624b\u2026", "followers": "1,221", "datetime": "2018-07-16 11:55:34", "author": "@D_Plius"}, "1012732949517627392": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "548", "datetime": "2018-06-29 16:22:05", "author": "@k_glt"}, "1011711644744015879": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "8,627", "datetime": "2018-06-26 20:43:47", "author": "@Jack_Burdick"}, "1011669187570397185": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "145", "datetime": "2018-06-26 17:55:04", "author": "@esvhd"}, "1011739364806873089": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "25,578", "datetime": "2018-06-26 22:33:56", "author": "@Miles_Brundage"}, "1011777234447798272": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "91", "datetime": "2018-06-27 01:04:25", "author": "@anmclark2005"}, "1011735030568140801": {"content_summary": "Fast Differentiable Architecture Search https://t.co/Pjr17CRHe1", "followers": "962", "datetime": "2018-06-26 22:16:43", "author": "@jnhwkim"}, "1011671242133463041": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "47", "datetime": "2018-06-26 18:03:14", "author": "@syspulse"}, "1012319819343880193": {"content_summary": "RT @yutakashino: [1806.09055] DARTS: Differentiable Architecture Search https://t.co/H9WfxoS7BK \u3053\u308c\uff0c\u8aad\u3093\u3060\u3089\u9762\u767d\u304b\u3063\u305f\u3057\uff0cPyTorch\u5b9f\u88c5\u3082\u52d5\u304b\u3057\u3066\u76ee\u304b\u3089\u9c57\u7cfb\u306a\u306e\u3067\uff0c\u6a5f\u4f1a\u304c\u3042\u3063\u305f\u2026", "followers": "74", "datetime": "2018-06-28 13:00:27", "author": "@anoyumenotuzuki"}, "1011826337470767104": {"content_summary": "RT @aiskoaskosd: DARTS: Differentiable Architecture Search: https://t.co/FC5f8N4fSB gradient\u30d9\u30fc\u30b9\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30b5\u30fc\u30c1\u3002\u7d50\u679c\u304c\u826f\u304f\u3066\u3001\u8a08\u7b97\u91cf\u304c\u8efd\u3044\u3002(cifar10\u3067\u306fsingle g\u2026", "followers": "1,667", "datetime": "2018-06-27 04:19:32", "author": "@Scaled_Wurm"}, "1011775074200883200": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "1,077", "datetime": "2018-06-27 00:55:50", "author": "@jeffksmithjr"}, "1012404458154807297": {"content_summary": "Got to love this paper for it's ingenuity!! https://t.co/jzmKHNlcVh", "followers": "40", "datetime": "2018-06-28 18:36:47", "author": "@AlgorLabs"}, "1013356530308206592": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "18", "datetime": "2018-07-01 09:39:58", "author": "@DinAShie"}, "1011741627373633537": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "22", "datetime": "2018-06-26 22:42:55", "author": "@xuhonghu"}, "1020166435648299008": {"content_summary": "RT @DINDIN92: > \u30bc\u30df\u306e\u8ad6\u6587\u7d39\u4ecb\u3067\u7d39\u4ecb\u3059\u308b\u3082\u306e\u306b\u56f0\u3063\u3066\u307e\u3059 \u6a5f\u68b0\u5b66\u7fd2\u304b\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30f4\u30a3\u30b8\u30e7\u30f3\u306e\u5206\u91ce\u3067\u9762\u767d\u3044\u3082\u306e\u3042\u308a\u307e\u3059\u304b\uff1f \u81ea\u5206\u304c\u6709\u610f\u7fa9\u3068\u601d\u3046\u306e\u306f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u81ea\u52d5\u8a2d\u8a08\u3067\u3059\u306d\u3002 \u4f8b\u3048\u3070DARTS: Differentiable Architecture Sea\u2026", "followers": "12,765", "datetime": "2018-07-20 04:40:06", "author": "@jaguring1"}, "1026474102180200450": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,121", "datetime": "2018-08-06 14:24:31", "author": "@somnirons"}, "1013624499445481472": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "1,322", "datetime": "2018-07-02 03:24:47", "author": "@ararabo"}, "1011915826415456256": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "36", "datetime": "2018-06-27 10:15:08", "author": "@vasan_ashwin"}, "1012953304119177216": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "991", "datetime": "2018-06-30 06:57:42", "author": "@arika_nashika"}, "1011664298479845376": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "5,279", "datetime": "2018-06-26 17:35:39", "author": "@dataScienceRet"}, "1070441480404164608": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,927", "datetime": "2018-12-05 22:15:11", "author": "@evolvingstuff"}, "1012439637141442560": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "234", "datetime": "2018-06-28 20:56:34", "author": "@eleansa"}, "1011948523703754752": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "561", "datetime": "2018-06-27 12:25:03", "author": "@frankcarey"}, "1014382291672444928": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "477", "datetime": "2018-07-04 05:35:59", "author": "@TyzenLee"}, "1011709727204507648": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "45", "datetime": "2018-06-26 20:36:10", "author": "@nullbytep"}, "1013088554635780096": {"content_summary": "> \u30bc\u30df\u306e\u8ad6\u6587\u7d39\u4ecb\u3067\u7d39\u4ecb\u3059\u308b\u3082\u306e\u306b\u56f0\u3063\u3066\u307e\u3059 \u6a5f\u68b0\u5b66\u7fd2\u304b\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30f4\u30a3\u30b8\u30e7\u30f3\u306e\u5206\u91ce\u3067\u9762\u767d\u3044\u3082\u306e\u3042\u308a\u307e\u3059\u304b\uff1f \u81ea\u5206\u304c\u6709\u610f\u7fa9\u3068\u601d\u3046\u306e\u306f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u81ea\u52d5\u8a2d\u8a08\u3067\u3059\u306d\u3002 \u4f8b\u3048\u3070DARTS: Differentiable Architecture Search https://t.co/4KkdOK7qe3 #peing #\u8cea\u554f\u7bb1 https://t.co/NKU67IzzRJ", "followers": "1,454", "datetime": "2018-06-30 15:55:08", "author": "@DINDIN92"}, "1016947753337827328": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "175", "datetime": "2018-07-11 07:30:13", "author": "@Cyril__"}, "1011693039721410561": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "34", "datetime": "2018-06-26 19:29:51", "author": "@BrunoGCh"}, "1011733501710721024": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "367", "datetime": "2018-06-26 22:10:38", "author": "@mez_gebre"}, "1011694773999226883": {"content_summary": "\"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\" Try it now from: https://t.co/8khIix99ma https://t.co/HFuW0II5Hl", "followers": "96,072", "datetime": "2018-06-26 19:36:45", "author": "@PyTorch"}, "1011713901967257600": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "23", "datetime": "2018-06-26 20:52:45", "author": "@basharjaankhan"}, "1011781258953682944": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "260", "datetime": "2018-06-27 01:20:24", "author": "@vishnuvig"}, "1011645866900316160": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "595", "datetime": "2018-06-26 16:22:24", "author": "@cddadr"}, "1013065500283138048": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "281", "datetime": "2018-06-30 14:23:31", "author": "@yuxx_"}, "1013024292349534209": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "545", "datetime": "2018-06-30 11:39:47", "author": "@d_gfx"}, "1013064702199357440": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "63", "datetime": "2018-06-30 14:20:21", "author": "@hiroyax"}, "1012361175114403840": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,913", "datetime": "2018-06-28 15:44:47", "author": "@0Knaomi"}, "1011860826536411136": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "360", "datetime": "2018-06-27 06:36:35", "author": "@NyatzAnger"}, "1011709818632011776": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "189", "datetime": "2018-06-26 20:36:32", "author": "@daviddelachurch"}, "1012937076470267904": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,314", "datetime": "2018-06-30 05:53:13", "author": "@mitsushinakada"}, "1011664169282744321": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "144", "datetime": "2018-06-26 17:35:08", "author": "@gbonanse"}, "1012701563809251329": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "21", "datetime": "2018-06-29 14:17:22", "author": "@nhannguyen1995"}, "1011435620332261376": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "1,377", "datetime": "2018-06-26 02:26:58", "author": "@kaineko"}, "1011935056883957761": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "225", "datetime": "2018-06-27 11:31:33", "author": "@ElectronNest"}, "1070888896936861697": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "274", "datetime": "2018-12-07 03:53:03", "author": "@cghosh_"}, "1011803742172151808": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "528", "datetime": "2018-06-27 02:49:45", "author": "@rexplorations"}, "1045624914814820352": {"content_summary": "RT @imenurok: SNAS: stochastic neural architecture search https://t.co/dfYL7C6ka7 DARTS\u306eLiu et al.\u306e\u5f8c\u7d9a\u7814\u7a76\u306e\u4e88\u611f\u304c\u3059\u308b\u3002 https://t.co/kTcrdwzH2u", "followers": "26", "datetime": "2018-09-28 10:43:01", "author": "@fumiaki_sato_"}, "1011727942219489281": {"content_summary": "RT @tarantulae: Very cool approach for relaxing the categorical choice of operations. DARTS (https://t.co/wgWwQ9QRCe). https://t.co/ozKSxtl\u2026", "followers": "161", "datetime": "2018-06-26 21:48:33", "author": "@farhanhubble"}, "1012886096244457473": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,145", "datetime": "2018-06-30 02:30:38", "author": "@niku9Tenhou"}, "1023098701601021952": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,043", "datetime": "2018-07-28 06:51:53", "author": "@GOGLINJF"}, "1011807535349817344": {"content_summary": "mark https://t.co/RXJhW6LggE", "followers": "19", "datetime": "2018-06-27 03:04:49", "author": "@zhichao_dong"}, "1011669942998093826": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "196", "datetime": "2018-06-26 17:58:04", "author": "@blue_ammar"}, "1012364308041248768": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "191,988", "datetime": "2018-06-28 15:57:14", "author": "@fbplatform"}, "1011752559772610560": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "17", "datetime": "2018-06-26 23:26:22", "author": "@liucaoming"}, "1012418551011917824": {"content_summary": "Architecture search field is moving really fast, and I'm fairly convinced it will be a standard component of network design moving forward. No longer requires hundred-GPU clusters. Should be a thin layer on top of training e.g. hyperparameter tuning. https", "followers": "350", "datetime": "2018-06-28 19:32:47", "author": "@dkislyuk"}, "1011441012277833729": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "432", "datetime": "2018-06-26 02:48:23", "author": "@tsukamakiri"}, "1011673721805987841": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "31", "datetime": "2018-06-26 18:13:05", "author": "@koenboeckx"}, "1011849544609431557": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "324", "datetime": "2018-06-27 05:51:45", "author": "@mx_glitter"}, "1012604327863767040": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "565", "datetime": "2018-06-29 07:50:59", "author": "@Higashi38"}, "1080326292615114752": {"content_summary": "\u9ed1\u79d1\u6280\uff1f", "followers": "337", "datetime": "2019-01-02 04:53:54", "author": "@ThisIsBullet51"}, "1011776389920509953": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "2", "datetime": "2018-06-27 01:01:03", "author": "@lukekuang"}, "1011883586335756288": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "75", "datetime": "2018-06-27 08:07:01", "author": "@MohammadOtoofi"}, "1011681124014329861": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,293", "datetime": "2018-06-26 18:42:30", "author": "@ImNickHuber"}, "1011664370005405697": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "235", "datetime": "2018-06-26 17:35:56", "author": "@denisoliveirac"}, "1011782256703074304": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "109", "datetime": "2018-06-27 01:24:22", "author": "@ram_cse"}, "1011752038433263618": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "215", "datetime": "2018-06-26 23:24:18", "author": "@ailgroup"}, "1011992468030550018": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "85", "datetime": "2018-06-27 15:19:40", "author": "@lzhou_arch"}, "1011793201202630656": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "16,813", "datetime": "2018-06-27 02:07:52", "author": "@octonion"}, "1011698464818855936": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "242", "datetime": "2018-06-26 19:51:25", "author": "@crieramolina"}, "1012599479692742656": {"content_summary": "\u30e1\u30e2: DARTS: Differentiable Architecture Search https://t.co/10MFZpdDl7", "followers": "595", "datetime": "2018-06-29 07:31:43", "author": "@hamasyou"}, "1011926379242258432": {"content_summary": "RT @yutakashino: [1806.09055] DARTS: Differentiable Architecture Search https://t.co/H9WfxoS7BK \u3053\u308c\uff0c\u8aad\u3093\u3060\u3089\u9762\u767d\u304b\u3063\u305f\u3057\uff0cPyTorch\u5b9f\u88c5\u3082\u52d5\u304b\u3057\u3066\u76ee\u304b\u3089\u9c57\u7cfb\u306a\u306e\u3067\uff0c\u6a5f\u4f1a\u304c\u3042\u3063\u305f\u2026", "followers": "145", "datetime": "2018-06-27 10:57:04", "author": "@m_ishimu"}, "1012827738959278080": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,035", "datetime": "2018-06-29 22:38:45", "author": "@ryunosinfx"}, "1013016310756794368": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "29", "datetime": "2018-06-30 11:08:04", "author": "@vimukti3"}, "1011801729883627521": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "183", "datetime": "2018-06-27 02:41:45", "author": "@dkastaniotis"}, "1011694809994670080": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "6,089", "datetime": "2018-06-26 19:36:53", "author": "@mariuskarma"}, "1012164953287974912": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "228", "datetime": "2018-06-28 02:45:04", "author": "@hengcherkeng"}, "1012991212821929984": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "65", "datetime": "2018-06-30 09:28:20", "author": "@z4ckz4ckz4ck"}, "1013014256340500480": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "697", "datetime": "2018-06-30 10:59:54", "author": "@takatoh1"}, "1012106379946012672": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "63", "datetime": "2018-06-27 22:52:19", "author": "@hai_t_pham"}, "1011565304659374080": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "361", "datetime": "2018-06-26 11:02:17", "author": "@jadhavamitb"}, "1012285552991834112": {"content_summary": "This is the good kinda wonky DNN stuff that I'd like to see! https://t.co/3aouK56DCD", "followers": "17", "datetime": "2018-06-28 10:44:17", "author": "@onetruearavind"}, "1011664249465294848": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "8,738", "datetime": "2018-06-26 17:35:27", "author": "@Quesada"}, "1011670722962313217": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "0", "datetime": "2018-06-26 18:01:10", "author": "@GginisA"}, "1011892288803356672": {"content_summary": "\u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b https://t.co/djE5PJAjgS", "followers": "18,231", "datetime": "2018-06-27 08:41:36", "author": "@hillbig"}, "1012887709948379137": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "19", "datetime": "2018-06-30 02:37:03", "author": "@ki1la"}, "1190878682887286784": {"content_summary": "DARTS\u306e\u8ad6\u6587\u3092\u8aad\u3093\u3067Continuous relaxation\u3092\u3068\u308a\u3042\u3048\u305a\u7406\u89e3\u3057\u305f\u3002 \u3053\u306e\u624b\u6cd5\u3067\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u63a2\u7d22\u3092\u5fae\u5206\u53ef\u80fd\u306a\u30bf\u30b9\u30af\u306b\u843d\u3068\u3057\u8fbc\u3093\u3060\u3068\u3057\u3066\u3001GPU days\u304c3\u6841\u3050\u3089\u3044\u6e1b\u3063\u3066\u308b\u306e\u306f\u76f4\u611f\u7684\u306b\u306f\u307e\u3060\u3042\u307e\u308a\u30a4\u30e1\u30fc\u30b8\u3067\u304d\u3066\u306a\u3044 https://t.co/kY8xyEJ8lo", "followers": "1,271", "datetime": "2019-11-03 06:29:38", "author": "@c_bata_"}, "1012468602958573569": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "323", "datetime": "2018-06-28 22:51:40", "author": "@xpearhead"}, "1011950415565422592": {"content_summary": "RT @zhizhid: so cool https://t.co/bBCQhh19z4", "followers": "321", "datetime": "2018-06-27 12:32:34", "author": "@dajiangliu81"}, "1013423513519128576": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "593", "datetime": "2018-07-01 14:06:08", "author": "@soumen_eclectic"}, "1012820161844281344": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,258", "datetime": "2018-06-29 22:08:38", "author": "@gyabo"}, "1012369788969127936": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "165", "datetime": "2018-06-28 16:19:01", "author": "@gsautiere"}, "1011726694300782592": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "604", "datetime": "2018-06-26 21:43:35", "author": "@rharang"}, "1011822938935496704": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "12,934", "datetime": "2018-06-27 04:06:02", "author": "@maier_ak"}, "1011522249193488384": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "3,136", "datetime": "2018-06-26 08:11:12", "author": "@moai501"}, "1011521784183644160": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "793", "datetime": "2018-06-26 08:09:21", "author": "@__tmats__"}, "1011762911453147136": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "456", "datetime": "2018-06-27 00:07:30", "author": "@PerthMLGroup"}, "1012912473861574656": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "12", "datetime": "2018-06-30 04:15:27", "author": "@alittle_trippy"}, "1011657079231311873": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "299", "datetime": "2018-06-26 17:06:58", "author": "@AlOrozco53"}, "1012065375650009088": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "10,655", "datetime": "2018-06-27 20:09:23", "author": "@kaalam_ai"}, "1011707642073505792": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "224", "datetime": "2018-06-26 20:27:53", "author": "@recastrodiaz"}, "1011932377696923649": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "246", "datetime": "2018-06-27 11:20:54", "author": "@ramin_m_h"}, "1011711726516129793": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "232", "datetime": "2018-06-26 20:44:06", "author": "@brutforcimag"}, "1011724745715396610": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "132", "datetime": "2018-06-26 21:35:50", "author": "@f1yegor"}, "1011761383854297088": {"content_summary": "This is wonderful! https://t.co/vRWib4zbnH", "followers": "179", "datetime": "2018-06-27 00:01:26", "author": "@sidbrahma"}, "1011506876180074496": {"content_summary": "\u5fae\u5206\u53ef\u80fd\u3060\u3068\u3042\u308b\u7a2e\u306e\u6c17\u6301\u3061\u60aa\u3055\u306f\u306a\u304f\u306a\u308b\u3001\u3068\u601d\u3046\u2026 https://t.co/sHaRTuQ2s0", "followers": "249", "datetime": "2018-06-26 07:10:06", "author": "@mshero_y"}, "1011790348056780800": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "774", "datetime": "2018-06-27 01:56:31", "author": "@dmbanga"}, "1011932234805227521": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "478", "datetime": "2018-06-27 11:20:20", "author": "@yasuokajihei"}, "1016692269968187395": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,013", "datetime": "2018-07-10 14:35:01", "author": "@lpiot"}, "1091138644696416256": {"content_summary": "https://t.co/6WVOQlq0Pa \u5f37\u5316\u5b66\u7fd2\u3067\u306f\u306a\u304fSGD\u3092\u7528\u3044\u305fNAS\u3092\u63d0\u6848\u30021GPU x 1 day\u7a0b\u5ea6\u3067\u63a2\u7d22\u304c\u3067\u304d\u308b\u3002\u5404\u30bb\u30eb\u306e\u3042\u3089\u3086\u308b\u64cd\u4f5c\uff081x1Couv\u7b49\uff09\u3092softmax\u3067\u91cd\u307f\u4ed8\u3051\u3059\u308b\u3053\u3068\u3067\u5fae\u5206\u53ef\u80fd\u306b\u3057\u305f\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u3067\u5168\u64cd\u4f5c\u306e\u91cd\u307fW\u3092SGD\u3067\u66f4\u65b0\u3057, \u78ba\u8a8d\u30c7\u30fc\u30bf\u3067\u5404\u64cd\u4f5c\u306e\u5b9f\u73fe\u78ba\u7387\u03b1\u3092SGD\u3067\u66f4\u65b0\u3059\u308b\u3001\u3068\u3044\u3046\u64cd\u4f5c\u3092\u7e70\u308a\u8fd4\u3059", "followers": "1,309", "datetime": "2019-02-01 00:58:19", "author": "@akihiro_akichan"}, "1012773970544713729": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "303", "datetime": "2018-06-29 19:05:05", "author": "@utsushiiro"}, "1011937166551744512": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "2,043", "datetime": "2018-06-27 11:39:56", "author": "@dosei_sanga"}, "1011938153391886336": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "827", "datetime": "2018-06-27 11:43:51", "author": "@alimkhaldi"}, "1011842496412831744": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "172", "datetime": "2018-06-27 05:23:44", "author": "@CamJo89"}, "1011964563103854592": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "283", "datetime": "2018-06-27 13:28:47", "author": "@orl_London"}, "1012888495621148674": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "625", "datetime": "2018-06-30 02:40:10", "author": "@irration"}, "1013199698688118784": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "381", "datetime": "2018-06-30 23:16:47", "author": "@shyamal_chandra"}, "1012076368266452992": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "57", "datetime": "2018-06-27 20:53:04", "author": "@JianWu14"}, "1011743361647038464": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "82", "datetime": "2018-06-26 22:49:49", "author": "@duyongkim"}, "1030456383882182659": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "66", "datetime": "2018-08-17 14:08:41", "author": "@viigoo"}, "1011779718062931970": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "77", "datetime": "2018-06-27 01:14:17", "author": "@harishcancan"}, "1012594939773968385": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "5,410", "datetime": "2018-06-29 07:13:41", "author": "@yu4u"}, "1011886448897871872": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "969", "datetime": "2018-06-27 08:18:24", "author": "@HaydnBelfield"}, "1011573846468644864": {"content_summary": "RT @StatMLPapers: DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/ZWtzZkipuF", "followers": "275", "datetime": "2018-06-26 11:36:13", "author": "@kadarakos"}, "1023235861696208897": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,351", "datetime": "2018-07-28 15:56:54", "author": "@r_rbn"}, "1012622777164001280": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "280", "datetime": "2018-06-29 09:04:18", "author": "@ADMIS_Walker"}, "1012351749297004545": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "72", "datetime": "2018-06-28 15:07:20", "author": "@shaypal5"}, "1011933762832228352": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "198", "datetime": "2018-06-27 11:26:24", "author": "@MRsalman_333"}, "1011623622614515712": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "221", "datetime": "2018-06-26 14:54:01", "author": "@positivearrow"}, "1011657046524035072": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "154", "datetime": "2018-06-26 17:06:50", "author": "@DCasBol"}, "1012184031197388800": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "161", "datetime": "2018-06-28 04:00:53", "author": "@rajarishis"}, "1011661996645933056": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "85", "datetime": "2018-06-26 17:26:30", "author": "@Costines"}, "1011795919757438979": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "546", "datetime": "2018-06-27 02:18:40", "author": "@garywang"}, "1011707249956478978": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "4,688", "datetime": "2018-06-26 20:26:19", "author": "@meghafon"}, "1011648408409509891": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,293", "datetime": "2018-06-26 16:32:30", "author": "@ImNickHuber"}, "1012994494218698752": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "730", "datetime": "2018-06-30 09:41:22", "author": "@kzkt_bemani"}, "1012000120252985344": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "44", "datetime": "2018-06-27 15:50:05", "author": "@howardmeng"}, "1011921195338305541": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "5", "datetime": "2018-06-27 10:36:28", "author": "@lovefuture"}, "1011891553386881024": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "3,047", "datetime": "2018-06-27 08:38:41", "author": "@nick88msn"}, "1011630378073767936": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "592", "datetime": "2018-06-26 15:20:51", "author": "@pablete"}, "1011688649052905473": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "71", "datetime": "2018-06-26 19:12:24", "author": "@TheTiredSounds"}, "1015006172842201093": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "15", "datetime": "2018-07-05 22:55:04", "author": "@WalidMourou"}, "1011796917762682880": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "0", "datetime": "2018-06-27 02:22:38", "author": "@Sam09lol"}, "1012903514492686336": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "39,503", "datetime": "2018-06-30 03:39:51", "author": "@TJO_datasci"}, "1011687726045974528": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,088", "datetime": "2018-06-26 19:08:44", "author": "@gokstudio"}, "1121046360038563843": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/9FpoWDNN9I", "followers": "4,100", "datetime": "2019-04-24 13:40:54", "author": "@arxiv_cscv"}, "1011915872099819520": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "18", "datetime": "2018-06-27 10:15:19", "author": "@BhavishAgarwal"}, "1011887426980208640": {"content_summary": "RT @LiamFedus: Fully differentiable architecture search! Liu et al. compute a softmax over operators and setup an approx alternating gra\u2026", "followers": "1", "datetime": "2018-06-27 08:22:17", "author": "@YuriTrushkov"}, "1011665249269927936": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "818", "datetime": "2018-06-26 17:39:25", "author": "@stenichele"}, "1011683419208765442": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "273", "datetime": "2018-06-26 18:51:37", "author": "@denfromufa"}, "1011894666529132552": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "10", "datetime": "2018-06-27 08:51:03", "author": "@masterbabo"}, "1081459970187714561": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,293", "datetime": "2019-01-05 07:58:44", "author": "@ImNickHuber"}, "1011597611718111234": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "46", "datetime": "2018-06-26 13:10:39", "author": "@yumash3"}, "1011618071662825474": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "218", "datetime": "2018-06-26 14:31:57", "author": "@AssistedEvolve"}, "1011848025357078528": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "127", "datetime": "2018-06-27 05:45:43", "author": "@PipCruncher"}, "1011664975306338304": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "628", "datetime": "2018-06-26 17:38:20", "author": "@petercahill"}, "1011704800147275778": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "90", "datetime": "2018-06-26 20:16:35", "author": "@ElioQ"}, "1011747088852443136": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "3,126", "datetime": "2018-06-26 23:04:37", "author": "@MrMeritology"}, "1011922295999418368": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "532", "datetime": "2018-06-27 10:40:50", "author": "@mcarroll_91786"}, "1011632450471018496": {"content_summary": "RT @kchonyc: very nice! https://t.co/J6aUQWly2s", "followers": "4,327", "datetime": "2018-06-26 15:29:06", "author": "@jekbradbury"}, "1012580611444367361": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "12", "datetime": "2018-06-29 06:16:45", "author": "@octadero"}, "1011701344821043200": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "29", "datetime": "2018-06-26 20:02:51", "author": "@azak617"}, "1011484719014432768": {"content_summary": "\"DARTS: Differentiable Architecture Search\", Hanxiao Liu, Karen Simonyan, Yiming Yang https://t.co/ilDMI5Ib7h", "followers": "773", "datetime": "2018-06-26 05:42:04", "author": "@arxivml"}, "1011827957004939264": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "795", "datetime": "2018-06-27 04:25:58", "author": "@anskarl"}, "1011947011778711552": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "289", "datetime": "2018-06-27 12:19:03", "author": "@OmajDev"}, "1011846875417374720": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "185", "datetime": "2018-06-27 05:41:08", "author": "@fccagou"}, "1011969502756532224": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "42", "datetime": "2018-06-27 13:48:25", "author": "@mtnayeem"}, "1012274145466302464": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "243", "datetime": "2018-06-28 09:58:58", "author": "@karthiknrao"}, "1011731016413827074": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "79,157", "datetime": "2018-06-26 22:00:46", "author": "@machinelearnflx"}, "1013451300309225472": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "218", "datetime": "2018-07-01 15:56:33", "author": "@david_macedo"}, "1017811667126759426": {"content_summary": "#NeuralNetworks #DeepLearning #MachineLearning Differentiable network architecture search https://t.co/UhTFhUK6lZ", "followers": "4", "datetime": "2018-07-13 16:43:06", "author": "@NikitaKulagin66"}, "1012874720797048832": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "143", "datetime": "2018-06-30 01:45:26", "author": "@n_kats_"}, "1011764891651268614": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "21", "datetime": "2018-06-27 00:15:22", "author": "@thapraveensingh"}, "1011745892913696768": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "150", "datetime": "2018-06-26 22:59:52", "author": "@y_yammt"}, "1011522489409724416": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "516", "datetime": "2018-06-26 08:12:09", "author": "@thruthebckdr"}, "1012955126028333056": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "18", "datetime": "2018-06-30 07:04:56", "author": "@pitbull_wang"}, "1011676997981016064": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "331", "datetime": "2018-06-26 18:26:07", "author": "@philomate"}, "1011653463866871808": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "269,218", "datetime": "2018-06-26 16:52:36", "author": "@karpathy"}, "1012681814152962055": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,269", "datetime": "2018-06-29 12:58:53", "author": "@Linus_MK"}, "1011674352763449344": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "427", "datetime": "2018-06-26 18:15:36", "author": "@mikeful"}, "1011943997764321280": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "132", "datetime": "2018-06-27 12:07:04", "author": "@KumarSamalkha"}, "1011798360926253056": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "639", "datetime": "2018-06-27 02:28:22", "author": "@thoriqhidayah"}, "1011722910376001537": {"content_summary": "Very important. Differentiable search among architectures. Fast. https://t.co/8Ga4NZKq2C", "followers": "238", "datetime": "2018-06-26 21:28:33", "author": "@meapistol"}, "1011788512885137409": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "635", "datetime": "2018-06-27 01:49:14", "author": "@itmdata"}, "1011967496239439872": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "193", "datetime": "2018-06-27 13:40:27", "author": "@alexhock"}, "1011788619172868096": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "4", "datetime": "2018-06-27 01:49:39", "author": "@TaeseokLim1"}, "1011695694728474624": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,246", "datetime": "2018-06-26 19:40:24", "author": "@JonClarkSeattle"}, "1011679893396967424": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "1,445", "datetime": "2018-06-26 18:37:37", "author": "@shiatsumat"}, "1012560565271695361": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "56", "datetime": "2018-06-29 04:57:05", "author": "@DinnerOut1991"}, "1012929828721315840": {"content_summary": "Gradient based neural network architecture search DARTS: Differentiable Architecture Search https://t.co/E3gBRqpzrz", "followers": "49", "datetime": "2018-06-30 05:24:25", "author": "@rohitpgarg"}, "1012597659964600320": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,043", "datetime": "2018-06-29 07:24:29", "author": "@dosei_sanga"}, "1011717644591030272": {"content_summary": "Pretty fast architecture search, only 1.5 days! https://t.co/J2S2I2lonC", "followers": "5,735", "datetime": "2018-06-26 21:07:37", "author": "@jm_alexia"}, "1011902828963561472": {"content_summary": "RT @Rosenchild: #DARTS - Differentiable Architecture Search The scalability challenge of architecture search by formulating the task in a\u2026", "followers": "11,931", "datetime": "2018-06-27 09:23:29", "author": "@Rosenchild"}, "1011795250929717248": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "20", "datetime": "2018-06-27 02:16:00", "author": "@apriliogusrul"}, "1011982249309290496": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "58", "datetime": "2018-06-27 14:39:04", "author": "@ShuvenduBikash"}, "1011783505607442432": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,061", "datetime": "2018-06-27 01:29:20", "author": "@abarisser"}, "1011711532206559233": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "127", "datetime": "2018-06-26 20:43:20", "author": "@PipCruncher"}, "1012137347154997253": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "14", "datetime": "2018-06-28 00:55:22", "author": "@TsuguoMogami"}, "1012908048363466757": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "155", "datetime": "2018-06-30 03:57:52", "author": "@RaphCouturier"}, "1011699711483445249": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "441", "datetime": "2018-06-26 19:56:22", "author": "@Bouh___"}, "1012042880997736448": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "111", "datetime": "2018-06-27 18:40:00", "author": "@nimblel"}, "1011761414808260608": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "136", "datetime": "2018-06-27 00:01:33", "author": "@leo_assaff"}, "1011997778246070274": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "432", "datetime": "2018-06-27 15:40:47", "author": "@bhargavbardipur"}, "1012086929725128704": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "7,137", "datetime": "2018-06-27 21:35:02", "author": "@anshulkundaje"}, "1036772017595457536": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "58", "datetime": "2018-09-04 00:24:45", "author": "@doug_eek"}, "1012062598299254785": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,434", "datetime": "2018-06-27 19:58:21", "author": "@damianborth"}, "1012887019872137217": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "213", "datetime": "2018-06-30 02:34:18", "author": "@GonziHenri"}, "1011907351329136640": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "5", "datetime": "2018-06-27 09:41:27", "author": "@sonodano315"}, "1012537037226831872": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "2,456", "datetime": "2018-06-29 03:23:36", "author": "@jinbeizame007"}, "1012651853090177024": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,727", "datetime": "2018-06-29 10:59:50", "author": "@suikan_blackfin"}, "1011967008714313729": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "57", "datetime": "2018-06-27 13:38:30", "author": "@DennisYTShen"}, "1081535361107423232": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "179", "datetime": "2019-01-05 12:58:18", "author": "@tigger1o"}, "1012225561886781440": {"content_summary": "DARTS: Differentiable Architecture Search | arXiv https://t.co/SmWlQGXiru #ArchitectureSearch https://t.co/F229fTtWQI", "followers": "1,131", "datetime": "2018-06-28 06:45:54", "author": "@BioDecoded"}, "1011702631847415808": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,170", "datetime": "2018-06-26 20:07:58", "author": "@iskander"}, "1012150111470866435": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "15", "datetime": "2018-06-28 01:46:06", "author": "@tensoralex"}, "1013516287727820800": {"content_summary": "RT @antor: Deep learning que hace su propio deep learning: por ahora no es m\u00e1s que b\u00fasqueda m\u00e1s o menos guiada (a veces poco) para encontra\u2026", "followers": "168", "datetime": "2018-07-01 20:14:47", "author": "@JCarchenilla"}, "1011992988648501248": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "2,310", "datetime": "2018-06-27 15:21:45", "author": "@Vikram_Tiwari"}, "1012061379245768704": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "213", "datetime": "2018-06-27 19:53:30", "author": "@danelliottster"}, "1012897184692355072": {"content_summary": "\"...not restricted to any specific architecture family...able to discover both convolutional and recurrent networks... design a convolutional..competitive with the state-of-the-art result by regularized evolution\u2014obtained using three orders of magnitude mo", "followers": "320", "datetime": "2018-06-30 03:14:42", "author": "@microsurgeonbot"}, "1011810034190376960": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "264", "datetime": "2018-06-27 03:14:45", "author": "@hellorahulk"}, "1011410831928590336": {"content_summary": "https://t.co/QZtCP1KuX5 DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) #NLProc", "followers": "4,200", "datetime": "2018-06-26 00:48:28", "author": "@arxiv_cs_cl"}, "1011728291072544768": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "3,665", "datetime": "2018-06-26 21:49:56", "author": "@eigenhector"}, "1011620034957869056": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "113", "datetime": "2018-06-26 14:39:45", "author": "@isaiahtaguibao"}, "1012057667383255040": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "172", "datetime": "2018-06-27 19:38:45", "author": "@ggdupont"}, "1012858628393480194": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "150", "datetime": "2018-06-30 00:41:29", "author": "@i789_biz"}, "1011827924113113088": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "361", "datetime": "2018-06-27 04:25:50", "author": "@jadhavamitb"}, "1012304233658552320": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "11,931", "datetime": "2018-06-28 11:58:31", "author": "@Rosenchild"}, "1011764799586226177": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "1,170", "datetime": "2018-06-27 00:15:00", "author": "@yuki_mimu"}, "1014942212495323136": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2", "datetime": "2018-07-05 18:40:54", "author": "@0_10bytes"}, "1013537671602290688": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "294", "datetime": "2018-07-01 21:39:46", "author": "@rose_miura"}, "1014641497004638209": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "0", "datetime": "2018-07-04 22:45:58", "author": "@polycyclohexadi"}, "1011903119893106688": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "208", "datetime": "2018-06-27 09:24:38", "author": "@sathya04"}, "1011596955364061184": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "399", "datetime": "2018-06-26 13:08:03", "author": "@kamilsindi"}, "1011669250203889664": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "117", "datetime": "2018-06-26 17:55:19", "author": "@d_kangin"}, "1011812012714684416": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "21", "datetime": "2018-06-27 03:22:37", "author": "@luoyuchu"}, "1012170987348033538": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "649", "datetime": "2018-06-28 03:09:03", "author": "@cortexelation"}, "1012361635715936256": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,164", "datetime": "2018-06-28 15:46:37", "author": "@alanyttian"}, "1014737777399746560": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "5", "datetime": "2018-07-05 05:08:33", "author": "@yuhang_dl"}, "1011727505777049601": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "152", "datetime": "2018-06-26 21:46:49", "author": "@felixdacaat454"}, "1012934057741594629": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "24", "datetime": "2018-06-30 05:41:13", "author": "@Jonmejoy1"}, "1011615427854659585": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,816", "datetime": "2018-06-26 14:21:27", "author": "@MikiBear_"}, "1012974273068138496": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "7,190", "datetime": "2018-06-30 08:21:01", "author": "@avelino0"}, "1012847004903301121": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "608", "datetime": "2018-06-29 23:55:18", "author": "@chaoticCats"}, "1011808393164619777": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "373", "datetime": "2018-06-27 03:08:14", "author": "@pnplex"}, "1013104844771504129": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "718", "datetime": "2018-06-30 16:59:52", "author": "@y_syami"}, "1011785162957512704": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "403", "datetime": "2018-06-27 01:35:55", "author": "@mattpetersen_ai"}, "1012588604667789313": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,050", "datetime": "2018-06-29 06:48:30", "author": "@shunk031"}, "1138234957673816064": {"content_summary": "https://t.co/NtP05MllwV A wonderful approach by @deepmind and CMU, for gradient-based meta-learning. But, doesn't this makes the search topology non-continuous? Wondering how would this approach behave with probabilistic models, any thoughts or intuition?", "followers": "116", "datetime": "2019-06-11 00:02:15", "author": "@koriavinash001"}, "1015119731798564864": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "332", "datetime": "2018-07-06 06:26:18", "author": "@c__laetitia"}, "1012057576572375040": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "111", "datetime": "2018-06-27 19:38:24", "author": "@nimblel"}, "1011843757078188037": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "54", "datetime": "2018-06-27 05:28:45", "author": "@vo_d_p"}, "1011848089945006080": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,200", "datetime": "2018-06-27 05:45:58", "author": "@hurrycane"}, "1012146313998188545": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "14", "datetime": "2018-06-28 01:31:00", "author": "@TsuguoMogami"}, "1021013659974324229": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,558", "datetime": "2018-07-22 12:46:40", "author": "@Ashygoyal"}, "1012955604162187265": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,034", "datetime": "2018-06-30 07:06:50", "author": "@mine02c4"}, "1036474172002586624": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/MDkFJTOHUd", "followers": "", "datetime": "2018-09-03 04:41:14", "author": "@unlimitcycle"}, "1012172470810378240": {"content_summary": "Neural network architecture search headache relief? \ud83d\ude05 https://t.co/qg8R56MNf5", "followers": "54", "datetime": "2018-06-28 03:14:56", "author": "@jsdelfino"}, "1183150503527469057": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "159", "datetime": "2019-10-12 22:40:36", "author": "@ieno_tech"}, "1011915729656938496": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "2,456", "datetime": "2018-06-27 10:14:45", "author": "@jinbeizame007"}, "1108949628290924545": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "543", "datetime": "2019-03-22 04:32:49", "author": "@wsuzume"}, "1011729205590151169": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "164,067", "datetime": "2018-06-26 21:53:34", "author": "@ceobillionaire"}, "1011875483062099968": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "26", "datetime": "2018-06-27 07:34:49", "author": "@hiendangesmart"}, "1011841603135127553": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "324", "datetime": "2018-06-27 05:20:11", "author": "@rahul_a_r"}, "1011760270614528000": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,170", "datetime": "2018-06-26 23:57:00", "author": "@yuki_mimu"}, "1011605274585649153": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/9FpoWDNN9I", "followers": "4,100", "datetime": "2018-06-26 13:41:06", "author": "@arxiv_cscv"}, "1011938524575264769": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "765", "datetime": "2018-06-27 11:45:19", "author": "@whyboris"}, "1011795623534825472": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "912", "datetime": "2018-06-27 02:17:29", "author": "@marianojavierd1"}, "1011953886238633984": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "169", "datetime": "2018-06-27 12:46:22", "author": "@kawamuramasahar"}, "1012312404179464192": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "5,315", "datetime": "2018-06-28 12:30:59", "author": "@HubBucket"}, "1011638597907202048": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "568", "datetime": "2018-06-26 15:53:31", "author": "@cxhrndz"}, "1011662956701069313": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "448", "datetime": "2018-06-26 17:30:19", "author": "@ameliovr"}, "1015524329520582656": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "180", "datetime": "2018-07-07 09:14:02", "author": "@AlgorithmHealth"}, "1011847546916880385": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "304", "datetime": "2018-06-27 05:43:49", "author": "@flrgsr"}, "1012035686340280320": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "117", "datetime": "2018-06-27 18:11:24", "author": "@imAArora"}, "1011840436351258625": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "403", "datetime": "2018-06-27 05:15:33", "author": "@mattpetersen_ai"}, "1012544899013472256": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "41", "datetime": "2018-06-29 03:54:50", "author": "@kurochan831"}, "1012285795590397952": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "4,750", "datetime": "2018-06-28 10:45:15", "author": "@cekahn"}, "1011769298019209216": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "99", "datetime": "2018-06-27 00:32:53", "author": "@treasured_write"}, "1011422671056367616": {"content_summary": "DARTS: Differentiable Architecture Search - Hanxiao Liu https://t.co/ZzyBgPZl5r", "followers": "858", "datetime": "2018-06-26 01:35:30", "author": "@deep_rl"}, "1011813651634782209": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "3,097", "datetime": "2018-06-27 03:29:07", "author": "@mrkgrnao"}, "1011805525695057920": {"content_summary": "DARTS: Differentiable Architecture Search: https://t.co/FC5f8N4fSB gradient\u30d9\u30fc\u30b9\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30b5\u30fc\u30c1\u3002\u7d50\u679c\u304c\u826f\u304f\u3066\u3001\u8a08\u7b97\u91cf\u304c\u8efd\u3044\u3002(cifar10\u3067\u306fsingle gpu\u30671.5\u65e5\u3001imagenet\u306f12\u65e5)\u3002\u3053\u306e\u8ad6\u6587\u3092\u76ae\u5207\u308a\u306b\u767a\u5c55\u3057\u3066\u3044\u304d\u305d\u3046\u3002\u304a\u3082\u3057\u308d\u3044\u8ad6\u6587\u3002", "followers": "231", "datetime": "2018-06-27 02:56:50", "author": "@aiskoaskosd"}, "1011847845240922112": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "304", "datetime": "2018-06-27 05:45:00", "author": "@flrgsr"}, "1012351444756951040": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "72", "datetime": "2018-06-28 15:06:07", "author": "@shaypal5"}, "1012319968497750016": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "236", "datetime": "2018-06-28 13:01:03", "author": "@flowing"}, "1011698825067720705": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,945", "datetime": "2018-06-26 19:52:51", "author": "@zaxtax"}, "1012278508008169472": {"content_summary": "RT @future_of_AI: https://t.co/TdNi8o4mHM #ai #machinelearning #artificialintelligence via @cmarschner", "followers": "1,833", "datetime": "2018-06-28 10:16:18", "author": "@msarozz"}, "1011729720315187202": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "164,067", "datetime": "2018-06-26 21:55:37", "author": "@ceobillionaire"}, "1011806342577876993": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "161", "datetime": "2018-06-27 03:00:05", "author": "@rajarishis"}, "1011831221624627200": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "535", "datetime": "2018-06-27 04:38:56", "author": "@DenDen047"}, "1011459122175209482": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "841", "datetime": "2018-06-26 04:00:21", "author": "@a2uky"}, "1011968590377975808": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "322", "datetime": "2018-06-27 13:44:48", "author": "@letranger14"}, "1011838458304663553": {"content_summary": "RT @LiamFedus: Fully differentiable architecture search! Liu et al. compute a softmax over operators and setup an approx alternating gra\u2026", "followers": "2,439", "datetime": "2018-06-27 05:07:42", "author": "@mawsonguy"}, "1012541465623318529": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "3,403", "datetime": "2018-06-29 03:41:12", "author": "@rinakatase"}, "1011920754521370624": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "913", "datetime": "2018-06-27 10:34:43", "author": "@AndreaBanino"}, "1011442013047144449": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "2,435", "datetime": "2018-06-26 02:52:22", "author": "@marsee101"}, "1012889631367495680": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "14", "datetime": "2018-06-30 02:44:41", "author": "@jie_song"}, "1011978393963855872": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "129", "datetime": "2018-06-27 14:23:45", "author": "@miguel_algaba"}, "1011838813822504960": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "754", "datetime": "2018-06-27 05:09:06", "author": "@suneelmarthi"}, "1011734956173811712": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "212", "datetime": "2018-06-26 22:16:25", "author": "@nanjakorewa"}, "1012608547920621568": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,470", "datetime": "2018-06-29 08:07:45", "author": "@mikumo_UR"}, "1011701389628727298": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "301", "datetime": "2018-06-26 20:03:02", "author": "@tobias_sterbak"}, "1011916195371601921": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "36", "datetime": "2018-06-27 10:16:36", "author": "@vasan_ashwin"}, "1011750029290233856": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "65", "datetime": "2018-06-26 23:16:19", "author": "@maestroderek"}, "1011659488200413184": {"content_summary": "#DeepLearning Automatic Architecture Search #AutoML #MachineLearning \ud83e\udd16 https://t.co/DKcCiHEM9n", "followers": "84", "datetime": "2018-06-26 17:16:32", "author": "@SamiSakly"}, "1012126786392477696": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "174", "datetime": "2018-06-28 00:13:24", "author": "@sappy_and_sappy"}, "1012185178033278976": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "830", "datetime": "2018-06-28 04:05:26", "author": "@hugo_glez"}, "1011939038188785666": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "128", "datetime": "2018-06-27 11:47:22", "author": "@alrshidi10"}, "1012364459908608000": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "741", "datetime": "2018-06-28 15:57:50", "author": "@shoma"}, "1013255729703030784": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "244", "datetime": "2018-07-01 02:59:25", "author": "@Yutt_93"}, "1011597600204689411": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "377", "datetime": "2018-06-26 13:10:37", "author": "@nicklaw296"}, "1012013625270263808": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "42", "datetime": "2018-06-27 16:43:45", "author": "@faw114"}, "1011995386049978371": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "21", "datetime": "2018-06-27 15:31:16", "author": "@new_rinat"}, "1011865164809990144": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "321", "datetime": "2018-06-27 06:53:49", "author": "@Soria_Emilio"}, "1012905261630029825": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "533", "datetime": "2018-06-30 03:46:47", "author": "@open_shota_ngym"}, "1012947904737173506": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "249", "datetime": "2018-06-30 06:36:14", "author": "@mshero_y"}, "1011625786296676353": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "449", "datetime": "2018-06-26 15:02:37", "author": "@michalwols"}, "1011599497670135808": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "161", "datetime": "2018-06-26 13:18:09", "author": "@farhanhubble"}, "1011657586800656385": {"content_summary": "This is amazing! https://t.co/PRtPLgnoAj", "followers": "120", "datetime": "2018-06-26 17:08:59", "author": "@SumitBinnani"}, "1011927738955911168": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "35", "datetime": "2018-06-27 11:02:28", "author": "@hollischao"}, "1013044622107410432": {"content_summary": "RT @hillbig: For efficient network architecture search with gradient information, they propose to use softmax relaxation to select the oper\u2026", "followers": "129", "datetime": "2018-06-30 13:00:34", "author": "@FlussThaya"}, "1021816079386124289": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "315", "datetime": "2018-07-24 17:55:12", "author": "@RyutaroT92"}, "1011793544133177345": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "49", "datetime": "2018-06-27 02:09:13", "author": "@mishig25"}, "1011660637288554496": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "152", "datetime": "2018-06-26 17:21:06", "author": "@felixdacaat454"}, "1011667027306647552": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "6", "datetime": "2018-06-26 17:46:29", "author": "@fr47123"}, "1014558197020004352": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "8", "datetime": "2018-07-04 17:14:58", "author": "@KumarMalaiya"}, "1011758379721678850": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "121", "datetime": "2018-06-26 23:49:29", "author": "@mktozk"}, "1011685755498975232": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "83", "datetime": "2018-06-26 19:00:54", "author": "@RangnekarAneesh"}, "1011696089043554304": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "152", "datetime": "2018-06-26 19:41:58", "author": "@alirg1"}, "1014873074204921856": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "46", "datetime": "2018-07-05 14:06:10", "author": "@davidbarbera9"}, "1011654330238341120": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "249", "datetime": "2018-06-26 16:56:02", "author": "@olgunaydinn"}, "1011658247953006593": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "125", "datetime": "2018-06-26 17:11:36", "author": "@srv_m"}, "1011643503615414273": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "147", "datetime": "2018-06-26 16:13:01", "author": "@TakeshiHase"}, "1012734131376013312": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "3,243", "datetime": "2018-06-29 16:26:47", "author": "@yellowshippo"}, "1011629754686959616": {"content_summary": "RT @mundt_martin: More nice work on deep neural network architecture search. Thanks to the authors for a great out of the box working #Py\u2026", "followers": "75", "datetime": "2018-06-26 15:18:23", "author": "@JyothirAditya5"}, "1013022142982574082": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "147", "datetime": "2018-06-30 11:31:14", "author": "@TakeshiHase"}, "1011865968883224576": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "19", "datetime": "2018-06-27 06:57:01", "author": "@AVSave"}, "1011761984050728963": {"content_summary": "'Kenreisman/machine-learning' Top: [1806.09055] DARTS: Differentiable Architect\u2026 https://t.co/FAMCEqMllw, see more https://t.co/VAU8peuLvN", "followers": "950", "datetime": "2018-06-27 00:03:49", "author": "@anitayorker"}, "1011698103504818176": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "24", "datetime": "2018-06-26 19:49:58", "author": "@paveltropin"}, "1011922411489460225": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "188", "datetime": "2018-06-27 10:41:18", "author": "@AIWorksBot"}, "1011589865778106368": {"content_summary": "RT @kchonyc: very nice! https://t.co/J6aUQWly2s", "followers": "17", "datetime": "2018-06-26 12:39:53", "author": "@andybaoxv"}, "1011900215379410944": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "167", "datetime": "2018-06-27 09:13:06", "author": "@Planning203"}, "1011918382231240705": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "1,171", "datetime": "2018-06-27 10:25:17", "author": "@kibo35"}, "1012544289316827136": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "408", "datetime": "2018-06-29 03:52:25", "author": "@A_Ym"}, "1012057261659869185": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "425", "datetime": "2018-06-27 19:37:08", "author": "@jsb_solis"}, "1012655493347606528": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "172", "datetime": "2018-06-29 11:14:18", "author": "@myjn_alphage"}, "1011775920187871232": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "317", "datetime": "2018-06-27 00:59:11", "author": "@teenvan1995"}, "1011733320458121216": {"content_summary": "\uc6b0\uc640~ https://t.co/yqhnyFaL5d", "followers": "142", "datetime": "2018-06-26 22:09:55", "author": "@loveiori"}, "1011975708514512896": {"content_summary": "DARTS: Differentiable Architecture Search \u3053\u306e\u30a2\u30a4\u30c7\u30a2\u3001\u30b7\u30f3\u30d7\u30eb\u3067\u3059\u3054\u3044\u3002 https://t.co/jNsrOqmFeH", "followers": "342", "datetime": "2018-06-27 14:13:05", "author": "@koumeitomida"}, "1011790008343134208": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "198", "datetime": "2018-06-27 01:55:10", "author": "@omar_javd"}, "1011821454847930369": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "9", "datetime": "2018-06-27 04:00:08", "author": "@MengWei29252169"}, "1012796217045209089": {"content_summary": "RT @antor: Deep learning que hace su propio deep learning: por ahora no es m\u00e1s que b\u00fasqueda m\u00e1s o menos guiada (a veces poco) para encontra\u2026", "followers": "746", "datetime": "2018-06-29 20:33:29", "author": "@navarroangel"}, "1011869931816849408": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "89", "datetime": "2018-06-27 07:12:46", "author": "@oguked"}, "1011726927604809728": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "262", "datetime": "2018-06-26 21:44:31", "author": "@tbmihaylov"}, "1011692829859565568": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,583", "datetime": "2018-06-26 19:29:01", "author": "@JeanKossaifi"}, "1045571909436334086": {"content_summary": "RT @imenurok: SNAS: stochastic neural architecture search https://t.co/dfYL7C6ka7 DARTS\u306eLiu et al.\u306e\u5f8c\u7d9a\u7814\u7a76\u306e\u4e88\u611f\u304c\u3059\u308b\u3002 https://t.co/kTcrdwzH2u", "followers": "4,615", "datetime": "2018-09-28 07:12:23", "author": "@HITStales"}, "1011696067694473217": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "181", "datetime": "2018-06-26 19:41:53", "author": "@laviavigdor"}, "1011941819591090176": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "307", "datetime": "2018-06-27 11:58:25", "author": "@shehriih"}, "1011866146763571200": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "145", "datetime": "2018-06-27 06:57:43", "author": "@esvhd"}, "1012004687485079552": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "13,631", "datetime": "2018-06-27 16:08:14", "author": "@s7ephen"}, "1012741143971356672": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "512", "datetime": "2018-06-29 16:54:39", "author": "@shadow_jp"}, "1011703948665872384": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "162", "datetime": "2018-06-26 20:13:12", "author": "@lasleandro"}, "1011897487089651712": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "295,998", "datetime": "2018-06-27 09:02:15", "author": "@DeepMindAI"}, "1011696629433491461": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "28", "datetime": "2018-06-26 19:44:07", "author": "@Mouatez"}, "1013223714626756608": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,825", "datetime": "2018-07-01 00:52:13", "author": "@prototechno"}, "1012173493536878592": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "11", "datetime": "2018-06-28 03:19:00", "author": "@yeh_terrence"}, "1012808146442584064": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "6", "datetime": "2018-06-29 21:20:53", "author": "@abhijeetbhorkar"}, "1011836234807721984": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,633", "datetime": "2018-06-27 04:58:52", "author": "@xiangrenUSC"}, "1013070818299920384": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "99", "datetime": "2018-06-30 14:44:39", "author": "@npe_tokyo"}, "1011717717995515904": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "78", "datetime": "2018-06-26 21:07:55", "author": "@jordi_delatorre"}, "1012314485686538243": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "1,667", "datetime": "2018-06-28 12:39:15", "author": "@Scaled_Wurm"}, "1011997249256198146": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "252", "datetime": "2018-06-27 15:38:40", "author": "@hAlmudarra"}, "1013027344057974784": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "3,745", "datetime": "2018-06-30 11:51:54", "author": "@Nao_u_"}, "1011966483423850496": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "243", "datetime": "2018-06-27 13:36:25", "author": "@JaiyamSharma"}, "1011632169356288001": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "31", "datetime": "2018-06-26 15:27:59", "author": "@koenboeckx"}, "1012786022336352257": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "91", "datetime": "2018-06-29 19:52:59", "author": "@dalcimar"}, "1011603083086921732": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "165", "datetime": "2018-06-26 13:32:24", "author": "@saar_ahy"}, "1012007889420996609": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "553", "datetime": "2018-06-27 16:20:57", "author": "@omgjjd"}, "1012833132804911104": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,365", "datetime": "2018-06-29 23:00:11", "author": "@akinori_ito"}, "1011803468141506561": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "135", "datetime": "2018-06-27 02:48:39", "author": "@Chitsthemadness"}, "1013062204814340096": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "7", "datetime": "2018-06-30 14:10:26", "author": "@Mani20734381"}, "1011729084915712000": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "51", "datetime": "2018-06-26 21:53:05", "author": "@r3dst4r_ms"}, "1011680799488438273": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "128", "datetime": "2018-06-26 18:41:13", "author": "@bazile"}, "1011867606326882304": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "74", "datetime": "2018-06-27 07:03:31", "author": "@aayushmaann"}, "1022762076366954497": {"content_summary": "\"DARTS: Differentiable Architecture Search\" - a reasonably fast way to search for a successful neural network architecture, using gradient descent https://t.co/KZpN9xz6UU", "followers": "149", "datetime": "2018-07-27 08:34:15", "author": "@Octavian_ai"}, "1011732641412939777": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,070", "datetime": "2018-06-26 22:07:13", "author": "@Pvalsfr"}, "1011697755155255296": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "14,059", "datetime": "2018-06-26 19:48:35", "author": "@_rockt"}, "1011708055069843457": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "23", "datetime": "2018-06-26 20:29:31", "author": "@ThinklabAI"}, "1012944526787297282": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "717", "datetime": "2018-06-30 06:22:49", "author": "@rashude1"}, "1012024055216656384": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "85", "datetime": "2018-06-27 17:25:11", "author": "@Neatware"}, "1011475690242428928": {"content_summary": "RT @Miles_Brundage: \"DARTS: Differentiable Architecture Search,\" Liu et al.: https://t.co/qixqxtY8BN", "followers": "1,288", "datetime": "2018-06-26 05:06:11", "author": "@heghbalz"}, "1011861526679097344": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "4,891", "datetime": "2018-06-27 06:39:22", "author": "@IgorCarron"}, "1025251690331758592": {"content_summary": "RT @davilagrau: Interesting! Improving image classification, finding convolutional architectures with reinforcement learning https://t.co/N\u2026", "followers": "925", "datetime": "2018-08-03 05:27:05", "author": "@aabedraba"}, "1011939580994416641": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "216", "datetime": "2018-06-27 11:49:31", "author": "@KSKSKSKS2"}, "1012674210613694464": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "653", "datetime": "2018-06-29 12:28:41", "author": "@fukutax"}, "1011906449939795968": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "210", "datetime": "2018-06-27 09:37:52", "author": "@MihaelFeldman"}, "1026474642050048000": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "232", "datetime": "2018-08-06 14:26:40", "author": "@sunw37"}, "1012599710744363008": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,456", "datetime": "2018-06-29 07:32:38", "author": "@jinbeizame007"}, "1011688202766147584": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "547", "datetime": "2018-06-26 19:10:38", "author": "@Butlerjustin"}, "1013026955766030340": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "459", "datetime": "2018-06-30 11:50:22", "author": "@so_ym_kg"}, "1011802414398070785": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "54", "datetime": "2018-06-27 02:44:28", "author": "@jsdelfino"}, "1013031170253025280": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "18", "datetime": "2018-06-30 12:07:06", "author": "@kaerucar"}, "1012714460652318721": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "403", "datetime": "2018-06-29 15:08:37", "author": "@SF_yomi"}, "1011686997700689920": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "30", "datetime": "2018-06-26 19:05:51", "author": "@fanyangxyz"}, "1012360886147837953": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,795", "datetime": "2018-06-28 15:43:38", "author": "@__ice9"}, "1012931628199337985": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "9", "datetime": "2018-06-30 05:31:34", "author": "@tolin_tolin"}, "1011691223130759168": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "413", "datetime": "2018-06-26 19:22:38", "author": "@ThomasBoquet"}, "1011925096410124289": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "304", "datetime": "2018-06-27 10:51:58", "author": "@flrgsr"}, "1012015028478750720": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "70,485", "datetime": "2018-06-27 16:49:19", "author": "@bbriniotis"}, "1011817393688121344": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "271", "datetime": "2018-06-27 03:43:59", "author": "@devingoodsell"}, "1011802378620715008": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "512", "datetime": "2018-06-27 02:44:20", "author": "@outlandkarasu"}, "1011680432642035718": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "539", "datetime": "2018-06-26 18:39:45", "author": "@fabiointheuk"}, "1011760648232022016": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,335", "datetime": "2018-06-26 23:58:30", "author": "@rrika9"}, "1121046392003284992": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/bvdTLm8GEe", "followers": "3,501", "datetime": "2019-04-24 13:41:02", "author": "@arxiv_cscl"}, "1011893975387648000": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "40", "datetime": "2018-06-27 08:48:18", "author": "@AlgorLabs"}, "1011822419894591488": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "1,288", "datetime": "2018-06-27 04:03:58", "author": "@heghbalz"}, "1012630245625626624": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "811", "datetime": "2018-06-29 09:33:58", "author": "@lifeslash"}, "1016665982733914112": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "172", "datetime": "2018-07-10 12:50:33", "author": "@bayalis"}, "1012627500650807296": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "49", "datetime": "2018-06-29 09:23:04", "author": "@tw_exception"}, "1011835541627834369": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "66", "datetime": "2018-06-27 04:56:06", "author": "@iamtpb"}, "1012599830126813184": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,482", "datetime": "2018-06-29 07:33:07", "author": "@gongon2018"}, "1011762598650392576": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "29", "datetime": "2018-06-27 00:06:15", "author": "@chenlailin"}, "1011926847855185922": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "9", "datetime": "2018-06-27 10:58:55", "author": "@rajective"}, "1011824729173495808": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "16,813", "datetime": "2018-06-27 04:13:08", "author": "@octonion"}, "1013048737181118464": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/4rituvOto5 Towards automated deep-learning, where the optimum neural network architecture is learned during training #DeepLearning https://t.co/fdANm60nTo", "followers": "1,674", "datetime": "2018-06-30 13:16:55", "author": "@vmirly"}, "1011813175828738048": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "174", "datetime": "2018-06-27 03:27:14", "author": "@ljvmiranda921"}, "1012885519615660032": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/rkRccK2kxw https://t.co/uiGgdUj0Uc", "followers": "512", "datetime": "2018-06-30 02:28:21", "author": "@tmasada"}, "1012899085492187136": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "946", "datetime": "2018-06-30 03:22:15", "author": "@adacola"}, "1012959870574911488": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "19", "datetime": "2018-06-30 07:23:47", "author": "@bharadwajymg"}, "1011829691127336965": {"content_summary": "This could be huge - efficient architecture search will be critical if we want to get ML systems into production and delivering value quickly https://t.co/1SSoVM24UR", "followers": "523", "datetime": "2018-06-27 04:32:51", "author": "@bensprecher"}, "1046199832614850562": {"content_summary": "RT @imenurok: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u63a2\u7d22\u624b\u2026", "followers": "478", "datetime": "2018-09-30 00:47:32", "author": "@yasuokajihei"}, "1019597991282290688": {"content_summary": "DARTS: Differentiable Architecture Search continuous relaxation of the architecture representation, allowing an efficient search of the architecture using gradient descent https://t.co/iu8lVqLKBc", "followers": "32", "datetime": "2018-07-18 15:01:18", "author": "@jaiaravind4u"}, "1013591471730057216": {"content_summary": "Efficient search of neural network architectures: https://t.co/IvlXVRs3xl Gradients are the key :)", "followers": "180", "datetime": "2018-07-02 01:13:33", "author": "@chetvil"}, "1011682120023068672": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "10", "datetime": "2018-06-26 18:46:28", "author": "@egerds"}, "1011940000722632704": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "226", "datetime": "2018-06-27 11:51:11", "author": "@kurochan1222"}, "1012946071587360769": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "521", "datetime": "2018-06-30 06:28:57", "author": "@metasemantic"}, "1011730913485578240": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "517", "datetime": "2018-06-26 22:00:21", "author": "@AlexYTimia"}, "1011868127452385280": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,169", "datetime": "2018-06-27 07:05:35", "author": "@udemeudofia"}, "1011754300853239808": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "145", "datetime": "2018-06-26 23:33:17", "author": "@m_ishimu"}, "1011919675482140673": {"content_summary": "[1806.09055] DARTS: Differentiable Architecture Search https://t.co/H9WfxoS7BK \u3053\u308c\uff0c\u8aad\u3093\u3060\u3089\u9762\u767d\u304b\u3063\u305f\u3057\uff0cPyTorch\u5b9f\u88c5\u3082\u52d5\u304b\u3057\u3066\u76ee\u304b\u3089\u9c57\u7cfb\u306a\u306e\u3067\uff0c\u6a5f\u4f1a\u304c\u3042\u3063\u305f\u3089\u3069\u3053\u304b\u3067\u767a\u8868\u3057\u305f\u3044\u6c17\u6301\u3061\u304c\u3067\u3066\u304d\u307e\u3057\u305f\uff0e", "followers": "11,766", "datetime": "2018-06-27 10:30:25", "author": "@yutakashino"}, "1011750217601859584": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "145", "datetime": "2018-06-26 23:17:03", "author": "@m_ishimu"}, "1011661309140586496": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,141", "datetime": "2018-06-26 17:23:46", "author": "@arvind_io"}, "1011982509683269632": {"content_summary": "RT @koumeitomida: DARTS: Differentiable Architecture Search \u3053\u306e\u30a2\u30a4\u30c7\u30a2\u3001\u30b7\u30f3\u30d7\u30eb\u3067\u3059\u3054\u3044\u3002 https://t.co/jNsrOqmFeH", "followers": "12,765", "datetime": "2018-06-27 14:40:06", "author": "@jaguring1"}, "1012803119409967106": {"content_summary": "RT @StatMLPapers: DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/ZWtzZkipuF", "followers": "9", "datetime": "2018-06-29 21:00:55", "author": "@lostujjwal"}, "1012935088563150850": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "599", "datetime": "2018-06-30 05:45:19", "author": "@VentArgente"}, "1011702636603674624": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "629", "datetime": "2018-06-26 20:07:59", "author": "@oshtim"}, "1011714896499798016": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "304", "datetime": "2018-06-26 20:56:42", "author": "@sebastien_wood"}, "1011718699257155586": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "85", "datetime": "2018-06-26 21:11:49", "author": "@Johanfx"}, "1012038912498454531": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "518", "datetime": "2018-06-27 18:24:14", "author": "@313V"}, "1011996734283644933": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "72", "datetime": "2018-06-27 15:36:38", "author": "@nigefong"}, "1015483901093920768": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "18", "datetime": "2018-07-07 06:33:23", "author": "@SladeGrantham"}, "1207494481592766465": {"content_summary": "RT @PMinervini: @narges_razavian @kchonyc At a first glance I though it was about https://t.co/mxTMBg71QY!", "followers": "0", "datetime": "2019-12-19 02:54:53", "author": "@Sam09lol"}, "1011769962669568000": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "44", "datetime": "2018-06-27 00:35:31", "author": "@howardmeng"}, "1068513531757240320": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "559", "datetime": "2018-11-30 14:34:12", "author": "@JayChance5"}, "1012048477419814913": {"content_summary": "one of the best AutoML papers this year. Amazingly clean and powerful. https://t.co/Nd7obcA8UN", "followers": "113", "datetime": "2018-06-27 19:02:14", "author": "@TallNeuralNet"}, "1013028314603114496": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "528", "datetime": "2018-06-30 11:55:46", "author": "@u1nakano"}, "1012578342657089536": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "71", "datetime": "2018-06-29 06:07:44", "author": "@rickyofmontay"}, "1011744007867830273": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "63", "datetime": "2018-06-26 22:52:23", "author": "@Little__Boat"}, "1013050645346168833": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "203", "datetime": "2018-06-30 13:24:30", "author": "@konilovsky"}, "1011618199677239296": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,215", "datetime": "2018-06-26 14:32:28", "author": "@devnag"}, "1012615071225090048": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "603", "datetime": "2018-06-29 08:33:41", "author": "@Yoshi_DD"}, "1012922375799619585": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "533", "datetime": "2018-06-30 04:54:48", "author": "@KAZUMUSI"}, "1011654478196543490": {"content_summary": "https://t.co/vIbC6hJFsA This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner.", "followers": "2,338", "datetime": "2018-06-26 16:56:37", "author": "@aileengemma"}, "1012648208412151811": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "40", "datetime": "2018-06-29 10:45:21", "author": "@The_Anig"}, "1011637407702081538": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "85", "datetime": "2018-06-26 15:48:47", "author": "@minhpham"}, "1011897511840309249": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/QX8Ar4gJ8s", "followers": "196", "datetime": "2018-06-27 09:02:21", "author": "@luckflow"}, "1011768925976080384": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "28", "datetime": "2018-06-27 00:31:24", "author": "@sxzou"}, "1012933853084696576": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "967", "datetime": "2018-06-30 05:40:24", "author": "@gstypenov"}, "1011436190581473280": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "353", "datetime": "2018-06-26 02:29:14", "author": "@shikihuton"}, "1011844197798690816": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "38", "datetime": "2018-06-27 05:30:30", "author": "@experiencor"}, "1011760257280901120": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "67", "datetime": "2018-06-26 23:56:57", "author": "@the_Chojnacki"}, "1026855129339682816": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "5", "datetime": "2018-08-07 15:38:35", "author": "@nqhuyptit"}, "1011953024158355456": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "1,377", "datetime": "2018-06-27 12:42:56", "author": "@Yazanator"}, "1011791505449766913": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "783", "datetime": "2018-06-27 02:01:07", "author": "@muktabh"}, "1011857198966767616": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "14", "datetime": "2018-06-27 06:22:10", "author": "@emanpleb"}, "1011732320032702464": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "247", "datetime": "2018-06-26 22:05:56", "author": "@KazuyaUjihara"}, "1011621390510780420": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "143", "datetime": "2018-06-26 14:45:09", "author": "@n_kats_"}, "1011907257158848515": {"content_summary": "#DARTS - Differentiable Architecture Search The scalability challenge of architecture search by formulating the task in a differentiable manner. \u2728https://t.co/I4cqTskciA @HubBucket, @HubDataScience, @HubAnalysis1 #DataScience, #MachineLearning, #DeepLe", "followers": "5,315", "datetime": "2018-06-27 09:41:05", "author": "@HubBucket"}, "1011871042950836224": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "590", "datetime": "2018-06-27 07:17:10", "author": "@codekee"}, "1012562574171201536": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "471", "datetime": "2018-06-29 05:05:04", "author": "@daytb_twy"}, "1011927424920154112": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "47", "datetime": "2018-06-27 11:01:13", "author": "@hrirkslab"}, "1016007540516126722": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "268", "datetime": "2018-07-08 17:14:08", "author": "@sc_codeUM"}, "1011793384690905088": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "260", "datetime": "2018-06-27 02:08:35", "author": "@kevinbolding"}, "1012867938435469312": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "43", "datetime": "2018-06-30 01:18:29", "author": "@freedial_dev"}, "1012841811570614272": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,051", "datetime": "2018-06-29 23:34:40", "author": "@niszet0"}, "1011682439025119232": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "37,494", "datetime": "2018-06-26 18:47:44", "author": "@sedielem"}, "1011629692661559296": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,670", "datetime": "2018-06-26 15:18:08", "author": "@ayirpelle"}, "1013034614787469313": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "91", "datetime": "2018-06-30 12:20:48", "author": "@shunEnshuu"}, "1012713917557030914": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,050", "datetime": "2018-06-29 15:06:27", "author": "@termoshtt"}, "1011721770125152256": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "76,883", "datetime": "2018-06-26 21:24:01", "author": "@NandoDF"}, "1012548869589065728": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "2,861", "datetime": "2018-06-29 04:10:37", "author": "@Tarpon_red2"}, "1011751519333572608": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,213", "datetime": "2018-06-26 23:22:14", "author": "@barbolo"}, "1013770035066822656": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "26", "datetime": "2018-07-02 13:03:05", "author": "@slyat"}, "1012970557254406144": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "470", "datetime": "2018-06-30 08:06:15", "author": "@marukarasu1"}, "1011695298698067968": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "158", "datetime": "2018-06-26 19:38:50", "author": "@yunjingxu"}, "1012094822751096838": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "160", "datetime": "2018-06-27 22:06:24", "author": "@johnmsheffield"}, "1011837382235074560": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "106", "datetime": "2018-06-27 05:03:25", "author": "@_jruales"}, "1012453234412158977": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "16", "datetime": "2018-06-28 21:50:36", "author": "@pro_about_pro"}, "1011942986366767105": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "2,647", "datetime": "2018-06-27 12:03:03", "author": "@Rakawe86"}, "1011710261118431232": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "8", "datetime": "2018-06-26 20:38:17", "author": "@AkshayYesR"}, "1015110395885846530": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "96", "datetime": "2018-07-06 05:49:12", "author": "@uku_peter"}, "1011798136107327488": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "361", "datetime": "2018-06-27 02:27:28", "author": "@jadhavamitb"}, "1011941973975068674": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "5", "datetime": "2018-06-27 11:59:02", "author": "@MJahangeerQ"}, "1013422472853536768": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,213", "datetime": "2018-07-01 14:02:00", "author": "@sampathweb"}, "1011752993975427072": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "130", "datetime": "2018-06-26 23:28:05", "author": "@orlandxrf"}, "1011682170400718849": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "74", "datetime": "2018-06-26 18:46:40", "author": "@aayushmaann"}, "1015145646968303617": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "71", "datetime": "2018-07-06 08:09:17", "author": "@soulwangh"}, "1011695020775280641": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,087", "datetime": "2018-06-26 19:37:43", "author": "@ak1010"}, "1011891230161039360": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "371", "datetime": "2018-06-27 08:37:23", "author": "@hrmoaddeli"}, "1012735209551290368": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2", "datetime": "2018-06-29 16:31:04", "author": "@pohsienliu"}, "1011927609486204928": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "674", "datetime": "2018-06-27 11:01:57", "author": "@hidemotoNakada"}, "1011463667475406848": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "824", "datetime": "2018-06-26 04:18:25", "author": "@morioka"}, "1011881201680838656": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "29", "datetime": "2018-06-27 07:57:32", "author": "@the_firealarm"}, "1011785005259821056": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,766", "datetime": "2018-06-27 01:35:17", "author": "@jaialkdanel"}, "1011712064660869122": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "214", "datetime": "2018-06-26 20:45:27", "author": "@Varal7"}, "1011702444487782403": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "5,505", "datetime": "2018-06-26 20:07:13", "author": "@KaiLashArul"}, "1013126357260255232": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "12", "datetime": "2018-06-30 18:25:21", "author": "@2000Qiu"}, "1012280720658763776": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2", "datetime": "2018-06-28 10:25:05", "author": "@greenmaree"}, "1011869423303446529": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "41", "datetime": "2018-06-27 07:10:44", "author": "@haiyongw"}, "1011847097522454528": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "721", "datetime": "2018-06-27 05:42:01", "author": "@cmarschner"}, "1011937983849738240": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "206", "datetime": "2018-06-27 11:43:10", "author": "@NamiViTo"}, "1011883146709798912": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "263", "datetime": "2018-06-27 08:05:16", "author": "@songyunlu"}, "1011727627759972352": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,670", "datetime": "2018-06-26 21:47:18", "author": "@ayirpelle"}, "1011718336256888832": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "7,074", "datetime": "2018-06-26 21:10:22", "author": "@nsthorat"}, "1012992815087828992": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "851", "datetime": "2018-06-30 09:34:42", "author": "@kuro_7_nyan"}, "1012905532603002880": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "84", "datetime": "2018-06-30 03:47:52", "author": "@sjain_stanford"}, "1011818347514793984": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "71", "datetime": "2018-06-27 03:47:47", "author": "@MatthieuPerrot"}, "1011894743704395778": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "543", "datetime": "2018-06-27 08:51:21", "author": "@wsuzume"}, "1011433487516119040": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u63a2\u7d22\u624b\u6cd5\u304c\u767b\u5834\u3002 \u4e88\u3081\u63a2\u7d22\u5bfe\u8c61\u3068\u306a\u308b\u69cb\u9020\u3092\u5185\u5305\u3057\u3066\u304a\u308a\u3001\u91cd\u307f\u306e\u6700\u9069\u5316\u3068\u69cb\u9020\u306e\u6700\u9069\u5316\u3092\u4ea4\u4e92\u306b\u884c\u3044\u306a\u304c\u3089\u6700\u9069\u306a\u69cb\u9020\u3092\u63a2\u7d22\u3002 https://t.co/Nl5dQKsk6M", "followers": "2,043", "datetime": "2018-06-26 02:18:29", "author": "@dosei_sanga"}, "1011741189152780289": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "186", "datetime": "2018-06-26 22:41:11", "author": "@vamsi_kurama"}, "1012009427002675201": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "553", "datetime": "2018-06-27 16:27:04", "author": "@Madskoefoed"}, "1011818202626654213": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,288", "datetime": "2018-06-27 03:47:12", "author": "@heghbalz"}, "1016784322659958784": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "153", "datetime": "2018-07-10 20:40:48", "author": "@ComplexQubit"}, "1011982646765764608": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "9", "datetime": "2018-06-27 14:40:39", "author": "@spencerpomme"}, "1012543461281558528": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "1,051", "datetime": "2018-06-29 03:49:07", "author": "@niszet0"}, "1012963543547695104": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "4,877", "datetime": "2018-06-30 07:38:23", "author": "@dancing_eel"}, "1012426174050467840": {"content_summary": "RT @dkislyuk: Architecture search field is moving really fast, and I'm fairly convinced it will be a standard component of network design m\u2026", "followers": "410", "datetime": "2018-06-28 20:03:04", "author": "@kgourg"}, "1011829205330485248": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "422", "datetime": "2018-06-27 04:30:56", "author": "@jcvasquezc1"}, "1025123837141282819": {"content_summary": "Top story: [1806.09055] DARTS: Differentiable Architecture Search https://t.co/tI2uFeGHQ2, see more https://t.co/NThubCuiOJ", "followers": "14,497", "datetime": "2018-08-02 20:59:03", "author": "@rautsan"}, "1012876387680768001": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "642", "datetime": "2018-06-30 01:52:03", "author": "@gsiwo"}, "1168439075642064896": {"content_summary": "[1806.09055] DARTS: Differentiable Architecture Search https://t.co/PHS6CN6tOy", "followers": "130", "datetime": "2019-09-02 08:22:38", "author": "@rhira2016"}, "1012903680641662976": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "45", "datetime": "2018-06-30 03:40:30", "author": "@NEBULA8765_e"}, "1013397276927066116": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "3,500", "datetime": "2018-07-01 12:21:53", "author": "@EnrikeLopez"}, "1011735151569559552": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "962", "datetime": "2018-06-26 22:17:11", "author": "@jnhwkim"}, "1011956087459926017": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "37", "datetime": "2018-06-27 12:55:07", "author": "@dgdaudert"}, "1120865129019650050": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/9FpoWDNN9I", "followers": "4,100", "datetime": "2019-04-24 01:40:46", "author": "@arxiv_cscv"}, "1013025608459345920": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "132", "datetime": "2018-06-30 11:45:00", "author": "@Emran_Saleh"}, "1011539074547703809": {"content_summary": "DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relaxation of the search space, and gradient descent their way to top performance in ~1 GPU day! Paper: https://t.co/Bjf8HKu149 Code:", "followers": "3,883", "datetime": "2018-06-26 09:18:03", "author": "@ajmooch"}, "1011656480251002880": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "506", "datetime": "2018-06-26 17:04:35", "author": "@sksq96"}, "1011711978140852224": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "422", "datetime": "2018-06-26 20:45:06", "author": "@zacharynado"}, "1011723963708264448": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "910", "datetime": "2018-06-26 21:32:44", "author": "@Homoronro"}, "1012651851181785090": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "155", "datetime": "2018-06-29 10:59:50", "author": "@Trtd6Trtd"}, "1081449798472032256": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "189", "datetime": "2019-01-05 07:18:18", "author": "@oneinfinitezero"}, "1012956053993021441": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "62", "datetime": "2018-06-30 07:08:37", "author": "@cmas_m78"}, "1012847252769943552": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,409", "datetime": "2018-06-29 23:56:17", "author": "@kagakuma"}, "1011765095527903232": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,946", "datetime": "2018-06-27 00:16:11", "author": "@micahstubbs"}, "1012018317094105088": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "15", "datetime": "2018-06-27 17:02:23", "author": "@tibjoz"}, "1011733115109195776": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "236", "datetime": "2018-06-26 22:09:06", "author": "@x_hexy"}, "1011706212721700864": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "405", "datetime": "2018-06-26 20:22:12", "author": "@SamRNolen"}, "1011437925588799489": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "302", "datetime": "2018-06-26 02:36:07", "author": "@mofumofu1729"}, "1011651813647441921": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "122", "datetime": "2018-06-26 16:46:02", "author": "@_smuddu"}, "1011799514858942464": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,911", "datetime": "2018-06-27 02:32:57", "author": "@agm1984"}, "1011655895338704896": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "15", "datetime": "2018-06-26 17:02:15", "author": "@JadeHelenWei"}, "1011691817627074561": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "10", "datetime": "2018-06-26 19:25:00", "author": "@yarphs"}, "1013905852544118784": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "167", "datetime": "2018-07-02 22:02:47", "author": "@EugeneOskin"}, "1011434997582925824": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "2,456", "datetime": "2018-06-26 02:24:29", "author": "@jinbeizame007"}, "1012638870045773824": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "225", "datetime": "2018-06-29 10:08:15", "author": "@ElectronNest"}, "1013194815973068802": {"content_summary": "Meta learning https://t.co/Rbof2rmE9Z", "followers": "15", "datetime": "2018-06-30 22:57:23", "author": "@ajonatok"}, "1013097553041207296": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "793", "datetime": "2018-06-30 16:30:53", "author": "@StylianosIordan"}, "1011675706445533185": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "916", "datetime": "2018-06-26 18:20:59", "author": "@Tshields44"}, "1011729012065013760": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "3,013", "datetime": "2018-06-26 21:52:48", "author": "@sarahbadr"}, "1012953989632090112": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "130", "datetime": "2018-06-30 07:00:25", "author": "@jkronand"}, "1012169274012549121": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "361", "datetime": "2018-06-28 03:02:14", "author": "@jadhavamitb"}, "1011587287363325952": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,068", "datetime": "2018-06-26 12:29:38", "author": "@emrobSci"}, "1011796274742300672": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,798", "datetime": "2018-06-27 02:20:04", "author": "@cchio"}, "1011719340763172864": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "335", "datetime": "2018-06-26 21:14:22", "author": "@kobi78"}, "1011831865676791808": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "193", "datetime": "2018-06-27 04:41:30", "author": "@thembani_p"}, "1011842768803647490": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "549", "datetime": "2018-06-27 05:24:49", "author": "@El_Dryosa"}, "1012439071229001728": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "13,209", "datetime": "2018-06-28 20:54:19", "author": "@debashis_dutta"}, "1012807381812695040": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "10,251", "datetime": "2018-06-29 21:17:51", "author": "@glenbeer"}, "1011664606882775040": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "516", "datetime": "2018-06-26 17:36:52", "author": "@thruthebckdr"}, "1011949097752948737": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "21", "datetime": "2018-06-27 12:27:20", "author": "@sarathknv"}, "1012596590446383107": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "986", "datetime": "2018-06-29 07:20:14", "author": "@sp4ghet"}, "1165682101590446080": {"content_summary": "\u8aad\u3093\u3067\u3044\u308b - DARTS: Differentiable Architecture Search https://t.co/5hY4DRY9QC", "followers": "797", "datetime": "2019-08-25 17:47:25", "author": "@eagle_raptor"}, "1012983356269588480": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "133", "datetime": "2018-06-30 08:57:07", "author": "@takahashikazuyu"}, "1011582986838519808": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "255", "datetime": "2018-06-26 12:12:33", "author": "@josipK"}, "1025045205567725568": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "8", "datetime": "2018-08-02 15:46:36", "author": "@chkno"}, "1011902273524359168": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "1,467", "datetime": "2018-06-27 09:21:16", "author": "@TommSciortino"}, "1011892807747813376": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "223", "datetime": "2018-06-27 08:43:40", "author": "@kamome01X"}, "1012904890379563009": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "138", "datetime": "2018-06-30 03:45:19", "author": "@kisser_caffe"}, "1012277622796115969": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "115", "datetime": "2018-06-28 10:12:47", "author": "@JLSanchezR"}, "1011624176115802112": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "0", "datetime": "2018-06-26 14:56:13", "author": "@Sam09lol"}, "1012513842209939456": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "845", "datetime": "2018-06-29 01:51:26", "author": "@oxanderv"}, "1196775228912930816": {"content_summary": "@narges_razavian @kchonyc At a first glance I though it was about https://t.co/mxTMBg71QY!", "followers": "1,325", "datetime": "2019-11-19 13:00:24", "author": "@PMinervini"}, "1012588099329642496": {"content_summary": "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u3067\u5b9f\u73fe\u3067\u304d\u308b\uff0e https://t.co/clDD2fmvfd https://t.co/AFt0wMSfrf", "followers": "2,319", "datetime": "2018-06-29 06:46:30", "author": "@ss_shopetan"}, "1011951735554756608": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "23,781", "datetime": "2018-06-27 12:37:49", "author": "@DD_FaFa_"}, "1020330709213474816": {"content_summary": "@wgussml Is there something peculiar with the optimization landscape for the problem of \"finding good priors\" that makes evolution especially suited for this? I haven't watched the field closely but SGD has better sample complexity on architecture search a", "followers": "440", "datetime": "2018-07-20 15:32:52", "author": "@FlorinGogianu"}, "1011436820419055616": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "150", "datetime": "2018-06-26 02:31:44", "author": "@y_yammt"}, "1055480374279589888": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,293", "datetime": "2018-10-25 15:25:05", "author": "@ImNickHuber"}, "1012257431810924544": {"content_summary": "The brutal inclusion of random in the DARTS architecture search paper made me laugh out loud: https://t.co/02UZH7tL1I. Impressed by the authors' diligence in reproduction and comparison! https://t.co/zsTOVAUTAO", "followers": "761", "datetime": "2018-06-28 08:52:33", "author": "@yieldthought"}, "1011912772324642816": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,634", "datetime": "2018-06-27 10:03:00", "author": "@markomanka"}, "1011599684211806208": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "117", "datetime": "2018-06-26 13:18:53", "author": "@Warvito"}, "1012868986755801088": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "665", "datetime": "2018-06-30 01:22:39", "author": "@adelong"}, "1011448369560969217": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "408", "datetime": "2018-06-26 03:17:37", "author": "@A_Ym"}, "1011887790714511360": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "2,662", "datetime": "2018-06-27 08:23:43", "author": "@odbmsorg"}, "1012714401307086848": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "3,177", "datetime": "2018-06-29 15:08:23", "author": "@tjmlab"}, "1012940048591753217": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "61", "datetime": "2018-06-30 06:05:01", "author": "@jjjjjjjjjjjj31"}, "1013034446860083200": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "657", "datetime": "2018-06-30 12:20:08", "author": "@komakusaryama"}, "1011664270310952961": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "247", "datetime": "2018-06-26 17:35:32", "author": "@deeplearningret"}, "1011735104501116931": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "102", "datetime": "2018-06-26 22:17:00", "author": "@liseos_x140"}, "1011869833447665664": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "13", "datetime": "2018-06-27 07:12:22", "author": "@CvRocker_XuJian"}, "1011769966389915649": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,043", "datetime": "2018-06-27 00:35:32", "author": "@dosei_sanga"}, "1011666450027859968": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "299", "datetime": "2018-06-26 17:44:12", "author": "@westis96"}, "1012760501154086914": {"content_summary": "Deep learning que hace su propio deep learning: por ahora no es m\u00e1s que b\u00fasqueda m\u00e1s o menos guiada (a veces poco) para encontrar redes que funcionen bien. No obstante la m\u00e1s eficiente requiere hoy unos 7 meses con una GPU para encontrar una buena red. htt", "followers": "6,647", "datetime": "2018-06-29 18:11:34", "author": "@antor"}, "1012915011105067008": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "29", "datetime": "2018-06-30 04:25:32", "author": "@metaforce_"}, "1011792535415504896": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,654", "datetime": "2018-06-27 02:05:13", "author": "@brextonpham"}, "1011912602799296513": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "44", "datetime": "2018-06-27 10:02:19", "author": "@Dr_Orobosa"}, "1012030403602014208": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,329", "datetime": "2018-06-27 17:50:25", "author": "@rcalsaverini"}, "1108949448640454656": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "4,130", "datetime": "2019-03-22 04:32:06", "author": "@hayashiyus"}, "1012654880329170946": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,171", "datetime": "2018-06-29 11:11:52", "author": "@kibo35"}, "1013032758321373184": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "512", "datetime": "2018-06-30 12:13:25", "author": "@outlandkarasu"}, "1012943014317023232": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "936", "datetime": "2018-06-30 06:16:48", "author": "@496_"}, "1011723182431014912": {"content_summary": "RT @tarantulae: Very cool approach for relaxing the categorical choice of operations. DARTS (https://t.co/wgWwQ9QRCe). https://t.co/ozKSxtl\u2026", "followers": "28,418", "datetime": "2018-06-26 21:29:38", "author": "@ogrisel"}, "1011687918170230788": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "485", "datetime": "2018-06-26 19:09:30", "author": "@_LMiguel"}, "1011596659221032961": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,092", "datetime": "2018-06-26 13:06:52", "author": "@ok_mozy"}, "1011693859871645699": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "205", "datetime": "2018-06-26 19:33:07", "author": "@atomobianco"}, "1013415681931522048": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "35", "datetime": "2018-07-01 13:35:01", "author": "@sebszyller"}, "1012046721436790790": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "218", "datetime": "2018-06-27 18:55:15", "author": "@moezbac"}, "1011596331154960384": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "81,490", "datetime": "2018-06-26 13:05:34", "author": "@hardmaru"}, "1011670291553181701": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "172", "datetime": "2018-06-26 17:59:28", "author": "@FerranDiego"}, "1013469872431468544": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "416", "datetime": "2018-07-01 17:10:21", "author": "@rickybennesby"}, "1011956381623054336": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "21", "datetime": "2018-06-27 12:56:17", "author": "@JohnHanyCN"}, "1011975924764553218": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "1,304", "datetime": "2018-06-27 14:13:56", "author": "@rad2015"}, "1012165248218890242": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "228", "datetime": "2018-06-28 02:46:14", "author": "@hengcherkeng"}, "1013022028193062913": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "3", "datetime": "2018-06-30 11:30:47", "author": "@nkataieva"}, "1012004979803123713": {"content_summary": "RT @Miles_Brundage: \"DARTS: Differentiable Architecture Search,\" Liu et al.: https://t.co/qixqxtY8BN", "followers": "52", "datetime": "2018-06-27 16:09:23", "author": "@HengjianJia"}, "1011822034001715201": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "22", "datetime": "2018-06-27 04:02:26", "author": "@hrtdate"}, "1045855894100008962": {"content_summary": "RT @imenurok: SNAS: stochastic neural architecture search https://t.co/dfYL7C6ka7 DARTS\u306eLiu et al.\u306e\u5f8c\u7d9a\u7814\u7a76\u306e\u4e88\u611f\u304c\u3059\u308b\u3002 https://t.co/kTcrdwzH2u", "followers": "486", "datetime": "2018-09-29 02:00:50", "author": "@nmygle"}, "1011780728848355328": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "96", "datetime": "2018-06-27 01:18:18", "author": "@A00944076"}, "1011831524663099393": {"content_summary": "RT @LiamFedus: Fully differentiable architecture search! Liu et al. compute a softmax over operators and setup an approx alternating gra\u2026", "followers": "130", "datetime": "2018-06-27 04:40:09", "author": "@prafull7"}, "1011993301421940737": {"content_summary": "[1806.09055] DARTS: Differentiable Architecture Search https://t.co/9qQ0OV3Vo4", "followers": "602", "datetime": "2018-06-27 15:22:59", "author": "@Swall0wTech"}, "1133682888543571968": {"content_summary": "DARTS\u3053\u308c\u304b https://t.co/KGyaZ1Zr6I #MLCT", "followers": "174", "datetime": "2019-05-29 10:33:58", "author": "@fuc6w"}, "1013014335847739392": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "639", "datetime": "2018-06-30 11:00:13", "author": "@konats_showsets"}, "1011976504262066176": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "2,456", "datetime": "2018-06-27 14:16:14", "author": "@jinbeizame007"}, "1011820469832413185": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "1,020", "datetime": "2018-06-27 03:56:13", "author": "@matthew_ashburn"}, "1012618263451217920": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,117", "datetime": "2018-06-29 08:46:22", "author": "@minjinaffa"}, "1011760895876186113": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "219", "datetime": "2018-06-26 23:59:29", "author": "@__phanhoang__"}, "1011871824932687872": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "590", "datetime": "2018-06-27 07:20:17", "author": "@codekee"}, "1013117955473858562": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "24", "datetime": "2018-06-30 17:51:58", "author": "@paveltropin"}, "1012951921051815936": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "230", "datetime": "2018-06-30 06:52:12", "author": "@ErdemPulcu"}, "1012918055049936896": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "20", "datetime": "2018-06-30 04:37:38", "author": "@chong_minsk"}, "1011601141614956544": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "10,282", "datetime": "2018-06-26 13:24:41", "author": "@golbin"}, "1011685613068849152": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "645", "datetime": "2018-06-26 19:00:21", "author": "@ionandrou"}, "1011864756024733696": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "1,613", "datetime": "2018-06-27 06:52:12", "author": "@diegosevilla"}, "1012600021605179393": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "95", "datetime": "2018-06-29 07:33:53", "author": "@summer4an"}, "1011739910385135617": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "82", "datetime": "2018-06-26 22:36:06", "author": "@brugui2304"}, "1012019336524062720": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "323", "datetime": "2018-06-27 17:06:26", "author": "@dnlcrl"}, "1012043076158672896": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "646", "datetime": "2018-06-27 18:40:46", "author": "@gauravssnl"}, "1011752408580489217": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "16", "datetime": "2018-06-26 23:25:46", "author": "@gtb_r3search"}, "1011672852699983872": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "223", "datetime": "2018-06-26 18:09:38", "author": "@posadajd"}, "1011747639203975169": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "23", "datetime": "2018-06-26 23:06:49", "author": "@Srini_freak"}, "1012925411464916992": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "274", "datetime": "2018-06-30 05:06:51", "author": "@siphilia_rn"}, "1011691673489956866": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "91", "datetime": "2018-06-26 19:24:25", "author": "@ManuelSH"}, "1011731322463707136": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,448", "datetime": "2018-06-26 22:01:58", "author": "@dicekicker"}, "1012987749803048960": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "182", "datetime": "2018-06-30 09:14:34", "author": "@s_sangaimatsu"}, "1011546085792206848": {"content_summary": "RT @Miles_Brundage: \"DARTS: Differentiable Architecture Search,\" Liu et al.: https://t.co/qixqxtY8BN", "followers": "456", "datetime": "2018-06-26 09:45:55", "author": "@PerthMLGroup"}, "1011687188310814720": {"content_summary": "This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architecture Search https://t.co/fJbkOMptAr", "followers": "99,929", "datetime": "2018-06-26 19:06:36", "author": "@jeremyphoward"}, "1012713421907742721": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,944", "datetime": "2018-06-29 15:04:29", "author": "@hurutoriya"}, "1011597714201759746": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "110", "datetime": "2018-06-26 13:11:04", "author": "@Raquel1934"}, "1011863125270892544": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "2,120", "datetime": "2018-06-27 06:45:43", "author": "@shanecelis"}, "1011885913134194689": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "24", "datetime": "2018-06-27 08:16:16", "author": "@fainessence"}, "1011700511123394561": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "949", "datetime": "2018-06-26 19:59:32", "author": "@m_deff"}, "1120851721289379842": {"content_summary": "https://t.co/slQb1Y9nJw DARTS: Differentiable Architecture Search. (arXiv:1806.09055v2 [cs.LG] UPDATED) #NLProc", "followers": "4,200", "datetime": "2019-04-24 00:47:29", "author": "@arxiv_cs_cl"}, "1012875002318733312": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "302", "datetime": "2018-06-30 01:46:33", "author": "@mofumofu1729"}, "1011722430564438017": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,846", "datetime": "2018-06-26 21:26:38", "author": "@carlosGCMS"}, "1012897261175517185": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "783", "datetime": "2018-06-30 03:15:00", "author": "@K_Ryuichirou"}, "1012848081807671296": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "841", "datetime": "2018-06-29 23:59:35", "author": "@a2uky"}, "1012579521764184064": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "354", "datetime": "2018-06-29 06:12:25", "author": "@indy9000"}, "1012918324353589248": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "199", "datetime": "2018-06-30 04:38:42", "author": "@satou30"}, "1011732110552363009": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,483", "datetime": "2018-06-26 22:05:06", "author": "@mikestrattonNET"}, "1012290532414910464": {"content_summary": "@RebelScience FYI https://t.co/vo2InxKZYz", "followers": "25", "datetime": "2018-06-28 11:04:05", "author": "@pao_meng"}, "1011948587993858050": {"content_summary": "DARTS: Differentiable Architecture Search continuous relaxation of the architecture representation, allowing an efficient search of the architecture using gradient descent https://t.co/zAKZRgEGZy https://t.co/X3XcMohkjC", "followers": "24", "datetime": "2018-06-27 12:25:19", "author": "@RishuSharma2"}, "1011893588727222272": {"content_summary": "For efficient network architecture search with gradient information, they propose to use softmax relaxation to select the operation for each unit and use the validation loss after the single step of SGD as the objective function. https://t.co/djE5PJAjgS", "followers": "18,231", "datetime": "2018-06-27 08:46:46", "author": "@hillbig"}, "1011714364813045762": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "274", "datetime": "2018-06-26 20:54:35", "author": "@mir_k"}, "1011658596432728065": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,160", "datetime": "2018-06-26 17:12:59", "author": "@_ambodi"}, "1011901082598068229": {"content_summary": "#DARTS - Differentiable Architecture Search The scalability challenge of architecture search by formulating the task in a differentiable manner. \u2728https://t.co/y2LWhhYfik @HubBucket, @HubDataScience, @HubAnalysis1 #DataScience, #MachineLearning, #DeepLe", "followers": "11,931", "datetime": "2018-06-27 09:16:32", "author": "@Rosenchild"}, "1011605295242588162": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "283", "datetime": "2018-06-26 13:41:11", "author": "@njwfish"}, "1011702117541675008": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "70,485", "datetime": "2018-06-26 20:05:55", "author": "@bbriniotis"}, "1121167065207828480": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/bvdTLlR5fE", "followers": "3,501", "datetime": "2019-04-24 21:40:33", "author": "@arxiv_cscl"}, "1011786049935196165": {"content_summary": "Hopefully, a game changer. https://t.co/qLacHNh5Hi", "followers": "160", "datetime": "2018-06-27 01:39:27", "author": "@Foivos_Diak"}, "1011933426377805824": {"content_summary": "\u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0629 \u0628\u0634\u0643\u0644 \u0622\u0644\u064a. \u0648\u064a\u0639\u062a\u0628\u0631 \u062e\u0637\u0648\u0629 \u0645\u0647\u0645\u0629 \u0644\u0623\u062a\u0645\u062a\u0629 \u062a\u0639\u0644\u0645 \u0627\u0644\u0622\u0644\u0629\u060c \u0623\u0648 \u0645\u0627 \u064a\u0637\u0644\u0642 \u0639\u0644\u064a\u0647 AutoML. https://t.co/9wK01jYMXE", "followers": "20,877", "datetime": "2018-06-27 11:25:04", "author": "@qunaieer"}, "1011713226457874432": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "38", "datetime": "2018-06-26 20:50:04", "author": "@AIWithAttitude"}, "1011676541309411328": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "331", "datetime": "2018-06-26 18:24:18", "author": "@philomate"}, "1012854035450171393": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "681", "datetime": "2018-06-30 00:23:14", "author": "@Chu_pan"}, "1011656805993406465": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "22,788", "datetime": "2018-06-26 17:05:52", "author": "@dotCSV"}, "1011947326045224961": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "115", "datetime": "2018-06-27 12:20:18", "author": "@skywindtalker"}, "1013013769897689089": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,530", "datetime": "2018-06-30 10:57:58", "author": "@SJ_PROJECT"}, "1045849442346094592": {"content_summary": "RT @imenurok: SNAS: stochastic neural architecture search https://t.co/dfYL7C6ka7 DARTS\u306eLiu et al.\u306e\u5f8c\u7d9a\u7814\u7a76\u306e\u4e88\u611f\u304c\u3059\u308b\u3002 https://t.co/kTcrdwzH2u", "followers": "231", "datetime": "2018-09-29 01:35:12", "author": "@aiskoaskosd"}, "1013402399422205952": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,371", "datetime": "2018-07-01 12:42:14", "author": "@Ourghanlian"}, "1012885031746822144": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "68", "datetime": "2018-06-30 02:26:24", "author": "@prpr_akachuki"}, "1011948674685939712": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "45", "datetime": "2018-06-27 12:25:39", "author": "@nullbytep"}, "1011658766251683841": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "22", "datetime": "2018-06-26 17:13:40", "author": "@Tsingggg"}, "1158966594682286080": {"content_summary": "@karanchahal96 @quocleix Hi Karanbir, AutoML has evolved: recent algorithms (such as DARTS https://t.co/qfH1rcXymV) can finish a search in a couple of GPU hours.", "followers": "768", "datetime": "2019-08-07 05:02:23", "author": "@tanmingxing"}, "1013001183760269312": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "776", "datetime": "2018-06-30 10:07:57", "author": "@rail_ya"}, "1011586344060059648": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "5,089", "datetime": "2018-06-26 12:25:53", "author": "@ankurhandos"}, "1011723853851254785": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "3", "datetime": "2018-06-26 21:32:18", "author": "@brentkomer"}, "1011767520141852672": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "661", "datetime": "2018-06-27 00:25:49", "author": "@mimoralea"}, "1013217664112553984": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "65", "datetime": "2018-07-01 00:28:10", "author": "@maestroderek"}, "1020167173027713026": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "12,765", "datetime": "2018-07-20 04:43:02", "author": "@jaguring1"}, "1011566830849286144": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "53", "datetime": "2018-06-26 11:08:21", "author": "@AMaknickas"}, "1011896869277061120": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "9", "datetime": "2018-06-27 08:59:48", "author": "@Yuvraj_Domun_"}, "1011550496484708352": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "920", "datetime": "2018-06-26 10:03:26", "author": "@KloudStrife"}, "1011906462128336896": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "3,530", "datetime": "2018-06-27 09:37:55", "author": "@kazuoyano"}, "1011993664602558464": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "264", "datetime": "2018-06-27 15:24:26", "author": "@ShanbhagMahesh"}, "1011769260094337024": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "99", "datetime": "2018-06-27 00:32:44", "author": "@treasured_write"}, "1011884105481547776": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "635", "datetime": "2018-06-27 08:09:05", "author": "@lievAnastazia"}, "1011982863439237121": {"content_summary": "RT @yutakashino: [1806.09055] DARTS: Differentiable Architecture Search https://t.co/H9WfxoS7BK \u3053\u308c\uff0c\u8aad\u3093\u3060\u3089\u9762\u767d\u304b\u3063\u305f\u3057\uff0cPyTorch\u5b9f\u88c5\u3082\u52d5\u304b\u3057\u3066\u76ee\u304b\u3089\u9c57\u7cfb\u306a\u306e\u3067\uff0c\u6a5f\u4f1a\u304c\u3042\u3063\u305f\u2026", "followers": "82", "datetime": "2018-06-27 14:41:31", "author": "@RyoHWS"}, "1011977219219120129": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2", "datetime": "2018-06-27 14:19:05", "author": "@nanenaro"}, "1012099289730781184": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "189", "datetime": "2018-06-27 22:24:09", "author": "@tnarihi"}, "1011598415883620352": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "477", "datetime": "2018-06-26 13:13:51", "author": "@NKPyo"}, "1011901598682042370": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "212", "datetime": "2018-06-27 09:18:36", "author": "@manuel_lmartin"}, "1011935224631037954": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "89", "datetime": "2018-06-27 11:32:13", "author": "@Rajeevr71956401"}, "1012908568062746626": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,352", "datetime": "2018-06-30 03:59:56", "author": "@cocoatomo"}, "1012910614753234946": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "3,152", "datetime": "2018-06-30 04:08:04", "author": "@1amageek"}, "1012662661044056065": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "945", "datetime": "2018-06-29 11:42:47", "author": "@30eesti"}, "1011628284424130566": {"content_summary": "More nice work on deep neural network architecture search. Thanks to the authors for a great out of the box working #PyTorch code too! (says version 0.3 but also seems to work with 0.4). Excited to steadily be going towards less manually designed deep", "followers": "600", "datetime": "2018-06-26 15:12:32", "author": "@mundt_martin"}, "1012990469746364416": {"content_summary": "\ud83e\udd16 DARTS: Differentiable Architecture Search \u270d\ufe0f Hanxiao Liu et al. \ud83d\udd17 https://t.co/fuknL5PsAD \ud83d\udd0a Tweeted by @OriolVinyalsML et al. #Learning #csLG #csCL #csCV #statML https://t.co/JEPFt6Ind5", "followers": "311", "datetime": "2018-06-30 09:25:23", "author": "@arxivtrends"}, "1011815066327371776": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "169", "datetime": "2018-06-27 03:34:45", "author": "@tofugranola"}, "1011670885793660928": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "40", "datetime": "2018-06-26 18:01:49", "author": "@GuocanShang"}, "1011766362702659584": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,607", "datetime": "2018-06-27 00:21:13", "author": "@tereka114"}, "1011727513712619520": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "90,659", "datetime": "2018-06-26 21:46:50", "author": "@stanfordnlp"}, "1011871401106657281": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "48", "datetime": "2018-06-27 07:18:36", "author": "@ThingsReallyR"}, "1045571153434095617": {"content_summary": "SNAS: stochastic neural architecture search https://t.co/dfYL7C6ka7 DARTS\u306eLiu et al.\u306e\u5f8c\u7d9a\u7814\u7a76\u306e\u4e88\u611f\u304c\u3059\u308b\u3002 https://t.co/kTcrdwzH2u", "followers": "2,043", "datetime": "2018-09-28 07:09:23", "author": "@imenurok"}, "1011789884573585410": {"content_summary": "Uno de los papers que espero tener el tiempo de leer. https://t.co/Sv8JQ6mYMv", "followers": "646", "datetime": "2018-06-27 01:54:41", "author": "@ebonex"}, "1011982664750919680": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "82", "datetime": "2018-06-27 14:40:43", "author": "@RyoHWS"}, "1011414233580367872": {"content_summary": "DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/9K1MOR1lZR This paper addresses the scalability challen", "followers": "755", "datetime": "2018-06-26 01:01:59", "author": "@M157q_News_RSS"}, "1011435552451653633": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "4,019", "datetime": "2018-06-26 02:26:41", "author": "@ballforest"}, "1011748339728175104": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "833", "datetime": "2018-06-26 23:09:36", "author": "@shigeakishigea"}, "1011996110884364290": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "1,137", "datetime": "2018-06-27 15:34:09", "author": "@leriomaggio"}, "1011707796687974400": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "161", "datetime": "2018-06-26 20:28:30", "author": "@farhanhubble"}, "1012017436437237760": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,911", "datetime": "2018-06-27 16:58:53", "author": "@fcolmenero"}, "1013386533599105024": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "21", "datetime": "2018-07-01 11:39:12", "author": "@MikhailPavlov5"}, "1012881366965342208": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "470", "datetime": "2018-06-30 02:11:50", "author": "@spartanhaden"}, "1011945858991054848": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "633", "datetime": "2018-06-27 12:14:28", "author": "@N_w_94"}, "1011645648616095745": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "3,243", "datetime": "2018-06-26 16:21:32", "author": "@yellowshippo"}, "1011751472793620480": {"content_summary": "Fascinating steps towards meta learning: https://t.co/uyJOV2dTpI", "followers": "11,718", "datetime": "2018-06-26 23:22:03", "author": "@Plinz"}, "1011733748143058944": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4", "datetime": "2018-06-26 22:11:37", "author": "@timjones101"}, "1012953556431749120": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "3,467", "datetime": "2018-06-30 06:58:42", "author": "@_primenumber"}, "1011938859071000577": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "168", "datetime": "2018-06-27 11:46:39", "author": "@tez_romach"}, "1012990762617733120": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,601", "datetime": "2018-06-30 09:26:32", "author": "@gg_hatano"}, "1011833203898888193": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "24", "datetime": "2018-06-27 04:46:49", "author": "@_Dolshe"}, "1013057522226229248": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,667", "datetime": "2018-06-30 13:51:49", "author": "@Scaled_Wurm"}, "1011660622243639296": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "221", "datetime": "2018-06-26 17:21:02", "author": "@positivearrow"}, "1012010386311262209": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "52", "datetime": "2018-06-27 16:30:52", "author": "@Light_Cynapse"}, "1011674936879013888": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "16,813", "datetime": "2018-06-26 18:17:55", "author": "@octonion"}, "1011799736280547330": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "76", "datetime": "2018-06-27 02:33:50", "author": "@MArchanjoBR"}, "1011766193630269442": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "425", "datetime": "2018-06-27 00:20:32", "author": "@0x1FC0"}, "1011759995883360257": {"content_summary": "RT @Plinz: Fascinating steps towards meta learning: https://t.co/uyJOV2dTpI", "followers": "322", "datetime": "2018-06-26 23:55:55", "author": "@letranger14"}, "1011934324969443331": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "225", "datetime": "2018-06-27 11:28:38", "author": "@ElectronNest"}, "1011474981769957378": {"content_summary": "DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/bUMLF4sc1c", "followers": "380", "datetime": "2018-06-26 05:03:22", "author": "@MLandDL_papers"}, "1011823197178642432": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "2,927", "datetime": "2018-06-27 04:07:03", "author": "@evolvingstuff"}, "1011555392801857536": {"content_summary": "DARTS: Differentiable Architecture Search. Hanxiao Liu, Karen Simonyan, and Yiming Yang https://t.co/oTg1nriWdL", "followers": "311", "datetime": "2018-06-26 10:22:54", "author": "@arxiv_cs_LG"}, "1023149762063740933": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "302", "datetime": "2018-07-28 10:14:47", "author": "@subhobrata1"}, "1012002361869467654": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "88", "datetime": "2018-06-27 15:58:59", "author": "@hugeiezzy"}, "1011915975011328001": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "36", "datetime": "2018-06-27 10:15:43", "author": "@vasan_ashwin"}, "1011562706678231040": {"content_summary": "RT @StatMLPapers: DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/ZWtzZkipuF", "followers": "1,348", "datetime": "2018-06-26 10:51:57", "author": "@udmrzn"}, "1011730471082852352": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "9", "datetime": "2018-06-26 21:58:36", "author": "@WilliamFerng"}, "1011577865605824512": {"content_summary": "RT @kchonyc: very nice! https://t.co/J6aUQWly2s", "followers": "8,233", "datetime": "2018-06-26 11:52:12", "author": "@mat_kelcey"}, "1011721300027506690": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "200", "datetime": "2018-06-26 21:22:09", "author": "@oscmansan"}, "1043418420920766464": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "160", "datetime": "2018-09-22 08:35:11", "author": "@tdzungz"}, "1012012576761409537": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "82", "datetime": "2018-06-27 16:39:35", "author": "@aradhyanmathur"}, "1013267505584865280": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "35", "datetime": "2018-07-01 03:46:13", "author": "@Tommiiiiiiiyyyy"}, "1011861013854072832": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "219", "datetime": "2018-06-27 06:37:19", "author": "@rahul722j"}, "1011942889545330688": {"content_summary": "RT @yutakashino: [1806.09055] DARTS: Differentiable Architecture Search https://t.co/H9WfxoS7BK \u3053\u308c\uff0c\u8aad\u3093\u3060\u3089\u9762\u767d\u304b\u3063\u305f\u3057\uff0cPyTorch\u5b9f\u88c5\u3082\u52d5\u304b\u3057\u3066\u76ee\u304b\u3089\u9c57\u7cfb\u306a\u306e\u3067\uff0c\u6a5f\u4f1a\u304c\u3042\u3063\u305f\u2026", "followers": "578", "datetime": "2018-06-27 12:02:40", "author": "@usagisan2020"}, "1011733541523095552": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,486", "datetime": "2018-06-26 22:10:48", "author": "@Pyshkov"}, "1011656701294985216": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,844", "datetime": "2018-06-26 17:05:27", "author": "@prasanna"}, "1011854953231634433": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "365", "datetime": "2018-06-27 06:13:14", "author": "@JeanMarcJAzzi"}, "1011602460408983554": {"content_summary": "[R] DARTS: Differentiable Architecture Search https://t.co/pKuYZpmYwf", "followers": "4,453", "datetime": "2018-06-26 13:29:55", "author": "@GiovanniToschi"}, "1012627556804096000": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "824", "datetime": "2018-06-29 09:23:17", "author": "@morioka"}, "1011708236230086662": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "54", "datetime": "2018-06-26 20:30:14", "author": "@JeremyKawahara"}, "1070439627104894976": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "972", "datetime": "2018-12-05 22:07:49", "author": "@Roswitamind"}, "1011633174055510016": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "425", "datetime": "2018-06-26 15:31:58", "author": "@iamknighton"}, "1011762943552180225": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "512", "datetime": "2018-06-27 00:07:38", "author": "@shadow_jp"}, "1011757584955527169": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "150", "datetime": "2018-06-26 23:46:20", "author": "@PadmanabhanKri"}, "1011653883494649856": {"content_summary": "[1806.09055] DARTS: Differentiable Architecture Search - https://t.co/9D1COPolYq https://t.co/amJZvqPWQG", "followers": "195", "datetime": "2018-06-26 16:54:16", "author": "@hereticreader"}, "1012947258113867776": {"content_summary": "Learning to learn the network architecture https://t.co/tqV3l2N3mL", "followers": "46", "datetime": "2018-06-30 06:33:40", "author": "@DeepakB94018371"}, "1045874356813873152": {"content_summary": "RT @imenurok: SNAS: stochastic neural architecture search https://t.co/dfYL7C6ka7 DARTS\u306eLiu et al.\u306e\u5f8c\u7d9a\u7814\u7a76\u306e\u4e88\u611f\u304c\u3059\u308b\u3002 https://t.co/kTcrdwzH2u", "followers": "150", "datetime": "2018-09-29 03:14:12", "author": "@y_yammt"}, "1012935597399236608": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "12", "datetime": "2018-06-30 05:47:20", "author": "@SINoA_Wreath"}, "1011982568864878592": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "12,765", "datetime": "2018-06-27 14:40:20", "author": "@jaguring1"}, "1030018035275448320": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "66", "datetime": "2018-08-16 09:06:51", "author": "@11shubh_laabh11"}, "1013010122434600964": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,002", "datetime": "2018-06-30 10:43:28", "author": "@MuratKurtUbe"}, "1011612825112834052": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "882", "datetime": "2018-06-26 14:11:07", "author": "@vadimkantorov"}, "1011515002132553733": {"content_summary": "RT @arxiv_cs_cl: https://t.co/QZtCP1KuX5 DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) #NLProc", "followers": "783", "datetime": "2018-06-26 07:42:24", "author": "@muktabh"}, "1026374578896023553": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,293", "datetime": "2018-08-06 07:49:03", "author": "@ImNickHuber"}, "1011665152905752582": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "28", "datetime": "2018-06-26 17:39:02", "author": "@Mouatez"}, "1011609713170092037": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "184", "datetime": "2018-06-26 13:58:45", "author": "@johnnyprothero"}, "1011854888689692672": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "5,413", "datetime": "2018-06-27 06:12:59", "author": "@firoozye"}, "1012874784517050368": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "185,668", "datetime": "2018-06-30 01:45:41", "author": "@demishassabis"}, "1047359320567009281": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,193", "datetime": "2018-10-03 05:34:55", "author": "@scottpenberthy"}, "1012886252192858114": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "237", "datetime": "2018-06-30 02:31:15", "author": "@veydpz_public"}, "1012066776216166401": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "212", "datetime": "2018-06-27 20:14:57", "author": "@EsuSpec"}, "1013133884844736512": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "185", "datetime": "2018-06-30 18:55:15", "author": "@nt776"}, "1011725973774110721": {"content_summary": "Boom. Move over NAS-NET. \u201cGradient architecture Search used a single GPU over a day.\u201d https://t.co/EE3Xm5bANq", "followers": "3,864", "datetime": "2018-06-26 21:40:43", "author": "@drsxr"}, "1012033733665476614": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "14", "datetime": "2018-06-27 18:03:39", "author": "@andrei_st_n"}, "1012644756277510144": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "569", "datetime": "2018-06-29 10:31:38", "author": "@Woofer30"}, "1013631871782146049": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "703", "datetime": "2018-07-02 03:54:05", "author": "@castolosan"}, "1012977793645199362": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "435", "datetime": "2018-06-30 08:35:00", "author": "@kawauso_kun"}, "1013318067164626946": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "597", "datetime": "2018-07-01 07:07:08", "author": "@Snow_Hedgehog"}, "1012521938571354114": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "75", "datetime": "2018-06-29 02:23:36", "author": "@zimizile"}, "1011419703351259137": {"content_summary": "RT @StatMLPapers: DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/ZWtzZkipuF", "followers": "145", "datetime": "2018-06-26 01:23:43", "author": "@m_ishimu"}, "1012593556970561536": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,861", "datetime": "2018-06-29 07:08:11", "author": "@Tarpon_red2"}, "1012059859473260544": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "534", "datetime": "2018-06-27 19:47:28", "author": "@benoitmarchant"}, "1012746520020561921": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "800", "datetime": "2018-06-29 17:16:00", "author": "@reworkkatie"}, "1012661200398630912": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,014", "datetime": "2018-06-29 11:36:59", "author": "@melonsode"}, "1013025534140387328": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "339", "datetime": "2018-06-30 11:44:43", "author": "@AfliHaithem"}, "1011859737858617344": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "63", "datetime": "2018-06-27 06:32:15", "author": "@443202293Lht"}, "1014844090171711489": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "8", "datetime": "2018-07-05 12:11:00", "author": "@LukasSteindl"}, "1012898377552388097": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "186", "datetime": "2018-06-30 03:19:26", "author": "@SagarSharma4244"}, "1011609957081407488": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "91", "datetime": "2018-06-26 13:59:43", "author": "@DrJimFan"}, "1012667172697460736": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,448", "datetime": "2018-06-29 12:00:43", "author": "@dicekicker"}, "1011940428558553091": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "431", "datetime": "2018-06-27 11:52:53", "author": "@hh_amin"}, "1012415288107782151": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "46", "datetime": "2018-06-28 19:19:49", "author": "@MichelSpeiser"}, "1011911911687032832": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "108", "datetime": "2018-06-27 09:59:34", "author": "@mducoffe"}, "1012148159005380609": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "111", "datetime": "2018-06-28 01:38:20", "author": "@marcoleewow"}, "1011857226628304897": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "355", "datetime": "2018-06-27 06:22:16", "author": "@joeknowbest"}, "1013681711631069185": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "4,825", "datetime": "2018-07-02 07:12:08", "author": "@prototechno"}, "1011777304362532866": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "164,067", "datetime": "2018-06-27 01:04:41", "author": "@ceobillionaire"}, "1012037358508822529": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "1", "datetime": "2018-06-27 18:18:03", "author": "@DzianisHa"}, "1013090491007561728": {"content_summary": "RT @koehrsen_will: Was finally starting to understand model-based optimization, but now this paper says (differentiable) gradient-based opt\u2026", "followers": "67", "datetime": "2018-06-30 16:02:50", "author": "@SonOfHills"}, "1011682552422289408": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "667", "datetime": "2018-06-26 18:48:11", "author": "@LordAstinus"}, "1012355085039386624": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "94", "datetime": "2018-06-28 15:20:35", "author": "@ozlhubby"}, "1011729142918852609": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "733", "datetime": "2018-06-26 21:53:19", "author": "@IZIREN"}, "1011861521033383936": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "615", "datetime": "2018-06-27 06:39:20", "author": "@KouroshMeshgi"}, "1012950907598884864": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "278", "datetime": "2018-06-30 06:48:10", "author": "@gmorison"}, "1011668421308768257": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,898", "datetime": "2018-06-26 17:52:02", "author": "@nsaphra"}, "1011900049557770242": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "11,931", "datetime": "2018-06-27 09:12:26", "author": "@Rosenchild"}, "1011968357376184320": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "29", "datetime": "2018-06-27 13:43:52", "author": "@prashan_gaikwad"}, "1012134221366878208": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,231", "datetime": "2018-06-28 00:42:57", "author": "@jackiefloyd"}, "1011915871156088832": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "247", "datetime": "2018-06-27 10:15:18", "author": "@kdubovikov"}, "1012610527111966721": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,567", "datetime": "2018-06-29 08:15:37", "author": "@et0nia"}, "1012047784042745857": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "6", "datetime": "2018-06-27 18:59:29", "author": "@joshualin24"}, "1011806726457262081": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "55", "datetime": "2018-06-27 03:01:36", "author": "@libematus"}, "1031285765211389952": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "25", "datetime": "2018-08-19 21:04:21", "author": "@AlexYalunin"}, "1011653014837452800": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/IOVM8wnCpc #deeplearning #machinelearning", "followers": "25,311", "datetime": "2018-06-26 16:50:48", "author": "@deeplearning4j"}, "1013045535455043585": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "139", "datetime": "2018-06-30 13:04:11", "author": "@AnthonyBoz"}, "1012358137133895682": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "44", "datetime": "2018-06-28 15:32:43", "author": "@AndreyDulub"}, "1011747463672131584": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "74", "datetime": "2018-06-26 23:06:07", "author": "@ljastrzebski"}, "1012909364699488256": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "591", "datetime": "2018-06-30 04:03:06", "author": "@tt_p10"}, "1011645067939868672": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "4,019", "datetime": "2018-06-26 16:19:14", "author": "@ballforest"}, "1011827818668482560": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "115", "datetime": "2018-06-27 04:25:25", "author": "@novasponge"}, "1012514392892534784": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "3", "datetime": "2018-06-29 01:53:37", "author": "@festivalWon"}, "1011921265509224454": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "248", "datetime": "2018-06-27 10:36:44", "author": "@gsksantosh"}, "1011907549916872704": {"content_summary": "RT @HubBucket: #DARTS - Differentiable Architecture Search The scalability challenge of architecture search by formulating the task in a d\u2026", "followers": "104", "datetime": "2018-06-27 09:42:14", "author": "@Rajrajachozhan"}, "1011737628830359552": {"content_summary": "Excellent! https://t.co/O2loPpHkpa", "followers": "6,721", "datetime": "2018-06-26 22:27:02", "author": "@paulportesi"}, "1011721296835514368": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "11,766", "datetime": "2018-06-26 21:22:08", "author": "@yutakashino"}, "1014429627429937152": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "56", "datetime": "2018-07-04 08:44:05", "author": "@ppweni"}, "1012939849995816961": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "148", "datetime": "2018-06-30 06:04:14", "author": "@Mesnard_Thomas"}, "1011965476807770117": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "946", "datetime": "2018-06-27 13:32:25", "author": "@alienobserver1"}, "1012331721210003456": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "268", "datetime": "2018-06-28 13:47:45", "author": "@sc_codeUM"}, "1011842582320730112": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "576", "datetime": "2018-06-27 05:24:05", "author": "@elieah"}, "1011701438437777408": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "111", "datetime": "2018-06-26 20:03:14", "author": "@nimblel"}, "1013078597697859584": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "631", "datetime": "2018-06-30 15:15:34", "author": "@fugu2929fat"}, "1192355955725365250": {"content_summary": "RT @imenurok: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u63a2\u7d22\u624b\u2026", "followers": "13", "datetime": "2019-11-07 08:19:47", "author": "@vx5tLpYpNKv0XAe"}, "1011979809637961728": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "709", "datetime": "2018-06-27 14:29:22", "author": "@arthurostapenko"}, "1012014834034999296": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "70,485", "datetime": "2018-06-27 16:48:33", "author": "@bbriniotis"}, "1011641984791048192": {"content_summary": "#AI Experiments on CIFAR-10, ImageNet, .. show this excels in discovering convolutional architectures for image classification and recurrent architectures for language modeling, while being faster than state-of-the-art non-differentiable techniques. https", "followers": "10,655", "datetime": "2018-06-26 16:06:59", "author": "@kaalam_ai"}, "1011735230569299968": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "962", "datetime": "2018-06-26 22:17:30", "author": "@jnhwkim"}, "1013508359230775296": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1", "datetime": "2018-07-01 19:43:17", "author": "@faqqe_"}, "1046198274397331456": {"content_summary": "RT @imenurok: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u63a2\u7d22\u624b\u2026", "followers": "2,663", "datetime": "2018-09-30 00:41:20", "author": "@chie8842"}, "1012942692660043776": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "274", "datetime": "2018-06-30 06:15:32", "author": "@wrongwrong16337"}, "1011897506882576384": {"content_summary": "RT DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/vO1T3Bqjj8", "followers": "56", "datetime": "2018-06-27 09:02:20", "author": "@Communicate_AI"}, "1011716208054317056": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "228", "datetime": "2018-06-26 21:01:55", "author": "@hengcherkeng"}, "1011847084004130817": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "115", "datetime": "2018-06-27 05:41:58", "author": "@viirya"}, "1012771242330525696": {"content_summary": "Interesting paper on neural network architecture search... https://t.co/8AVpj9Ivg2", "followers": "40", "datetime": "2018-06-29 18:54:15", "author": "@stephbaggerohr"}, "1013389717738610691": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "6", "datetime": "2018-07-01 11:51:51", "author": "@mjfbnkr"}, "1011778727624224769": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,063", "datetime": "2018-06-27 01:10:21", "author": "@DrMAJr"}, "1011715111055167494": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "30,548", "datetime": "2018-06-26 20:57:33", "author": "@NalKalchbrenner"}, "1013086319843500034": {"content_summary": "gradient descent: This method is orders of magnitude faster than state-of-the-art non-differentiable techniques. https://t.co/O0eLw2KgaA", "followers": "914", "datetime": "2018-06-30 15:46:15", "author": "@camgirl_world"}, "1012035034688118790": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "78", "datetime": "2018-06-27 18:08:49", "author": "@en_zxteloiv"}, "1011692532126900224": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "317", "datetime": "2018-06-26 19:27:50", "author": "@teenvan1995"}, "1012301116887875585": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "475", "datetime": "2018-06-28 11:46:08", "author": "@nfunato"}, "1012370334656458752": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "298", "datetime": "2018-06-28 16:21:11", "author": "@andcallmejackal"}, "1011741343151022080": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "201", "datetime": "2018-06-26 22:41:48", "author": "@cristina_canero"}, "1012264326915346432": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "232", "datetime": "2018-06-28 09:19:57", "author": "@a9b4b60dae2548c"}, "1011786184626987013": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "160", "datetime": "2018-06-27 01:39:59", "author": "@johnmsheffield"}, "1011748087226884097": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "52", "datetime": "2018-06-26 23:08:36", "author": "@musafirtweetsz"}, "1011501566254174208": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "543", "datetime": "2018-06-26 06:49:00", "author": "@wsuzume"}, "1011897978649337856": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "509", "datetime": "2018-06-27 09:04:12", "author": "@Johnnyira"}, "1011940253735645185": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "412", "datetime": "2018-06-27 11:52:12", "author": "@deanofthewebb"}, "1011776441460101120": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "145", "datetime": "2018-06-27 01:01:16", "author": "@adamajm"}, "1011434590022467584": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "12,765", "datetime": "2018-06-26 02:22:52", "author": "@jaguring1"}, "1011989862331965442": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "43", "datetime": "2018-06-27 15:09:19", "author": "@jeetkanjani7"}, "1011897617335250944": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "4,615", "datetime": "2018-06-27 09:02:46", "author": "@HITStales"}, "1011659961338822659": {"content_summary": "Good https://t.co/FofxqcVwrf", "followers": "717", "datetime": "2018-06-26 17:18:25", "author": "@sethupathy_ts"}, "1012193706726776832": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "60", "datetime": "2018-06-28 04:39:19", "author": "@takaha4"}, "1115339046904111105": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "79,157", "datetime": "2019-04-08 19:42:05", "author": "@machinelearnflx"}, "1012878810578997248": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "0", "datetime": "2018-06-30 02:01:41", "author": "@Sam09lol"}, "1011637889933996032": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "43", "datetime": "2018-06-26 15:50:42", "author": "@jeandut14000"}, "1012905218667831296": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "57", "datetime": "2018-06-30 03:46:37", "author": "@Catalina1344"}, "1013250477025181696": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "252", "datetime": "2018-07-01 02:38:33", "author": "@haiattoC"}, "1011822687755202560": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "1,652", "datetime": "2018-06-27 04:05:02", "author": "@RyanDavidReece"}, "1011847193165262849": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "4", "datetime": "2018-06-27 05:42:24", "author": "@ZilongZhong"}, "1012654029590024193": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,201", "datetime": "2018-06-29 11:08:29", "author": "@UTiCd"}, "1012008563584032768": {"content_summary": "RT @hillbig: For efficient network architecture search with gradient information, they propose to use softmax relaxation to select the oper\u2026", "followers": "169", "datetime": "2018-06-27 16:23:38", "author": "@kawamuramasahar"}, "1011640109270118400": {"content_summary": "RT @kchonyc: very nice! https://t.co/J6aUQWly2s", "followers": "518", "datetime": "2018-06-26 15:59:32", "author": "@pijili"}, "1011656182984069126": {"content_summary": "Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques. DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. Paper: https://t.co/gnKLXx6Pi9 Code: https:", "followers": "88,923", "datetime": "2018-06-26 17:03:24", "author": "@OriolVinyalsML"}, "1012039950383005696": {"content_summary": "interesting paper to show that gradient are not dead yet https://t.co/82RFQOVSDm", "followers": "781", "datetime": "2018-06-27 18:28:21", "author": "@AlexandreRbcqt"}, "1011604883324178432": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "69", "datetime": "2018-06-26 13:39:33", "author": "@__hitanjan__"}, "1011656047050870786": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "6", "datetime": "2018-06-26 17:02:51", "author": "@neethisp"}, "1012189407896629253": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "299", "datetime": "2018-06-28 04:22:15", "author": "@westis96"}, "1011410534590308352": {"content_summary": "DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/ZWtzZkipuF", "followers": "9,689", "datetime": "2018-06-26 00:47:17", "author": "@StatMLPapers"}, "1011747771177631744": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "159,742", "datetime": "2018-06-26 23:07:20", "author": "@Montreal_IA"}, "1011906989272813568": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "4,312", "datetime": "2018-06-27 09:40:01", "author": "@a_hun1972"}, "1012189470962024448": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "6", "datetime": "2018-06-28 04:22:30", "author": "@nahidcse05"}, "1011871298711060481": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "12", "datetime": "2018-06-27 07:18:11", "author": "@labh111349"}, "1021561351175647232": {"content_summary": "sn-news: #sw #ml #dev DARTS - Differentiable Architecture Search https://t.co/3qqeBI9A7i", "followers": "774", "datetime": "2018-07-24 01:03:00", "author": "@jmsunico"}, "1011947164581486593": {"content_summary": "so cool https://t.co/bBCQhh19z4", "followers": "121", "datetime": "2018-06-27 12:19:39", "author": "@zhizhid"}, "1012974244802846720": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "1,331", "datetime": "2018-06-30 08:20:54", "author": "@GadioOumoul"}, "1011857062148489216": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "2,670", "datetime": "2018-06-27 06:21:37", "author": "@ayirpelle"}, "1012966105055313921": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "641", "datetime": "2018-06-30 07:48:34", "author": "@romaspqr"}, "1012947503874838528": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "158", "datetime": "2018-06-30 06:34:39", "author": "@otyahauwaiyodai"}, "1011929958288166913": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "164,067", "datetime": "2018-06-27 11:11:17", "author": "@ceobillionaire"}, "1011917112074493952": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "1,253", "datetime": "2018-06-27 10:20:14", "author": "@constellatio"}, "1012954870683353088": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "186", "datetime": "2018-06-30 07:03:55", "author": "@rackowsteinberg"}, "1011732110460309505": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "67", "datetime": "2018-06-26 22:05:06", "author": "@the_Chojnacki"}, "1011862744897937408": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "4,891", "datetime": "2018-06-27 06:44:12", "author": "@IgorCarron"}, "1012176459694297090": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "596", "datetime": "2018-06-28 03:30:47", "author": "@gracielagon"}, "1012613704901275650": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "226", "datetime": "2018-06-29 08:28:15", "author": "@mishi_e1"}, "1011668501587726336": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,312", "datetime": "2018-06-26 17:52:21", "author": "@a_hun1972"}, "1011433703854125057": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "810", "datetime": "2018-06-26 02:19:21", "author": "@_tkato_"}, "1012397566703566848": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "31", "datetime": "2018-06-28 18:09:23", "author": "@Vladslinger"}, "1011701172950818816": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "12", "datetime": "2018-06-26 20:02:10", "author": "@vmsemc2"}, "1011864418332954625": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "2,535", "datetime": "2018-06-27 06:50:51", "author": "@npinto"}, "1011830462589820928": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "141", "datetime": "2018-06-27 04:35:55", "author": "@atulvinayak"}, "1012109695497195520": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "207", "datetime": "2018-06-27 23:05:30", "author": "@MsalehiSadegh"}, "1011632000900399105": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "420", "datetime": "2018-06-26 15:27:18", "author": "@fenbielding"}, "1011691381063143424": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "189", "datetime": "2018-06-26 19:23:16", "author": "@AndreuSancho"}, "1016665056308793344": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "458,687", "datetime": "2018-07-10 12:46:52", "author": "@ValaAfshar"}, "1017621005450317824": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "2,293", "datetime": "2018-07-13 04:05:28", "author": "@ImNickHuber"}, "1011860710891114496": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "728", "datetime": "2018-06-27 06:36:07", "author": "@sarnthil"}, "1011762719626629120": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "485", "datetime": "2018-06-27 00:06:44", "author": "@eve_yk"}, "1011829009368395782": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "1,703", "datetime": "2018-06-27 04:30:09", "author": "@keremcaliskan"}, "1011820519535140864": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "315", "datetime": "2018-06-27 03:56:25", "author": "@Dev_ila"}, "1011908857256431617": {"content_summary": "RT @HubBucket: #DARTS - Differentiable Architecture Search The scalability challenge of architecture search by formulating the task in a d\u2026", "followers": "5,315", "datetime": "2018-06-27 09:47:26", "author": "@HubBucket"}, "1012897161128759299": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "2,691", "datetime": "2018-06-30 03:14:36", "author": "@rf0444"}, "1011704894493847552": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "28,868", "datetime": "2018-06-26 20:16:58", "author": "@ymatsuo"}, "1018194667245129728": {"content_summary": "DARTS: #Differentiable Architecture Search for #DeepLearning, #ConvNets #RecurrentNets orders of magnitude faster than non-differentiable methods. https://t.co/PozPJ1LCiS", "followers": "65", "datetime": "2018-07-14 18:05:00", "author": "@ingeni_us"}, "1011449822551818240": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "4,615", "datetime": "2018-06-26 03:23:24", "author": "@HITStales"}, "1011667298409680896": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,938", "datetime": "2018-06-26 17:47:34", "author": "@EldarSilver"}, "1011662320454402048": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "22", "datetime": "2018-06-26 17:27:47", "author": "@cezzo_sw"}, "1012185403141513216": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "18", "datetime": "2018-06-28 04:06:20", "author": "@xu3kev"}, "1011893109033070592": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "216", "datetime": "2018-06-27 08:44:51", "author": "@Johnson37975725"}, "1011675566225940480": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "360", "datetime": "2018-06-26 18:20:25", "author": "@NyatzAnger"}, "1011647171467227137": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "946", "datetime": "2018-06-26 16:27:35", "author": "@arashvahdat"}, "1012591454248685568": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "1,602", "datetime": "2018-06-29 06:59:50", "author": "@alxcnwy"}, "1012189662553595905": {"content_summary": "this is crazily awesome https://t.co/8SZ9ARxBVe", "followers": "67", "datetime": "2018-06-28 04:23:15", "author": "@SonOfHills"}, "1011596577075539970": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "4,503", "datetime": "2018-06-26 13:06:33", "author": "@Flexi23"}, "1011691260221034497": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "545", "datetime": "2018-06-26 19:22:47", "author": "@nicolarohrseitz"}, "1011870650451910656": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "13", "datetime": "2018-06-27 07:15:37", "author": "@CvRocker_XuJian"}, "1011782333219921921": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "26", "datetime": "2018-06-27 01:24:40", "author": "@AKASH_2907"}, "1070441740782456835": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,293", "datetime": "2018-12-05 22:16:13", "author": "@ImNickHuber"}, "1013009358710378496": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "202", "datetime": "2018-06-30 10:40:26", "author": "@PandaMiffy"}, "1011820241846857728": {"content_summary": "Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zero (which means no connection), to make everything differentiable, thus jointly learn architecture & weights via gradient desc", "followers": "25,193", "datetime": "2018-06-27 03:55:19", "author": "@Reza_Zadeh"}, "1011749131017244677": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "159,742", "datetime": "2018-06-26 23:12:44", "author": "@Montreal_IA"}, "1012086921777041408": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "4,754", "datetime": "2018-06-27 21:35:00", "author": "@rzembo"}, "1011897844465205248": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "38", "datetime": "2018-06-27 09:03:40", "author": "@minskyway"}, "1011544891422195712": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "145", "datetime": "2018-06-26 09:41:10", "author": "@m_ishimu"}, "1042862409453641728": {"content_summary": "DARTS - searching best #NeuralNetwork architecture with gradient descent. Looks like an alternative to ENAS Paper: https://t.co/UYEGCAfQfe #MLpaperoftheday #ML #DeepLearning https://t.co/mch3NLYWGO", "followers": "15", "datetime": "2018-09-20 19:45:48", "author": "@subpath"}, "1011692060770893824": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "388", "datetime": "2018-06-26 19:25:58", "author": "@adropboxspace"}, "1011695358735454213": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "157", "datetime": "2018-06-26 19:39:04", "author": "@webdizz"}, "1133442911075389440": {"content_summary": "\ud835\udc03\ud835\udc00\ud835\udc11\ud835\udc13\ud835\udc12: Algorithm t0 Automate the process of \ud835\udc00\ud835\udc2b\ud835\udc1c\ud835\udc21\ud835\udc22\ud835\udc2d\ud835\udc1e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc03\ud835\udc1e\ud835\udc2c\ud835\udc22\ud835\udc20\ud835\udc27 for neural networks by allowing an efficient search of the architecture using \ud835\udc06\ud835\udc2b\ud835\udc1a\ud835\udc1d-\ud835\udc03\ud835\udc1e\ud835\udc2c\ud835\udc1c\ud835\udc1e\ud835\udc27\ud835\udc2d. This Neural Network Optimizes Itself | Two Minute Papers #212 https://t.co/FhxGqnDWyA", "followers": "191", "datetime": "2019-05-28 18:40:23", "author": "@F4izy"}, "1013035198286458880": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "920", "datetime": "2018-06-30 12:23:07", "author": "@mebiusbox2"}, "1013207422054395905": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "18", "datetime": "2018-06-30 23:47:28", "author": "@VasiliosDanos"}, "1012607765187948544": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "24,148", "datetime": "2018-06-29 08:04:39", "author": "@ripple_chan"}, "1012278208220291074": {"content_summary": "https://t.co/TdNi8o4mHM #ai #machinelearning #artificialintelligence via @cmarschner", "followers": "2,285", "datetime": "2018-06-28 10:15:06", "author": "@future_of_AI"}, "1011605363358085121": {"content_summary": "DARTS: Differentiable Architecture Search https://t.co/bvdTLm8GEe", "followers": "3,501", "datetime": "2018-06-26 13:41:28", "author": "@arxiv_cscl"}, "1012881834319937538": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,891", "datetime": "2018-06-30 02:13:42", "author": "@IgorCarron"}, "1011880583406866433": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "164", "datetime": "2018-06-27 07:55:05", "author": "@seungjaeryanlee"}, "1011660031727685632": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "478", "datetime": "2018-06-26 17:18:41", "author": "@arifatbaran"}, "1026817953151508480": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "40", "datetime": "2018-08-07 13:10:52", "author": "@AlgorLabs"}, "1026360485656940545": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "39", "datetime": "2018-08-06 06:53:03", "author": "@YingjieJIa92"}, "1013118115364986885": {"content_summary": "RT @vmirly: DARTS: Differentiable Architecture Search https://t.co/4rituvOto5 Towards automated deep-learning, where the optimum neural net\u2026", "followers": "1,417", "datetime": "2018-06-30 17:52:36", "author": "@seanmylaw"}, "1011728876605661184": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "432", "datetime": "2018-06-26 21:52:15", "author": "@tsukamakiri"}, "1011798176842506240": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "14", "datetime": "2018-06-27 02:27:38", "author": "@teng_yu"}, "1011790329375125504": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "35", "datetime": "2018-06-27 01:56:27", "author": "@jdily"}, "1127020621261619200": {"content_summary": "@drsxr https://t.co/9GwIXy0ncY Is this the paper??", "followers": "1,427", "datetime": "2019-05-11 01:20:29", "author": "@UsmanSattarMD"}, "1011815161181687808": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "82", "datetime": "2018-06-27 03:35:07", "author": "@aradhyanmathur"}, "1011573881289621506": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "24", "datetime": "2018-06-26 11:36:22", "author": "@NORA__0013"}, "1011628360009646081": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "740", "datetime": "2018-06-26 15:12:50", "author": "@JoaoVictor_AC"}, "1011656448353243136": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "75", "datetime": "2018-06-26 17:04:27", "author": "@abienfredagarap"}, "1011825752319225856": {"content_summary": "This! https://t.co/9JKazhejNd", "followers": "11", "datetime": "2018-06-27 04:17:12", "author": "@Aiolia21"}, "1012149402176278528": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "2,625", "datetime": "2018-06-28 01:43:16", "author": "@robert_thas"}, "1011987052462669824": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "6,486", "datetime": "2018-06-27 14:58:09", "author": "@jingbay"}, "1011731390080081920": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,222", "datetime": "2018-06-26 22:02:15", "author": "@shinyaelix"}, "1017688714309275649": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "26", "datetime": "2018-07-13 08:34:31", "author": "@Quanguet"}, "1011959331367948288": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,987", "datetime": "2018-06-27 13:08:00", "author": "@DeepLearningFTW"}, "1012088480493518850": {"content_summary": "RT @yutakashino: [1806.09055] DARTS: Differentiable Architecture Search https://t.co/H9WfxoS7BK \u3053\u308c\uff0c\u8aad\u3093\u3060\u3089\u9762\u767d\u304b\u3063\u305f\u3057\uff0cPyTorch\u5b9f\u88c5\u3082\u52d5\u304b\u3057\u3066\u76ee\u304b\u3089\u9c57\u7cfb\u306a\u306e\u3067\uff0c\u6a5f\u4f1a\u304c\u3042\u3063\u305f\u2026", "followers": "841", "datetime": "2018-06-27 21:41:12", "author": "@a2uky"}, "1012831706573725696": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "412", "datetime": "2018-06-29 22:54:31", "author": "@bikeandcat"}, "1011724128661803009": {"content_summary": "Next gen for architecture search! https://t.co/adZXaXcUeI", "followers": "854", "datetime": "2018-06-26 21:33:23", "author": "@mbeissinger"}, "1011729789374394368": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "518", "datetime": "2018-06-26 21:55:53", "author": "@Tethysicx"}, "1011775289159012352": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,248", "datetime": "2018-06-27 00:56:41", "author": "@daisuzu"}, "1011622772814954497": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,471", "datetime": "2018-06-26 14:50:38", "author": "@shigepong"}, "1012157666658062337": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "402", "datetime": "2018-06-28 02:16:07", "author": "@darksider9"}, "1012968015942463488": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "333", "datetime": "2018-06-30 07:56:09", "author": "@Nikkou"}, "1138455359071444993": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "189", "datetime": "2019-06-11 14:38:03", "author": "@ChristnDonovan"}, "1012538078563405830": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "82", "datetime": "2018-06-29 03:27:44", "author": "@RyoHWS"}, "1012350340140863488": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "6", "datetime": "2018-06-28 15:01:44", "author": "@sixmonth1"}, "1011744009671372802": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "187", "datetime": "2018-06-26 22:52:23", "author": "@vicen_cm"}, "1011822614573023232": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "1,048", "datetime": "2018-06-27 04:04:44", "author": "@tackson5"}, "1011471638582329344": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "119", "datetime": "2018-06-26 04:50:05", "author": "@toto_toilet"}, "1011678474640285698": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "117", "datetime": "2018-06-26 18:31:59", "author": "@pabaldonedo"}, "1011711718647476224": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "478", "datetime": "2018-06-26 20:44:05", "author": "@yasuokajihei"}, "1012699291867987974": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,593", "datetime": "2018-06-29 14:08:20", "author": "@asaokitan"}, "1012290970858094592": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "297", "datetime": "2018-06-28 11:05:49", "author": "@tomit3"}, "1011792593192128513": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "783", "datetime": "2018-06-27 02:05:27", "author": "@muktabh"}, "1011741979959427073": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "41", "datetime": "2018-06-26 22:44:19", "author": "@nannoki96"}, "1013039977532280832": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "216", "datetime": "2018-06-30 12:42:06", "author": "@KSKSKSKS2"}, "1013073226321334274": {"content_summary": "Was finally starting to understand model-based optimization, but now this paper says (differentiable) gradient-based optimization achieves better results for neural network architecture design: https://t.co/N0jbMNfXoi", "followers": "7,819", "datetime": "2018-06-30 14:54:13", "author": "@koehrsen_will"}, "1011916789406687232": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "11", "datetime": "2018-06-27 10:18:57", "author": "@BasuDebdeep"}, "1011728726634033154": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "593", "datetime": "2018-06-26 21:51:40", "author": "@7GTech"}, "1011695557105119236": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "2,898", "datetime": "2018-06-26 19:39:51", "author": "@ptrblck_de"}, "1011725376232411136": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "27", "datetime": "2018-06-26 21:38:21", "author": "@amitjainiitd"}, "1011823722402066433": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "124", "datetime": "2018-06-27 04:09:08", "author": "@Santiag72427700"}, "1011920412735950848": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "4,804", "datetime": "2018-06-27 10:33:21", "author": "@cto_movidius"}, "1011654356322652161": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,338", "datetime": "2018-06-26 16:56:08", "author": "@aileengemma"}, "1011893441502957568": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "252", "datetime": "2018-06-27 08:46:11", "author": "@AshitaHamatsuri"}, "1012933428180684801": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "400", "datetime": "2018-06-30 05:38:43", "author": "@zakizaki_4daime"}, "1011873395779174400": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "411", "datetime": "2018-06-27 07:26:31", "author": "@Robin__Teuwens"}, "1012875975615565824": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "295", "datetime": "2018-06-30 01:50:25", "author": "@balicea1"}, "1011634374998220801": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "934", "datetime": "2018-06-26 15:36:44", "author": "@pavelkordik"}, "1123764798523609088": {"content_summary": "DARTS \u25bcDNN\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3(\u30e2\u30c7\u30eb)\u306e\u63a2\u7d22 https://t.co/w7ZaOmKwSZ", "followers": "190", "datetime": "2019-05-02 01:43:01", "author": "@nskm_m"}, "1011977932804243456": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "5", "datetime": "2018-06-27 14:21:55", "author": "@Koundinya33"}, "1011810184900108288": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "110", "datetime": "2018-06-27 03:15:21", "author": "@_aatkinson_"}, "1025014654781796352": {"content_summary": "Interesting! Improving image classification, finding convolutional architectures with reinforcement learning https://t.co/N3P8lm0FEH #machine #learning #trends", "followers": "3,563", "datetime": "2018-08-02 13:45:12", "author": "@davilagrau"}, "1011737525071765504": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "6,721", "datetime": "2018-06-26 22:26:37", "author": "@paulportesi"}, "1012603828221251584": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "41", "datetime": "2018-06-29 07:49:00", "author": "@kurochan831"}, "1012224355542052864": {"content_summary": "Great paper : DARTS: Differentiable Architecture Search #ai https://t.co/b56vyjaDbL", "followers": "234", "datetime": "2018-06-28 06:41:07", "author": "@iamsiddhantsahu"}, "1021023920726724609": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,293", "datetime": "2018-07-22 13:27:27", "author": "@ImNickHuber"}, "1012285419340345344": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "17", "datetime": "2018-06-28 10:43:45", "author": "@onetruearavind"}, "1011987166921142272": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "37", "datetime": "2018-06-27 14:58:37", "author": "@eng42802943"}, "1011658353544704005": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "813", "datetime": "2018-06-26 17:12:01", "author": "@vadimlearning"}, "1011896113966788608": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "129", "datetime": "2018-06-27 08:56:48", "author": "@VR_AnotherWorld"}, "1012260834465271808": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "40", "datetime": "2018-06-28 09:06:04", "author": "@burakkose41"}, "1011915262126383104": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "792", "datetime": "2018-06-27 10:12:53", "author": "@antonioalegria"}, "1011972824578211840": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "1,726", "datetime": "2018-06-27 14:01:37", "author": "@superbradyon"}, "1069717013914886145": {"content_summary": "RT @HubBucket: #DARTS - Differentiable Architecture Search The scalability challenge of architecture search by formulating the task in a d\u2026", "followers": "131", "datetime": "2018-12-03 22:16:25", "author": "@HubAnalysis1"}, "1011804638293549056": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "409", "datetime": "2018-06-27 02:53:18", "author": "@indrapalijama"}, "1028466866732322817": {"content_summary": "RT @qunaieer: \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 DARTS \u0623\u062d\u062f\u062b\u062a \u0636\u062c\u0629 \u0641\u064a \u0627\u0644\u064a\u0648\u0645\u064a\u0646 \u0647\u0630\u064a\u060c \u062d\u064a\u062b \u062a\u062a\u064a\u062d \u0628\u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u0643\u0641\u0627\u0626\u0629 \u0645\u0646 \u0627\u0644\u0633\u0627\u0628\u0642 \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0623\u0641\u0636\u0644 \u0634\u0643\u0644/\u0645\u0639\u0645\u0627\u0631\u064a\u0629 (architecture) \u0644\u0644\u0634\u0628\u0643\u0627\u2026", "followers": "1,226", "datetime": "2018-08-12 02:23:03", "author": "@meshal1401MU"}, "1011489180936007680": {"content_summary": "RT @StatMLPapers: DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/ZWtzZkipuF", "followers": "4,891", "datetime": "2018-06-26 05:59:47", "author": "@IgorCarron"}, "1055477573822537729": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "325", "datetime": "2018-10-25 15:13:58", "author": "@CalcCon"}, "1011678860092592128": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "591", "datetime": "2018-06-26 18:33:30", "author": "@rmaestrem"}, "1011727605408514048": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "2,670", "datetime": "2018-06-26 21:47:12", "author": "@ayirpelle"}, "1011608284728446977": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "83", "datetime": "2018-06-26 13:53:04", "author": "@san6ee9"}, "1011912875005259776": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "294", "datetime": "2018-06-27 10:03:24", "author": "@rose_miura"}, "1018079611538853888": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "209", "datetime": "2018-07-14 10:27:49", "author": "@DrOtudi"}, "1011469423012532224": {"content_summary": "RT @Miles_Brundage: \"DARTS: Differentiable Architecture Search,\" Liu et al.: https://t.co/qixqxtY8BN", "followers": "218", "datetime": "2018-06-26 04:41:17", "author": "@AssistedEvolve"}, "1011820693749751808": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "279", "datetime": "2018-06-27 03:57:06", "author": "@QuantScientist"}, "1106262421956521985": {"content_summary": "Differentiable representation of neural network architecture \u2192 use gradient descent to find an architecture that can be trained with gradient descent https://t.co/aP4a3ntJM0", "followers": "8", "datetime": "2019-03-14 18:34:49", "author": "@chkno"}, "1012094728387604480": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "103", "datetime": "2018-06-27 22:06:01", "author": "@avmoldovan"}, "1011891112586424321": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "112", "datetime": "2018-06-27 08:36:55", "author": "@RohanSaphal"}, "1011845108235268096": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,443", "datetime": "2018-06-27 05:34:07", "author": "@qevni"}, "1011757617352343552": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "2,670", "datetime": "2018-06-26 23:46:28", "author": "@ayirpelle"}, "1011722630418845696": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "28,418", "datetime": "2018-06-26 21:27:26", "author": "@ogrisel"}, "1011597993106173953": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "178", "datetime": "2018-06-26 13:12:10", "author": "@drdeanjones"}, "1011623245945102336": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "65", "datetime": "2018-06-26 14:52:31", "author": "@russell_lliu"}, "1011884605052317696": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "45", "datetime": "2018-06-27 08:11:04", "author": "@lrsobrien"}, "1011812143405002752": {"content_summary": "nice nice very nice\ud83e\udd14 https://t.co/aAxPQqA7u8", "followers": "21", "datetime": "2018-06-27 03:23:08", "author": "@luoyuchu"}, "1012627818700681216": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "4,019", "datetime": "2018-06-29 09:24:20", "author": "@ballforest"}, "1012310611106021384": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "9", "datetime": "2018-06-28 12:23:52", "author": "@jason_han214"}, "1011991979280957440": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "427", "datetime": "2018-06-27 15:17:44", "author": "@jp_axs4ll"}, "1011949749174460416": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "829", "datetime": "2018-06-27 12:29:55", "author": "@marielacerrada"}, "1011579708453072897": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "722", "datetime": "2018-06-26 11:59:31", "author": "@GygliMichael"}, "1011860847704997888": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "615", "datetime": "2018-06-27 06:36:40", "author": "@KouroshMeshgi"}, "1011891983651045377": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "244", "datetime": "2018-06-27 08:40:23", "author": "@paulobousfield"}, "1012987903696408577": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "34", "datetime": "2018-06-30 09:15:11", "author": "@QuentinRendu"}, "1012950711745646592": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "463", "datetime": "2018-06-30 06:47:24", "author": "@jack_frost_will"}, "1011720358175502336": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "335", "datetime": "2018-06-26 21:18:24", "author": "@kobi78"}, "1011902846676037632": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "98", "datetime": "2018-06-27 09:23:33", "author": "@ngi644"}, "1012017477570703360": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "826", "datetime": "2018-06-27 16:59:03", "author": "@tangled_zans"}, "1011939159085379584": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "15", "datetime": "2018-06-27 11:47:51", "author": "@xvrtzn"}, "1011700630279409665": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "112", "datetime": "2018-06-26 20:00:01", "author": "@MSripadarao"}, "1011952367909199872": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "2,619", "datetime": "2018-06-27 12:40:20", "author": "@Tsundu_Mak"}, "1011847701447790592": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "48", "datetime": "2018-06-27 05:44:25", "author": "@jcupe17"}, "1012982129314189312": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,918", "datetime": "2018-06-30 08:52:14", "author": "@DocXavi"}, "1011885853717737472": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "340", "datetime": "2018-06-27 08:16:02", "author": "@Cedias_"}, "1011546455452966912": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "19", "datetime": "2018-06-26 09:47:23", "author": "@_keeeal"}, "1026879815675260930": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "1,331", "datetime": "2018-08-07 17:16:41", "author": "@GadioOumoul"}, "1115866662241275904": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "45", "datetime": "2019-04-10 06:38:38", "author": "@yoquankara"}, "1012960426588454912": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,139", "datetime": "2018-06-30 07:26:00", "author": "@BugbearR"}, "1011952197909860352": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "159,742", "datetime": "2018-06-27 12:39:39", "author": "@Montreal_IA"}, "1011891279028862976": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "120", "datetime": "2018-06-27 08:37:35", "author": "@andridns"}, "1011755880940015616": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "73", "datetime": "2018-06-26 23:39:34", "author": "@cdbockman"}, "1011659631851134976": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "1,020", "datetime": "2018-06-26 17:17:06", "author": "@serrjoa"}, "1011978173578264577": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "91", "datetime": "2018-06-27 14:22:52", "author": "@yutajuly"}, "1012006826555011073": {"content_summary": "RT @jeremyphoward: This looks quite encouraging. Still some room for improvement in the results, but a good direction for Neural Architectu\u2026", "followers": "193", "datetime": "2018-06-27 16:16:44", "author": "@arshak"}, "1012923949439578112": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,515", "datetime": "2018-06-30 05:01:03", "author": "@jo7ueb"}, "1011735422089613312": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "886", "datetime": "2018-06-26 22:18:16", "author": "@annajafarpour"}, "1011674822215118849": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "52", "datetime": "2018-06-26 18:17:28", "author": "@r_lepert"}, "1011545674830237696": {"content_summary": "RT @Miles_Brundage: \"DARTS: Differentiable Architecture Search,\" Liu et al.: https://t.co/qixqxtY8BN", "followers": "4,812", "datetime": "2018-06-26 09:44:17", "author": "@IntuitMachine"}, "1011922064330985472": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "42", "datetime": "2018-06-27 10:39:55", "author": "@AliBaghernezhad"}, "1011587675403370496": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "3,265", "datetime": "2018-06-26 12:31:10", "author": "@ymym3412"}, "1012035900799406080": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "5,017", "datetime": "2018-06-27 18:12:16", "author": "@Clive_G_Brown"}, "1012535908606726144": {"content_summary": "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u5404\u51e6\u7406\u306e\u7d50\u679c\u306b\u304b\u3051\u308b\u91cd\u307f\u306b\u306a\u3063\u3066\u3044\u308b\u3002 https://t.co/TU1la7PlHC", "followers": "11,462", "datetime": "2018-06-29 03:19:07", "author": "@icoxfog417"}, "1011853396335136768": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "186", "datetime": "2018-06-27 06:07:03", "author": "@surangasms01"}, "1012324863162441728": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "765", "datetime": "2018-06-28 13:20:30", "author": "@whyboris"}, "1011754525844049920": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "395", "datetime": "2018-06-26 23:34:11", "author": "@linkoffate"}, "1011661418838536197": {"content_summary": "Very interesting work on architecture search! https://t.co/vU64ZfSPOX", "followers": "233", "datetime": "2018-06-26 17:24:12", "author": "@tsp_thomas"}, "1011691864406147072": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "106", "datetime": "2018-06-26 19:25:11", "author": "@_jruales"}, "1011762869434658816": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "14", "datetime": "2018-06-27 00:07:20", "author": "@ZhaiAndrew"}, "1012637080906694657": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "353", "datetime": "2018-06-29 10:01:08", "author": "@hrnbskgc"}, "1011798206525534208": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "182", "datetime": "2018-06-27 02:27:45", "author": "@NilayShri"}, "1012009380638650369": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "14", "datetime": "2018-06-27 16:26:53", "author": "@HARSH_306"}, "1011826979367260165": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "274", "datetime": "2018-06-27 04:22:05", "author": "@cghosh_"}, "1011781700827967488": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "80", "datetime": "2018-06-27 01:22:10", "author": "@Alexhein"}, "1012575388302639104": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "2,067", "datetime": "2018-06-29 05:55:59", "author": "@yo_ehara"}, "1012594286309920768": {"content_summary": "Amazing to see this softmax strategy work. Comparing it to the equally efficient, RL-based ENAS it seems that the key factor might not be following gradients to be more sample efficient, but to reuse learned parameters, which this method does naturally and", "followers": "1,119", "datetime": "2018-06-29 07:11:05", "author": "@eric_brachmann"}, "1011958896338956291": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "233", "datetime": "2018-06-27 13:06:16", "author": "@bamboo4031"}, "1011599282401677321": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "354", "datetime": "2018-06-26 13:17:18", "author": "@indy9000"}, "1012924930847997952": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "13", "datetime": "2018-06-30 05:04:57", "author": "@Ricky_A_Ng"}, "1017618318340034560": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "203", "datetime": "2018-07-13 03:54:48", "author": "@gibranfp"}, "1014354852044894208": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "660", "datetime": "2018-07-04 03:46:57", "author": "@Zephyros225"}, "1012959906989854720": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "19", "datetime": "2018-06-30 07:23:56", "author": "@bharadwajymg"}, "1012905170340962304": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,563", "datetime": "2018-06-30 03:46:26", "author": "@KASServerTF2"}, "1011934988001005568": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "232", "datetime": "2018-06-27 11:31:16", "author": "@GhadaOsaimi"}, "1070444352089010179": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,061", "datetime": "2018-12-05 22:26:36", "author": "@mvaldenegro"}, "1011717868625580034": {"content_summary": "RT @tarantulae: Very cool approach for relaxing the categorical choice of operations. DARTS (https://t.co/wgWwQ9QRCe). https://t.co/ozKSxtl\u2026", "followers": "309", "datetime": "2018-06-26 21:08:31", "author": "@Daniel_J_Im"}, "1011635357102804993": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "1,451", "datetime": "2018-06-26 15:40:39", "author": "@smllmp"}, "1011821136697544704": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "258", "datetime": "2018-06-27 03:58:52", "author": "@PositiveExist"}, "1014003758429343744": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "37", "datetime": "2018-07-03 04:31:49", "author": "@cometyang"}, "1011821310408843269": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "2,340", "datetime": "2018-06-27 03:59:33", "author": "@im2b"}, "1011571344981594112": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "2,813", "datetime": "2018-06-26 11:26:17", "author": "@CSProfKGD"}, "1011788354323714048": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "15", "datetime": "2018-06-27 01:48:36", "author": "@FelipeTorresVan"}, "1012231628490358784": {"content_summary": "RT @DeepMindAI: DARTS: Differentiable Architecture Search https://t.co/zuuvnFprEf", "followers": "234", "datetime": "2018-06-28 07:10:01", "author": "@iamsiddhantsahu"}, "1011921261155504128": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "528", "datetime": "2018-06-27 10:36:43", "author": "@kauaguilar"}, "1012888277748146177": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "220", "datetime": "2018-06-30 02:39:18", "author": "@eiichisugiyama1"}, "1011893938926440448": {"content_summary": "RT @hillbig: \u5f93\u6765\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u63a2\u7d22\u306f\u52fe\u914d\u3092\u5fc5\u8981\u3068\u3057\u306a\u3044\u5f37\u5316\u5b66\u7fd2\u3084GA\u304c\u4f7f\u308f\u308c\u3066\u3044\u305f\u304c\u3001\u5404\u30e6\u30cb\u30c3\u30c8\u3067softmax\u3067\u3069\u306e\u64cd\u4f5c\u3092\u9078\u629e\u3059\u308b\u304b\u3092\u6c7a\u3081\u3001SGD\u3067\u306e1\u30b9\u30c6\u30c3\u30d7\u66f4\u65b0\u5f8c\u3092\u76ee\u6a19\u306b\u69cb\u9020\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u9069\u5316\u3059\u308b\u3053\u3068\u3067\u3001\u52fe\u914d\u3092\u4f7f\u3063\u305f\u52b9\u7387\u7684\u306a\u69cb\u9020\u63a2\u7d22\u304c\u5b9f\u73fe\u3067\u304d\u308b htt\u2026", "followers": "917", "datetime": "2018-06-27 08:48:09", "author": "@chronologic1"}, "1011753839987445766": {"content_summary": "Darts: Differentiable architecture search for convolutional and recurrent networks https://t.co/3rKmoapMeO #Python", "followers": "98", "datetime": "2018-06-26 23:31:27", "author": "@JekiCode"}, "1011843439942565889": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "545", "datetime": "2018-06-27 05:27:29", "author": "@nicolarohrseitz"}, "1011687310927286273": {"content_summary": "RT @dosei_sanga: DARTS: Differentiable Architecture Search https://t.co/VkwsTL98mj NASNet\u306e\u3088\u3046\u306a\u5f37\u5316\u5b66\u7fd2\u3067\u3082\u3001AmoebaNet\u306e\u3088\u3046\u306a\u9032\u5316\u578b\u8a08\u7b97\u3067\u3082\u306a\u3044\u3001\u5fae\u5206\u53ef\u80fd\u306a\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u69cb\u9020\u2026", "followers": "1,044", "datetime": "2018-06-26 19:07:05", "author": "@ysaito8015"}, "1011822961299460101": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "293", "datetime": "2018-06-27 04:06:07", "author": "@RickGalbo"}, "1013601126967439361": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "94", "datetime": "2018-07-02 01:51:55", "author": "@ozlhubby"}, "1011941860351397888": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "52", "datetime": "2018-06-27 11:58:35", "author": "@jccalvojackson"}, "1011835816300175361": {"content_summary": "RT @Reza_Zadeh: Efficient Neural Network Architecture Search, main idea: Softmax over \"operations\", such as convolution, max pooling, & zer\u2026", "followers": "11,242", "datetime": "2018-06-27 04:57:12", "author": "@damienclzl"}, "1011822660563689472": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "54", "datetime": "2018-06-27 04:04:55", "author": "@drorhilman"}, "1011541413140418565": {"content_summary": "@theshelfist https://t.co/UVvahEG0ML", "followers": "3,888", "datetime": "2018-06-26 09:27:21", "author": "@TheShelfist"}, "1011426909740298240": {"content_summary": "DARTS: Differentiable Architecture Search. Hanxiao Liu, Karen Simonyan, and Yiming Yang https://t.co/r0FeJABDe9", "followers": "3,882", "datetime": "2018-06-26 01:52:21", "author": "@BrundageBot"}, "1011926826824839168": {"content_summary": "RT @OriolVinyalsML: Welcome back, gradients! This method is orders of magnitude faster than state-of-the-art non-differentiable techniques.\u2026", "followers": "31", "datetime": "2018-06-27 10:58:50", "author": "@sourajit1330101"}, "1011790210911350784": {"content_summary": "Fully differentiable architecture search! Liu et al. compute a softmax over operators and setup an approx alternating gradient descent optimization of weights and architectures. Excited about the continued improvements in architecture search efficiency", "followers": "3,452", "datetime": "2018-06-27 01:55:59", "author": "@LiamFedus"}, "1012642044223733760": {"content_summary": "RT @icoxfog417: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\u63a2\u7d22\u3092\u52fe\u914d\u6cd5\u3067\u5b66\u7fd2\u3059\u308b\u624b\u6cd5(\u5b9f\u8cea\u7684\u306b\u306f\u69cb\u9020\u5168\u4f53\u3067\u306a\u304f\u30bb\u30eb\u69cb\u9020\u306e\u63a2\u7d22)\u3002\u30ce\u30fc\u30c9\u3092\u3064\u306a\u3050\u51e6\u7406\u306e\u9078\u629e\u78ba\u7387\u3068(\u30ce\u30fc\u30c9\u6570\u306f\u4e8b\u524d\u306b\u6c7a\u3081\u308b)\u3001\u51e6\u7406\u306b\u4f7f\u7528\u3059\u308b\u91cd\u307f\u3092\u4ea4\u4e92\u306b\u5b66\u7fd2\u3057\u3066\u3044\u304f\u3002\u300c\u51e6\u7406\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u306e\u306f\u5fae\u5206\u4e0d\u53ef\u80fd\u306a\u306e\u3067\u3001\u5b9f\u8cea\u7684\u306b\u306f\u2026", "followers": "225", "datetime": "2018-06-29 10:20:51", "author": "@ElectronNest"}, "1012588238882549760": {"content_summary": "RT @ss_shopetan: \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a71\uff0e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u69cb\u9020\u3092\u5fae\u5206\u53ef\u80fd\u306a\u554f\u984c\u306b\u5b9a\u5f0f\u5316\u3059\u308b\u3053\u3068\u3067\u52fe\u914d\u964d\u4e0b\u3092\u7528\u3044\u305f\u52b9\u7387\u7684\u306a\u63a2\u7d22\u304c\u53ef\u80fd\uff0e\u65e2\u5b58\u624b\u6cd5\u3067\u306f\u6570\u767e\u304b\u3089\u6570\u5343\u306eGPU\u304c\u5fc5\u8981\u3060\u3063\u305f\u304c\uff0c\u3053\u308c\u3089\u306e\u624b\u6cd5\u306b\u5339\u6575(\u3042\u308b\u3044\u306f\u51cc\u99d5)\u3059\u308b\u7d50\u679c\u3092\u6570\u53f0\u306eGPU\u2026", "followers": "1,263", "datetime": "2018-06-29 06:47:03", "author": "@emaxser"}, "1011565138409734145": {"content_summary": "RT @StatMLPapers: DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG]) https://t.co/ZWtzZkipuF", "followers": "243", "datetime": "2018-06-26 11:01:37", "author": "@karthiknrao"}, "1011742584191029248": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "301", "datetime": "2018-06-26 22:46:43", "author": "@PistonDeveloper"}, "1011871241404321792": {"content_summary": "RT @PyTorch: \"remarkable architecture search efficiency (with 4 GPUs: 2.83% error on CIFAR10 in 1 day; 56.1 perplexity on PTB in 6 hours)\"\u2026", "followers": "14", "datetime": "2018-06-27 07:17:58", "author": "@whatmeigel"}, "1011618701055934464": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "140", "datetime": "2018-06-26 14:34:27", "author": "@GrovesJohn"}, "1011651318308638721": {"content_summary": "RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang. They operate on a continuous relax\u2026", "followers": "344", "datetime": "2018-06-26 16:44:04", "author": "@jefkine"}}}