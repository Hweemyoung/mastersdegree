{"tab": "twitter", "completed": "1", "twitter": {"1112968263225401345": {"author": "@KouroshMeshgi", "followers": "622", "datetime": "2019-04-02 06:41:26", "content_summary": "RT @heuritechlab: \"Continual Learning via Neural Pruning\": Learning an increasing number of tasks, while keep a fixed model capacity. The a\u2026"}, "1110878141117952000": {"author": "@ElectronNest", "followers": "231", "datetime": "2019-03-27 12:16:02", "content_summary": "\"Continual Learning via Neural Pruning\" https://t.co/KV4PTNuHJN"}, "1112957941127278592": {"author": "@heuritechlab", "followers": "146", "datetime": "2019-04-02 06:00:25", "content_summary": "\"Continual Learning via Neural Pruning\": Learning an increasing number of tasks, while keep a fixed model capacity. The algo uses sparsification with a L1 regularization & pruning to keep a subset of weights for each tasks. See Lottery Ticket Hypothesi"}, "1105487250710777856": {"author": "@TusharJain_007", "followers": "123", "datetime": "2019-03-12 15:14:34", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1107984505275666434": {"author": "@Michael_A_Kagan", "followers": "532", "datetime": "2019-03-19 12:37:46", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1105377088054353920": {"author": "@kchonyc", "followers": "24,295", "datetime": "2019-03-12 07:56:49", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1107999506480721920": {"author": "@mrdrozdov", "followers": "877", "datetime": "2019-03-19 13:37:22", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1105310421626564613": {"author": "@arxivml", "followers": "787", "datetime": "2019-03-12 03:31:54", "content_summary": "\"Continual Learning via Neural Pruning\", Siavash Golkar, Michael Kagan, Kyunghyun Cho https://t.co/7jGPzZThOO"}, "1105395812194873345": {"author": "@namhoonlee09", "followers": "178", "datetime": "2019-03-12 09:11:13", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1105284339934347264": {"author": "@BrundageBot", "followers": "3,913", "datetime": "2019-03-12 01:48:16", "content_summary": "Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1108167814060244994": {"author": "@treasured_write", "followers": "101", "datetime": "2019-03-20 00:46:10", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1105618693613121536": {"author": "@Eschersand", "followers": "748", "datetime": "2019-03-12 23:56:52", "content_summary": "we formalize and incorporate the concept of graceful forgetting: the idea that it is preferable to suffer a small amount of forgetting in a controlled manner if it helps regain network capacity and prevents uncontrolled loss of performance during the train"}, "1105378508660912128": {"author": "@shilpa15397", "followers": "100", "datetime": "2019-03-12 08:02:28", "content_summary": "Very interesting ideas in this paper! Addresses a lot of issues with static learning models that we have today. Looking forward to seeing applications https://t.co/0SJCouqgMp"}, "1105387447792386053": {"author": "@kudkudakpl", "followers": "820", "datetime": "2019-03-12 08:37:59", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1113001011680104450": {"author": "@Ar_Douillard", "followers": "285", "datetime": "2019-04-02 08:51:34", "content_summary": "RT @heuritechlab: \"Continual Learning via Neural Pruning\": Learning an increasing number of tasks, while keep a fixed model capacity. The a\u2026"}, "1107989541254844417": {"author": "@glouppe", "followers": "6,130", "datetime": "2019-03-19 12:57:46", "content_summary": "RT @BrundageBot: Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/fRir6VQbZb"}, "1105588525938941953": {"author": "@JMAi1729", "followers": "4", "datetime": "2019-03-12 21:57:00", "content_summary": "https://t.co/0zQzxDK6By"}, "1105807132430139398": {"author": "@arxiv_cs_LG", "followers": "322", "datetime": "2019-03-13 12:25:39", "content_summary": "Continual Learning via Neural Pruning. Siavash Golkar, Michael Kagan, and Kyunghyun Cho https://t.co/FBsAaBDcvp"}}, "citation_id": "56869995", "queriedAt": "2020-06-04 00:25:15"}