{"completed": "1", "tab": "twitter", "queriedAt": "2020-05-21 18:20:48", "citation_id": "53430276", "twitter": {"1081752022834208769": {"followers": "1,260", "author": "@mlmemoirs", "datetime": "2019-01-06 03:19:14", "content_summary": "#arXiv #machinelearning [cs.LG] Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/3hvWZMvkhL Adversarial examples are delicately perturbed inputs, which aim to mislead machine learning models towards incorrect outputs. While"}, "1081068109048492032": {"followers": "777", "author": "@arxivml", "datetime": "2019-01-04 06:01:37", "content_summary": "\"Multi-Label Adversarial Perturbations\", Qingquan Song, Haifeng Jin, Xiao Huang, Xia Hu https://t.co/hsFSy6dAiN"}, "1082101151363936258": {"followers": "5,317", "author": "@HubBucket", "datetime": "2019-01-07 02:26:33", "content_summary": "RT @arxiv_org: Multi-Label Adversarial Perturbations. https://t.co/MFXNet78Ms https://t.co/0zFnYMFBq8"}, "1081883202732650498": {"followers": "2,136", "author": "@theChrisChua", "datetime": "2019-01-06 12:00:30", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/MZBJqFtKq4\u2026"}, "1081027248826826752": {"followers": "49", "author": "@yapp1e", "datetime": "2019-01-04 03:19:15", "content_summary": "Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/dVQ3Y4X10R Adversarial examples are delicately perturbed inputs, which aim to mislead machine learning models towards incorrect outputs. While most of the existing work focus"}, "1081858232627412992": {"followers": "1,348", "author": "@udmrzn", "datetime": "2019-01-06 10:21:17", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/MZBJqFtKq4\u2026"}, "1081001345090506752": {"followers": "9,706", "author": "@StatMLPapers", "datetime": "2019-01-04 01:36:19", "content_summary": "Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/kLUFBJ8vsf"}, "1081016176833105920": {"followers": "858", "author": "@deep_rl", "datetime": "2019-01-04 02:35:15", "content_summary": "Multi-Label Adversarial Perturbations - Qingquan Song https://t.co/LoFPnk21QS"}, "1081019328106037249": {"followers": "3,890", "author": "@BrundageBot", "datetime": "2019-01-04 02:47:46", "content_summary": "Multi-Label Adversarial Perturbations. Qingquan Song, Haifeng Jin, Xiao Huang, and Xia Hu https://t.co/lCROx5Ki3G"}, "1081160869503918081": {"followers": "186", "author": "@SagarSharma4244", "datetime": "2019-01-04 12:10:12", "content_summary": "RT @arxiv_org: Multi-Label Adversarial Perturbations. https://t.co/MFXNet78Ms https://t.co/0zFnYMFBq8"}, "1081158658619105280": {"followers": "12,758", "author": "@arxiv_org", "datetime": "2019-01-04 12:01:25", "content_summary": "Multi-Label Adversarial Perturbations. https://t.co/MFXNet78Ms https://t.co/0zFnYMFBq8"}, "1081035702870040576": {"followers": "5,454", "author": "@StatsPapers", "datetime": "2019-01-04 03:52:50", "content_summary": "Multi-Label Adversarial Perturbations. https://t.co/UAxP7WQT2V"}, "1081746712690081793": {"followers": "1,743", "author": "@arXiv__ml", "datetime": "2019-01-06 02:58:08", "content_summary": "#arXiv #machinelearning [cs.LG] Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/MZBJqFtKq4 Adversarial examples are delicately perturbed inputs, which aim to mislead machine learning models towards incorrect outputs. While"}, "1081752407661518849": {"followers": "8,280", "author": "@SantchiWeb", "datetime": "2019-01-06 03:20:46", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/MZBJqFtKq4\u2026"}, "1081883135359340546": {"followers": "1,341", "author": "@Apurba3110", "datetime": "2019-01-06 12:00:14", "content_summary": "RT @arXiv__ml: #arXiv #machinelearning [cs.LG] Multi-Label Adversarial Perturbations. (arXiv:1901.00546v1 [cs.LG]) https://t.co/MZBJqFtKq4\u2026"}, "1081013688482578433": {"followers": "5,454", "author": "@StatsPapers", "datetime": "2019-01-04 02:25:22", "content_summary": "Multi-Label Adversarial Perturbations. https://t.co/UAxP7X8urv"}}}