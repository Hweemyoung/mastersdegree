[{"items": [{"snippet": {"channelId": "UCKKEHuAGzwVtIEIFW3cZOPg", "tags": ["debt nation", "debtnation", "transhumanism", "transhumanist", "Douglas Rushkof", "Rethinking Transhumanism", "Ray Kurzweil", "artificial intelligence", "singularity", "futurism", "nanotechnology", "robotics", "biotechnology", "What is Transhumanism", "becoming robots"], "description": "CHECK OUT SEASON 1 PLAYLIST: https://www.youtube.com/watch?v=ic9AV4mMbOQ&list=PL_GIV9cvJ8b-F1QTPzFZVAitbMC34bPF- \n\nKEEP THE SHOW ON-AIR! : WWW.PATREON.COM/DEBTNATION \n\n\u2022 PLEASE CHECK OUR SPONSOR: WWW.IAMTRANSHUMAN.ORG/ \n\n\u2022  LINK TO BOOK: https://www.amazon.com/Transhumanism-Handbook-Newton-Lee/dp/3030169197?fbclid=IwAR06yPT-iFo6C98i-7uG1tbbOCTbVcJdUWqXPjxZR0GU1oqnrNbjPDU2fpU\n...\nIN THIS EPISODE:\n\n\u2022 Foresight AI Fellow Page: \nPeter Ecklersky's paper on AI Ethics and AI Safety: \nhttps://arxiv.org/abs/1901.00064\n\n\u2022 Dan Elton's preprint: \"Self-explaining AI as an alternative to interpretable AI\"\nhttps://arxiv.org/abs/2002.05149\n\n\u2022 Message Dan on facebook: \nhttps://www.facebook.com/Daniel.Elton\n\n\u2022 Follow Dan on Twitter: \nhttps://twitter.com/moreisdifferent\n\n\u2022 https://foresight.org/fellowship-class-of-2020/\n\n....\n\nThis episode of Debt Nation is sponsored by Thrivous, the human enhancement company (https://thrivous.com). Thrivous develops and distributes advanced nootropic and geroprotector dietary supplements, to enhance cognition and promote healthy aging. Each nutrient and each dose is based on multiple human studies. And all quality control is completely open source.\n\nThrivous is giving an exponential gift to one randomly-selected person who shares this episode of Debt Nation. The value of the gift increases exponentially as more people share this episode.\n\n\u2022 If 1 person shares this episode, the gift is worth $5.\n\u2022 If 2 or 3 people share this episode, the gift is worth $10.\n\u2022 If 4 to 7 people share this episode, the gift is worth $20.\n\u2022 If 8 to 15 people share this episode, the gift is worth $40.\n\u2022 If 16 to 31 people share this episode, the gift is worth $80.\n\u2022 If 32 or more people share this episode, the gift is worth $160.\n\nTo qualify, you must share this episode of Debt Nation according to these rules:\n\n1) Share a post on Facebook, Twitter, LinkedIn, Pinterest, or Instagram.\n2) The post must be public.\n3) The post must include a direct link to this episode on YouTube.\n4) The post must include a REAL comment about this episode (no spam).\n5) The post must tag and thank Thrivous for sponsoring this episode.\n6) Share the post within 24 hours of the publication of this episode.\n\nTo ensure that we see the post that you share, we recommend that you also post a comment here on YouTube. Make sure to include a REAL comment about this episode (no spam). And include a link to the post that you shared on social media. This is optional.\n\nWe reserve the right to ignore any shares, posts, and comments that we consider spam. So please comment thoughtfully about this episode of Debt Nation.\n\nAfter 24 hours have passed, Thrivous will select a random winner from among people who shared this episode. Thrivous will announce the winner in the comments on this episode. The gift will be in the form of credit at Thrivous. And the winner must contact Thrivous (support@thrivous.com) within 7 days to claim the credit.\n\nThanks for watching Debt Nation!", "title": "AI SAFETY / DR.DAN ELTON 221. DEBT NATION", "channelTitle": "Debt Nation", "publishedAt": "2020-04-14T02:38:18Z"}, "contentDetails": {"duration": "PT47M12S"}, "id": "TN9lybsLYG4", "statistics": {"dislikeCount": "0", "likeCount": "13", "viewCount": "102", "commentCount": "3", "favoriteCount": "0"}}], "idx_paper": 1, "q": "arxiv.org/abs/1901.00064"}, {"items": [{"snippet": {"channelId": "UChOZWexCwxgpcz_rAU1QNaA", "tags": ["Obstacle Tower", "COG 2019", "Reinforcement Learning", "PPO"], "description": "This video elaborates the taken approach and the achieved results to reach the seventh place in the Obstacle Tower Challenge. This video is a submission to the IEEE CoG 2019 Short Video Competition.\n\n\nCredits:\n\nA. Juliani, A. Khalifa, V. Berges, J. Harper, E. Teng, H. Henry, A. Crespi, J. Togelius, D. Lange (2019). Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning.\nhttps://arxiv.org/abs/1902.01378\n\nA. Nichol (2019). Prierarchy: Implicit Hierarchies. https://blog.aqnichol.com/2019/04/03/prierarchy-implicit-hierarchies/\n\nObstacle Tower Challenge\nhttps://www.aicrowd.com/challenges/unity-obstacle-tower-challenge\n\nMusic: https://www.bensound.com\n\n\nAlso check out my CoG 2019 paper:\nM. Pleines, F. Zimmer, V. Berges (2019). Action Spaces in Deep Reinforcement Learning to Mimic Human Input Devices. https://ieeexplore.ieee.org/document/8848080", "title": "Rising to the Obstacle Tower Challenge - IEEE CoG 2019 Short Video Competition", "channelTitle": "Marco Pleines", "publishedAt": "2019-08-09T10:09:32Z"}, "contentDetails": {"duration": "PT4M59S"}, "id": "P2rBDHBHxcM", "statistics": {"dislikeCount": "0", "likeCount": "29", "viewCount": "389", "commentCount": "3", "favoriteCount": "0"}}], "idx_paper": 54, "q": "arxiv.org/abs/1902.01378"}, {"items": [{"snippet": {"channelId": "UCCEKLgJ4Rc2fMebAq4hdgHg", "title": "DREAMR - Supplementary Video", "channelTitle": "SISL", "publishedAt": "2019-02-10T01:40:48Z", "description": "Accompanying video for the paper \"Dynamic Real-time Multimodal Routing with Hierarchical Hybrid Planning\" - https://arxiv.org/abs/1902.01560"}, "contentDetails": {"duration": "PT1M44S"}, "id": "e5IcB79TEXY", "statistics": {"viewCount": "275", "favoriteCount": "0"}}], "idx_paper": 58, "q": "arxiv.org/abs/1902.01560"}, {"items": [{"snippet": {"channelId": "UC1H1NWNTG2Xi3pt85ykVSHA", "defaultLanguage": "en", "tags": ["machine learning", "artificial intelligence", "reproducibility", "ai", "ml", "computer science"], "description": "Turns out that reproducing other people\u2019s results is hard. \n\nBecome a Patron! http://www.patreon.com/everydAI\n\nThank you to Jeff, Gerald, Milan, Ian, Becky, Jino, Daniel, Narskogr, Jason, and Mariano for being $5+/month Patrons!\n\nFollow me on Twitter! http://twitter.com/jordanbharrod\n\neverydAI is a YouTube channel focused on highlighting the ways we interact with artificial intelligence every day. \n\nSources: \n\nArtificial Intelligence Confronts a Reproducibility Crisis (WIRED) - https://www.wired.com/story/artificial-intelligence-confronts-reproducibility-crisis/\n\nArtificial intelligence faces reproducibility crisis (Nature, $$) - https://science.sciencemag.org/content/359/6377/725\n\nOn Reproducible AI: Towards Reproducible Research, Open Science, and Digital Scholarship in AI Publications - https://www.isi.edu/~gil/papers/gundersen-etal-aimagazine18.pdf\n\nWinner\u2019s Curse (Googla AI, ICLR) - https://openreview.net/references/pdf?id=HyT0zqkwG\n\nClosing the AI Knowledge Gap (MIT Media Lab, pre-print): https://arxiv.org/abs/1803.07233\n\nThe Reproducibility Crisis and Why It\u2019s Bad For AI (Towards Data Science) - https://towardsdatascience.com/the-reproducibility-crisis-and-why-its-bad-for-ai-c8179b0f5d38\n\n1500 scientists lift the lid on reproducibility (Nature) - https://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970\nNeurIPS Reproducibility Checklist (NeurIPS/McGill) - https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf\n\nShow Your Work: Improved Reporting of Experimental Results (Carnegie Mellon/Allen Institute, preprint) - https://arxiv.org/abs/1909.03004\n\nELF OpenGo: An Analysis and Open Reimplementation of AlphaZero (Facebook) - https://arxiv.org/abs/1902.04522\n\nLet\u2019s Play Again: Variability of Deep Reinforcement Learning Agents in Atari Environments - https://arxiv.org/pdf/1904.06312.pdf", "defaultAudioLanguage": "en", "title": "Is AI Facing A Reproducibility Crisis?", "channelTitle": "Jordan Harrod", "publishedAt": "2019-11-02T00:18:30Z"}, "contentDetails": {"duration": "PT7M59S"}, "id": "fNpWMlGL3Ys", "statistics": {"dislikeCount": "1", "likeCount": "123", "viewCount": "813", "commentCount": "32", "favoriteCount": "0"}}], "idx_paper": 122, "q": "arxiv.org/abs/1902.04522"}, {"items": [{"snippet": {"channelId": "UCYztb8yVDT02TyeKoMiL6kg", "title": "Lecture by Robert Kleinberg & Devon Graham (CS 159 Spring 2020)", "channelTitle": "Yisong Yue", "publishedAt": "2020-05-28T07:38:45Z", "description": "Structured Procrastination for Automated Algorithm Design.\n(With obligatory technical difficulty!)\n\nRelevant Papers:\nhttps://www.ijcai.org/Proceedings/2017/0281.pdf\nhttps://arxiv.org/abs/1902.05454\n\nSlides:\nhttps://drive.google.com/file/d/1_ickBy_KbNuUDTFvfHwx-nqhggyLgaxb/view?usp=sharing\nhttps://drive.google.com/file/d/1YtnaMzoM77m7q1KTvaw4in8lytHKnR8V/view?usp=sharing\n\nCourse:\nhttps://sites.google.com/view/cs-159-spring-2020/"}, "contentDetails": {"duration": "PT1H35M36S"}, "id": "WzirK392vAo", "statistics": {"dislikeCount": "0", "likeCount": "3", "viewCount": "126", "commentCount": "1", "favoriteCount": "0"}}], "idx_paper": 132, "q": "arxiv.org/abs/1902.05454"}, {"items": [{"snippet": {"channelId": "UCe7xz-EVulSSg_-QSA3a-YQ", "tags": ["AI", "IJCAI", "ai alignment", "impact", "side effects", "ai safety"], "description": "It's hard to ask an AI to do exactly what we want. Can we design them so that disaster doesn't ensue, even if we ask for the wrong thing? I think so, and this lovingly illustrated presentation explains why.\n\nPresented at IJCAI 2019 AISafety Workshop. Read more at https://arxiv.org/abs/1902.09725.", "defaultAudioLanguage": "en", "title": "Conservative Agency", "channelTitle": "Alex Turner", "publishedAt": "2019-08-26T04:05:11Z"}, "contentDetails": {"duration": "PT9M14S"}, "id": "-5IyNrh8Dgc", "statistics": {"dislikeCount": "0", "likeCount": "1", "viewCount": "45", "commentCount": "0", "favoriteCount": "0"}}], "idx_paper": 181, "q": "arxiv.org/abs/1902.09725"}, {"items": [{"snippet": {"channelId": "UCVxIwH78_3C26N5F_-AIIEg", "tags": ["Hexapod", "Spherical Robot", "LPZRobots", "Event cognition", "Behavioral primitives", "Cognitive Modeling", "Autonomous Learning"], "description": "Overview of our computational learning architecture, termed surprise-based behavioral modularization into event-predictive structures (SUBMODES). The SUBMODES system explores behavior, identifies the underlying behavioral primitives and transitions in behavior, and learns event-predictive models of behavioral primitives and behavior transitions completely from scratch.\n \nSensorimotor exploration is bootstrapped by applying differential extrinsic plasticity (DEP, more information: https://youtu.be/iIkcsR1HyN4). While exploring the behavioral capabilities of its own body, the system learns modular, compositional structures that predict the sensorimotor dynamics and generate the associated behavior. In line with recent theories of event perception, the system uses unexpected prediction error signals, i.e., surprise, to detect transitions between successive behavioral primitives. After intial exploration the SUBMODES system can use its learned models for goal-directed planning: When the system wants to reach a desired goal state, it uses its predictive encodings of behavior to 'imagine' how its state will change when performing a certain behavior and it activates the available behavioral primitive that brings the robot closest to its goal.\n\nLinks:\n- arXiv submission (https://arxiv.org/abs/1902.09948)\n- Cognitive Modeling Group, University of T\u00fcbingen (https://cm.inf.uni-tuebingen.de)\n- Autonomous Learning Group, Max Planck Institute for Intelligent Systems, T\u00fcbingen (https://al.is.tuebingen.mpg.de)\n- LPZRobots simulator (http://robot.informatik.uni-leipzig.de/software/)", "title": "SUBMODES- Exploring, Detecting, Encoding & Using Behavioral Primitives", "channelTitle": "CognitiveModeling", "publishedAt": "2019-03-27T12:17:39Z"}, "contentDetails": {"duration": "PT5M8S"}, "id": "QKQnecYjmTA", "statistics": {"dislikeCount": "0", "likeCount": "1", "viewCount": "85", "commentCount": "0", "favoriteCount": "0"}}], "idx_paper": 188, "q": "arxiv.org/abs/1902.09948"}, {"items": [{"snippet": {"channelId": "UCgl_MmjatQif8juz3Lt6iPw", "tags": ["Algorithm", "Beneficial", "Robust", "Artificial intelligence", "AI", "Machine learning", "Computer science", "Security", "Safety", "Ethics", "Philosophy"], "description": "Intelligent Autonomous Things on the Battlefield. AI for the Internet of Everything. A Kott and E Stump 19.\nhttps://arxiv.org/ftp/arxiv/papers/1902/1902.10086.pdf\n\nSlaughterbots. Future of life Institute 17.\nhttps://www.youtube.com/watch?v=HipTO_7mUOw\n\nThe Future of War, and How It Affects YOU (Multi-Domain Operations). Smarter Every Day 211.\nhttps://www.youtube.com/watch?v=qOTYgcdNrXE\n\nFind out more on the Robustly Beneficial Wiki:\nhttps://robustlybeneficial.org/wiki/index.php?title=Robustly_beneficial\nhttps://robustlybeneficial.org/wiki/index.php?title=Robust_statistics\n\nNext week's paper is about MuZero.\nMastering Atari, Go, Chess and Shogi by Planning with a Learned Model. SAHSS+20.\nhttps://arxiv.org/abs/1911.08265", "defaultAudioLanguage": "en", "title": "Can autonomous weapons be safe? #RB6", "channelTitle": "Robustly Beneficial", "publishedAt": "2020-02-21T13:45:59Z"}, "contentDetails": {"duration": "PT37M14S"}, "id": "gxwGkZeSg30", "statistics": {"dislikeCount": "0", "likeCount": "20", "viewCount": "649", "commentCount": "3", "favoriteCount": "0"}}], "idx_paper": 191, "q": "arxiv.org/abs/1902.10086"}, {"items": [{"snippet": {"channelId": "UC7CChC6wRPFtx_pdrEVGtJQ", "title": "Docherty Christopher 1155139798 - link to paper in description", "channelTitle": "thedoc99 _", "publishedAt": "2019-12-18T23:54:05Z", "description": "https://arxiv.org/abs/1903.00900"}, "contentDetails": {"duration": "PT4M34S"}, "id": "PGmb4e7aS7c", "statistics": {"dislikeCount": "0", "likeCount": "0", "viewCount": "2", "commentCount": "0", "favoriteCount": "0"}}], "idx_paper": 596, "q": "arxiv.org/abs/1903.00900"}, {"items": [{"snippet": {"channelId": "UCRKaDEaiZUwcsVFO5u5huaQ", "defaultLanguage": "en", "description": "The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation\nChih-Yao Ma, Zuxuan Wu, Ghassan AlRegib, Caiming Xiong, Zsolt Kira\nCVPR, 2019 (Oral)\n\narXiv: https://arxiv.org/abs/1903.01602\nGitHub: https://github.com/chihyaoma/regretful-agent\nProject: https://chihyaoma.github.io/project/2019/02/25/regretful.html", "defaultAudioLanguage": "en", "title": "CVPR 2019 (Oral) The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation", "channelTitle": "Kevin Chih-Yao Ma", "publishedAt": "2019-06-09T21:00:35Z"}, "contentDetails": {"duration": "PT4M47S"}, "id": "zN7HrtJ_nlc", "statistics": {"dislikeCount": "0", "likeCount": "1", "viewCount": "144", "commentCount": "2", "favoriteCount": "0"}}], "idx_paper": 601, "q": "arxiv.org/abs/1903.01602"}, {"items": [{"snippet": {"channelId": "UCJ84PeM97V3BCeaA9Wiqt7A", "title": "3D Simulation of the IPC rover domain", "channelTitle": "Mehrdad Zakershahrak", "publishedAt": "2019-07-31T20:35:08Z", "description": "This video is presented as a part of a study to human subjects for Online Explanation Generation in Human-Robot Teaming (https://arxiv.org/abs/1903.06418)."}, "contentDetails": {"duration": "PT1M31S"}, "id": "Ba_XXF-yuxk", "statistics": {"dislikeCount": "0", "likeCount": "1", "viewCount": "19", "commentCount": "0", "favoriteCount": "0"}}], "idx_paper": 656, "q": "arxiv.org/abs/1903.06418"}]